{
  "id": "42",
  "blame_commit": {
    "commit": {
      "commit_id": "5f42b953192febca773ebe45f2cf669993cfdfd1",
      "commit_message": "ENH: enable pivot_table with more complex aggregation function and hack multiple level column unstacking into existing hierarchical columns. close #2643",
      "commit_author": "Wes McKinney",
      "commit_date": "2013-01-05 14:51:25",
      "commit_parent": "077186518698eaa8407bb9bebe6262c71d324dae"
    },
    "function": {
      "function_name": "_unstack_multiple",
      "function_code_before": "",
      "function_code_after": "",
      "function_before_start_line": "",
      "function_before_end_line": "",
      "function_after_start_line": "",
      "function_after_end_line": "",
      "function_before_token_count": 0,
      "function_after_token_count": 0,
      "functions_name_modified_file": [
        "_long_prod",
        "_stack_multi_columns",
        "get_compressed_ids",
        "block2d_to_block3d",
        "get_new_columns",
        "unstack",
        "get_new_index",
        "pivot_simple",
        "lreshape",
        "_unstack_multiple",
        "get_new_values",
        "_make_selectors",
        "stack",
        "get_result",
        "_slow_pivot",
        "_unstack_frame",
        "convert_dummies",
        "melt",
        "block2d_to_blocknd",
        "__init__",
        "factor_indexer",
        "get_dummies",
        "pivot",
        "make_axis_dummies",
        "_make_sorted_values_labels"
      ],
      "functions_name_all_files": [
        "test_diff",
        "test_margins",
        "map",
        "_get_method",
        "format",
        "__or__",
        "test_getitem_group_select",
        "_stack_multi_columns",
        "test_get_level_number_integer",
        "test_join_inner",
        "swaplevel",
        "_ensure_index",
        "test_print_unicode_columns",
        "test_unicode_string_with_unicode",
        "_cleanup",
        "get_new_index",
        "_drop_from_level",
        "test_get_indexer_backfill",
        "test_getitem",
        "_get_names",
        "get_loc",
        "test_equals",
        "_has_complex_internals",
        "_wrap_joined_index",
        "test_cant_or_shouldnt_cast",
        "tolist",
        "stack",
        "order",
        "_handle_legacy_indexes",
        "test_iter",
        "dtype",
        "test_pass_function",
        "test_astype",
        "__new__",
        "test_intersection",
        "test_summary",
        "test_take",
        "test_get_set_value",
        "_shouldbe_timestamp",
        "_bounds",
        "test_is_numeric",
        "_engine",
        "test_tuple_union_bug",
        "unique",
        "test_slice_locs_dup",
        "test_pivot_no_level_overlap",
        "__getitem__",
        "melt",
        "setUp",
        "__init__",
        "test_slice_locs_not_contained",
        "test_crosstab_margins",
        "__sub__",
        "test_slice_locs_partial",
        "factor_indexer",
        "isin",
        "get_dummies",
        "test_get_loc_duplicates",
        "__setstate__",
        "_all_indexes_same",
        "_validate_join_method",
        "_get_distinct_indexes",
        "has_duplicates",
        "equal_levels",
        "is_numeric",
        "test_from_arrays",
        "diff",
        "_get_consensus_names",
        "test_slice_locs_not_sorted",
        "truncate",
        "test_contains",
        "test_from_tuples",
        "test_constructor",
        "get_compressed_ids",
        "test_is_monotonic_incomparable",
        "shift",
        "test_pivot_table_multiple",
        "test_add_string",
        "test_from_tuples_index_values",
        "_unstack_multiple",
        "get_level_values",
        "nlevels",
        "_maybe_box",
        "test_append_empty_preserve_name",
        "__bytes__",
        "get_new_values",
        "_trim_front",
        "argsort",
        "__contains__",
        "get_indexer",
        "_tuple_index",
        "test_compat",
        "test_join_level",
        "test_pivot_columns_lexsorted",
        "drop",
        "asof_locs",
        "_join_level",
        "test_append_multiple",
        "take",
        "_join_monotonic",
        "test_get_combined_index",
        "test_legacy_v2_unpickle",
        "test_take_preserve_name",
        "test_copy",
        "test_join_left",
        "from_arrays",
        "__reduce__",
        "__str__",
        "test_boolean_cmp",
        "test_comparators",
        "test_get_loc_level",
        "reorder_levels",
        "test_sortlevel_deterministic",
        "_get_level_number",
        "union",
        "_wrap_union_result",
        "test_new_axis",
        "test_join_non_unique",
        "holds_integer",
        "is_all_dates",
        "test_format_none",
        "test_union_noncomparable",
        "test_pivot_multi_functions",
        "inferred_type",
        "__len__",
        "test_get_indexer",
        "test_format_datetime_with_time",
        "test_constructor_corner",
        "make_axis_dummies",
        "test_crosstab_ndarray",
        "test_insert",
        "_shallow_copy",
        "test_shallow_copy",
        "astype",
        "groupby",
        "test_join_non_int_index",
        "asof",
        "_long_prod",
        "_is_v2",
        "is_monotonic",
        "_indexOp",
        "append",
        "_partial_tup_index",
        "test_droplevel_with_names",
        "test_format_sparse_display",
        "block2d_to_block3d",
        "get_new_columns",
        "unstack",
        "test_shift",
        "test_pivot_table",
        "_get_combined_index",
        "test_index_ctor_infer_periodindex",
        "is_lexsorted",
        "insert",
        "lreshape",
        "test_deepcopy",
        "test_legacy_pickle",
        "_sanitize_and_check",
        "test_pivot_integer_columns",
        "test_hash_error",
        "__hash__",
        "test_pivot_multi_values",
        "test_join_outer",
        "test_crosstab_single",
        "_possibly_promote",
        "_make_selectors",
        "get_loc_level",
        "test_mutability",
        "__unicode__",
        "_ensure_compat_concat",
        "__add__",
        "_slow_pivot",
        "_from_elements",
        "_check_method_works",
        "test_repr_summary",
        "test_reorder_levels",
        "test_dims",
        "levshape",
        "_array_values",
        "_union_indexes",
        "_unstack_frame",
        "__repr__",
        "test_get_level_values",
        "block2d_to_blocknd",
        "test_consistency",
        "test_coerce_list",
        "test_nlevels",
        "test_get_loc",
        "_assert_can_do_setop",
        "test_crosstab_multiple",
        "test_format",
        "__deepcopy__",
        "__array_finalize__",
        "is_type_compatible",
        "sortlevel",
        "test_slice_locs",
        "test_dtype",
        "pivot",
        "test_view_Index",
        "_mpl_repr",
        "test_get_indexer_pad",
        "__getslice__",
        "test_int_name_format",
        "__setitem__",
        "test_constructor_no_levels",
        "test_crosstab_pass_values",
        "_make_sorted_values_labels",
        "_get_level_indexer",
        "test_format_integer_names",
        "test_duplicates",
        "test_truncate",
        "test_sort",
        "test_duplicate_names",
        "lexsort_depth",
        "from_tuples",
        "test_format_sparse_config",
        "test_reindex_level",
        "test_pivot_complex_aggfunc",
        "test_bounds",
        "test_constructor_single_level",
        "_join_non_unique",
        "test_join_right",
        "reindex",
        "pivot_simple",
        "test_has_duplicates",
        "set_value",
        "equals",
        "test_bytestring_with_unicode",
        "test_asof",
        "__and__",
        "test_repr_with_unicode_data",
        "test_tolist",
        "get_duplicates",
        "is_unique",
        "__iter__",
        "test_add",
        "test_drop",
        "test_sortlevel",
        "intersection",
        "test_pass_array",
        "test_argsort",
        "to_datetime",
        "test_union",
        "test_is_monotonic",
        "get_result",
        "_is_v1",
        "test_isin",
        "_set_names",
        "test_pickle",
        "test_view",
        "test_intersect_str_dates",
        "get_value",
        "slice_locs",
        "_constructor",
        "test_reindex",
        "summary",
        "droplevel",
        "delete",
        "convert_dummies",
        "test_is_all_dates",
        "test_append",
        "values",
        "test_droplevel_multiple",
        "join",
        "test_booleanindex",
        "test_prevent_casting",
        "test_fancy",
        "test_format_with_name_time_info",
        "sort",
        "_sparsify"
      ],
      "functions_name_co_evolved_modified_file": [],
      "functions_name_co_evolved_all_files": [
        "test_get_level_values",
        "test_pivot_complex_aggfunc",
        "get_level_values"
      ]
    },
    "file": {
      "file_name": "reshape.py",
      "file_nloc": 490,
      "file_complexity": 120,
      "file_token_count": 4279,
      "file_before": "# pylint: disable=E1101,E1103\n# pylint: disable=W0703,W0622,W0613,W0201\n\nimport itertools\n\nimport numpy as np\n\nfrom pandas.core.series import Series\nfrom pandas.core.frame import DataFrame\n\nfrom pandas.core.categorical import Categorical\nfrom pandas.core.common import notnull, _ensure_platform_int\nfrom pandas.core.groupby import (get_group_index, _compress_group_index,\n                                 decons_group_index)\nimport pandas.core.common as com\nimport pandas.algos as algos\n\n\nfrom pandas.core.index import MultiIndex\n\n\nclass ReshapeError(Exception):\n    pass\n\n\nclass _Unstacker(object):\n    \"\"\"\n    Helper class to unstack data / pivot with multi-level index\n\n    Parameters\n    ----------\n    level : int or str, default last level\n        Level to \"unstack\". Accepts a name for the level.\n\n    Examples\n    --------\n    >>> s\n    one  a   1.\n    one  b   2.\n    two  a   3.\n    two  b   4.\n\n    >>> s.unstack(level=-1)\n         a   b\n    one  1.  2.\n    two  3.  4.\n\n    >>> s.unstack(level=0)\n       one  two\n    a  1.   2.\n    b  3.   4.\n\n    Returns\n    -------\n    unstacked : DataFrame\n    \"\"\"\n    def __init__(self, values, index, level=-1, value_columns=None):\n        if values.ndim == 1:\n            values = values[:, np.newaxis]\n        self.values = values\n        self.value_columns = value_columns\n\n        if value_columns is None and values.shape[1] != 1:  # pragma: no cover\n            raise ValueError('must pass column labels for multi-column data')\n\n        self.index = index\n        self.level = self.index._get_level_number(level)\n\n        self.new_index_levels = list(index.levels)\n        self.new_index_names = list(index.names)\n\n        self.removed_name = self.new_index_names.pop(self.level)\n        self.removed_level = self.new_index_levels.pop(self.level)\n\n        self._make_sorted_values_labels()\n        self._make_selectors()\n\n    def _make_sorted_values_labels(self):\n        v = self.level\n\n        labs = self.index.labels\n        levs = self.index.levels\n        to_sort = labs[:v] + labs[v + 1:] + [labs[v]]\n        sizes = [len(x) for x in levs[:v] + levs[v + 1:] + [levs[v]]]\n\n        comp_index, obs_ids = get_compressed_ids(to_sort, sizes)\n\n        # group_index = get_group_index(to_sort, sizes)\n        # comp_index, obs_ids = _compress_group_index(group_index)\n\n        ngroups = len(obs_ids)\n\n        indexer = algos.groupsort_indexer(comp_index, ngroups)[0]\n        indexer = _ensure_platform_int(indexer)\n\n        self.sorted_values = com.take_2d(self.values, indexer, axis=0)\n        self.sorted_labels = [l.take(indexer) for l in to_sort]\n\n    def _make_selectors(self):\n        new_levels = self.new_index_levels\n\n        # make the mask\n        remaining_labels = self.sorted_labels[:-1]\n        level_sizes = [len(x) for x in new_levels]\n\n        comp_index, obs_ids = get_compressed_ids(remaining_labels, level_sizes)\n        ngroups = len(obs_ids)\n\n        comp_index = _ensure_platform_int(comp_index)\n        stride = self.index.levshape[self.level]\n        self.full_shape = ngroups, stride\n\n        selector = self.sorted_labels[-1] + stride * comp_index\n        mask = np.zeros(np.prod(self.full_shape), dtype=bool)\n        mask.put(selector, True)\n\n        if mask.sum() < len(self.index):\n            raise ReshapeError('Index contains duplicate entries, '\n                               'cannot reshape')\n\n        self.group_index = comp_index\n        self.mask = mask\n        self.unique_groups = obs_ids\n        self.compressor = comp_index.searchsorted(np.arange(ngroups))\n\n    def get_result(self):\n        # TODO: find a better way than this masking business\n\n        values, value_mask = self.get_new_values()\n        columns = self.get_new_columns()\n        index = self.get_new_index()\n\n        # filter out missing levels\n        if values.shape[1] > 0:\n            col_inds, obs_ids = _compress_group_index(self.sorted_labels[-1])\n            # rare case, level values not observed\n            if len(obs_ids) < self.full_shape[1]:\n                inds = (value_mask.sum(0) > 0).nonzero()[0]\n                values = com.take_2d(values, inds, axis=1)\n                columns = columns[inds]\n\n        return DataFrame(values, index=index, columns=columns)\n\n    def get_new_values(self):\n        values = self.values\n        # place the values\n        length, width = self.full_shape\n        stride = values.shape[1]\n        result_width = width * stride\n\n        new_values = np.empty((length, result_width), dtype=values.dtype)\n        new_mask = np.zeros((length, result_width), dtype=bool)\n\n        new_values = com._maybe_upcast(new_values)\n        new_values.fill(np.nan)\n\n        # is there a simpler / faster way of doing this?\n        for i in xrange(values.shape[1]):\n            chunk = new_values[:, i * width : (i + 1) * width]\n            mask_chunk = new_mask[:, i * width : (i + 1) * width]\n\n            chunk.flat[self.mask] = self.sorted_values[:, i]\n            mask_chunk.flat[self.mask] = True\n\n        return new_values, new_mask\n\n    def get_new_columns(self):\n        if self.value_columns is None:\n            return self.removed_level\n\n        stride = len(self.removed_level)\n        width = len(self.value_columns)\n        propagator = np.repeat(np.arange(width), stride)\n        if isinstance(self.value_columns, MultiIndex):\n            new_levels = self.value_columns.levels + [self.removed_level]\n            new_names = self.value_columns.names + [self.removed_name]\n\n            new_labels = [lab.take(propagator)\n                          for lab in self.value_columns.labels]\n            new_labels.append(np.tile(np.arange(stride), width))\n        else:\n            new_levels = [self.value_columns, self.removed_level]\n            new_names = [self.value_columns.name, self.removed_name]\n\n            new_labels = []\n\n            new_labels.append(propagator)\n            new_labels.append(np.tile(np.arange(stride), width))\n\n        return MultiIndex(levels=new_levels, labels=new_labels,\n                          names=new_names)\n\n    def get_new_index(self):\n        result_labels = []\n        for cur in self.sorted_labels[:-1]:\n            result_labels.append(cur.take(self.compressor))\n\n        # construct the new index\n        if len(self.new_index_levels) == 1:\n            new_index = self.new_index_levels[0].take(self.unique_groups)\n            new_index.name = self.new_index_names[0]\n        else:\n            new_index = MultiIndex(levels=self.new_index_levels,\n                                   labels=result_labels,\n                                   names=self.new_index_names)\n\n        return new_index\n\n\ndef _unstack_multiple(data, clocs):\n    if len(clocs) == 0:\n        return data\n\n    # NOTE: This doesn't deal with hierarchical columns yet\n\n    index = data.index\n\n    clocs = [index._get_level_number(i) for i in clocs]\n\n    rlocs = [i for i in range(index.nlevels) if i not in clocs]\n\n    clevels = [index.levels[i] for i in clocs]\n    clabels = [index.labels[i] for i in clocs]\n    cnames = [index.names[i] for i in clocs]\n    rlevels = [index.levels[i] for i in rlocs]\n    rlabels = [index.labels[i] for i in rlocs]\n    rnames = [index.names[i] for i in rlocs]\n\n    shape = [len(x) for x in clevels]\n    group_index = get_group_index(clabels, shape)\n\n    comp_ids, obs_ids = _compress_group_index(group_index, sort=False)\n    recons_labels = decons_group_index(obs_ids, shape)\n\n    dummy_index = MultiIndex(levels=rlevels + [obs_ids],\n                             labels=rlabels + [comp_ids],\n                             names=rnames + ['__placeholder__'])\n\n    if isinstance(data, Series):\n        dummy = Series(data.values, index=dummy_index)\n        unstacked = dummy.unstack('__placeholder__')\n        new_levels = clevels\n        new_names = cnames\n        new_labels = recons_labels\n    else:\n        if isinstance(data.columns, MultiIndex):\n            raise NotImplementedError('Unstacking multiple levels with '\n                                      'hierarchical columns not yet supported')\n\n        dummy = DataFrame(data.values, index=dummy_index,\n                          columns=data.columns)\n\n        unstacked = dummy.unstack('__placeholder__')\n        if isinstance(unstacked, Series):\n            unstcols = unstacked.index\n        else:\n            unstcols = unstacked.columns\n        new_levels = [unstcols.levels[0]] + clevels\n        new_names = [data.columns.name] + cnames\n\n        new_labels = [unstcols.labels[0]]\n        for rec in recons_labels:\n            new_labels.append(rec.take(unstcols.labels[-1]))\n\n    new_columns = MultiIndex(levels=new_levels, labels=new_labels,\n                             names=new_names)\n\n    if isinstance(unstacked, Series):\n        unstacked.index = new_columns\n    else:\n        unstacked.columns = new_columns\n\n    return unstacked\n\n\ndef pivot(self, index=None, columns=None, values=None):\n    \"\"\"\n    See DataFrame.pivot\n    \"\"\"\n    if values is None:\n        indexed = self.set_index([index, columns])\n        return indexed.unstack(columns)\n    else:\n        indexed = Series(self[values].values,\n                         index=[self[index], self[columns]])\n        return indexed.unstack(columns)\n\n\ndef pivot_simple(index, columns, values):\n    \"\"\"\n    Produce 'pivot' table based on 3 columns of this DataFrame.\n    Uses unique values from index / columns and fills with values.\n\n    Parameters\n    ----------\n    index : ndarray\n        Labels to use to make new frame's index\n    columns : ndarray\n        Labels to use to make new frame's columns\n    values : ndarray\n        Values to use for populating new frame's values\n\n    Note\n    ----\n    Obviously, all 3 of the input arguments must have the same length\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    if (len(index) != len(columns)) or (len(columns) != len(values)):\n        raise AssertionError('Length of index, columns, and values must be the'\n                             ' same')\n\n    if len(index) == 0:\n        return DataFrame(index=[])\n\n    hindex = MultiIndex.from_arrays([index, columns])\n    series = Series(values.ravel(), index=hindex)\n    series = series.sortlevel(0)\n    return series.unstack()\n\n\ndef _slow_pivot(index, columns, values):\n    \"\"\"\n    Produce 'pivot' table based on 3 columns of this DataFrame.\n    Uses unique values from index / columns and fills with values.\n\n    Parameters\n    ----------\n    index : string or object\n        Column name to use to make new frame's index\n    columns : string or object\n        Column name to use to make new frame's columns\n    values : string or object\n        Column name to use for populating new frame's values\n\n    Could benefit from some Cython here.\n    \"\"\"\n    tree = {}\n    for i, (idx, col) in enumerate(itertools.izip(index, columns)):\n        if col not in tree:\n            tree[col] = {}\n        branch = tree[col]\n        branch[idx] = values[i]\n\n    return DataFrame(tree)\n\n\ndef unstack(obj, level):\n    if isinstance(level, (tuple, list)):\n        return _unstack_multiple(obj, level)\n\n    if isinstance(obj, DataFrame):\n        if isinstance(obj.index, MultiIndex):\n            return _unstack_frame(obj, level)\n        else:\n            return obj.T.stack(dropna=False)\n    else:\n        unstacker = _Unstacker(obj.values, obj.index, level=level)\n        return unstacker.get_result()\n\n\ndef _unstack_frame(obj, level):\n    from pandas.core.internals import BlockManager, make_block\n\n    if obj._is_mixed_type:\n        unstacker = _Unstacker(np.empty(obj.shape, dtype=bool),  # dummy\n                               obj.index, level=level,\n                               value_columns=obj.columns)\n        new_columns = unstacker.get_new_columns()\n        new_index = unstacker.get_new_index()\n        new_axes = [new_columns, new_index]\n\n        new_blocks = []\n        mask_blocks = []\n        for blk in obj._data.blocks:\n            bunstacker = _Unstacker(blk.values.T, obj.index, level=level,\n                                    value_columns=blk.items)\n            new_items = bunstacker.get_new_columns()\n            new_values, mask = bunstacker.get_new_values()\n\n            mblk = make_block(mask.T, new_items, new_columns)\n            mask_blocks.append(mblk)\n\n            newb = make_block(new_values.T, new_items, new_columns)\n            new_blocks.append(newb)\n\n        result = DataFrame(BlockManager(new_blocks, new_axes))\n        mask_frame = DataFrame(BlockManager(mask_blocks, new_axes))\n        return result.ix[:, mask_frame.sum(0) > 0]\n    else:\n        unstacker = _Unstacker(obj.values, obj.index, level=level,\n                               value_columns=obj.columns)\n        return unstacker.get_result()\n\ndef get_compressed_ids(labels, sizes):\n    # no overflow\n    if _long_prod(sizes) < 2**63:\n        group_index = get_group_index(labels, sizes)\n        comp_index, obs_ids = _compress_group_index(group_index)\n    else:\n        n = len(labels[0])\n        mask = np.zeros(n, dtype=bool)\n        for v in labels:\n            mask |= v < 0\n\n        while _long_prod(sizes) >= 2**63:\n            i = len(sizes)\n            while _long_prod(sizes[:i]) >= 2**63:\n                i -= 1\n\n            rem_index, rem_ids = get_compressed_ids(labels[:i],\n                                                    sizes[:i])\n            sizes = [len(rem_ids)] + sizes[i:]\n            labels = [rem_index] + labels[i:]\n\n        return get_compressed_ids(labels, sizes)\n\n    return comp_index, obs_ids\n\ndef _long_prod(vals):\n    result = 1L\n    for x in vals:\n        result *= x\n    return result\n\ndef stack(frame, level=-1, dropna=True):\n    \"\"\"\n    Convert DataFrame to Series with multi-level Index. Columns become the\n    second level of the resulting hierarchical index\n\n    Returns\n    -------\n    stacked : Series\n    \"\"\"\n    N, K = frame.shape\n    if isinstance(level, int) and level < 0:\n        level += frame.columns.nlevels\n\n    level = frame.columns._get_level_number(level)\n\n    if isinstance(frame.columns, MultiIndex):\n        return _stack_multi_columns(frame, level=level, dropna=True)\n    elif isinstance(frame.index, MultiIndex):\n        new_levels = list(frame.index.levels)\n        new_levels.append(frame.columns)\n\n        new_labels = [lab.repeat(K) for lab in frame.index.labels]\n        new_labels.append(np.tile(np.arange(K), N).ravel())\n\n        new_names = list(frame.index.names)\n        new_names.append(frame.columns.name)\n        new_index = MultiIndex(levels=new_levels, labels=new_labels,\n                               names=new_names)\n    else:\n        ilabels = np.arange(N).repeat(K)\n        clabels = np.tile(np.arange(K), N).ravel()\n        new_index = MultiIndex(levels=[frame.index, frame.columns],\n                               labels=[ilabels, clabels],\n                               names=[frame.index.name, frame.columns.name])\n\n    new_values = frame.values.ravel()\n    if dropna:\n        mask = notnull(new_values)\n        new_values = new_values[mask]\n        new_index = new_index[mask]\n    return Series(new_values, index=new_index)\n\n\ndef _stack_multi_columns(frame, level=-1, dropna=True):\n    this = frame.copy()\n\n    # this makes life much simpler\n    if level != frame.columns.nlevels - 1:\n        # roll levels to put selected level at end\n        roll_columns = this.columns\n        for i in range(level, frame.columns.nlevels - 1):\n            roll_columns = roll_columns.swaplevel(i, i + 1)\n        this.columns = roll_columns\n\n    if not this.columns.is_lexsorted():\n        this = this.sortlevel(0, axis=1)\n\n    # tuple list excluding level for grouping columns\n    if len(frame.columns.levels) > 2:\n        tuples = zip(*[lev.values.take(lab)\n                       for lev, lab in zip(this.columns.levels[:-1],\n                                           this.columns.labels[:-1])])\n        unique_groups = [key for key, _ in itertools.groupby(tuples)]\n        new_names = this.columns.names[:-1]\n        new_columns = MultiIndex.from_tuples(unique_groups, names=new_names)\n    else:\n        new_columns = unique_groups = this.columns.levels[0]\n\n    # time to ravel the values\n    new_data = {}\n    level_vals = this.columns.levels[-1]\n    levsize = len(level_vals)\n    for key in unique_groups:\n        loc = this.columns.get_loc(key)\n\n        # can make more efficient?\n        if loc.stop - loc.start != levsize:\n            chunk = this.ix[:, this.columns[loc]]\n            chunk.columns = level_vals.take(chunk.columns.labels[-1])\n            value_slice = chunk.reindex(columns=level_vals).values\n        else:\n            if frame._is_mixed_type:\n                value_slice = this.ix[:, this.columns[loc]].values\n            else:\n                value_slice = this.values[:, loc]\n\n        new_data[key] = value_slice.ravel()\n\n    N = len(this)\n\n    if isinstance(this.index, MultiIndex):\n        new_levels = list(this.index.levels)\n        new_names = list(this.index.names)\n        new_labels = [lab.repeat(levsize) for lab in this.index.labels]\n    else:\n        new_levels = [this.index]\n        new_labels = [np.arange(N).repeat(levsize)]\n        new_names = [this.index.name]  # something better?\n\n    new_levels.append(frame.columns.levels[level])\n    new_labels.append(np.tile(np.arange(levsize), N))\n    new_names.append(frame.columns.names[level])\n\n    new_index = MultiIndex(levels=new_levels, labels=new_labels,\n                           names=new_names)\n\n    result = DataFrame(new_data, index=new_index, columns=new_columns)\n\n    # more efficient way to go about this? can do the whole masking biz but\n    # will only save a small amount of time...\n    if dropna:\n        result = result.dropna(axis=0, how='all')\n\n    return result\n\n\ndef melt(frame, id_vars=None, value_vars=None):\n    \"\"\"\n    \"Unpivots\" a DataFrame from wide format to long format, optionally leaving\n    id variables set\n\n    Parameters\n    ----------\n    frame : DataFrame\n    id_vars :\n    value_vars :\n\n    Examples\n    --------\n    >>> df\n    A B C\n    a 1 2\n    b 3 4\n    c 5 6\n\n    >>> melt(df, id_vars=['A'], value_vars=['B'])\n    A variable value\n    a B        1\n    b B        3\n    c B        5\n    \"\"\"\n    # TODO: what about the existing index?\n    if id_vars is not None:\n        if not isinstance(id_vars, (tuple, list, np.ndarray)):\n            id_vars = [id_vars]\n        else:\n            id_vars = list(id_vars)\n    else:\n        id_vars = []\n\n    if value_vars is not None:\n        if not isinstance(value_vars, (tuple, list, np.ndarray)):\n            value_vars = [value_vars]\n        frame = frame.ix[:, id_vars + value_vars]\n    else:\n        frame = frame.copy()\n\n    N, K = frame.shape\n    K -= len(id_vars)\n\n    mdata = {}\n    for col in id_vars:\n        mdata[col] = np.tile(frame.pop(col).values, K)\n\n    mcolumns = id_vars + ['variable', 'value']\n\n    mdata['value'] = frame.values.ravel('F')\n\n    mdata['variable'] = np.asarray(frame.columns).repeat(N)\n    return DataFrame(mdata, columns=mcolumns)\n\n\ndef lreshape(data, groups, dropna=True, label=None):\n    \"\"\"\n    Reshape long-format data to wide. Generalized inverse of DataFrame.pivot\n\n    Parameters\n    ----------\n    data : DataFrame\n    groups : dict\n        {new_name : list_of_columns}\n    dropna : boolean, default True\n\n    Examples\n    --------\n    >>> data\n       hr1  hr2     team  year1  year2\n    0  514  545  Red Sox   2007   2008\n    1  573  526  Yankees   2007   2008\n\n    >>> pd.lreshape(data, {'year': ['year1', 'year2'],\n                           'hr': ['hr1', 'hr2']})\n          team   hr  year\n    0  Red Sox  514  2007\n    1  Yankees  573  2007\n    2  Red Sox  545  2008\n    3  Yankees  526  2008\n\n    Returns\n    -------\n    reshaped : DataFrame\n    \"\"\"\n    if isinstance(groups, dict):\n        keys = groups.keys()\n        values = groups.values()\n    else:\n        keys, values = zip(*groups)\n\n    all_cols = list(set.union(*[set(x) for x in values]))\n    id_cols = list(data.columns.diff(all_cols))\n\n    K = len(values[0])\n\n    for seq in values:\n        if len(seq) != K:\n            raise ValueError('All column lists must be same length')\n\n    mdata = {}\n    pivot_cols = []\n\n    for target, names in zip(keys, values):\n        mdata[target] = com._concat_compat([data[col].values for col in names])\n        pivot_cols.append(target)\n\n    for col in id_cols:\n        mdata[col] = np.tile(data[col].values, K)\n\n    if dropna:\n        mask = np.ones(len(mdata[pivot_cols[0]]), dtype=bool)\n        for c in pivot_cols:\n            mask &= notnull(mdata[c])\n        if not mask.all():\n            mdata = dict((k, v[mask]) for k, v in mdata.iteritems())\n\n    return DataFrame(mdata, columns=id_cols + pivot_cols)\n\n\ndef convert_dummies(data, cat_variables, prefix_sep='_'):\n    \"\"\"\n    Compute DataFrame with specified columns converted to dummy variables (0 /\n    1). Result columns will be prefixed with the column name, then the level\n    name, e.g. 'A_foo' for column A and level foo\n\n    Parameters\n    ----------\n    data : DataFrame\n    cat_variables : list-like\n        Must be column names in the DataFrame\n    prefix_sep : string, default '_'\n        String to use to separate column name from dummy level\n\n    Returns\n    -------\n    dummies : DataFrame\n    \"\"\"\n    result = data.drop(cat_variables, axis=1)\n    for variable in cat_variables:\n        dummies = get_dummies(data[variable], prefix=variable,\n                              prefix_sep=prefix_sep)\n        result = result.join(dummies)\n    return result\n\n\ndef get_dummies(data, prefix=None, prefix_sep='_'):\n    \"\"\"\n    Convert categorical variable into dummy/indicator variables\n\n    Parameters\n    ----------\n    data : array-like or Series\n    prefix : string, default None\n        String to append DataFrame column names\n    prefix_sep : string, default '_'\n        If appending prefix, separator/delimiter to use\n\n    Returns\n    -------\n    dummies : DataFrame\n    \"\"\"\n    cat = Categorical.from_array(np.asarray(data))\n    dummy_mat = np.eye(len(cat.levels)).take(cat.labels, axis=0)\n\n    if prefix is not None:\n        dummy_cols = ['%s%s%s' % (prefix, prefix_sep, str(v))\n                      for v in cat.levels]\n    else:\n        dummy_cols = cat.levels\n\n    if isinstance(data, Series):\n        index = data.index\n    else:\n        index = None\n\n    return DataFrame(dummy_mat, index=index, columns=dummy_cols)\n\n\ndef make_axis_dummies(frame, axis='minor', transform=None):\n    \"\"\"\n    Construct 1-0 dummy variables corresponding to designated axis\n    labels\n\n    Parameters\n    ----------\n    axis : {'major', 'minor'}, default 'minor'\n    transform : function, default None\n        Function to apply to axis labels first. For example, to\n        get \"day of week\" dummies in a time series regression you might\n        call:\n            make_axis_dummies(panel, axis='major',\n                              transform=lambda d: d.weekday())\n    Returns\n    -------\n    dummies : DataFrame\n        Column names taken from chosen axis\n    \"\"\"\n    numbers = {\n        'major': 0,\n        'minor': 1\n    }\n    num = numbers.get(axis, axis)\n\n    items = frame.index.levels[num]\n    labels = frame.index.labels[num]\n    if transform is not None:\n        mapped_items = items.map(transform)\n        cat = Categorical.from_array(mapped_items.take(labels))\n        labels = cat.labels\n        items = cat.levels\n\n    values = np.eye(len(items), dtype=float)\n    values = values.take(labels, axis=0)\n\n    return DataFrame(values, columns=items, index=frame.index)\n\n\ndef block2d_to_block3d(values, items, shape, major_labels, minor_labels,\n                       ref_items=None):\n    \"\"\"\n    Developer method for pivoting DataFrame -> Panel. Used in HDFStore and\n    DataFrame.to_panel\n    \"\"\"\n    from pandas.core.internals import make_block\n    panel_shape = (len(items),) + shape\n\n    # TODO: lexsort depth needs to be 2!!\n\n    # Create observation selection vector using major and minor\n    # labels, for converting to panel format.\n    selector = minor_labels + shape[1] * major_labels\n    mask = np.zeros(np.prod(shape), dtype=bool)\n    mask.put(selector, True)\n\n    pvalues = np.empty(panel_shape, dtype=values.dtype)\n    if not issubclass(pvalues.dtype.type, (np.integer, np.bool_)):\n        pvalues.fill(np.nan)\n    elif not mask.all():\n        pvalues = com._maybe_upcast(pvalues)\n        pvalues.fill(np.nan)\n\n    values = values\n    for i in xrange(len(items)):\n        pvalues[i].flat[mask] = values[:, i]\n\n    if ref_items is None:\n        ref_items = items\n\n    return make_block(pvalues, items, ref_items)\n\ndef block2d_to_blocknd(values, items, shape, labels, ref_items=None):\n    \"\"\" pivot to the labels shape \"\"\"\n    from pandas.core.internals import make_block\n    panel_shape = (len(items),) + shape\n\n    # TODO: lexsort depth needs to be 2!!\n\n    # Create observation selection vector using major and minor\n    # labels, for converting to panel format.\n    selector = factor_indexer(shape[1:],labels)\n    mask = np.zeros(np.prod(shape), dtype=bool)\n    mask.put(selector, True)\n\n    pvalues = np.empty(panel_shape, dtype=values.dtype)\n    if not issubclass(pvalues.dtype.type, (np.integer, np.bool_)):\n        pvalues.fill(np.nan)\n    elif not mask.all():\n        pvalues = com._maybe_upcast(pvalues)\n        pvalues.fill(np.nan)\n\n    values = values\n    for i in xrange(len(items)):\n        pvalues[i].flat[mask] = values[:, i]\n\n    if ref_items is None:\n        ref_items = items\n\n    return make_block(pvalues, items, ref_items)\n\ndef factor_indexer(shape, labels):\n    \"\"\" given a tuple of shape and a list of Factor lables, return the expanded label indexer \"\"\"\n    mult   = np.array(shape)[::-1].cumprod()[::-1]\n    return np.sum(np.array(labels).T * np.append(mult,[1]), axis=1).T\n",
      "file_after": "# pylint: disable=E1101,E1103\n# pylint: disable=W0703,W0622,W0613,W0201\n\nimport itertools\n\nimport numpy as np\n\nfrom pandas.core.series import Series\nfrom pandas.core.frame import DataFrame\n\nfrom pandas.core.categorical import Categorical\nfrom pandas.core.common import notnull, _ensure_platform_int\nfrom pandas.core.groupby import (get_group_index, _compress_group_index,\n                                 decons_group_index)\nimport pandas.core.common as com\nimport pandas.algos as algos\n\n\nfrom pandas.core.index import MultiIndex\n\n\nclass ReshapeError(Exception):\n    pass\n\n\nclass _Unstacker(object):\n    \"\"\"\n    Helper class to unstack data / pivot with multi-level index\n\n    Parameters\n    ----------\n    level : int or str, default last level\n        Level to \"unstack\". Accepts a name for the level.\n\n    Examples\n    --------\n    >>> s\n    one  a   1.\n    one  b   2.\n    two  a   3.\n    two  b   4.\n\n    >>> s.unstack(level=-1)\n         a   b\n    one  1.  2.\n    two  3.  4.\n\n    >>> s.unstack(level=0)\n       one  two\n    a  1.   2.\n    b  3.   4.\n\n    Returns\n    -------\n    unstacked : DataFrame\n    \"\"\"\n    def __init__(self, values, index, level=-1, value_columns=None):\n        if values.ndim == 1:\n            values = values[:, np.newaxis]\n        self.values = values\n        self.value_columns = value_columns\n\n        if value_columns is None and values.shape[1] != 1:  # pragma: no cover\n            raise ValueError('must pass column labels for multi-column data')\n\n        self.index = index\n        self.level = self.index._get_level_number(level)\n\n        self.new_index_levels = list(index.levels)\n        self.new_index_names = list(index.names)\n\n        self.removed_name = self.new_index_names.pop(self.level)\n        self.removed_level = self.new_index_levels.pop(self.level)\n\n        self._make_sorted_values_labels()\n        self._make_selectors()\n\n    def _make_sorted_values_labels(self):\n        v = self.level\n\n        labs = self.index.labels\n        levs = self.index.levels\n        to_sort = labs[:v] + labs[v + 1:] + [labs[v]]\n        sizes = [len(x) for x in levs[:v] + levs[v + 1:] + [levs[v]]]\n\n        comp_index, obs_ids = get_compressed_ids(to_sort, sizes)\n\n        # group_index = get_group_index(to_sort, sizes)\n        # comp_index, obs_ids = _compress_group_index(group_index)\n\n        ngroups = len(obs_ids)\n\n        indexer = algos.groupsort_indexer(comp_index, ngroups)[0]\n        indexer = _ensure_platform_int(indexer)\n\n        self.sorted_values = com.take_2d(self.values, indexer, axis=0)\n        self.sorted_labels = [l.take(indexer) for l in to_sort]\n\n    def _make_selectors(self):\n        new_levels = self.new_index_levels\n\n        # make the mask\n        remaining_labels = self.sorted_labels[:-1]\n        level_sizes = [len(x) for x in new_levels]\n\n        comp_index, obs_ids = get_compressed_ids(remaining_labels, level_sizes)\n        ngroups = len(obs_ids)\n\n        comp_index = _ensure_platform_int(comp_index)\n        stride = self.index.levshape[self.level]\n        self.full_shape = ngroups, stride\n\n        selector = self.sorted_labels[-1] + stride * comp_index\n        mask = np.zeros(np.prod(self.full_shape), dtype=bool)\n        mask.put(selector, True)\n\n        if mask.sum() < len(self.index):\n            raise ReshapeError('Index contains duplicate entries, '\n                               'cannot reshape')\n\n        self.group_index = comp_index\n        self.mask = mask\n        self.unique_groups = obs_ids\n        self.compressor = comp_index.searchsorted(np.arange(ngroups))\n\n    def get_result(self):\n        # TODO: find a better way than this masking business\n\n        values, value_mask = self.get_new_values()\n        columns = self.get_new_columns()\n        index = self.get_new_index()\n\n        # filter out missing levels\n        if values.shape[1] > 0:\n            col_inds, obs_ids = _compress_group_index(self.sorted_labels[-1])\n            # rare case, level values not observed\n            if len(obs_ids) < self.full_shape[1]:\n                inds = (value_mask.sum(0) > 0).nonzero()[0]\n                values = com.take_2d(values, inds, axis=1)\n                columns = columns[inds]\n\n        return DataFrame(values, index=index, columns=columns)\n\n    def get_new_values(self):\n        values = self.values\n        # place the values\n        length, width = self.full_shape\n        stride = values.shape[1]\n        result_width = width * stride\n\n        new_values = np.empty((length, result_width), dtype=values.dtype)\n        new_mask = np.zeros((length, result_width), dtype=bool)\n\n        new_values = com._maybe_upcast(new_values)\n        new_values.fill(np.nan)\n\n        # is there a simpler / faster way of doing this?\n        for i in xrange(values.shape[1]):\n            chunk = new_values[:, i * width : (i + 1) * width]\n            mask_chunk = new_mask[:, i * width : (i + 1) * width]\n\n            chunk.flat[self.mask] = self.sorted_values[:, i]\n            mask_chunk.flat[self.mask] = True\n\n        return new_values, new_mask\n\n    def get_new_columns(self):\n        if self.value_columns is None:\n            return self.removed_level\n\n        stride = len(self.removed_level)\n        width = len(self.value_columns)\n        propagator = np.repeat(np.arange(width), stride)\n        if isinstance(self.value_columns, MultiIndex):\n            new_levels = self.value_columns.levels + [self.removed_level]\n            new_names = self.value_columns.names + [self.removed_name]\n\n            new_labels = [lab.take(propagator)\n                          for lab in self.value_columns.labels]\n            new_labels.append(np.tile(np.arange(stride), width))\n        else:\n            new_levels = [self.value_columns, self.removed_level]\n            new_names = [self.value_columns.name, self.removed_name]\n\n            new_labels = []\n\n            new_labels.append(propagator)\n            new_labels.append(np.tile(np.arange(stride), width))\n\n        return MultiIndex(levels=new_levels, labels=new_labels,\n                          names=new_names)\n\n    def get_new_index(self):\n        result_labels = []\n        for cur in self.sorted_labels[:-1]:\n            result_labels.append(cur.take(self.compressor))\n\n        # construct the new index\n        if len(self.new_index_levels) == 1:\n            new_index = self.new_index_levels[0].take(self.unique_groups)\n            new_index.name = self.new_index_names[0]\n        else:\n            new_index = MultiIndex(levels=self.new_index_levels,\n                                   labels=result_labels,\n                                   names=self.new_index_names)\n\n        return new_index\n\n\ndef _unstack_multiple(data, clocs):\n    if len(clocs) == 0:\n        return data\n\n    # NOTE: This doesn't deal with hierarchical columns yet\n\n    index = data.index\n\n    clocs = [index._get_level_number(i) for i in clocs]\n\n    rlocs = [i for i in range(index.nlevels) if i not in clocs]\n\n    clevels = [index.levels[i] for i in clocs]\n    clabels = [index.labels[i] for i in clocs]\n    cnames = [index.names[i] for i in clocs]\n    rlevels = [index.levels[i] for i in rlocs]\n    rlabels = [index.labels[i] for i in rlocs]\n    rnames = [index.names[i] for i in rlocs]\n\n    shape = [len(x) for x in clevels]\n    group_index = get_group_index(clabels, shape)\n\n    comp_ids, obs_ids = _compress_group_index(group_index, sort=False)\n    recons_labels = decons_group_index(obs_ids, shape)\n\n    dummy_index = MultiIndex(levels=rlevels + [obs_ids],\n                             labels=rlabels + [comp_ids],\n                             names=rnames + ['__placeholder__'])\n\n    if isinstance(data, Series):\n        dummy = Series(data.values, index=dummy_index)\n        unstacked = dummy.unstack('__placeholder__')\n        new_levels = clevels\n        new_names = cnames\n        new_labels = recons_labels\n    else:\n        if isinstance(data.columns, MultiIndex):\n            result = data\n            for val in clocs:\n                result = result.unstack(val)\n            return result\n\n        dummy = DataFrame(data.values, index=dummy_index,\n                          columns=data.columns)\n\n        unstacked = dummy.unstack('__placeholder__')\n        if isinstance(unstacked, Series):\n            unstcols = unstacked.index\n        else:\n            unstcols = unstacked.columns\n        new_levels = [unstcols.levels[0]] + clevels\n        new_names = [data.columns.name] + cnames\n\n        new_labels = [unstcols.labels[0]]\n        for rec in recons_labels:\n            new_labels.append(rec.take(unstcols.labels[-1]))\n\n    new_columns = MultiIndex(levels=new_levels, labels=new_labels,\n                             names=new_names)\n\n    if isinstance(unstacked, Series):\n        unstacked.index = new_columns\n    else:\n        unstacked.columns = new_columns\n\n    return unstacked\n\n\ndef pivot(self, index=None, columns=None, values=None):\n    \"\"\"\n    See DataFrame.pivot\n    \"\"\"\n    if values is None:\n        indexed = self.set_index([index, columns])\n        return indexed.unstack(columns)\n    else:\n        indexed = Series(self[values].values,\n                         index=[self[index], self[columns]])\n        return indexed.unstack(columns)\n\n\ndef pivot_simple(index, columns, values):\n    \"\"\"\n    Produce 'pivot' table based on 3 columns of this DataFrame.\n    Uses unique values from index / columns and fills with values.\n\n    Parameters\n    ----------\n    index : ndarray\n        Labels to use to make new frame's index\n    columns : ndarray\n        Labels to use to make new frame's columns\n    values : ndarray\n        Values to use for populating new frame's values\n\n    Note\n    ----\n    Obviously, all 3 of the input arguments must have the same length\n\n    Returns\n    -------\n    DataFrame\n    \"\"\"\n    if (len(index) != len(columns)) or (len(columns) != len(values)):\n        raise AssertionError('Length of index, columns, and values must be the'\n                             ' same')\n\n    if len(index) == 0:\n        return DataFrame(index=[])\n\n    hindex = MultiIndex.from_arrays([index, columns])\n    series = Series(values.ravel(), index=hindex)\n    series = series.sortlevel(0)\n    return series.unstack()\n\n\ndef _slow_pivot(index, columns, values):\n    \"\"\"\n    Produce 'pivot' table based on 3 columns of this DataFrame.\n    Uses unique values from index / columns and fills with values.\n\n    Parameters\n    ----------\n    index : string or object\n        Column name to use to make new frame's index\n    columns : string or object\n        Column name to use to make new frame's columns\n    values : string or object\n        Column name to use for populating new frame's values\n\n    Could benefit from some Cython here.\n    \"\"\"\n    tree = {}\n    for i, (idx, col) in enumerate(itertools.izip(index, columns)):\n        if col not in tree:\n            tree[col] = {}\n        branch = tree[col]\n        branch[idx] = values[i]\n\n    return DataFrame(tree)\n\n\ndef unstack(obj, level):\n    if isinstance(level, (tuple, list)):\n        return _unstack_multiple(obj, level)\n\n    if isinstance(obj, DataFrame):\n        if isinstance(obj.index, MultiIndex):\n            return _unstack_frame(obj, level)\n        else:\n            return obj.T.stack(dropna=False)\n    else:\n        unstacker = _Unstacker(obj.values, obj.index, level=level)\n        return unstacker.get_result()\n\n\ndef _unstack_frame(obj, level):\n    from pandas.core.internals import BlockManager, make_block\n\n    if obj._is_mixed_type:\n        unstacker = _Unstacker(np.empty(obj.shape, dtype=bool),  # dummy\n                               obj.index, level=level,\n                               value_columns=obj.columns)\n        new_columns = unstacker.get_new_columns()\n        new_index = unstacker.get_new_index()\n        new_axes = [new_columns, new_index]\n\n        new_blocks = []\n        mask_blocks = []\n        for blk in obj._data.blocks:\n            bunstacker = _Unstacker(blk.values.T, obj.index, level=level,\n                                    value_columns=blk.items)\n            new_items = bunstacker.get_new_columns()\n            new_values, mask = bunstacker.get_new_values()\n\n            mblk = make_block(mask.T, new_items, new_columns)\n            mask_blocks.append(mblk)\n\n            newb = make_block(new_values.T, new_items, new_columns)\n            new_blocks.append(newb)\n\n        result = DataFrame(BlockManager(new_blocks, new_axes))\n        mask_frame = DataFrame(BlockManager(mask_blocks, new_axes))\n        return result.ix[:, mask_frame.sum(0) > 0]\n    else:\n        unstacker = _Unstacker(obj.values, obj.index, level=level,\n                               value_columns=obj.columns)\n        return unstacker.get_result()\n\ndef get_compressed_ids(labels, sizes):\n    # no overflow\n    if _long_prod(sizes) < 2**63:\n        group_index = get_group_index(labels, sizes)\n        comp_index, obs_ids = _compress_group_index(group_index)\n    else:\n        n = len(labels[0])\n        mask = np.zeros(n, dtype=bool)\n        for v in labels:\n            mask |= v < 0\n\n        while _long_prod(sizes) >= 2**63:\n            i = len(sizes)\n            while _long_prod(sizes[:i]) >= 2**63:\n                i -= 1\n\n            rem_index, rem_ids = get_compressed_ids(labels[:i],\n                                                    sizes[:i])\n            sizes = [len(rem_ids)] + sizes[i:]\n            labels = [rem_index] + labels[i:]\n\n        return get_compressed_ids(labels, sizes)\n\n    return comp_index, obs_ids\n\ndef _long_prod(vals):\n    result = 1L\n    for x in vals:\n        result *= x\n    return result\n\ndef stack(frame, level=-1, dropna=True):\n    \"\"\"\n    Convert DataFrame to Series with multi-level Index. Columns become the\n    second level of the resulting hierarchical index\n\n    Returns\n    -------\n    stacked : Series\n    \"\"\"\n    N, K = frame.shape\n    if isinstance(level, int) and level < 0:\n        level += frame.columns.nlevels\n\n    level = frame.columns._get_level_number(level)\n\n    if isinstance(frame.columns, MultiIndex):\n        return _stack_multi_columns(frame, level=level, dropna=True)\n    elif isinstance(frame.index, MultiIndex):\n        new_levels = list(frame.index.levels)\n        new_levels.append(frame.columns)\n\n        new_labels = [lab.repeat(K) for lab in frame.index.labels]\n        new_labels.append(np.tile(np.arange(K), N).ravel())\n\n        new_names = list(frame.index.names)\n        new_names.append(frame.columns.name)\n        new_index = MultiIndex(levels=new_levels, labels=new_labels,\n                               names=new_names)\n    else:\n        ilabels = np.arange(N).repeat(K)\n        clabels = np.tile(np.arange(K), N).ravel()\n        new_index = MultiIndex(levels=[frame.index, frame.columns],\n                               labels=[ilabels, clabels],\n                               names=[frame.index.name, frame.columns.name])\n\n    new_values = frame.values.ravel()\n    if dropna:\n        mask = notnull(new_values)\n        new_values = new_values[mask]\n        new_index = new_index[mask]\n    return Series(new_values, index=new_index)\n\n\ndef _stack_multi_columns(frame, level=-1, dropna=True):\n    this = frame.copy()\n\n    # this makes life much simpler\n    if level != frame.columns.nlevels - 1:\n        # roll levels to put selected level at end\n        roll_columns = this.columns\n        for i in range(level, frame.columns.nlevels - 1):\n            roll_columns = roll_columns.swaplevel(i, i + 1)\n        this.columns = roll_columns\n\n    if not this.columns.is_lexsorted():\n        this = this.sortlevel(0, axis=1)\n\n    # tuple list excluding level for grouping columns\n    if len(frame.columns.levels) > 2:\n        tuples = zip(*[lev.values.take(lab)\n                       for lev, lab in zip(this.columns.levels[:-1],\n                                           this.columns.labels[:-1])])\n        unique_groups = [key for key, _ in itertools.groupby(tuples)]\n        new_names = this.columns.names[:-1]\n        new_columns = MultiIndex.from_tuples(unique_groups, names=new_names)\n    else:\n        new_columns = unique_groups = this.columns.levels[0]\n\n    # time to ravel the values\n    new_data = {}\n    level_vals = this.columns.levels[-1]\n    levsize = len(level_vals)\n    for key in unique_groups:\n        loc = this.columns.get_loc(key)\n\n        # can make more efficient?\n        if loc.stop - loc.start != levsize:\n            chunk = this.ix[:, this.columns[loc]]\n            chunk.columns = level_vals.take(chunk.columns.labels[-1])\n            value_slice = chunk.reindex(columns=level_vals).values\n        else:\n            if frame._is_mixed_type:\n                value_slice = this.ix[:, this.columns[loc]].values\n            else:\n                value_slice = this.values[:, loc]\n\n        new_data[key] = value_slice.ravel()\n\n    N = len(this)\n\n    if isinstance(this.index, MultiIndex):\n        new_levels = list(this.index.levels)\n        new_names = list(this.index.names)\n        new_labels = [lab.repeat(levsize) for lab in this.index.labels]\n    else:\n        new_levels = [this.index]\n        new_labels = [np.arange(N).repeat(levsize)]\n        new_names = [this.index.name]  # something better?\n\n    new_levels.append(frame.columns.levels[level])\n    new_labels.append(np.tile(np.arange(levsize), N))\n    new_names.append(frame.columns.names[level])\n\n    new_index = MultiIndex(levels=new_levels, labels=new_labels,\n                           names=new_names)\n\n    result = DataFrame(new_data, index=new_index, columns=new_columns)\n\n    # more efficient way to go about this? can do the whole masking biz but\n    # will only save a small amount of time...\n    if dropna:\n        result = result.dropna(axis=0, how='all')\n\n    return result\n\n\ndef melt(frame, id_vars=None, value_vars=None):\n    \"\"\"\n    \"Unpivots\" a DataFrame from wide format to long format, optionally leaving\n    id variables set\n\n    Parameters\n    ----------\n    frame : DataFrame\n    id_vars :\n    value_vars :\n\n    Examples\n    --------\n    >>> df\n    A B C\n    a 1 2\n    b 3 4\n    c 5 6\n\n    >>> melt(df, id_vars=['A'], value_vars=['B'])\n    A variable value\n    a B        1\n    b B        3\n    c B        5\n    \"\"\"\n    # TODO: what about the existing index?\n    if id_vars is not None:\n        if not isinstance(id_vars, (tuple, list, np.ndarray)):\n            id_vars = [id_vars]\n        else:\n            id_vars = list(id_vars)\n    else:\n        id_vars = []\n\n    if value_vars is not None:\n        if not isinstance(value_vars, (tuple, list, np.ndarray)):\n            value_vars = [value_vars]\n        frame = frame.ix[:, id_vars + value_vars]\n    else:\n        frame = frame.copy()\n\n    N, K = frame.shape\n    K -= len(id_vars)\n\n    mdata = {}\n    for col in id_vars:\n        mdata[col] = np.tile(frame.pop(col).values, K)\n\n    mcolumns = id_vars + ['variable', 'value']\n\n    mdata['value'] = frame.values.ravel('F')\n\n    mdata['variable'] = np.asarray(frame.columns).repeat(N)\n    return DataFrame(mdata, columns=mcolumns)\n\n\ndef lreshape(data, groups, dropna=True, label=None):\n    \"\"\"\n    Reshape long-format data to wide. Generalized inverse of DataFrame.pivot\n\n    Parameters\n    ----------\n    data : DataFrame\n    groups : dict\n        {new_name : list_of_columns}\n    dropna : boolean, default True\n\n    Examples\n    --------\n    >>> data\n       hr1  hr2     team  year1  year2\n    0  514  545  Red Sox   2007   2008\n    1  573  526  Yankees   2007   2008\n\n    >>> pd.lreshape(data, {'year': ['year1', 'year2'],\n                           'hr': ['hr1', 'hr2']})\n          team   hr  year\n    0  Red Sox  514  2007\n    1  Yankees  573  2007\n    2  Red Sox  545  2008\n    3  Yankees  526  2008\n\n    Returns\n    -------\n    reshaped : DataFrame\n    \"\"\"\n    if isinstance(groups, dict):\n        keys = groups.keys()\n        values = groups.values()\n    else:\n        keys, values = zip(*groups)\n\n    all_cols = list(set.union(*[set(x) for x in values]))\n    id_cols = list(data.columns.diff(all_cols))\n\n    K = len(values[0])\n\n    for seq in values:\n        if len(seq) != K:\n            raise ValueError('All column lists must be same length')\n\n    mdata = {}\n    pivot_cols = []\n\n    for target, names in zip(keys, values):\n        mdata[target] = com._concat_compat([data[col].values for col in names])\n        pivot_cols.append(target)\n\n    for col in id_cols:\n        mdata[col] = np.tile(data[col].values, K)\n\n    if dropna:\n        mask = np.ones(len(mdata[pivot_cols[0]]), dtype=bool)\n        for c in pivot_cols:\n            mask &= notnull(mdata[c])\n        if not mask.all():\n            mdata = dict((k, v[mask]) for k, v in mdata.iteritems())\n\n    return DataFrame(mdata, columns=id_cols + pivot_cols)\n\n\ndef convert_dummies(data, cat_variables, prefix_sep='_'):\n    \"\"\"\n    Compute DataFrame with specified columns converted to dummy variables (0 /\n    1). Result columns will be prefixed with the column name, then the level\n    name, e.g. 'A_foo' for column A and level foo\n\n    Parameters\n    ----------\n    data : DataFrame\n    cat_variables : list-like\n        Must be column names in the DataFrame\n    prefix_sep : string, default '_'\n        String to use to separate column name from dummy level\n\n    Returns\n    -------\n    dummies : DataFrame\n    \"\"\"\n    result = data.drop(cat_variables, axis=1)\n    for variable in cat_variables:\n        dummies = get_dummies(data[variable], prefix=variable,\n                              prefix_sep=prefix_sep)\n        result = result.join(dummies)\n    return result\n\n\ndef get_dummies(data, prefix=None, prefix_sep='_'):\n    \"\"\"\n    Convert categorical variable into dummy/indicator variables\n\n    Parameters\n    ----------\n    data : array-like or Series\n    prefix : string, default None\n        String to append DataFrame column names\n    prefix_sep : string, default '_'\n        If appending prefix, separator/delimiter to use\n\n    Returns\n    -------\n    dummies : DataFrame\n    \"\"\"\n    cat = Categorical.from_array(np.asarray(data))\n    dummy_mat = np.eye(len(cat.levels)).take(cat.labels, axis=0)\n\n    if prefix is not None:\n        dummy_cols = ['%s%s%s' % (prefix, prefix_sep, str(v))\n                      for v in cat.levels]\n    else:\n        dummy_cols = cat.levels\n\n    if isinstance(data, Series):\n        index = data.index\n    else:\n        index = None\n\n    return DataFrame(dummy_mat, index=index, columns=dummy_cols)\n\n\ndef make_axis_dummies(frame, axis='minor', transform=None):\n    \"\"\"\n    Construct 1-0 dummy variables corresponding to designated axis\n    labels\n\n    Parameters\n    ----------\n    axis : {'major', 'minor'}, default 'minor'\n    transform : function, default None\n        Function to apply to axis labels first. For example, to\n        get \"day of week\" dummies in a time series regression you might\n        call:\n            make_axis_dummies(panel, axis='major',\n                              transform=lambda d: d.weekday())\n    Returns\n    -------\n    dummies : DataFrame\n        Column names taken from chosen axis\n    \"\"\"\n    numbers = {\n        'major': 0,\n        'minor': 1\n    }\n    num = numbers.get(axis, axis)\n\n    items = frame.index.levels[num]\n    labels = frame.index.labels[num]\n    if transform is not None:\n        mapped_items = items.map(transform)\n        cat = Categorical.from_array(mapped_items.take(labels))\n        labels = cat.labels\n        items = cat.levels\n\n    values = np.eye(len(items), dtype=float)\n    values = values.take(labels, axis=0)\n\n    return DataFrame(values, columns=items, index=frame.index)\n\n\ndef block2d_to_block3d(values, items, shape, major_labels, minor_labels,\n                       ref_items=None):\n    \"\"\"\n    Developer method for pivoting DataFrame -> Panel. Used in HDFStore and\n    DataFrame.to_panel\n    \"\"\"\n    from pandas.core.internals import make_block\n    panel_shape = (len(items),) + shape\n\n    # TODO: lexsort depth needs to be 2!!\n\n    # Create observation selection vector using major and minor\n    # labels, for converting to panel format.\n    selector = minor_labels + shape[1] * major_labels\n    mask = np.zeros(np.prod(shape), dtype=bool)\n    mask.put(selector, True)\n\n    pvalues = np.empty(panel_shape, dtype=values.dtype)\n    if not issubclass(pvalues.dtype.type, (np.integer, np.bool_)):\n        pvalues.fill(np.nan)\n    elif not mask.all():\n        pvalues = com._maybe_upcast(pvalues)\n        pvalues.fill(np.nan)\n\n    values = values\n    for i in xrange(len(items)):\n        pvalues[i].flat[mask] = values[:, i]\n\n    if ref_items is None:\n        ref_items = items\n\n    return make_block(pvalues, items, ref_items)\n\ndef block2d_to_blocknd(values, items, shape, labels, ref_items=None):\n    \"\"\" pivot to the labels shape \"\"\"\n    from pandas.core.internals import make_block\n    panel_shape = (len(items),) + shape\n\n    # TODO: lexsort depth needs to be 2!!\n\n    # Create observation selection vector using major and minor\n    # labels, for converting to panel format.\n    selector = factor_indexer(shape[1:],labels)\n    mask = np.zeros(np.prod(shape), dtype=bool)\n    mask.put(selector, True)\n\n    pvalues = np.empty(panel_shape, dtype=values.dtype)\n    if not issubclass(pvalues.dtype.type, (np.integer, np.bool_)):\n        pvalues.fill(np.nan)\n    elif not mask.all():\n        pvalues = com._maybe_upcast(pvalues)\n        pvalues.fill(np.nan)\n\n    values = values\n    for i in xrange(len(items)):\n        pvalues[i].flat[mask] = values[:, i]\n\n    if ref_items is None:\n        ref_items = items\n\n    return make_block(pvalues, items, ref_items)\n\ndef factor_indexer(shape, labels):\n    \"\"\" given a tuple of shape and a list of Factor lables, return the expanded label indexer \"\"\"\n    mult   = np.array(shape)[::-1].cumprod()[::-1]\n    return np.sum(np.array(labels).T * np.append(mult,[1]), axis=1).T\n",
      "file_patch": "@@ -244,8 +244,10 @@ def _unstack_multiple(data, clocs):\n         new_labels = recons_labels\n     else:\n         if isinstance(data.columns, MultiIndex):\n-            raise NotImplementedError('Unstacking multiple levels with '\n-                                      'hierarchical columns not yet supported')\n+            result = data\n+            for val in clocs:\n+                result = result.unstack(val)\n+            return result\n \n         dummy = DataFrame(data.values, index=dummy_index,\n                           columns=data.columns)\n",
      "files_name_in_blame_commit": [
        "reshape.py",
        "index.py",
        "test_pivot.py",
        "test_index.py"
      ]
    }
  },
  "commits_modify_file_before_fix": {
    "size": 233
  },
  "recursive_blame_commits": {}
}