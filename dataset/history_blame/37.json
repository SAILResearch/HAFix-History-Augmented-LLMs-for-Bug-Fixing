{
  "id": "37",
  "blame_commit": {
    "commit": {
      "commit_id": "bf6763458d08067edb43e83caf64661f3b968188",
      "commit_message": "BUG #19860 Corrected use of mixed indexes with .at (#22436)",
      "commit_author": "Marius Potgieter",
      "commit_date": "2018-08-29 08:49:02",
      "commit_parent": "e28d2a6281a58be67f2f303b45d2c7ee57067af0"
    },
    "function": {
      "function_name": "_convert_key",
      "function_code_before": "def _convert_key(self, key, is_setter=False):\n    \"\"\" require they keys to be the same type as the index (so we don't\n        fallback)\n        \"\"\"\n    if is_setter:\n        return list(key)\n    for (ax, i) in zip(self.obj.axes, key):\n        if ax.is_integer():\n            if not is_integer(i):\n                raise ValueError('At based indexing on an integer index can only have integer indexers')\n        elif is_integer(i):\n            raise ValueError('At based indexing on an non-integer index can only have non-integer indexers')\n    return key",
      "function_code_after": "def _convert_key(self, key, is_setter=False):\n    \"\"\" require they keys to be the same type as the index (so we don't\n        fallback)\n        \"\"\"\n    if is_setter:\n        return list(key)\n    for (ax, i) in zip(self.obj.axes, key):\n        if ax.is_integer():\n            if not is_integer(i):\n                raise ValueError('At based indexing on an integer index can only have integer indexers')\n        elif is_integer(i) and (not ax.holds_integer()):\n            raise ValueError('At based indexing on an non-integer index can only have non-integer indexers')\n    return key",
      "function_before_start_line": 2342,
      "function_before_end_line": 2361,
      "function_after_start_line": 2342,
      "function_after_end_line": 2361,
      "function_before_token_count": 73,
      "function_after_token_count": 80,
      "functions_name_modified_file": [
        "_convert_for_reindex",
        "_setitem_with_indexer",
        "check_bool_indexer",
        "_getitem_nested_tuple",
        "_align_panel",
        "_convert_to_indexer",
        "_getbool_axis",
        "_get_slice_axis",
        "_getitem_scalar",
        "_has_valid_tuple",
        "maybe_droplevels",
        "_align_series",
        "maybe_convert_ix",
        "_has_valid_setitem_indexer",
        "_multi_take_opportunity",
        "_non_reducing_slice",
        "__iter__",
        "_validate_key",
        "_convert_slice_indexer",
        "convert_missing_indexer",
        "_convert_scalar_indexer",
        "is_list_like_indexer",
        "maybe_convert_indices",
        "_get_setitem_indexer",
        "_validate_read_indexer",
        "_getitem_iterable",
        "_get_partial_string_timestamp_match_key",
        "_handle_lowerdim_multi_index_axis0",
        "_convert_tuple",
        "_is_scalar_access",
        "_is_nested_tuple_indexer",
        "_validate_integer",
        "_get_loc",
        "is_label_like",
        "_convert_range",
        "need_slice",
        "_has_valid_positional_setitem_indexer",
        "_maybe_numeric_slice",
        "__getitem__",
        "_get_listlike_indexer",
        "_getitem_tuple",
        "_getitem_axis",
        "__init__",
        "convert_to_index_sliceable",
        "convert_from_missing_indexer_tuple",
        "__call__",
        "check_setitem_lengths",
        "is_nested_tuple",
        "validate_indices",
        "_tuplify",
        "_getitem_lowerdim",
        "_multi_take",
        "_slice",
        "_get_list_axis",
        "get_indexers_list",
        "__setitem__",
        "_convert_key",
        "length_of_indexer",
        "_get_label",
        "_align_frame"
      ],
      "functions_name_all_files": [
        "map",
        "format",
        "_getbool_axis",
        "test_multitype_list_index_access",
        "is_floating",
        "get_loc",
        "identical",
        "test_dups_fancy_indexing",
        "_handle_lowerdim_multi_index_axis0",
        "test_mixed_index_not_contains",
        "_can_hold_identifiers_and_holds_name",
        "_format_native_types",
        "unique",
        "_getitem_tuple",
        "is_nested_tuple",
        "test_string_slice",
        "_multi_take",
        "_string_data_error",
        "_validate_join_method",
        "test_imethods_with_dups",
        "drop_duplicates",
        "_convert_for_reindex",
        "_simple_new",
        "test_validate_indices_low",
        "_update_inplace",
        "is_",
        "test_multi_assign",
        "_trim_front",
        "argsort",
        "_new_Index",
        "__contains__",
        "get_indexer",
        "test_at_and_iat_get",
        "drop",
        "test_iat_invalid_args",
        "test_at_with_tz",
        "_join_level",
        "_validate_integer",
        "_get_loc",
        "_make_arithmetic_op",
        "_get_consensus_name",
        "_join_monotonic",
        "test_rhs_alignment",
        "__xor__",
        "_get_level_number",
        "_invalid_indexer",
        "_getitem_lowerdim",
        "inferred_type",
        "__nonzero__",
        "length_of_indexer",
        "ravel",
        "test_slice_with_zero_step_raises",
        "test_maybe_numeric_slice",
        "_has_valid_setitem_indexer",
        "_get_level_values",
        "_maybe_cast_slice_bound",
        "__array__",
        "_try_get_item",
        "test_dups_fancy_indexing2",
        "test_mixed_index_assignment",
        "duplicated",
        "__call__",
        "__deepcopy__",
        "_validate_for_numeric_unaryop",
        "_is_strictly_monotonic_decreasing",
        "_join_non_unique",
        "test_none_coercion_loc_and_dataframe",
        "test_validate_indices_high",
        "repeat",
        "test_setitem_ndarray_1d",
        "test_coercion_with_setitem",
        "slice_locs",
        "test_mixed_index_contains",
        "test_range_in_series_indexing",
        "_constructor",
        "droplevel",
        "_get_nearest_indexer",
        "delete",
        "_maybe_promote",
        "to_series",
        "to_frame",
        "symmetric_difference",
        "view",
        "test_none_coercion_mixed_dtypes",
        "test_str_label_slicing_with_negative_step",
        "sort_values",
        "_getitem_scalar",
        "_align_series",
        "is_boolean",
        "_get_names",
        "_validate_key",
        "_get_unique_index",
        "_add_numeric_methods_disabled",
        "_is_scalar_access",
        "test_partial_boolean_frame_indexing",
        "default_index",
        "__getitem__",
        "__sub__",
        "_convert_key",
        "_get_label",
        "get_indexer_non_unique",
        "_setitem_with_indexer",
        "_validate_indexer",
        "_values",
        "test_mixed_index_at_iat_loc_iloc_dataframe",
        "test_at_and_iat_set",
        "_join_multi",
        "_get_fill_indexer",
        "_add_numeric_methods_unary",
        "is_all_dates",
        "slice_indexer",
        "_evaluate_with_datetime_like",
        "_get_loc_only_exact_matches",
        "maybe_convert_ix",
        "_format_with_header",
        "test_list_slice",
        "__hash__",
        "_convert_index_indexer",
        "__radd__",
        "is_categorical",
        "dtype_str",
        "__add__",
        "is_interval",
        "fillna",
        "_concat",
        "validate_indices",
        "is_type_compatible",
        "sortlevel",
        "__iadd__",
        "_slice",
        "_get_list_axis",
        "__setitem__",
        "_make_comparison_op",
        "test_no_reference_cycle",
        "test_validate_indices_empty",
        "_convert_to_indexer",
        "get_slice_bound",
        "_format_attrs",
        "_add_numeric_methods",
        "set_value",
        "test_coercion_with_loc",
        "__iter__",
        "_convert_list_indexer",
        "intersection",
        "test_astype_assignment",
        "_coerce_scalar_to_index",
        "need_slice",
        "_validate_for_numeric_binop",
        "_evaluate_with_timedelta_like",
        "_maybe_numeric_slice",
        "test_at_iat_coercion",
        "summary",
        "_convert_listlike_indexer",
        "convert_from_missing_indexer_tuple",
        "test_multi_nan_indexing",
        "values",
        "dropna",
        "_get_fill_indexer_searchsorted",
        "_sort_levels_monotonic",
        "__or__",
        "_get_slice_axis",
        "_has_valid_tuple",
        "memory_usage",
        "is_monotonic_decreasing",
        "_add_logical_methods_disabled",
        "_add_comparison_methods",
        "is_lexsorted_for_tuple",
        "_convert_slice_indexer",
        "_has_complex_internals",
        "_getitem_iterable",
        "_convert_tuple",
        "dtype",
        "is_mixed",
        "__new__",
        "_has_valid_positional_setitem_indexer",
        "test_setitem_dtype_upcast",
        "test_coercion_with_loc_setitem",
        "__init__",
        "_get_grouper_for_level",
        "test_float_index_non_scalar_assignment",
        "test_setitem_list",
        "test_at_to_fail",
        "contains",
        "maybe_convert_indices",
        "ensure_index",
        "is_numeric",
        "_getitem_nested_tuple",
        "set_names",
        "get_indexer_for",
        "_convert_for_op",
        "_validate_index_level",
        "test_set_index_nan",
        "asof_locs",
        "_is_strictly_monotonic_increasing",
        "take",
        "_convert_range",
        "union",
        "check_setitem_lengths",
        "__len__",
        "test_validate_indices_ok",
        "astype",
        "append",
        "_summary",
        "_non_reducing_slice",
        "isna",
        "is_list_like_indexer",
        "_get_setitem_indexer",
        "where",
        "__unicode__",
        "_maybe_cast_indexer",
        "_can_reindex",
        "_tuplify",
        "_mpl_repr",
        "_add_logical_methods",
        "equals",
        "__and__",
        "is_unique",
        "rename",
        "_convert_scalar_indexer",
        "_to_safe_for_reshape",
        "test_indexing_assignment_dict_already_exists",
        "_shallow_copy_with_infer",
        "_set_names",
        "get_value",
        "test_astype_assignment_with_dups",
        "_ensure_has_len",
        "_filter_indexer_tolerance",
        "is_object",
        "test_mixed_index_at_iat_loc_iloc_series",
        "__copy__",
        "test_float_index_at_iat",
        "test_indexer_caching",
        "_scalar_data_error",
        "_concat_same_dtype",
        "_align_frame",
        "test_non_reducing_slice",
        "test_index_not_contains",
        "test_index_type_coercion",
        "_align_panel",
        "test_indexing_mixed_frame_bug",
        "_cleanup",
        "test_indexing_dtypes_on_empty",
        "to_native_types",
        "_format_space",
        "_reindex_non_unique",
        "_wrap_joined_index",
        "notna",
        "_engine",
        "test_mi_access",
        "isin",
        "_is_memory_usage_qualified",
        "_maybe_update_attributes",
        "__setstate__",
        "get_indexers_list",
        "has_duplicates",
        "__rsub__",
        "_isnan",
        "shift",
        "_formatter_func",
        "_convert_can_do_setop",
        "_add_numeric_methods_add_sub_disabled",
        "hasnans",
        "_searchsorted_monotonic",
        "test_coercion_with_setitem_and_dataframe",
        "nlevels",
        "convert_missing_indexer",
        "_validate_read_indexer",
        "test_mixed_index_no_fallback",
        "_to_embed",
        "is_label_like",
        "__reduce__",
        "_try_convert_to_int_index",
        "convert_to_index_sliceable",
        "_wrap_union_result",
        "test_float_index_to_mixed",
        "_add_numeric_methods_binary",
        "holds_integer",
        "test_inf_upcast",
        "test_coercion_with_loc_and_series",
        "_assert_take_fillable",
        "_shallow_copy",
        "_nan_idxs",
        "groupby",
        "asof",
        "check_bool_indexer",
        "is_monotonic",
        "_assert_can_do_op",
        "_deepcopy_if_needed",
        "maybe_droplevels",
        "_convert_tolerance",
        "insert",
        "_multi_take_opportunity",
        "_reset_identity",
        "is_integer",
        "_is_nested_tuple_indexer",
        "test_coercion_with_setitem_and_series",
        "_get_attributes_dict",
        "difference",
        "_get_listlike_indexer",
        "putmask",
        "_assert_can_do_setop",
        "copy",
        "_format_data",
        "reindex",
        "_coerce_to_ndarray",
        "is_monotonic_increasing",
        "ensure_index_from_sequences",
        "_get_string_slice",
        "get_duplicates",
        "_get_partial_string_timestamp_match_key",
        "__array_wrap__",
        "get_values",
        "_validate_names",
        "_getitem_axis",
        "test_index_contains",
        "join",
        "_convert_arr_indexer",
        "sort"
      ],
      "functions_name_co_evolved_modified_file": [],
      "functions_name_co_evolved_all_files": [
        "test_mixed_index_not_contains",
        "test_mixed_index_no_fallback",
        "test_mixed_index_at_iat_loc_iloc_series",
        "get_value",
        "test_mixed_index_contains",
        "test_mixed_index_at_iat_loc_iloc_dataframe",
        "test_mixed_index_assignment"
      ]
    },
    "file": {
      "file_name": "indexing.py",
      "file_nloc": 1768,
      "file_complexity": 549,
      "file_token_count": 9229,
      "file_before": "# pylint: disable=W0223\nimport textwrap\nimport warnings\nimport numpy as np\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nfrom pandas.core.dtypes.generic import ABCDataFrame, ABCPanel, ABCSeries\nfrom pandas.core.dtypes.common import (\n    is_integer_dtype,\n    is_integer, is_float,\n    is_list_like,\n    is_sequence,\n    is_iterator,\n    is_scalar,\n    is_sparse,\n    ensure_platform_int)\nfrom pandas.core.dtypes.missing import isna, _infer_fill_value\nfrom pandas.errors import AbstractMethodError\nfrom pandas.util._decorators import Appender\n\nfrom pandas.core.index import Index, MultiIndex\n\nimport pandas.core.common as com\nfrom pandas._libs.indexing import _NDFrameIndexerBase\n\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix', _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc', _LocIndexer),\n        ('at', _AtIndexer),\n        ('iat', _iAtIndexer),\n    ]\n\n\n# \"null slice\"\n_NS = slice(None, None)\n\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    \"\"\"\n    Create an object to more easily perform multi-index slicing\n\n    See Also\n    --------\n    MultiIndex.remove_unused_levels : New MultiIndex with no unused levels.\n\n    Notes\n    -----\n    See :ref:`Defined Levels <advanced.shown_levels>`\n    for further info on slicing a MultiIndex.\n\n    Examples\n    --------\n\n    >>> midx = pd.MultiIndex.from_product([['A0','A1'], ['B0','B1','B2','B3']])\n    >>> columns = ['foo', 'bar']\n    >>> dfmi = pd.DataFrame(np.arange(16).reshape((len(midx), len(columns))),\n                            index=midx, columns=columns)\n\n    Using the default slice command:\n\n    >>> dfmi.loc[(slice(None), slice('B0', 'B1')), :]\n               foo  bar\n        A0 B0    0    1\n           B1    2    3\n        A1 B0    8    9\n           B1   10   11\n\n    Using the IndexSlice class for a more intuitive command:\n\n    >>> idx = pd.IndexSlice\n    >>> dfmi.loc[idx[:, 'B0':'B1'], :]\n               foo  bar\n        A0 B0    0    1\n           B1    2    3\n        A1 B0    8    9\n           B1   10   11\n    \"\"\"\n\n    def __getitem__(self, arg):\n        return arg\n\n\nIndexSlice = _IndexSlice()\n\n\nclass IndexingError(Exception):\n    pass\n\n\nclass _NDFrameIndexer(_NDFrameIndexerBase):\n    _valid_types = None\n    _exception = KeyError\n    axis = None\n\n    def __call__(self, axis=None):\n        # we need to return a copy of ourselves\n        new_self = self.__class__(self.name, self.obj)\n\n        if axis is not None:\n            axis = self.obj._get_axis_number(axis)\n        new_self.axis = axis\n        return new_self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            key = tuple(com.apply_if_callable(x, self.obj)\n                        for x in key)\n            try:\n                values = self.obj._get_value(*key)\n                if is_scalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            # we by definition only have the 0th axis\n            axis = self.axis or 0\n\n            key = com.apply_if_callable(key, self.obj)\n            return self._getitem_axis(key, axis=axis)\n\n    def _get_label(self, label, axis=None):\n        if axis is None:\n            axis = self.axis or 0\n\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            return self.obj._xs(label, axis=axis)\n        elif isinstance(label, tuple) and isinstance(label[axis], slice):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=None):\n        if axis is None:\n            axis = self.axis\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=None, kind=None):\n        if axis is None:\n            axis = self.axis\n        return self.obj._slice(obj, axis=axis, kind=kind)\n\n    def _get_setitem_indexer(self, key):\n        if self.axis is not None:\n            return self._convert_tuple(key, is_setter=True)\n\n        axis = self.obj._get_axis(0)\n\n        if isinstance(axis, MultiIndex) and self.name != 'iloc':\n            try:\n                return axis.get_loc(key)\n            except Exception:\n                pass\n\n        if isinstance(key, tuple):\n            try:\n                return self._convert_tuple(key, is_setter=True)\n            except IndexingError:\n                pass\n\n        if isinstance(key, range):\n            return self._convert_range(key, is_setter=True)\n\n        try:\n            return self._convert_to_indexer(key, is_setter=True)\n        except TypeError as e:\n\n            # invalid indexer type vs 'other' indexing errors\n            if 'cannot do' in str(e):\n                raise\n            raise IndexingError(key)\n\n    def __setitem__(self, key, value):\n        if isinstance(key, tuple):\n            key = tuple(com.apply_if_callable(x, self.obj)\n                        for x in key)\n        else:\n            key = com.apply_if_callable(key, self.obj)\n        indexer = self._get_setitem_indexer(key)\n        self._setitem_with_indexer(indexer, value)\n\n    def _validate_key(self, key, axis):\n        \"\"\"\n        Ensure that key is valid for current indexer.\n\n        Parameters\n        ----------\n        key : scalar, slice or list-like\n            The key requested\n\n        axis : int\n            Dimension on which the indexing is being made\n\n        Raises\n        ------\n        TypeError\n            If the key (or some element of it) has wrong type\n\n        IndexError\n            If the key (or some element of it) is out of bounds\n\n        KeyError\n            If the key was not found\n        \"\"\"\n        raise AbstractMethodError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            try:\n                self._validate_key(k, i)\n            except ValueError:\n                raise ValueError(\"Location based indexing can only have \"\n                                 \"[{types}] types\"\n                                 .format(types=self._valid_types))\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any(isinstance(ax, MultiIndex) for ax in self.obj.axes):\n            return any(is_nested_tuple(tup, ax) for ax in self.obj.axes)\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(\n                        key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                if i >= self.obj.ndim:\n                    raise IndexingError('Too many indexers')\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_range(self, key, is_setter=False):\n        \"\"\" convert a range argument \"\"\"\n        return list(key)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        if axis is None:\n            axis = 0\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, kind=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, kind=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n        will raise if needed, does not modify the indexer externally\n        \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like_indexer(i):\n                    # should check the elements?\n                    pass\n                elif is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{name} cannot enlarge its target \"\n                                         \"object\".format(name=self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{name} cannot enlarge its target object\"\n                                     .format(name=self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        # TODO: Panel, DataFrame are not imported, remove?\n        from pandas import Panel, DataFrame, Series  # noqa\n        info_axis = self.obj._info_axis_number\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n\n        # if there is only one block/type, still have to take split path\n        # unless the block is one-dimensional or it can hold the value\n        if not take_split_path and self.obj._data.blocks:\n            blk, = self.obj._data.blocks\n            if 1 < blk.ndim:  # in case of dict, keys are indices\n                val = list(value.values()) if isinstance(value,\n                                                         dict) else value\n                take_split_path = not blk._can_hold_element(val)\n\n        if isinstance(indexer, tuple) and len(indexer) == len(self.obj.axes):\n\n            for i, ax in zip(indexer, self.obj.axes):\n\n                # if we have any multi-indexes that have non-trivial slices\n                # (not null slices) then we must take the split path, xref\n                # GH 10360\n                if (isinstance(ax, MultiIndex) and\n                        not (is_integer(i) or com.is_null_slice(i))):\n                    take_split_path = True\n                    break\n\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any(not l for l in len_non_info_axes):\n                            if not is_list_like_indexer(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n                        # add a new item with the dtype setup\n                        self.obj[key] = _infer_fill_value(value)\n\n                        new_indexer = convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = index.insert(len(index), key)\n                    self.obj._data = self.obj.reindex(labels, axis=i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj._is_copy = None\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    new_index = index.insert(len(index), indexer)\n\n                    # we have a coerced indexer, e.g. a float\n                    # that matches in an Int64Index, so\n                    # we will not create a duplicate index, rather\n                    # index to that element\n                    # e.g. 0.0 -> 0\n                    # GH12246\n                    if index.is_unique:\n                        new_indexer = index.get_indexer([new_index[-1]])\n                        if (new_indexer != -1).any():\n                            return self._setitem_with_indexer(new_indexer,\n                                                              value)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value])._values\n                    if len(self.obj._values):\n                        try:\n                            new_values = np.concatenate([self.obj._values,\n                                                         new_values])\n                        except TypeError:\n                            as_obj = self.obj.astype(object)\n                            new_values = np.concatenate([as_obj,\n                                                         new_values])\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\"cannot set a frame with no defined \"\n                                         \"columns\")\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,\n                                              copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if is_list_like_indexer(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\"cannot set a row with \"\n                                                 \"mismatched columns\")\n\n                        value = Series(value, index=self.obj.columns,\n                                       name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        item_labels = self.obj._get_axis(info_axis)\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].axes[0], MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like_indexer(value) and np.iterable(\n                        value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\"cannot set using a multi-index \"\n                                         \"selection indexer with a different \"\n                                         \"length than the value\")\n\n                    # make sure we have an ndarray\n                    value = getattr(value, 'values', value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj._consolidate_inplace()\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]),\n                                                  value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = length_of_indexer(plane_indexer[0],\n                                                       plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice or a slice with full bounds\n                # which means essentially reassign to the columns of a\n                # multi-dim object\n                # GH6149 (null slice), GH10408 (full bounds)\n                if (isinstance(pi, tuple) and\n                        all(com.is_null_slice(idx) or\n                            com.is_full_slice(idx, len(self.obj))\n                            for idx in pi)):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s._consolidate_inplace()\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if (not len(labels) == 1 or not np.iterable(value) or\n                        is_scalar(plane_indexer[0])):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an iterable, with a ndim of at least 1\n            # eg. don't pass through np.array(0)\n            if is_list_like_indexer(value) and getattr(value, 'ndim', 1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n                    sub_indexer = list(indexer)\n                    multiindex_indexer = isinstance(labels, MultiIndex)\n\n                    for item in labels:\n                        if item in value:\n                            sub_indexer[info_axis] = item\n                            v = self._align_series(\n                                tuple(sub_indexer), value[item],\n                                multiindex_indexer)\n                        else:\n                            v = np.nan\n\n                        setter(item, v)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value, dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = maybe_convert_ix(*indexer)\n\n                # if we are setting on the info axis ONLY\n                # set using those methods to avoid block-splitting\n                # logic here\n                if (len(indexer) > info_axis and\n                        is_integer(indexer[info_axis]) and\n                        all(com.is_null_slice(idx)\n                            for i, idx in enumerate(indexer)\n                            if i != info_axis) and\n                        item_labels.is_unique):\n                    self.obj[item_labels[indexer[info_axis]]] = value\n                    return\n\n            if isinstance(value, (ABCSeries, dict)):\n                # TODO(EA): ExtensionBlock.setitem this causes issues with\n                # setting for extensionarrays that store dicts. Need to decide\n                # if it's worth supporting that.\n                value = self._align_series(indexer, Series(value))\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._consolidate_inplace()\n            self.obj._data = self.obj._data.setitem(indexer=indexer,\n                                                    value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser, multiindex_indexer=False):\n        \"\"\"\n        Parameters\n        ----------\n        indexer : tuple, slice, scalar\n            The indexer used to get the locations that will be set to\n            `ser`\n\n        ser : pd.Series\n            The values to assign to the locations specified by `indexer`\n\n        multiindex_indexer : boolean, optional\n            Defaults to False. Should be set to True if `indexer` was from\n            a `pd.MultiIndex`, to avoid unnecessary broadcasting.\n\n\n        Returns:\n        --------\n        `np.array` of `ser` broadcast to the appropriate shape for assignment\n        to the locations selected by `indexer`\n\n        \"\"\"\n        if isinstance(indexer, (slice, np.ndarray, list, Index)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            # flatten np.ndarray indexers\n            def ravel(i):\n                return i.ravel() if isinstance(i, np.ndarray) else i\n            indexer = tuple(map(ravel, indexer))\n\n            aligners = [not com.is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all(is_sequence(_) for _ in indexer)):\n                ser = ser.reindex(obj.axes[0][indexer[0]], copy=True)._values\n\n                # single indexer\n                if len(indexer) > 1 and not multiindex_indexer:\n                    l = len(indexer[1])\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and com.is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like_indexer(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix)\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser._values.copy()\n\n                    return ser.reindex(new_ix)._values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser._values.copy()\n                    return ser.reindex(ax)._values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser._values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif is_scalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser._values.copy()\n\n            return ser.reindex(ax)._values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n\n        if isinstance(indexer, tuple):\n\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if is_sequence(ix) or isinstance(ix, slice):\n                    if isinstance(ix, np.ndarray):\n                        ix = ix.ravel()\n                    if idx is None:\n                        idx = ax[ix]\n                    elif cols is None:\n                        cols = ax[ix]\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n\n                # need to conform to the convention\n                # as we are not selecting on the items axis\n                # and we have a single indexer\n                # GH 7763\n                if len(sindexers) == 1 and sindexers[0] != 0:\n                    df = df.T\n\n                if idx is None:\n                    idx = df.index\n                if cols is None:\n                    cols = df.columns\n\n            if idx is not None and cols is not None:\n\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy()._values\n                else:\n                    val = df.reindex(idx, columns=cols)._values\n                return val\n\n        elif ((isinstance(indexer, slice) or is_list_like_indexer(indexer)) and\n              is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy()._values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if (isinstance(ax, MultiIndex) and\n                        isinstance(df.index, MultiIndex) and\n                        ax.nlevels != df.index.nlevels):\n                    raise TypeError(\"cannot align on a multi-index with out \"\n                                    \"specifying the join levels\")\n\n                val = df.reindex(index=ax)._values\n            return val\n\n        elif is_scalar(indexer) and is_panel:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy()._values\n\n            return df.reindex(idx, columns=cols)._values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if com.is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        \"\"\"\n        Check whether there is the possibility to use ``_multi_take``.\n        Currently the limit is that all axes being indexed must be indexed with\n        list-likes.\n\n        Parameters\n        ----------\n        tup : tuple\n            Tuple of indexers, one per axis\n\n        Returns\n        -------\n        boolean: Whether the current indexing can be passed through _multi_take\n        \"\"\"\n        if not all(is_list_like_indexer(x) for x in tup):\n            return False\n\n        # just too complicated\n        if any(com.is_bool_indexer(x) for x in tup):\n            return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\"\n        Create the indexers for the passed tuple of keys, and execute the take\n        operation. This allows the take operation to be executed all at once -\n        rather than once for each dimension - improving efficiency.\n\n        Parameters\n        ----------\n        tup : tuple\n            Tuple of indexers, one per axis\n\n        Returns\n        -------\n        values: same type as the object being indexed\n        \"\"\"\n        # GH 836\n        o = self.obj\n        d = {axis: self._get_listlike_indexer(key, axis)\n             for (key, axis) in zip(tup, o._AXIS_ORDERS)}\n        return o._reindex_with_indexers(d, copy=True, allow_dups=True)\n\n    def _convert_for_reindex(self, key, axis=None):\n        return key\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=self.axis)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        # ...but iloc should handle the tuple as simple integer-location\n        # instead of checking it as multiindex representation (GH 13797)\n        if isinstance(ax0, MultiIndex) and self.name != 'iloc':\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not is_list_like_indexer(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0 and\n                            len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # Slices should return views, but calling iloc/loc with a null\n                # slice returns a new object.\n                if com.is_null_slice(new_key):\n                    return section\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of\n            # selectors\n            return self._getitem_axis(tup, axis=self.axis)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if com.is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if is_scalar(obj) or not hasattr(obj, 'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=None):\n\n        if axis is None:\n            axis = self.axis or 0\n\n        if is_iterator(key):\n            key = list(key)\n        self._validate_key(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif (is_list_like_indexer(key) and\n              not (isinstance(key, tuple) and\n                   isinstance(labels, MultiIndex))):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n\n            # maybe coerce a float scalar to integer\n            key = labels._maybe_cast_indexer(key)\n\n            if is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _get_listlike_indexer(self, key, axis, raise_missing=False):\n        \"\"\"\n        Transform a list-like of keys into a new index and an indexer.\n\n        Parameters\n        ----------\n        key : list-like\n            Target labels\n        axis: int\n            Dimension on which the indexing is being made\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n\n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n\n        Returns\n        -------\n        keyarr: Index\n            New index (coinciding with 'key' if the axis is unique)\n        values : array-like\n            An indexer for the return object; -1 denotes keys not found\n        \"\"\"\n        o = self.obj\n        ax = o._get_axis(axis)\n\n        # Have the index compute an indexer or return None\n        # if it cannot handle:\n        indexer, keyarr = ax._convert_listlike_indexer(key,\n                                                       kind=self.name)\n        # We only act on all found values:\n        if indexer is not None and (indexer != -1).all():\n            self._validate_read_indexer(key, indexer, axis,\n                                        raise_missing=raise_missing)\n            return ax[indexer], indexer\n\n        if ax.is_unique:\n            # If we are trying to get actual keys from empty Series, we\n            # patiently wait for a KeyError later on - otherwise, convert\n            if len(ax) or not len(key):\n                key = self._convert_for_reindex(key, axis)\n            indexer = ax.get_indexer_for(key)\n            keyarr = ax.reindex(keyarr)[0]\n        else:\n            keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr)\n\n        self._validate_read_indexer(keyarr, indexer,\n                                    o._get_axis_number(axis),\n                                    raise_missing=raise_missing)\n        return keyarr, indexer\n\n    def _getitem_iterable(self, key, axis=None):\n        \"\"\"\n        Index current object with an an iterable key (which can be a boolean\n        indexer, or a collection of keys).\n\n        Parameters\n        ----------\n        key : iterable\n            Target labels, or boolean indexer\n        axis: int, default None\n            Dimension on which the indexing is being made\n\n        Raises\n        ------\n        KeyError\n            If no key was found. Will change in the future to raise if not all\n            keys were found.\n        IndexingError\n            If the boolean indexer is unalignable with the object being\n            indexed.\n\n        Returns\n        -------\n        scalar, DataFrame, or Series: indexed value(s),\n        \"\"\"\n\n        if axis is None:\n            axis = self.axis or 0\n\n        self._validate_key(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        if com.is_bool_indexer(key):\n            # A boolean indexer\n            key = check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj._take(inds, axis=axis)\n        else:\n            # A collection of keys\n            keyarr, indexer = self._get_listlike_indexer(key, axis,\n                                                         raise_missing=False)\n            return self.obj._reindex_with_indexers({axis: [keyarr, indexer]},\n                                                   copy=True, allow_dups=True)\n\n    def _validate_read_indexer(self, key, indexer, axis, raise_missing=False):\n        \"\"\"\n        Check that indexer can be used to return a result (e.g. at least one\n        element was found, unless the list of keys was actually empty).\n\n        Parameters\n        ----------\n        key : list-like\n            Target labels (only used to show correct error message)\n        indexer: array-like of booleans\n            Indices corresponding to the key (with -1 indicating not found)\n        axis: int\n            Dimension on which the indexing is being made\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n\n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n\n        ax = self.obj._get_axis(axis)\n\n        if len(key) == 0:\n            return\n\n        # Count missing values:\n        missing = (indexer < 0).sum()\n\n        if missing:\n            if missing == len(indexer):\n                raise KeyError(\n                    u\"None of [{key}] are in the [{axis}]\".format(\n                        key=key, axis=self.obj._get_axis_name(axis)))\n\n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if not(self.name == 'loc' and not raise_missing):\n                not_found = list(set(key) - set(ax))\n                raise KeyError(\"{} not in index\".format(not_found))\n\n            # we skip the warning on Categorical/Interval\n            # as this check is actually done (check for\n            # non-missing values), but a bit later in the\n            # code, so we want to avoid warning & then\n            # just raising\n\n            _missing_key_warning = textwrap.dedent(\"\"\"\n            Passing list-likes to .loc or [] with any missing label will raise\n            KeyError in the future, you can use .reindex() as an alternative.\n\n            See the documentation here:\n            https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\"\"\")  # noqa\n\n            if not (ax.is_categorical() or ax.is_interval()):\n                warnings.warn(_missing_key_warning,\n                              FutureWarning, stacklevel=6)\n\n    def _convert_to_indexer(self, obj, axis=None, is_setter=False,\n                            raise_missing=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        'In the face of ambiguity, refuse the temptation to guess.'\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        if axis is None:\n            axis = self.axis or 0\n\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        # try to find out correct indexer, if not type correct raise\n        try:\n            obj = self._convert_scalar_indexer(obj, axis)\n        except TypeError:\n\n            # but we will allow setting\n            if is_setter:\n                pass\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except LookupError:\n            if isinstance(obj, tuple) and isinstance(labels, MultiIndex):\n                if is_setter and len(obj) == labels.nlevels:\n                    return {'key': obj}\n                raise\n        except TypeError:\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n\n        elif is_list_like_indexer(obj):\n\n            if com.is_bool_indexer(obj):\n                obj = check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                # When setting, missing keys are not allowed, even with .loc:\n                kwargs = {'raise_missing': True if is_setter else\n                          raise_missing}\n                return self._get_listlike_indexer(obj, axis, **kwargs)[1]\n        else:\n            try:\n                return labels.get_loc(obj)\n            except LookupError:\n                # allow a not found key only if we are a setter\n                if not is_list_like_indexer(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=None):\n        obj = self.obj\n\n        if axis is None:\n            axis = self.axis or 0\n\n        if not need_slice(slice_obj):\n            return obj.copy(deep=False)\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, kind='iloc')\n        else:\n            return self.obj._take(indexer, axis=axis)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n    \"\"\"A primarily label-location based indexer, with integer position\n    fallback.\n\n    Warning: Starting in 0.20.0, the .ix indexer is deprecated, in\n    favor of the more strict .iloc and .loc indexers.\n\n    ``.ix[]`` supports mixed integer and label based access. It is\n    primarily label based, but will fall back to integer positional\n    access unless the corresponding axis is of integer type.\n\n    ``.ix`` is the most general indexer and will support any of the\n    inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n    point label schemes. ``.ix`` is exceptionally useful when dealing\n    with mixed positional and label based hierarchical indexes.\n\n    However, when an axis is integer based, ONLY label based access\n    and not positional access is supported. Thus, in such cases, it's\n    usually better to be explicit and use ``.iloc`` or ``.loc``.\n\n    See more at :ref:`Advanced Indexing <advanced>`.\n\n    \"\"\"\n\n    def __init__(self, name, obj):\n\n        _ix_deprecation_warning = textwrap.dedent(\"\"\"\n            .ix is deprecated. Please use\n            .loc for label based indexing or\n            .iloc for positional indexing\n\n            See the documentation here:\n            http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\"\"\")  # noqa\n\n        warnings.warn(_ix_deprecation_warning,\n                      DeprecationWarning, stacklevel=2)\n        super(_IXIndexer, self).__init__(name, obj)\n\n    @Appender(_NDFrameIndexer._validate_key.__doc__)\n    def _validate_key(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif com.is_bool_indexer(key):\n            return True\n\n        elif is_list_like_indexer(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n    def _convert_for_reindex(self, key, axis=None):\n        \"\"\"\n        Transform a list of keys into a new array ready to be used as axis of\n        the object we return (e.g. including NaNs).\n\n        Parameters\n        ----------\n        key : list-like\n            Target labels\n        axis: int\n            Where the indexing is being made\n\n        Returns\n        -------\n        list-like of labels\n        \"\"\"\n\n        if axis is None:\n            axis = self.axis or 0\n        labels = self.obj._get_axis(axis)\n\n        if com.is_bool_indexer(key):\n            key = check_bool_indexer(labels, key)\n            return labels[key]\n\n        if isinstance(key, Index):\n            keyarr = labels._convert_index_indexer(key)\n        else:\n            # asarray can be unsafe, NumPy strings are weird\n            keyarr = com.asarray_tuplesafe(key)\n\n        if is_integer_dtype(keyarr):\n            # Cast the indexer to uint64 if possible so\n            # that the values returned from indexing are\n            # also uint64.\n            keyarr = labels._convert_arr_indexer(keyarr)\n\n            if not labels.is_integer():\n                keyarr = ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n        return keyarr\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            key = tuple(com.apply_if_callable(x, self.obj)\n                        for x in key)\n            try:\n                if self._is_scalar_access(key):\n                    return self._getitem_scalar(key)\n            except (KeyError, IndexError):\n                pass\n            return self._getitem_tuple(key)\n        else:\n            # we by definition only have the 0th axis\n            axis = self.axis or 0\n\n            maybe_callable = com.apply_if_callable(key, self.obj)\n            return self._getitem_axis(maybe_callable, axis=axis)\n\n    def _is_scalar_access(self, key):\n        raise NotImplementedError()\n\n    def _getitem_scalar(self, key):\n        raise NotImplementedError()\n\n    def _getitem_axis(self, key, axis=None):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=None):\n        if axis is None:\n            axis = self.axis or 0\n        labels = self.obj._get_axis(axis)\n        key = check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj._take(inds, axis=axis)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=None):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        if axis is None:\n            axis = self.axis or 0\n\n        obj = self.obj\n        if not need_slice(slice_obj):\n            return obj.copy(deep=False)\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step, kind=self.name)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, kind='iloc')\n        else:\n            return self.obj._take(indexer, axis=axis)\n\n\nclass _LocIndexer(_LocationIndexer):\n    \"\"\"\n    Access a group of rows and columns by label(s) or a boolean array.\n\n    ``.loc[]`` is primarily label based, but may also be used with a\n    boolean array.\n\n    Allowed inputs are:\n\n    - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n      interpreted as a *label* of the index, and **never** as an\n      integer position along the index).\n    - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n    - A slice object with labels, e.g. ``'a':'f'``.\n\n      .. warning:: Note that contrary to usual python slices, **both** the\n          start and the stop are included\n\n    - A boolean array of the same length as the axis being sliced,\n      e.g. ``[True, False, True]``.\n    - A ``callable`` function with one argument (the calling Series, DataFrame\n      or Panel) and that returns valid output for indexing (one of the above)\n\n    See more at :ref:`Selection by Label <indexing.label>`\n\n    See Also\n    --------\n    DataFrame.at : Access a single value for a row/column label pair\n    DataFrame.iloc : Access group of rows and columns by integer position(s)\n    DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n        Series/DataFrame.\n    Series.loc : Access group of values using labels\n\n    Examples\n    --------\n    **Getting values**\n\n    >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n    ...      index=['cobra', 'viper', 'sidewinder'],\n    ...      columns=['max_speed', 'shield'])\n    >>> df\n                max_speed  shield\n    cobra               1       2\n    viper               4       5\n    sidewinder          7       8\n\n    Single label. Note this returns the row as a Series.\n\n    >>> df.loc['viper']\n    max_speed    4\n    shield       5\n    Name: viper, dtype: int64\n\n    List of labels. Note using ``[[]]`` returns a DataFrame.\n\n    >>> df.loc[['viper', 'sidewinder']]\n                max_speed  shield\n    viper               4       5\n    sidewinder          7       8\n\n    Single label for row and column\n\n    >>> df.loc['cobra', 'shield']\n    2\n\n    Slice with labels for row and single label for column. As mentioned\n    above, note that both the start and stop of the slice are included.\n\n    >>> df.loc['cobra':'viper', 'max_speed']\n    cobra    1\n    viper    4\n    Name: max_speed, dtype: int64\n\n    Boolean list with the same length as the row axis\n\n    >>> df.loc[[False, False, True]]\n                max_speed  shield\n    sidewinder          7       8\n\n    Conditional that returns a boolean Series\n\n    >>> df.loc[df['shield'] > 6]\n                max_speed  shield\n    sidewinder          7       8\n\n    Conditional that returns a boolean Series with column labels specified\n\n    >>> df.loc[df['shield'] > 6, ['max_speed']]\n                max_speed\n    sidewinder          7\n\n    Callable that returns a boolean Series\n\n    >>> df.loc[lambda df: df['shield'] == 8]\n                max_speed  shield\n    sidewinder          7       8\n\n    **Setting values**\n\n    Set value for all items matching the list of labels\n\n    >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n    >>> df\n                max_speed  shield\n    cobra               1       2\n    viper               4      50\n    sidewinder          7      50\n\n    Set value for an entire row\n\n    >>> df.loc['cobra'] = 10\n    >>> df\n                max_speed  shield\n    cobra              10      10\n    viper               4      50\n    sidewinder          7      50\n\n    Set value for an entire column\n\n    >>> df.loc[:, 'max_speed'] = 30\n    >>> df\n                max_speed  shield\n    cobra              30      10\n    viper              30      50\n    sidewinder         30      50\n\n    Set value for rows matching callable condition\n\n    >>> df.loc[df['shield'] > 35] = 0\n    >>> df\n                max_speed  shield\n    cobra              30      10\n    viper               0       0\n    sidewinder          0       0\n\n    **Getting values on a DataFrame with an index that has integer labels**\n\n    Another example using integers for the index\n\n    >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n    ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n    >>> df\n       max_speed  shield\n    7          1       2\n    8          4       5\n    9          7       8\n\n    Slice with integer labels for rows. As mentioned above, note that both\n    the start and stop of the slice are included.\n\n    >>> df.loc[7:9]\n       max_speed  shield\n    7          1       2\n    8          4       5\n    9          7       8\n\n    **Getting values with a MultiIndex**\n\n    A number of examples using a DataFrame with a MultiIndex\n\n    >>> tuples = [\n    ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n    ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n    ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n    ... ]\n    >>> index = pd.MultiIndex.from_tuples(tuples)\n    >>> values = [[12, 2], [0, 4], [10, 20],\n    ...         [1, 4], [7, 1], [16, 36]]\n    >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n    >>> df\n                         max_speed  shield\n    cobra      mark i           12       2\n               mark ii           0       4\n    sidewinder mark i           10      20\n               mark ii           1       4\n    viper      mark ii           7       1\n               mark iii         16      36\n\n    Single label. Note this returns a DataFrame with a single index.\n\n    >>> df.loc['cobra']\n             max_speed  shield\n    mark i          12       2\n    mark ii          0       4\n\n    Single index tuple. Note this returns a Series.\n\n    >>> df.loc[('cobra', 'mark ii')]\n    max_speed    0\n    shield       4\n    Name: (cobra, mark ii), dtype: int64\n\n    Single label for row and column. Similar to passing in a tuple, this\n    returns a Series.\n\n    >>> df.loc['cobra', 'mark i']\n    max_speed    12\n    shield        2\n    Name: (cobra, mark i), dtype: int64\n\n    Single tuple. Note using ``[[]]`` returns a DataFrame.\n\n    >>> df.loc[[('cobra', 'mark ii')]]\n                   max_speed  shield\n    cobra mark ii          0       4\n\n    Single tuple for the index with a single label for the column\n\n    >>> df.loc[('cobra', 'mark i'), 'shield']\n    2\n\n    Slice from index tuple to single label\n\n    >>> df.loc[('cobra', 'mark i'):'viper']\n                         max_speed  shield\n    cobra      mark i           12       2\n               mark ii           0       4\n    sidewinder mark i           10      20\n               mark ii           1       4\n    viper      mark ii           7       1\n               mark iii         16      36\n\n    Slice from index tuple to index tuple\n\n    >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n                        max_speed  shield\n    cobra      mark i          12       2\n               mark ii          0       4\n    sidewinder mark i          10      20\n               mark ii          1       4\n    viper      mark ii          7       1\n\n    Raises\n    ------\n    KeyError:\n        when any items are not found\n    \"\"\"\n\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    @Appender(_NDFrameIndexer._validate_key.__doc__)\n    def _validate_key(self, key, axis):\n\n        # valid for a collection of labels (we check their presence later)\n        # slice of labels (where start-end in labels)\n        # slice of integers (only if in the labels)\n        # boolean\n\n        if isinstance(key, slice):\n            return\n\n        if com.is_bool_indexer(key):\n            return\n\n        if not is_list_like_indexer(key):\n            self._convert_scalar_indexer(key, axis)\n\n    def _is_scalar_access(self, key):\n        # this is a shortcut accessor to both .loc and .iloc\n        # that provide the equivalent access of .at and .iat\n        # a) avoid getting things via sections and (to minimize dtype changes)\n        # b) provide a performant path\n        if not hasattr(key, '__len__'):\n            return False\n\n        if len(key) != self.ndim:\n            return False\n\n        for i, k in enumerate(key):\n            if not is_scalar(k):\n                return False\n\n            ax = self.obj.axes[i]\n            if isinstance(ax, MultiIndex):\n                return False\n\n            if not ax.is_unique:\n                return False\n\n        return True\n\n    def _getitem_scalar(self, key):\n        # a fast-path to scalar access\n        # if not, raise\n        values = self.obj._get_value(*key)\n        return values\n\n    def _get_partial_string_timestamp_match_key(self, key, labels):\n        \"\"\"Translate any partial string timestamp matches in key, returning the\n        new key (GH 10331)\"\"\"\n        if isinstance(labels, MultiIndex):\n            if isinstance(key, compat.string_types) and \\\n                    labels.levels[0].is_all_dates:\n                # Convert key '2016-01-01' to\n                # ('2016-01-01'[, slice(None, None, None)]+)\n                key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))\n\n            if isinstance(key, tuple):\n                # Convert (..., '2016-01-01', ...) in tuple to\n                # (..., slice('2016-01-01', '2016-01-01', None), ...)\n                new_key = []\n                for i, component in enumerate(key):\n                    if isinstance(component, compat.string_types) and \\\n                            labels.levels[i].is_all_dates:\n                        new_key.append(slice(component, component, None))\n                    else:\n                        new_key.append(component)\n                key = tuple(new_key)\n\n        return key\n\n    def _getitem_axis(self, key, axis=None):\n        if axis is None:\n            axis = self.axis or 0\n\n        if is_iterator(key):\n            key = list(key)\n\n        labels = self.obj._get_axis(axis)\n        key = self._get_partial_string_timestamp_match_key(key, labels)\n\n        if isinstance(key, slice):\n            self._validate_key(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif com.is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif is_list_like_indexer(key):\n\n            # convert various list-like indexers\n            # to a list of keys\n            # we will use the *values* of the object\n            # and NOT the index if its a PandasObject\n            if isinstance(labels, MultiIndex):\n\n                if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:\n                    # Series, or 0,1 ndim ndarray\n                    # GH 14730\n                    key = list(key)\n                elif isinstance(key, ABCDataFrame):\n                    # GH 15438\n                    raise NotImplementedError(\"Indexing a MultiIndex with a \"\n                                              \"DataFrame key is not \"\n                                              \"implemented\")\n                elif hasattr(key, 'ndim') and key.ndim > 1:\n                    raise NotImplementedError(\"Indexing a MultiIndex with a \"\n                                              \"multidimensional key is not \"\n                                              \"implemented\")\n\n                if (not isinstance(key, tuple) and len(key) > 1 and\n                        not isinstance(key[0], tuple)):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [slice(None)] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._validate_key(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n    \"\"\"\n    Purely integer-location based indexing for selection by position.\n\n    ``.iloc[]`` is primarily integer position based (from ``0`` to\n    ``length-1`` of the axis), but may also be used with a boolean\n    array.\n\n    Allowed inputs are:\n\n    - An integer, e.g. ``5``.\n    - A list or array of integers, e.g. ``[4, 3, 0]``.\n    - A slice object with ints, e.g. ``1:7``.\n    - A boolean array.\n    - A ``callable`` function with one argument (the calling Series, DataFrame\n      or Panel) and that returns valid output for indexing (one of the above).\n      This is useful in method chains, when you don't have a reference to the\n      calling object, but would like to base your selection on some value.\n\n    ``.iloc`` will raise ``IndexError`` if a requested indexer is\n    out-of-bounds, except *slice* indexers which allow out-of-bounds\n    indexing (this conforms with python/numpy *slice* semantics).\n\n    See more at ref:`Selection by Position <indexing.integer>`.\n\n    See Also\n    --------\n    DataFrame.iat : Fast integer location scalar accessor.\n    DataFrame.loc : Purely label-location based indexer for selection by label.\n    Series.iloc : Purely integer-location based indexing for\n                   selection by position.\n\n    Examples\n    --------\n\n    >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n    ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n    ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n    >>> df = pd.DataFrame(mydict)\n    >>> df\n          a     b     c     d\n    0     1     2     3     4\n    1   100   200   300   400\n    2  1000  2000  3000  4000\n\n    **Indexing just the rows**\n\n    With a scalar integer.\n\n    >>> type(df.iloc[0])\n    <class 'pandas.core.series.Series'>\n    >>> df.iloc[0]\n    a    1\n    b    2\n    c    3\n    d    4\n    Name: 0, dtype: int64\n\n    With a list of integers.\n\n    >>> df.iloc[[0]]\n       a  b  c  d\n    0  1  2  3  4\n    >>> type(df.iloc[[0]])\n    <class 'pandas.core.frame.DataFrame'>\n\n    >>> df.iloc[[0, 1]]\n         a    b    c    d\n    0    1    2    3    4\n    1  100  200  300  400\n\n    With a `slice` object.\n\n    >>> df.iloc[:3]\n          a     b     c     d\n    0     1     2     3     4\n    1   100   200   300   400\n    2  1000  2000  3000  4000\n\n    With a boolean mask the same length as the index.\n\n    >>> df.iloc[[True, False, True]]\n          a     b     c     d\n    0     1     2     3     4\n    2  1000  2000  3000  4000\n\n    With a callable, useful in method chains. The `x` passed\n    to the ``lambda`` is the DataFrame being sliced. This selects\n    the rows whose index label even.\n\n    >>> df.iloc[lambda x: x.index % 2 == 0]\n          a     b     c     d\n    0     1     2     3     4\n    2  1000  2000  3000  4000\n\n    **Indexing both axes**\n\n    You can mix the indexer types for the index and columns. Use ``:`` to\n    select the entire axis.\n\n    With scalar integers.\n\n    >>> df.iloc[0, 1]\n    2\n\n    With lists of integers.\n\n    >>> df.iloc[[0, 2], [1, 3]]\n          b     d\n    0     2     4\n    2  2000  4000\n\n    With `slice` objects.\n\n    >>> df.iloc[1:3, 0:3]\n          a     b     c\n    1   100   200   300\n    2  1000  2000  3000\n\n    With a boolean array whose length matches the columns.\n\n    >>> df.iloc[:, [True, False, True, False]]\n          a     c\n    0     1     3\n    1   100   300\n    2  1000  3000\n\n    With a callable function that expects the Series or DataFrame.\n\n    >>> df.iloc[:, lambda df: [0, 2]]\n          a     c\n    0     1     3\n    1   100   300\n    2  1000  3000\n    \"\"\"\n\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _validate_key(self, key, axis):\n        if com.is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\"iLocation based boolean \"\n                                              \"indexing on an integer type \"\n                                              \"is not available\")\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return\n\n        if isinstance(key, slice):\n            return\n        elif is_integer(key):\n            self._validate_integer(key, axis)\n        elif isinstance(key, tuple):\n            # a tuple should already have been caught by this point\n            # so don't treat a tuple as a valid indexer\n            raise IndexingError('Too many indexers')\n        elif is_list_like_indexer(key):\n            # check that the key does not exceed the maximum size of the index\n            arr = np.array(key)\n            l = len(self.obj._get_axis(axis))\n\n            if len(arr) and (arr.max() >= l or arr.min() < -l):\n                raise IndexError(\"positional indexers are out-of-bounds\")\n        else:\n            raise ValueError(\"Can only index by location with \"\n                             \"a [{types}]\".format(types=self._valid_types))\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_scalar_access(self, key):\n        # this is a shortcut accessor to both .loc and .iloc\n        # that provide the equivalent access of .at and .iat\n        # a) avoid getting things via sections and (to minimize dtype changes)\n        # b) provide a performant path\n        if not hasattr(key, '__len__'):\n            return False\n\n        if len(key) != self.ndim:\n            return False\n\n        for i, k in enumerate(key):\n            if not is_integer(k):\n                return False\n\n            ax = self.obj.axes[i]\n            if not ax.is_unique:\n                return False\n\n        return True\n\n    def _getitem_scalar(self, key):\n        # a fast-path to scalar access\n        # if not, raise\n        values = self.obj._get_value(*key, takeable=True)\n        return values\n\n    def _validate_integer(self, key, axis):\n        \"\"\"\n        Check that 'key' is a valid position in the desired axis.\n\n        Parameters\n        ----------\n        key : int\n            Requested position\n        axis : int\n            Desired axis\n\n        Returns\n        -------\n        None\n\n        Raises\n        ------\n        IndexError\n            If 'key' is not a valid position in axis 'axis'\n        \"\"\"\n\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if key >= l or key < -l:\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if com.is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim < self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=None):\n        if axis is None:\n            axis = self.axis or 0\n        obj = self.obj\n\n        if not need_slice(slice_obj):\n            return obj.copy(deep=False)\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, kind='iloc')\n        else:\n            return self.obj._take(slice_obj, axis=axis)\n\n    def _get_list_axis(self, key, axis=None):\n        \"\"\"\n        Return Series values by list or array of integers\n\n        Parameters\n        ----------\n        key : list-like positional indexer\n        axis : int (can only be zero)\n\n        Returns\n        -------\n        Series object\n        \"\"\"\n        if axis is None:\n            axis = self.axis or 0\n        try:\n            return self.obj._take(key, axis=axis)\n        except IndexError:\n            # re-raise with different error message\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n    def _getitem_axis(self, key, axis=None):\n        if axis is None:\n            axis = self.axis or 0\n\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n\n        if isinstance(key, list):\n            key = np.asarray(key)\n\n        if com.is_bool_indexer(key):\n            self._validate_key(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a list of integers\n        elif is_list_like_indexer(key):\n            return self._get_list_axis(key, axis=axis)\n\n        # a single integer\n        else:\n            if not is_integer(key):\n                raise TypeError(\"Cannot index by location index with a \"\n                                \"non-integer key\")\n\n            # validate the location\n            self._validate_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=None, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n        if axis is None:\n            axis = self.axis or 0\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        try:\n            self._validate_key(obj, axis)\n            return obj\n        except ValueError:\n            raise ValueError(\"Can only index by location with \"\n                             \"a [{types}]\".format(types=self._valid_types))\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key, is_setter=False):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not is_list_like_indexer(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj._get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if isinstance(key, tuple):\n            key = tuple(com.apply_if_callable(x, self.obj)\n                        for x in key)\n        else:\n            # scalar callable may return tuple\n            key = com.apply_if_callable(key, self.obj)\n\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key, is_setter=True))\n        key.append(value)\n        self.obj._set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n    \"\"\"\n    Access a single value for a row/column label pair.\n\n    Similar to ``loc``, in that both provide label-based lookups. Use\n    ``at`` if you only need to get or set a single value in a DataFrame\n    or Series.\n\n    See Also\n    --------\n    DataFrame.iat : Access a single value for a row/column pair by integer\n        position\n    DataFrame.loc : Access a group of rows and columns by label(s)\n    Series.at : Access a single value using a label\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n    ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n    >>> df\n        A   B   C\n    4   0   2   3\n    5   0   4   1\n    6  10  20  30\n\n    Get value at specified row/column pair\n\n    >>> df.at[4, 'B']\n    2\n\n    Set value at specified row/column pair\n\n    >>> df.at[4, 'B'] = 10\n    >>> df.at[4, 'B']\n    10\n\n    Get value within a Series\n\n    >>> df.loc[5].at['B']\n    4\n\n    Raises\n    ------\n    KeyError\n        When label does not exist in DataFrame\n    \"\"\"\n\n    _takeable = False\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require they keys to be the same type as the index (so we don't\n        fallback)\n        \"\"\"\n\n        # allow arbitrary setting\n        if is_setter:\n            return list(key)\n\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index \"\n                                     \"can only have integer indexers\")\n            else:\n                if is_integer(i):\n                    raise ValueError(\"At based indexing on an non-integer \"\n                                     \"index can only have non-integer \"\n                                     \"indexers\")\n        return key\n\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n    \"\"\"\n    Access a single value for a row/column pair by integer position.\n\n    Similar to ``iloc``, in that both provide integer-based lookups. Use\n    ``iat`` if you only need to get or set a single value in a DataFrame\n    or Series.\n\n    See Also\n    --------\n    DataFrame.at : Access a single value for a row/column label pair\n    DataFrame.loc : Access a group of rows and columns by label(s)\n    DataFrame.iloc : Access a group of rows and columns by integer position(s)\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n    ...                   columns=['A', 'B', 'C'])\n    >>> df\n        A   B   C\n    0   0   2   3\n    1   0   4   1\n    2  10  20  30\n\n    Get value at specified row/column pair\n\n    >>> df.iat[1, 2]\n    1\n\n    Set value at specified row/column pair\n\n    >>> df.iat[1, 2] = 10\n    >>> df.iat[1, 2]\n    10\n\n    Get value within a series\n\n    >>> df.loc[0].iat[1]\n    2\n\n    Raises\n    ------\n    IndexError\n        When integer position is out of bounds\n    \"\"\"\n\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n\ndef length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = -step\n        return (stop - start + step - 1) // step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like_indexer(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, kind='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if obj._data.items.contains(key):\n            return None\n\n        # We might have a datetimelike string that we can translate to a\n        # slice here via partial string indexing\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except (KeyError, ValueError, NotImplementedError):\n                return None\n\n    return None\n\n\ndef check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = isna(result._values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series provided as '\n                                'indexer (index of the boolean Series and of '\n                                'the indexed object do not match')\n        result = result.astype(bool)._values\n    elif is_sparse(result):\n        result = result.to_dense()\n        result = np.asarray(result, dtype=bool)\n    else:\n        # is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef check_setitem_lengths(indexer, value, values):\n    \"\"\"Validate that value and indexer are the same length.\n\n    An special-case is allowed for when the indexer is a boolean array\n    and the number of true values equals the length of ``value``. In\n    this case, no exception is raised.\n\n    Parameters\n    ----------\n    indexer : sequence\n        The key for the setitem\n    value : array-like\n        The value for the setitem\n    values : array-like\n        The values being set into\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        When the indexer is an ndarray or list and the lengths don't\n        match.\n    \"\"\"\n    # boolean with truth values == len of the value is ok too\n    if isinstance(indexer, (np.ndarray, list)):\n        if is_list_like(value) and len(indexer) != len(value):\n            if not (isinstance(indexer, np.ndarray) and\n                    indexer.dtype == np.bool_ and\n                    len(indexer[indexer]) == len(value)):\n                raise ValueError(\"cannot set using a list-like indexer \"\n                                 \"with a different length than the value\")\n    # slice\n    elif isinstance(indexer, slice):\n\n        if is_list_like(value) and len(values):\n            if len(value) != length_of_indexer(indexer, values):\n                raise ValueError(\"cannot set using a slice indexer with a \"\n                                 \"different length than the value\")\n\n\ndef convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n    return the scalar indexer and a boolean indicating if we converted\n    \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key']) if isinstance(_idx, dict) else\n                _idx)\n\n    return tuple(get_indexer(_i, _idx) for _i, _idx in enumerate(indexer))\n\n\ndef maybe_convert_indices(indices, n):\n    \"\"\"\n    Attempt to convert indices into valid, positive indices.\n\n    If we have negative indices, translate to positive here.\n    If we have indices that are out-of-bounds, raise an IndexError.\n\n    Parameters\n    ----------\n    indices : array-like\n        The array of indices that we are to convert.\n    n : int\n        The number of elements in the array that we are indexing.\n\n    Returns\n    -------\n    valid_indices : array-like\n        An array-like of positive indices that correspond to the ones\n        that were passed in initially to this function.\n\n    Raises\n    ------\n    IndexError : one of the converted indices either exceeded the number\n        of elements (specified by `n`) OR was still negative.\n    \"\"\"\n\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.intp)\n\n    mask = indices < 0\n    if mask.any():\n        indices = indices.copy()\n        indices[mask] += n\n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef validate_indices(indices, n):\n    \"\"\"Perform bounds-checking for an indexer.\n\n    -1 is allowed for indicating missing values.\n\n    Parameters\n    ----------\n    indices : ndarray\n    n : int\n        length of the array being indexed\n\n    Raises\n    ------\n    ValueError\n\n    Examples\n    --------\n    >>> validate_indices([1, 2], 3)\n    # OK\n    >>> validate_indices([1, -2], 3)\n    ValueError\n    >>> validate_indices([1, 2, 3], 3)\n    IndexError\n    >>> validate_indices([-1, -1], 0)\n    # OK\n    >>> validate_indices([0, 1], 0)\n    IndexError\n    \"\"\"\n    if len(indices):\n        min_idx = indices.min()\n        if min_idx < -1:\n            msg = (\"'indices' contains values less than allowed ({} < {})\"\n                   .format(min_idx, -1))\n            raise ValueError(msg)\n\n        max_idx = indices.max()\n        if max_idx >= n:\n            raise IndexError(\"indices are out-of-bounds\")\n\n\ndef maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries, Index)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef is_nested_tuple(tup, labels):\n    # check for a compatible nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    for i, k in enumerate(tup):\n\n        if is_list_like(k) or isinstance(k, slice):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\n\ndef is_list_like_indexer(key):\n    # allow a list_like, but exclude NamedTuples which can be indexers\n    return is_list_like(key) and not (isinstance(key, tuple) and\n                                      type(key) is not tuple)\n\n\ndef is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not is_list_like_indexer(key)\n\n\ndef need_slice(obj):\n    return (obj.start is not None or obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n\n\ndef _non_reducing_slice(slice_):\n    \"\"\"\n    Ensurse that a slice doesn't reduce to a Series or Scalar.\n\n    Any user-paseed `subset` should have this called on it\n    to make sure we're always working with DataFrames.\n    \"\"\"\n    # default to column slice, like DataFrame\n    # ['A', 'B'] -> IndexSlices[:, ['A', 'B']]\n    kinds = tuple(list(compat.string_types) + [ABCSeries, np.ndarray, Index,\n                                               list])\n    if isinstance(slice_, kinds):\n        slice_ = IndexSlice[:, slice_]\n\n    def pred(part):\n        # true when slice does *not* reduce\n        return isinstance(part, slice) or is_list_like(part)\n\n    if not is_list_like(slice_):\n        if not isinstance(slice_, slice):\n            # a 1-d slice, like df.loc[1]\n            slice_ = [[slice_]]\n        else:\n            # slice(a, b, c)\n            slice_ = [slice_]  # to tuplize later\n    else:\n        slice_ = [part if pred(part) else [part] for part in slice_]\n    return tuple(slice_)\n\n\ndef _maybe_numeric_slice(df, slice_, include_bool=False):\n    \"\"\"\n    want nice defaults for background_gradient that don't break\n    with non-numeric data. But if slice_ is passed go with that.\n    \"\"\"\n    if slice_ is None:\n        dtypes = [np.number]\n        if include_bool:\n            dtypes.append(bool)\n        slice_ = IndexSlice[:, df.select_dtypes(include=dtypes).columns]\n    return slice_\n",
      "file_after": "# pylint: disable=W0223\nimport textwrap\nimport warnings\nimport numpy as np\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nfrom pandas.core.dtypes.generic import ABCDataFrame, ABCPanel, ABCSeries\nfrom pandas.core.dtypes.common import (\n    is_integer_dtype,\n    is_integer, is_float,\n    is_list_like,\n    is_sequence,\n    is_iterator,\n    is_scalar,\n    is_sparse,\n    ensure_platform_int)\nfrom pandas.core.dtypes.missing import isna, _infer_fill_value\nfrom pandas.errors import AbstractMethodError\nfrom pandas.util._decorators import Appender\n\nfrom pandas.core.index import Index, MultiIndex\n\nimport pandas.core.common as com\nfrom pandas._libs.indexing import _NDFrameIndexerBase\n\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix', _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc', _LocIndexer),\n        ('at', _AtIndexer),\n        ('iat', _iAtIndexer),\n    ]\n\n\n# \"null slice\"\n_NS = slice(None, None)\n\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    \"\"\"\n    Create an object to more easily perform multi-index slicing\n\n    See Also\n    --------\n    MultiIndex.remove_unused_levels : New MultiIndex with no unused levels.\n\n    Notes\n    -----\n    See :ref:`Defined Levels <advanced.shown_levels>`\n    for further info on slicing a MultiIndex.\n\n    Examples\n    --------\n\n    >>> midx = pd.MultiIndex.from_product([['A0','A1'], ['B0','B1','B2','B3']])\n    >>> columns = ['foo', 'bar']\n    >>> dfmi = pd.DataFrame(np.arange(16).reshape((len(midx), len(columns))),\n                            index=midx, columns=columns)\n\n    Using the default slice command:\n\n    >>> dfmi.loc[(slice(None), slice('B0', 'B1')), :]\n               foo  bar\n        A0 B0    0    1\n           B1    2    3\n        A1 B0    8    9\n           B1   10   11\n\n    Using the IndexSlice class for a more intuitive command:\n\n    >>> idx = pd.IndexSlice\n    >>> dfmi.loc[idx[:, 'B0':'B1'], :]\n               foo  bar\n        A0 B0    0    1\n           B1    2    3\n        A1 B0    8    9\n           B1   10   11\n    \"\"\"\n\n    def __getitem__(self, arg):\n        return arg\n\n\nIndexSlice = _IndexSlice()\n\n\nclass IndexingError(Exception):\n    pass\n\n\nclass _NDFrameIndexer(_NDFrameIndexerBase):\n    _valid_types = None\n    _exception = KeyError\n    axis = None\n\n    def __call__(self, axis=None):\n        # we need to return a copy of ourselves\n        new_self = self.__class__(self.name, self.obj)\n\n        if axis is not None:\n            axis = self.obj._get_axis_number(axis)\n        new_self.axis = axis\n        return new_self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            key = tuple(com.apply_if_callable(x, self.obj)\n                        for x in key)\n            try:\n                values = self.obj._get_value(*key)\n                if is_scalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            # we by definition only have the 0th axis\n            axis = self.axis or 0\n\n            key = com.apply_if_callable(key, self.obj)\n            return self._getitem_axis(key, axis=axis)\n\n    def _get_label(self, label, axis=None):\n        if axis is None:\n            axis = self.axis or 0\n\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            return self.obj._xs(label, axis=axis)\n        elif isinstance(label, tuple) and isinstance(label[axis], slice):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=None):\n        if axis is None:\n            axis = self.axis\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=None, kind=None):\n        if axis is None:\n            axis = self.axis\n        return self.obj._slice(obj, axis=axis, kind=kind)\n\n    def _get_setitem_indexer(self, key):\n        if self.axis is not None:\n            return self._convert_tuple(key, is_setter=True)\n\n        axis = self.obj._get_axis(0)\n\n        if isinstance(axis, MultiIndex) and self.name != 'iloc':\n            try:\n                return axis.get_loc(key)\n            except Exception:\n                pass\n\n        if isinstance(key, tuple):\n            try:\n                return self._convert_tuple(key, is_setter=True)\n            except IndexingError:\n                pass\n\n        if isinstance(key, range):\n            return self._convert_range(key, is_setter=True)\n\n        try:\n            return self._convert_to_indexer(key, is_setter=True)\n        except TypeError as e:\n\n            # invalid indexer type vs 'other' indexing errors\n            if 'cannot do' in str(e):\n                raise\n            raise IndexingError(key)\n\n    def __setitem__(self, key, value):\n        if isinstance(key, tuple):\n            key = tuple(com.apply_if_callable(x, self.obj)\n                        for x in key)\n        else:\n            key = com.apply_if_callable(key, self.obj)\n        indexer = self._get_setitem_indexer(key)\n        self._setitem_with_indexer(indexer, value)\n\n    def _validate_key(self, key, axis):\n        \"\"\"\n        Ensure that key is valid for current indexer.\n\n        Parameters\n        ----------\n        key : scalar, slice or list-like\n            The key requested\n\n        axis : int\n            Dimension on which the indexing is being made\n\n        Raises\n        ------\n        TypeError\n            If the key (or some element of it) has wrong type\n\n        IndexError\n            If the key (or some element of it) is out of bounds\n\n        KeyError\n            If the key was not found\n        \"\"\"\n        raise AbstractMethodError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            try:\n                self._validate_key(k, i)\n            except ValueError:\n                raise ValueError(\"Location based indexing can only have \"\n                                 \"[{types}] types\"\n                                 .format(types=self._valid_types))\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any(isinstance(ax, MultiIndex) for ax in self.obj.axes):\n            return any(is_nested_tuple(tup, ax) for ax in self.obj.axes)\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(\n                        key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                if i >= self.obj.ndim:\n                    raise IndexingError('Too many indexers')\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_range(self, key, is_setter=False):\n        \"\"\" convert a range argument \"\"\"\n        return list(key)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        if axis is None:\n            axis = 0\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, kind=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, kind=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n        will raise if needed, does not modify the indexer externally\n        \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like_indexer(i):\n                    # should check the elements?\n                    pass\n                elif is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{name} cannot enlarge its target \"\n                                         \"object\".format(name=self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{name} cannot enlarge its target object\"\n                                     .format(name=self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        # TODO: Panel, DataFrame are not imported, remove?\n        from pandas import Panel, DataFrame, Series  # noqa\n        info_axis = self.obj._info_axis_number\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n\n        # if there is only one block/type, still have to take split path\n        # unless the block is one-dimensional or it can hold the value\n        if not take_split_path and self.obj._data.blocks:\n            blk, = self.obj._data.blocks\n            if 1 < blk.ndim:  # in case of dict, keys are indices\n                val = list(value.values()) if isinstance(value,\n                                                         dict) else value\n                take_split_path = not blk._can_hold_element(val)\n\n        if isinstance(indexer, tuple) and len(indexer) == len(self.obj.axes):\n\n            for i, ax in zip(indexer, self.obj.axes):\n\n                # if we have any multi-indexes that have non-trivial slices\n                # (not null slices) then we must take the split path, xref\n                # GH 10360\n                if (isinstance(ax, MultiIndex) and\n                        not (is_integer(i) or com.is_null_slice(i))):\n                    take_split_path = True\n                    break\n\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any(not l for l in len_non_info_axes):\n                            if not is_list_like_indexer(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n                        # add a new item with the dtype setup\n                        self.obj[key] = _infer_fill_value(value)\n\n                        new_indexer = convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = index.insert(len(index), key)\n                    self.obj._data = self.obj.reindex(labels, axis=i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj._is_copy = None\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    new_index = index.insert(len(index), indexer)\n\n                    # we have a coerced indexer, e.g. a float\n                    # that matches in an Int64Index, so\n                    # we will not create a duplicate index, rather\n                    # index to that element\n                    # e.g. 0.0 -> 0\n                    # GH12246\n                    if index.is_unique:\n                        new_indexer = index.get_indexer([new_index[-1]])\n                        if (new_indexer != -1).any():\n                            return self._setitem_with_indexer(new_indexer,\n                                                              value)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value])._values\n                    if len(self.obj._values):\n                        try:\n                            new_values = np.concatenate([self.obj._values,\n                                                         new_values])\n                        except TypeError:\n                            as_obj = self.obj.astype(object)\n                            new_values = np.concatenate([as_obj,\n                                                         new_values])\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\"cannot set a frame with no defined \"\n                                         \"columns\")\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,\n                                              copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if is_list_like_indexer(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\"cannot set a row with \"\n                                                 \"mismatched columns\")\n\n                        value = Series(value, index=self.obj.columns,\n                                       name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        item_labels = self.obj._get_axis(info_axis)\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].axes[0], MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like_indexer(value) and np.iterable(\n                        value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\"cannot set using a multi-index \"\n                                         \"selection indexer with a different \"\n                                         \"length than the value\")\n\n                    # make sure we have an ndarray\n                    value = getattr(value, 'values', value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj._consolidate_inplace()\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]),\n                                                  value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = length_of_indexer(plane_indexer[0],\n                                                       plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice or a slice with full bounds\n                # which means essentially reassign to the columns of a\n                # multi-dim object\n                # GH6149 (null slice), GH10408 (full bounds)\n                if (isinstance(pi, tuple) and\n                        all(com.is_null_slice(idx) or\n                            com.is_full_slice(idx, len(self.obj))\n                            for idx in pi)):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s._consolidate_inplace()\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if (not len(labels) == 1 or not np.iterable(value) or\n                        is_scalar(plane_indexer[0])):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an iterable, with a ndim of at least 1\n            # eg. don't pass through np.array(0)\n            if is_list_like_indexer(value) and getattr(value, 'ndim', 1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n                    sub_indexer = list(indexer)\n                    multiindex_indexer = isinstance(labels, MultiIndex)\n\n                    for item in labels:\n                        if item in value:\n                            sub_indexer[info_axis] = item\n                            v = self._align_series(\n                                tuple(sub_indexer), value[item],\n                                multiindex_indexer)\n                        else:\n                            v = np.nan\n\n                        setter(item, v)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value, dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = maybe_convert_ix(*indexer)\n\n                # if we are setting on the info axis ONLY\n                # set using those methods to avoid block-splitting\n                # logic here\n                if (len(indexer) > info_axis and\n                        is_integer(indexer[info_axis]) and\n                        all(com.is_null_slice(idx)\n                            for i, idx in enumerate(indexer)\n                            if i != info_axis) and\n                        item_labels.is_unique):\n                    self.obj[item_labels[indexer[info_axis]]] = value\n                    return\n\n            if isinstance(value, (ABCSeries, dict)):\n                # TODO(EA): ExtensionBlock.setitem this causes issues with\n                # setting for extensionarrays that store dicts. Need to decide\n                # if it's worth supporting that.\n                value = self._align_series(indexer, Series(value))\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._consolidate_inplace()\n            self.obj._data = self.obj._data.setitem(indexer=indexer,\n                                                    value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser, multiindex_indexer=False):\n        \"\"\"\n        Parameters\n        ----------\n        indexer : tuple, slice, scalar\n            The indexer used to get the locations that will be set to\n            `ser`\n\n        ser : pd.Series\n            The values to assign to the locations specified by `indexer`\n\n        multiindex_indexer : boolean, optional\n            Defaults to False. Should be set to True if `indexer` was from\n            a `pd.MultiIndex`, to avoid unnecessary broadcasting.\n\n\n        Returns:\n        --------\n        `np.array` of `ser` broadcast to the appropriate shape for assignment\n        to the locations selected by `indexer`\n\n        \"\"\"\n        if isinstance(indexer, (slice, np.ndarray, list, Index)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            # flatten np.ndarray indexers\n            def ravel(i):\n                return i.ravel() if isinstance(i, np.ndarray) else i\n            indexer = tuple(map(ravel, indexer))\n\n            aligners = [not com.is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all(is_sequence(_) for _ in indexer)):\n                ser = ser.reindex(obj.axes[0][indexer[0]], copy=True)._values\n\n                # single indexer\n                if len(indexer) > 1 and not multiindex_indexer:\n                    l = len(indexer[1])\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and com.is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like_indexer(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix)\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser._values.copy()\n\n                    return ser.reindex(new_ix)._values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser._values.copy()\n                    return ser.reindex(ax)._values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser._values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif is_scalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser._values.copy()\n\n            return ser.reindex(ax)._values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n\n        if isinstance(indexer, tuple):\n\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if is_sequence(ix) or isinstance(ix, slice):\n                    if isinstance(ix, np.ndarray):\n                        ix = ix.ravel()\n                    if idx is None:\n                        idx = ax[ix]\n                    elif cols is None:\n                        cols = ax[ix]\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n\n                # need to conform to the convention\n                # as we are not selecting on the items axis\n                # and we have a single indexer\n                # GH 7763\n                if len(sindexers) == 1 and sindexers[0] != 0:\n                    df = df.T\n\n                if idx is None:\n                    idx = df.index\n                if cols is None:\n                    cols = df.columns\n\n            if idx is not None and cols is not None:\n\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy()._values\n                else:\n                    val = df.reindex(idx, columns=cols)._values\n                return val\n\n        elif ((isinstance(indexer, slice) or is_list_like_indexer(indexer)) and\n              is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy()._values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if (isinstance(ax, MultiIndex) and\n                        isinstance(df.index, MultiIndex) and\n                        ax.nlevels != df.index.nlevels):\n                    raise TypeError(\"cannot align on a multi-index with out \"\n                                    \"specifying the join levels\")\n\n                val = df.reindex(index=ax)._values\n            return val\n\n        elif is_scalar(indexer) and is_panel:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy()._values\n\n            return df.reindex(idx, columns=cols)._values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if com.is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        \"\"\"\n        Check whether there is the possibility to use ``_multi_take``.\n        Currently the limit is that all axes being indexed must be indexed with\n        list-likes.\n\n        Parameters\n        ----------\n        tup : tuple\n            Tuple of indexers, one per axis\n\n        Returns\n        -------\n        boolean: Whether the current indexing can be passed through _multi_take\n        \"\"\"\n        if not all(is_list_like_indexer(x) for x in tup):\n            return False\n\n        # just too complicated\n        if any(com.is_bool_indexer(x) for x in tup):\n            return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\"\n        Create the indexers for the passed tuple of keys, and execute the take\n        operation. This allows the take operation to be executed all at once -\n        rather than once for each dimension - improving efficiency.\n\n        Parameters\n        ----------\n        tup : tuple\n            Tuple of indexers, one per axis\n\n        Returns\n        -------\n        values: same type as the object being indexed\n        \"\"\"\n        # GH 836\n        o = self.obj\n        d = {axis: self._get_listlike_indexer(key, axis)\n             for (key, axis) in zip(tup, o._AXIS_ORDERS)}\n        return o._reindex_with_indexers(d, copy=True, allow_dups=True)\n\n    def _convert_for_reindex(self, key, axis=None):\n        return key\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=self.axis)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        # ...but iloc should handle the tuple as simple integer-location\n        # instead of checking it as multiindex representation (GH 13797)\n        if isinstance(ax0, MultiIndex) and self.name != 'iloc':\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not is_list_like_indexer(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0 and\n                            len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # Slices should return views, but calling iloc/loc with a null\n                # slice returns a new object.\n                if com.is_null_slice(new_key):\n                    return section\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of\n            # selectors\n            return self._getitem_axis(tup, axis=self.axis)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if com.is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if is_scalar(obj) or not hasattr(obj, 'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=None):\n\n        if axis is None:\n            axis = self.axis or 0\n\n        if is_iterator(key):\n            key = list(key)\n        self._validate_key(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif (is_list_like_indexer(key) and\n              not (isinstance(key, tuple) and\n                   isinstance(labels, MultiIndex))):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n\n            # maybe coerce a float scalar to integer\n            key = labels._maybe_cast_indexer(key)\n\n            if is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _get_listlike_indexer(self, key, axis, raise_missing=False):\n        \"\"\"\n        Transform a list-like of keys into a new index and an indexer.\n\n        Parameters\n        ----------\n        key : list-like\n            Target labels\n        axis: int\n            Dimension on which the indexing is being made\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n\n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n\n        Returns\n        -------\n        keyarr: Index\n            New index (coinciding with 'key' if the axis is unique)\n        values : array-like\n            An indexer for the return object; -1 denotes keys not found\n        \"\"\"\n        o = self.obj\n        ax = o._get_axis(axis)\n\n        # Have the index compute an indexer or return None\n        # if it cannot handle:\n        indexer, keyarr = ax._convert_listlike_indexer(key,\n                                                       kind=self.name)\n        # We only act on all found values:\n        if indexer is not None and (indexer != -1).all():\n            self._validate_read_indexer(key, indexer, axis,\n                                        raise_missing=raise_missing)\n            return ax[indexer], indexer\n\n        if ax.is_unique:\n            # If we are trying to get actual keys from empty Series, we\n            # patiently wait for a KeyError later on - otherwise, convert\n            if len(ax) or not len(key):\n                key = self._convert_for_reindex(key, axis)\n            indexer = ax.get_indexer_for(key)\n            keyarr = ax.reindex(keyarr)[0]\n        else:\n            keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr)\n\n        self._validate_read_indexer(keyarr, indexer,\n                                    o._get_axis_number(axis),\n                                    raise_missing=raise_missing)\n        return keyarr, indexer\n\n    def _getitem_iterable(self, key, axis=None):\n        \"\"\"\n        Index current object with an an iterable key (which can be a boolean\n        indexer, or a collection of keys).\n\n        Parameters\n        ----------\n        key : iterable\n            Target labels, or boolean indexer\n        axis: int, default None\n            Dimension on which the indexing is being made\n\n        Raises\n        ------\n        KeyError\n            If no key was found. Will change in the future to raise if not all\n            keys were found.\n        IndexingError\n            If the boolean indexer is unalignable with the object being\n            indexed.\n\n        Returns\n        -------\n        scalar, DataFrame, or Series: indexed value(s),\n        \"\"\"\n\n        if axis is None:\n            axis = self.axis or 0\n\n        self._validate_key(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        if com.is_bool_indexer(key):\n            # A boolean indexer\n            key = check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj._take(inds, axis=axis)\n        else:\n            # A collection of keys\n            keyarr, indexer = self._get_listlike_indexer(key, axis,\n                                                         raise_missing=False)\n            return self.obj._reindex_with_indexers({axis: [keyarr, indexer]},\n                                                   copy=True, allow_dups=True)\n\n    def _validate_read_indexer(self, key, indexer, axis, raise_missing=False):\n        \"\"\"\n        Check that indexer can be used to return a result (e.g. at least one\n        element was found, unless the list of keys was actually empty).\n\n        Parameters\n        ----------\n        key : list-like\n            Target labels (only used to show correct error message)\n        indexer: array-like of booleans\n            Indices corresponding to the key (with -1 indicating not found)\n        axis: int\n            Dimension on which the indexing is being made\n        raise_missing: bool\n            Whether to raise a KeyError if some labels are not found. Will be\n            removed in the future, and then this method will always behave as\n            if raise_missing=True.\n\n        Raises\n        ------\n        KeyError\n            If at least one key was requested but none was found, and\n            raise_missing=True.\n        \"\"\"\n\n        ax = self.obj._get_axis(axis)\n\n        if len(key) == 0:\n            return\n\n        # Count missing values:\n        missing = (indexer < 0).sum()\n\n        if missing:\n            if missing == len(indexer):\n                raise KeyError(\n                    u\"None of [{key}] are in the [{axis}]\".format(\n                        key=key, axis=self.obj._get_axis_name(axis)))\n\n            # We (temporarily) allow for some missing keys with .loc, except in\n            # some cases (e.g. setting) in which \"raise_missing\" will be False\n            if not(self.name == 'loc' and not raise_missing):\n                not_found = list(set(key) - set(ax))\n                raise KeyError(\"{} not in index\".format(not_found))\n\n            # we skip the warning on Categorical/Interval\n            # as this check is actually done (check for\n            # non-missing values), but a bit later in the\n            # code, so we want to avoid warning & then\n            # just raising\n\n            _missing_key_warning = textwrap.dedent(\"\"\"\n            Passing list-likes to .loc or [] with any missing label will raise\n            KeyError in the future, you can use .reindex() as an alternative.\n\n            See the documentation here:\n            https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\"\"\")  # noqa\n\n            if not (ax.is_categorical() or ax.is_interval()):\n                warnings.warn(_missing_key_warning,\n                              FutureWarning, stacklevel=6)\n\n    def _convert_to_indexer(self, obj, axis=None, is_setter=False,\n                            raise_missing=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        'In the face of ambiguity, refuse the temptation to guess.'\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        if axis is None:\n            axis = self.axis or 0\n\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        # try to find out correct indexer, if not type correct raise\n        try:\n            obj = self._convert_scalar_indexer(obj, axis)\n        except TypeError:\n\n            # but we will allow setting\n            if is_setter:\n                pass\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except LookupError:\n            if isinstance(obj, tuple) and isinstance(labels, MultiIndex):\n                if is_setter and len(obj) == labels.nlevels:\n                    return {'key': obj}\n                raise\n        except TypeError:\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n\n        elif is_list_like_indexer(obj):\n\n            if com.is_bool_indexer(obj):\n                obj = check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                # When setting, missing keys are not allowed, even with .loc:\n                kwargs = {'raise_missing': True if is_setter else\n                          raise_missing}\n                return self._get_listlike_indexer(obj, axis, **kwargs)[1]\n        else:\n            try:\n                return labels.get_loc(obj)\n            except LookupError:\n                # allow a not found key only if we are a setter\n                if not is_list_like_indexer(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=None):\n        obj = self.obj\n\n        if axis is None:\n            axis = self.axis or 0\n\n        if not need_slice(slice_obj):\n            return obj.copy(deep=False)\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, kind='iloc')\n        else:\n            return self.obj._take(indexer, axis=axis)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n    \"\"\"A primarily label-location based indexer, with integer position\n    fallback.\n\n    Warning: Starting in 0.20.0, the .ix indexer is deprecated, in\n    favor of the more strict .iloc and .loc indexers.\n\n    ``.ix[]`` supports mixed integer and label based access. It is\n    primarily label based, but will fall back to integer positional\n    access unless the corresponding axis is of integer type.\n\n    ``.ix`` is the most general indexer and will support any of the\n    inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n    point label schemes. ``.ix`` is exceptionally useful when dealing\n    with mixed positional and label based hierarchical indexes.\n\n    However, when an axis is integer based, ONLY label based access\n    and not positional access is supported. Thus, in such cases, it's\n    usually better to be explicit and use ``.iloc`` or ``.loc``.\n\n    See more at :ref:`Advanced Indexing <advanced>`.\n\n    \"\"\"\n\n    def __init__(self, name, obj):\n\n        _ix_deprecation_warning = textwrap.dedent(\"\"\"\n            .ix is deprecated. Please use\n            .loc for label based indexing or\n            .iloc for positional indexing\n\n            See the documentation here:\n            http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\"\"\")  # noqa\n\n        warnings.warn(_ix_deprecation_warning,\n                      DeprecationWarning, stacklevel=2)\n        super(_IXIndexer, self).__init__(name, obj)\n\n    @Appender(_NDFrameIndexer._validate_key.__doc__)\n    def _validate_key(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif com.is_bool_indexer(key):\n            return True\n\n        elif is_list_like_indexer(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n    def _convert_for_reindex(self, key, axis=None):\n        \"\"\"\n        Transform a list of keys into a new array ready to be used as axis of\n        the object we return (e.g. including NaNs).\n\n        Parameters\n        ----------\n        key : list-like\n            Target labels\n        axis: int\n            Where the indexing is being made\n\n        Returns\n        -------\n        list-like of labels\n        \"\"\"\n\n        if axis is None:\n            axis = self.axis or 0\n        labels = self.obj._get_axis(axis)\n\n        if com.is_bool_indexer(key):\n            key = check_bool_indexer(labels, key)\n            return labels[key]\n\n        if isinstance(key, Index):\n            keyarr = labels._convert_index_indexer(key)\n        else:\n            # asarray can be unsafe, NumPy strings are weird\n            keyarr = com.asarray_tuplesafe(key)\n\n        if is_integer_dtype(keyarr):\n            # Cast the indexer to uint64 if possible so\n            # that the values returned from indexing are\n            # also uint64.\n            keyarr = labels._convert_arr_indexer(keyarr)\n\n            if not labels.is_integer():\n                keyarr = ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n        return keyarr\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            key = tuple(com.apply_if_callable(x, self.obj)\n                        for x in key)\n            try:\n                if self._is_scalar_access(key):\n                    return self._getitem_scalar(key)\n            except (KeyError, IndexError):\n                pass\n            return self._getitem_tuple(key)\n        else:\n            # we by definition only have the 0th axis\n            axis = self.axis or 0\n\n            maybe_callable = com.apply_if_callable(key, self.obj)\n            return self._getitem_axis(maybe_callable, axis=axis)\n\n    def _is_scalar_access(self, key):\n        raise NotImplementedError()\n\n    def _getitem_scalar(self, key):\n        raise NotImplementedError()\n\n    def _getitem_axis(self, key, axis=None):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=None):\n        if axis is None:\n            axis = self.axis or 0\n        labels = self.obj._get_axis(axis)\n        key = check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj._take(inds, axis=axis)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=None):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        if axis is None:\n            axis = self.axis or 0\n\n        obj = self.obj\n        if not need_slice(slice_obj):\n            return obj.copy(deep=False)\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step, kind=self.name)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, kind='iloc')\n        else:\n            return self.obj._take(indexer, axis=axis)\n\n\nclass _LocIndexer(_LocationIndexer):\n    \"\"\"\n    Access a group of rows and columns by label(s) or a boolean array.\n\n    ``.loc[]`` is primarily label based, but may also be used with a\n    boolean array.\n\n    Allowed inputs are:\n\n    - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n      interpreted as a *label* of the index, and **never** as an\n      integer position along the index).\n    - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n    - A slice object with labels, e.g. ``'a':'f'``.\n\n      .. warning:: Note that contrary to usual python slices, **both** the\n          start and the stop are included\n\n    - A boolean array of the same length as the axis being sliced,\n      e.g. ``[True, False, True]``.\n    - A ``callable`` function with one argument (the calling Series, DataFrame\n      or Panel) and that returns valid output for indexing (one of the above)\n\n    See more at :ref:`Selection by Label <indexing.label>`\n\n    See Also\n    --------\n    DataFrame.at : Access a single value for a row/column label pair\n    DataFrame.iloc : Access group of rows and columns by integer position(s)\n    DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n        Series/DataFrame.\n    Series.loc : Access group of values using labels\n\n    Examples\n    --------\n    **Getting values**\n\n    >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n    ...      index=['cobra', 'viper', 'sidewinder'],\n    ...      columns=['max_speed', 'shield'])\n    >>> df\n                max_speed  shield\n    cobra               1       2\n    viper               4       5\n    sidewinder          7       8\n\n    Single label. Note this returns the row as a Series.\n\n    >>> df.loc['viper']\n    max_speed    4\n    shield       5\n    Name: viper, dtype: int64\n\n    List of labels. Note using ``[[]]`` returns a DataFrame.\n\n    >>> df.loc[['viper', 'sidewinder']]\n                max_speed  shield\n    viper               4       5\n    sidewinder          7       8\n\n    Single label for row and column\n\n    >>> df.loc['cobra', 'shield']\n    2\n\n    Slice with labels for row and single label for column. As mentioned\n    above, note that both the start and stop of the slice are included.\n\n    >>> df.loc['cobra':'viper', 'max_speed']\n    cobra    1\n    viper    4\n    Name: max_speed, dtype: int64\n\n    Boolean list with the same length as the row axis\n\n    >>> df.loc[[False, False, True]]\n                max_speed  shield\n    sidewinder          7       8\n\n    Conditional that returns a boolean Series\n\n    >>> df.loc[df['shield'] > 6]\n                max_speed  shield\n    sidewinder          7       8\n\n    Conditional that returns a boolean Series with column labels specified\n\n    >>> df.loc[df['shield'] > 6, ['max_speed']]\n                max_speed\n    sidewinder          7\n\n    Callable that returns a boolean Series\n\n    >>> df.loc[lambda df: df['shield'] == 8]\n                max_speed  shield\n    sidewinder          7       8\n\n    **Setting values**\n\n    Set value for all items matching the list of labels\n\n    >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n    >>> df\n                max_speed  shield\n    cobra               1       2\n    viper               4      50\n    sidewinder          7      50\n\n    Set value for an entire row\n\n    >>> df.loc['cobra'] = 10\n    >>> df\n                max_speed  shield\n    cobra              10      10\n    viper               4      50\n    sidewinder          7      50\n\n    Set value for an entire column\n\n    >>> df.loc[:, 'max_speed'] = 30\n    >>> df\n                max_speed  shield\n    cobra              30      10\n    viper              30      50\n    sidewinder         30      50\n\n    Set value for rows matching callable condition\n\n    >>> df.loc[df['shield'] > 35] = 0\n    >>> df\n                max_speed  shield\n    cobra              30      10\n    viper               0       0\n    sidewinder          0       0\n\n    **Getting values on a DataFrame with an index that has integer labels**\n\n    Another example using integers for the index\n\n    >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n    ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n    >>> df\n       max_speed  shield\n    7          1       2\n    8          4       5\n    9          7       8\n\n    Slice with integer labels for rows. As mentioned above, note that both\n    the start and stop of the slice are included.\n\n    >>> df.loc[7:9]\n       max_speed  shield\n    7          1       2\n    8          4       5\n    9          7       8\n\n    **Getting values with a MultiIndex**\n\n    A number of examples using a DataFrame with a MultiIndex\n\n    >>> tuples = [\n    ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n    ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n    ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n    ... ]\n    >>> index = pd.MultiIndex.from_tuples(tuples)\n    >>> values = [[12, 2], [0, 4], [10, 20],\n    ...         [1, 4], [7, 1], [16, 36]]\n    >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n    >>> df\n                         max_speed  shield\n    cobra      mark i           12       2\n               mark ii           0       4\n    sidewinder mark i           10      20\n               mark ii           1       4\n    viper      mark ii           7       1\n               mark iii         16      36\n\n    Single label. Note this returns a DataFrame with a single index.\n\n    >>> df.loc['cobra']\n             max_speed  shield\n    mark i          12       2\n    mark ii          0       4\n\n    Single index tuple. Note this returns a Series.\n\n    >>> df.loc[('cobra', 'mark ii')]\n    max_speed    0\n    shield       4\n    Name: (cobra, mark ii), dtype: int64\n\n    Single label for row and column. Similar to passing in a tuple, this\n    returns a Series.\n\n    >>> df.loc['cobra', 'mark i']\n    max_speed    12\n    shield        2\n    Name: (cobra, mark i), dtype: int64\n\n    Single tuple. Note using ``[[]]`` returns a DataFrame.\n\n    >>> df.loc[[('cobra', 'mark ii')]]\n                   max_speed  shield\n    cobra mark ii          0       4\n\n    Single tuple for the index with a single label for the column\n\n    >>> df.loc[('cobra', 'mark i'), 'shield']\n    2\n\n    Slice from index tuple to single label\n\n    >>> df.loc[('cobra', 'mark i'):'viper']\n                         max_speed  shield\n    cobra      mark i           12       2\n               mark ii           0       4\n    sidewinder mark i           10      20\n               mark ii           1       4\n    viper      mark ii           7       1\n               mark iii         16      36\n\n    Slice from index tuple to index tuple\n\n    >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n                        max_speed  shield\n    cobra      mark i          12       2\n               mark ii          0       4\n    sidewinder mark i          10      20\n               mark ii          1       4\n    viper      mark ii          7       1\n\n    Raises\n    ------\n    KeyError:\n        when any items are not found\n    \"\"\"\n\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    @Appender(_NDFrameIndexer._validate_key.__doc__)\n    def _validate_key(self, key, axis):\n\n        # valid for a collection of labels (we check their presence later)\n        # slice of labels (where start-end in labels)\n        # slice of integers (only if in the labels)\n        # boolean\n\n        if isinstance(key, slice):\n            return\n\n        if com.is_bool_indexer(key):\n            return\n\n        if not is_list_like_indexer(key):\n            self._convert_scalar_indexer(key, axis)\n\n    def _is_scalar_access(self, key):\n        # this is a shortcut accessor to both .loc and .iloc\n        # that provide the equivalent access of .at and .iat\n        # a) avoid getting things via sections and (to minimize dtype changes)\n        # b) provide a performant path\n        if not hasattr(key, '__len__'):\n            return False\n\n        if len(key) != self.ndim:\n            return False\n\n        for i, k in enumerate(key):\n            if not is_scalar(k):\n                return False\n\n            ax = self.obj.axes[i]\n            if isinstance(ax, MultiIndex):\n                return False\n\n            if not ax.is_unique:\n                return False\n\n        return True\n\n    def _getitem_scalar(self, key):\n        # a fast-path to scalar access\n        # if not, raise\n        values = self.obj._get_value(*key)\n        return values\n\n    def _get_partial_string_timestamp_match_key(self, key, labels):\n        \"\"\"Translate any partial string timestamp matches in key, returning the\n        new key (GH 10331)\"\"\"\n        if isinstance(labels, MultiIndex):\n            if isinstance(key, compat.string_types) and \\\n                    labels.levels[0].is_all_dates:\n                # Convert key '2016-01-01' to\n                # ('2016-01-01'[, slice(None, None, None)]+)\n                key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))\n\n            if isinstance(key, tuple):\n                # Convert (..., '2016-01-01', ...) in tuple to\n                # (..., slice('2016-01-01', '2016-01-01', None), ...)\n                new_key = []\n                for i, component in enumerate(key):\n                    if isinstance(component, compat.string_types) and \\\n                            labels.levels[i].is_all_dates:\n                        new_key.append(slice(component, component, None))\n                    else:\n                        new_key.append(component)\n                key = tuple(new_key)\n\n        return key\n\n    def _getitem_axis(self, key, axis=None):\n        if axis is None:\n            axis = self.axis or 0\n\n        if is_iterator(key):\n            key = list(key)\n\n        labels = self.obj._get_axis(axis)\n        key = self._get_partial_string_timestamp_match_key(key, labels)\n\n        if isinstance(key, slice):\n            self._validate_key(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif com.is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif is_list_like_indexer(key):\n\n            # convert various list-like indexers\n            # to a list of keys\n            # we will use the *values* of the object\n            # and NOT the index if its a PandasObject\n            if isinstance(labels, MultiIndex):\n\n                if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:\n                    # Series, or 0,1 ndim ndarray\n                    # GH 14730\n                    key = list(key)\n                elif isinstance(key, ABCDataFrame):\n                    # GH 15438\n                    raise NotImplementedError(\"Indexing a MultiIndex with a \"\n                                              \"DataFrame key is not \"\n                                              \"implemented\")\n                elif hasattr(key, 'ndim') and key.ndim > 1:\n                    raise NotImplementedError(\"Indexing a MultiIndex with a \"\n                                              \"multidimensional key is not \"\n                                              \"implemented\")\n\n                if (not isinstance(key, tuple) and len(key) > 1 and\n                        not isinstance(key[0], tuple)):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [slice(None)] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._validate_key(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n    \"\"\"\n    Purely integer-location based indexing for selection by position.\n\n    ``.iloc[]`` is primarily integer position based (from ``0`` to\n    ``length-1`` of the axis), but may also be used with a boolean\n    array.\n\n    Allowed inputs are:\n\n    - An integer, e.g. ``5``.\n    - A list or array of integers, e.g. ``[4, 3, 0]``.\n    - A slice object with ints, e.g. ``1:7``.\n    - A boolean array.\n    - A ``callable`` function with one argument (the calling Series, DataFrame\n      or Panel) and that returns valid output for indexing (one of the above).\n      This is useful in method chains, when you don't have a reference to the\n      calling object, but would like to base your selection on some value.\n\n    ``.iloc`` will raise ``IndexError`` if a requested indexer is\n    out-of-bounds, except *slice* indexers which allow out-of-bounds\n    indexing (this conforms with python/numpy *slice* semantics).\n\n    See more at ref:`Selection by Position <indexing.integer>`.\n\n    See Also\n    --------\n    DataFrame.iat : Fast integer location scalar accessor.\n    DataFrame.loc : Purely label-location based indexer for selection by label.\n    Series.iloc : Purely integer-location based indexing for\n                   selection by position.\n\n    Examples\n    --------\n\n    >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n    ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n    ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n    >>> df = pd.DataFrame(mydict)\n    >>> df\n          a     b     c     d\n    0     1     2     3     4\n    1   100   200   300   400\n    2  1000  2000  3000  4000\n\n    **Indexing just the rows**\n\n    With a scalar integer.\n\n    >>> type(df.iloc[0])\n    <class 'pandas.core.series.Series'>\n    >>> df.iloc[0]\n    a    1\n    b    2\n    c    3\n    d    4\n    Name: 0, dtype: int64\n\n    With a list of integers.\n\n    >>> df.iloc[[0]]\n       a  b  c  d\n    0  1  2  3  4\n    >>> type(df.iloc[[0]])\n    <class 'pandas.core.frame.DataFrame'>\n\n    >>> df.iloc[[0, 1]]\n         a    b    c    d\n    0    1    2    3    4\n    1  100  200  300  400\n\n    With a `slice` object.\n\n    >>> df.iloc[:3]\n          a     b     c     d\n    0     1     2     3     4\n    1   100   200   300   400\n    2  1000  2000  3000  4000\n\n    With a boolean mask the same length as the index.\n\n    >>> df.iloc[[True, False, True]]\n          a     b     c     d\n    0     1     2     3     4\n    2  1000  2000  3000  4000\n\n    With a callable, useful in method chains. The `x` passed\n    to the ``lambda`` is the DataFrame being sliced. This selects\n    the rows whose index label even.\n\n    >>> df.iloc[lambda x: x.index % 2 == 0]\n          a     b     c     d\n    0     1     2     3     4\n    2  1000  2000  3000  4000\n\n    **Indexing both axes**\n\n    You can mix the indexer types for the index and columns. Use ``:`` to\n    select the entire axis.\n\n    With scalar integers.\n\n    >>> df.iloc[0, 1]\n    2\n\n    With lists of integers.\n\n    >>> df.iloc[[0, 2], [1, 3]]\n          b     d\n    0     2     4\n    2  2000  4000\n\n    With `slice` objects.\n\n    >>> df.iloc[1:3, 0:3]\n          a     b     c\n    1   100   200   300\n    2  1000  2000  3000\n\n    With a boolean array whose length matches the columns.\n\n    >>> df.iloc[:, [True, False, True, False]]\n          a     c\n    0     1     3\n    1   100   300\n    2  1000  3000\n\n    With a callable function that expects the Series or DataFrame.\n\n    >>> df.iloc[:, lambda df: [0, 2]]\n          a     c\n    0     1     3\n    1   100   300\n    2  1000  3000\n    \"\"\"\n\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _validate_key(self, key, axis):\n        if com.is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\"iLocation based boolean \"\n                                              \"indexing on an integer type \"\n                                              \"is not available\")\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return\n\n        if isinstance(key, slice):\n            return\n        elif is_integer(key):\n            self._validate_integer(key, axis)\n        elif isinstance(key, tuple):\n            # a tuple should already have been caught by this point\n            # so don't treat a tuple as a valid indexer\n            raise IndexingError('Too many indexers')\n        elif is_list_like_indexer(key):\n            # check that the key does not exceed the maximum size of the index\n            arr = np.array(key)\n            l = len(self.obj._get_axis(axis))\n\n            if len(arr) and (arr.max() >= l or arr.min() < -l):\n                raise IndexError(\"positional indexers are out-of-bounds\")\n        else:\n            raise ValueError(\"Can only index by location with \"\n                             \"a [{types}]\".format(types=self._valid_types))\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_scalar_access(self, key):\n        # this is a shortcut accessor to both .loc and .iloc\n        # that provide the equivalent access of .at and .iat\n        # a) avoid getting things via sections and (to minimize dtype changes)\n        # b) provide a performant path\n        if not hasattr(key, '__len__'):\n            return False\n\n        if len(key) != self.ndim:\n            return False\n\n        for i, k in enumerate(key):\n            if not is_integer(k):\n                return False\n\n            ax = self.obj.axes[i]\n            if not ax.is_unique:\n                return False\n\n        return True\n\n    def _getitem_scalar(self, key):\n        # a fast-path to scalar access\n        # if not, raise\n        values = self.obj._get_value(*key, takeable=True)\n        return values\n\n    def _validate_integer(self, key, axis):\n        \"\"\"\n        Check that 'key' is a valid position in the desired axis.\n\n        Parameters\n        ----------\n        key : int\n            Requested position\n        axis : int\n            Desired axis\n\n        Returns\n        -------\n        None\n\n        Raises\n        ------\n        IndexError\n            If 'key' is not a valid position in axis 'axis'\n        \"\"\"\n\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if key >= l or key < -l:\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if com.is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim < self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=None):\n        if axis is None:\n            axis = self.axis or 0\n        obj = self.obj\n\n        if not need_slice(slice_obj):\n            return obj.copy(deep=False)\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, kind='iloc')\n        else:\n            return self.obj._take(slice_obj, axis=axis)\n\n    def _get_list_axis(self, key, axis=None):\n        \"\"\"\n        Return Series values by list or array of integers\n\n        Parameters\n        ----------\n        key : list-like positional indexer\n        axis : int (can only be zero)\n\n        Returns\n        -------\n        Series object\n        \"\"\"\n        if axis is None:\n            axis = self.axis or 0\n        try:\n            return self.obj._take(key, axis=axis)\n        except IndexError:\n            # re-raise with different error message\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n    def _getitem_axis(self, key, axis=None):\n        if axis is None:\n            axis = self.axis or 0\n\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n\n        if isinstance(key, list):\n            key = np.asarray(key)\n\n        if com.is_bool_indexer(key):\n            self._validate_key(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a list of integers\n        elif is_list_like_indexer(key):\n            return self._get_list_axis(key, axis=axis)\n\n        # a single integer\n        else:\n            if not is_integer(key):\n                raise TypeError(\"Cannot index by location index with a \"\n                                \"non-integer key\")\n\n            # validate the location\n            self._validate_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=None, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n        if axis is None:\n            axis = self.axis or 0\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        try:\n            self._validate_key(obj, axis)\n            return obj\n        except ValueError:\n            raise ValueError(\"Can only index by location with \"\n                             \"a [{types}]\".format(types=self._valid_types))\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key, is_setter=False):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not is_list_like_indexer(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj._get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if isinstance(key, tuple):\n            key = tuple(com.apply_if_callable(x, self.obj)\n                        for x in key)\n        else:\n            # scalar callable may return tuple\n            key = com.apply_if_callable(key, self.obj)\n\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key, is_setter=True))\n        key.append(value)\n        self.obj._set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n    \"\"\"\n    Access a single value for a row/column label pair.\n\n    Similar to ``loc``, in that both provide label-based lookups. Use\n    ``at`` if you only need to get or set a single value in a DataFrame\n    or Series.\n\n    See Also\n    --------\n    DataFrame.iat : Access a single value for a row/column pair by integer\n        position\n    DataFrame.loc : Access a group of rows and columns by label(s)\n    Series.at : Access a single value using a label\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n    ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n    >>> df\n        A   B   C\n    4   0   2   3\n    5   0   4   1\n    6  10  20  30\n\n    Get value at specified row/column pair\n\n    >>> df.at[4, 'B']\n    2\n\n    Set value at specified row/column pair\n\n    >>> df.at[4, 'B'] = 10\n    >>> df.at[4, 'B']\n    10\n\n    Get value within a Series\n\n    >>> df.loc[5].at['B']\n    4\n\n    Raises\n    ------\n    KeyError\n        When label does not exist in DataFrame\n    \"\"\"\n\n    _takeable = False\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require they keys to be the same type as the index (so we don't\n        fallback)\n        \"\"\"\n\n        # allow arbitrary setting\n        if is_setter:\n            return list(key)\n\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index \"\n                                     \"can only have integer indexers\")\n            else:\n                if is_integer(i) and not ax.holds_integer():\n                    raise ValueError(\"At based indexing on an non-integer \"\n                                     \"index can only have non-integer \"\n                                     \"indexers\")\n        return key\n\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n    \"\"\"\n    Access a single value for a row/column pair by integer position.\n\n    Similar to ``iloc``, in that both provide integer-based lookups. Use\n    ``iat`` if you only need to get or set a single value in a DataFrame\n    or Series.\n\n    See Also\n    --------\n    DataFrame.at : Access a single value for a row/column label pair\n    DataFrame.loc : Access a group of rows and columns by label(s)\n    DataFrame.iloc : Access a group of rows and columns by integer position(s)\n\n    Examples\n    --------\n    >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n    ...                   columns=['A', 'B', 'C'])\n    >>> df\n        A   B   C\n    0   0   2   3\n    1   0   4   1\n    2  10  20  30\n\n    Get value at specified row/column pair\n\n    >>> df.iat[1, 2]\n    1\n\n    Set value at specified row/column pair\n\n    >>> df.iat[1, 2] = 10\n    >>> df.iat[1, 2]\n    10\n\n    Get value within a series\n\n    >>> df.loc[0].iat[1]\n    2\n\n    Raises\n    ------\n    IndexError\n        When integer position is out of bounds\n    \"\"\"\n\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n\ndef length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = -step\n        return (stop - start + step - 1) // step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like_indexer(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, kind='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if obj._data.items.contains(key):\n            return None\n\n        # We might have a datetimelike string that we can translate to a\n        # slice here via partial string indexing\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except (KeyError, ValueError, NotImplementedError):\n                return None\n\n    return None\n\n\ndef check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = isna(result._values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series provided as '\n                                'indexer (index of the boolean Series and of '\n                                'the indexed object do not match')\n        result = result.astype(bool)._values\n    elif is_sparse(result):\n        result = result.to_dense()\n        result = np.asarray(result, dtype=bool)\n    else:\n        # is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef check_setitem_lengths(indexer, value, values):\n    \"\"\"Validate that value and indexer are the same length.\n\n    An special-case is allowed for when the indexer is a boolean array\n    and the number of true values equals the length of ``value``. In\n    this case, no exception is raised.\n\n    Parameters\n    ----------\n    indexer : sequence\n        The key for the setitem\n    value : array-like\n        The value for the setitem\n    values : array-like\n        The values being set into\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        When the indexer is an ndarray or list and the lengths don't\n        match.\n    \"\"\"\n    # boolean with truth values == len of the value is ok too\n    if isinstance(indexer, (np.ndarray, list)):\n        if is_list_like(value) and len(indexer) != len(value):\n            if not (isinstance(indexer, np.ndarray) and\n                    indexer.dtype == np.bool_ and\n                    len(indexer[indexer]) == len(value)):\n                raise ValueError(\"cannot set using a list-like indexer \"\n                                 \"with a different length than the value\")\n    # slice\n    elif isinstance(indexer, slice):\n\n        if is_list_like(value) and len(values):\n            if len(value) != length_of_indexer(indexer, values):\n                raise ValueError(\"cannot set using a slice indexer with a \"\n                                 \"different length than the value\")\n\n\ndef convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n    return the scalar indexer and a boolean indicating if we converted\n    \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key']) if isinstance(_idx, dict) else\n                _idx)\n\n    return tuple(get_indexer(_i, _idx) for _i, _idx in enumerate(indexer))\n\n\ndef maybe_convert_indices(indices, n):\n    \"\"\"\n    Attempt to convert indices into valid, positive indices.\n\n    If we have negative indices, translate to positive here.\n    If we have indices that are out-of-bounds, raise an IndexError.\n\n    Parameters\n    ----------\n    indices : array-like\n        The array of indices that we are to convert.\n    n : int\n        The number of elements in the array that we are indexing.\n\n    Returns\n    -------\n    valid_indices : array-like\n        An array-like of positive indices that correspond to the ones\n        that were passed in initially to this function.\n\n    Raises\n    ------\n    IndexError : one of the converted indices either exceeded the number\n        of elements (specified by `n`) OR was still negative.\n    \"\"\"\n\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.intp)\n\n    mask = indices < 0\n    if mask.any():\n        indices = indices.copy()\n        indices[mask] += n\n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef validate_indices(indices, n):\n    \"\"\"Perform bounds-checking for an indexer.\n\n    -1 is allowed for indicating missing values.\n\n    Parameters\n    ----------\n    indices : ndarray\n    n : int\n        length of the array being indexed\n\n    Raises\n    ------\n    ValueError\n\n    Examples\n    --------\n    >>> validate_indices([1, 2], 3)\n    # OK\n    >>> validate_indices([1, -2], 3)\n    ValueError\n    >>> validate_indices([1, 2, 3], 3)\n    IndexError\n    >>> validate_indices([-1, -1], 0)\n    # OK\n    >>> validate_indices([0, 1], 0)\n    IndexError\n    \"\"\"\n    if len(indices):\n        min_idx = indices.min()\n        if min_idx < -1:\n            msg = (\"'indices' contains values less than allowed ({} < {})\"\n                   .format(min_idx, -1))\n            raise ValueError(msg)\n\n        max_idx = indices.max()\n        if max_idx >= n:\n            raise IndexError(\"indices are out-of-bounds\")\n\n\ndef maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries, Index)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef is_nested_tuple(tup, labels):\n    # check for a compatible nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    for i, k in enumerate(tup):\n\n        if is_list_like(k) or isinstance(k, slice):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\n\ndef is_list_like_indexer(key):\n    # allow a list_like, but exclude NamedTuples which can be indexers\n    return is_list_like(key) and not (isinstance(key, tuple) and\n                                      type(key) is not tuple)\n\n\ndef is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not is_list_like_indexer(key)\n\n\ndef need_slice(obj):\n    return (obj.start is not None or obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n\n\ndef _non_reducing_slice(slice_):\n    \"\"\"\n    Ensurse that a slice doesn't reduce to a Series or Scalar.\n\n    Any user-paseed `subset` should have this called on it\n    to make sure we're always working with DataFrames.\n    \"\"\"\n    # default to column slice, like DataFrame\n    # ['A', 'B'] -> IndexSlices[:, ['A', 'B']]\n    kinds = tuple(list(compat.string_types) + [ABCSeries, np.ndarray, Index,\n                                               list])\n    if isinstance(slice_, kinds):\n        slice_ = IndexSlice[:, slice_]\n\n    def pred(part):\n        # true when slice does *not* reduce\n        return isinstance(part, slice) or is_list_like(part)\n\n    if not is_list_like(slice_):\n        if not isinstance(slice_, slice):\n            # a 1-d slice, like df.loc[1]\n            slice_ = [[slice_]]\n        else:\n            # slice(a, b, c)\n            slice_ = [slice_]  # to tuplize later\n    else:\n        slice_ = [part if pred(part) else [part] for part in slice_]\n    return tuple(slice_)\n\n\ndef _maybe_numeric_slice(df, slice_, include_bool=False):\n    \"\"\"\n    want nice defaults for background_gradient that don't break\n    with non-numeric data. But if slice_ is passed go with that.\n    \"\"\"\n    if slice_ is None:\n        dtypes = [np.number]\n        if include_bool:\n            dtypes.append(bool)\n        slice_ = IndexSlice[:, df.select_dtypes(include=dtypes).columns]\n    return slice_\n",
      "file_patch": "@@ -2354,7 +2354,7 @@ class _AtIndexer(_ScalarAccessIndexer):\n                     raise ValueError(\"At based indexing on an integer index \"\n                                      \"can only have integer indexers\")\n             else:\n-                if is_integer(i):\n+                if is_integer(i) and not ax.holds_integer():\n                     raise ValueError(\"At based indexing on an non-integer \"\n                                      \"index can only have non-integer \"\n                                      \"indexers\")\n",
      "files_name_in_blame_commit": [
        "base.py",
        "test_indexing.py",
        "indexing.py",
        "test_scalar.py"
      ]
    }
  },
  "commits_modify_file_before_fix": {
    "size": 420
  },
  "recursive_blame_commits": {
    "recursive_blame_function_lines": {
      "2342": {
        "commit_id": "8c51d868ed19dcd8ed346cd4f61e7494eb18aa05",
        "line_code": "    def _convert_key(self, key, is_setter=False):",
        "commit_date": "2014-10-05 16:47:20",
        "valid": 1
      },
      "2343": {
        "commit_id": "118fd01f2a8b5b3a709e98e082adbd7a8c3860be",
        "line_code": "        \"\"\" require they keys to be the same type as the index (so we don't",
        "commit_date": "2016-01-19 14:48:11",
        "valid": 1
      },
      "2344": {
        "commit_id": "118fd01f2a8b5b3a709e98e082adbd7a8c3860be",
        "line_code": "        fallback)",
        "commit_date": "2016-01-19 14:48:11",
        "valid": 1
      },
      "2345": {
        "commit_id": "118fd01f2a8b5b3a709e98e082adbd7a8c3860be",
        "line_code": "        \"\"\"",
        "commit_date": "2016-01-19 14:48:11",
        "valid": 1
      },
      "2346": {
        "commit_id": "8c51d868ed19dcd8ed346cd4f61e7494eb18aa05",
        "line_code": "",
        "commit_date": "2014-10-05 16:47:20",
        "valid": 0
      },
      "2347": {
        "commit_id": "8c51d868ed19dcd8ed346cd4f61e7494eb18aa05",
        "line_code": "        # allow arbitrary setting",
        "commit_date": "2014-10-05 16:47:20",
        "valid": 1
      },
      "2348": {
        "commit_id": "8c51d868ed19dcd8ed346cd4f61e7494eb18aa05",
        "line_code": "        if is_setter:",
        "commit_date": "2014-10-05 16:47:20",
        "valid": 1
      },
      "2349": {
        "commit_id": "8c51d868ed19dcd8ed346cd4f61e7494eb18aa05",
        "line_code": "            return list(key)",
        "commit_date": "2014-10-05 16:47:20",
        "valid": 1
      },
      "2350": {
        "commit_id": "8c51d868ed19dcd8ed346cd4f61e7494eb18aa05",
        "line_code": "",
        "commit_date": "2014-10-05 16:47:20",
        "valid": 0
      },
      "2351": {
        "commit_id": "2dce536d9a4bf1a9e6b18ae117ca54f3fdc5d2bb",
        "line_code": "        for ax, i in zip(self.obj.axes, key):",
        "commit_date": "2014-09-19 11:03:23",
        "valid": 1
      },
      "2352": {
        "commit_id": "2dce536d9a4bf1a9e6b18ae117ca54f3fdc5d2bb",
        "line_code": "            if ax.is_integer():",
        "commit_date": "2014-09-19 11:03:23",
        "valid": 1
      },
      "2353": {
        "commit_id": "379e145e2733fcee8ed055dec31f282efba1bd79",
        "line_code": "                if not is_integer(i):",
        "commit_date": "2015-02-13 22:38:12",
        "valid": 1
      },
      "2354": {
        "commit_id": "118fd01f2a8b5b3a709e98e082adbd7a8c3860be",
        "line_code": "                    raise ValueError(\"At based indexing on an integer index \"",
        "commit_date": "2016-01-19 14:48:11",
        "valid": 1
      },
      "2355": {
        "commit_id": "118fd01f2a8b5b3a709e98e082adbd7a8c3860be",
        "line_code": "                                     \"can only have integer indexers\")",
        "commit_date": "2016-01-19 14:48:11",
        "valid": 1
      },
      "2356": {
        "commit_id": "2dce536d9a4bf1a9e6b18ae117ca54f3fdc5d2bb",
        "line_code": "            else:",
        "commit_date": "2014-09-19 11:03:23",
        "valid": 1
      },
      "2357": {
        "commit_id": "379e145e2733fcee8ed055dec31f282efba1bd79",
        "line_code": "                if is_integer(i):",
        "commit_date": "2015-02-13 22:38:12",
        "valid": 1
      },
      "2358": {
        "commit_id": "118fd01f2a8b5b3a709e98e082adbd7a8c3860be",
        "line_code": "                    raise ValueError(\"At based indexing on an non-integer \"",
        "commit_date": "2016-01-19 14:48:11",
        "valid": 1
      },
      "2359": {
        "commit_id": "118fd01f2a8b5b3a709e98e082adbd7a8c3860be",
        "line_code": "                                     \"index can only have non-integer \"",
        "commit_date": "2016-01-19 14:48:11",
        "valid": 1
      },
      "2360": {
        "commit_id": "2dce536d9a4bf1a9e6b18ae117ca54f3fdc5d2bb",
        "line_code": "                                     \"indexers\")",
        "commit_date": "2014-09-19 11:03:23",
        "valid": 1
      },
      "2361": {
        "commit_id": "2dce536d9a4bf1a9e6b18ae117ca54f3fdc5d2bb",
        "line_code": "        return key",
        "commit_date": "2014-09-19 11:03:23",
        "valid": 1
      }
    },
    "commits": {
      "118fd01f2a8b5b3a709e98e082adbd7a8c3860be": {
        "commit": {
          "commit_id": "118fd01f2a8b5b3a709e98e082adbd7a8c3860be",
          "commit_message": "PEP: pandas/core round 4 (indexing, internals, missing)\n\nAuthor: rockg <grant.roch@gmail.com>\n\nCloses #12074 from rockg/pep8-round4 and squashes the following commits:\n\n13f6d4a [rockg] PEP: pandas/core round 4 (indexing, internals, missing)",
          "commit_author": "rockg",
          "commit_date": "2016-01-19 14:48:11",
          "commit_parent": "e8fbabdfd581c83b7530751270861da42ea9cefa"
        },
        "function": {
          "function_name": "_convert_key",
          "function_code_before": "def _convert_key(self, key, is_setter=False):\n    \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n    if is_setter:\n        return list(key)\n    for (ax, i) in zip(self.obj.axes, key):\n        if ax.is_integer():\n            if not is_integer(i):\n                raise ValueError('At based indexing on an integer index can only have integer indexers')\n        elif is_integer(i):\n            raise ValueError('At based indexing on an non-integer index can only have non-integer indexers')\n    return key",
          "function_code_after": "def _convert_key(self, key, is_setter=False):\n    \"\"\" require they keys to be the same type as the index (so we don't\n        fallback)\n        \"\"\"\n    if is_setter:\n        return list(key)\n    for (ax, i) in zip(self.obj.axes, key):\n        if ax.is_integer():\n            if not is_integer(i):\n                raise ValueError('At based indexing on an integer index can only have integer indexers')\n        elif is_integer(i):\n            raise ValueError('At based indexing on an non-integer index can only have non-integer indexers')\n    return key",
          "function_before_start_line": 1583,
          "function_before_end_line": 1599,
          "function_after_start_line": 1606,
          "function_after_end_line": 1625,
          "function_before_token_count": 72,
          "function_after_token_count": 73,
          "functions_name_modified_file": [
            "is_index_slice",
            "_convert_for_reindex",
            "_setitem_with_indexer",
            "check_bool_indexer",
            "_getitem_nested_tuple",
            "_align_panel",
            "_convert_to_indexer",
            "_getbool_axis",
            "_is_valid_list_like",
            "_get_slice_axis",
            "_has_valid_tuple",
            "maybe_droplevels",
            "_align_series",
            "maybe_convert_ix",
            "_has_valid_setitem_indexer",
            "_should_validate_iterable",
            "_has_valid_type",
            "_multi_take_opportunity",
            "__iter__",
            "_is_valid_integer",
            "_convert_slice_indexer",
            "_non_reducing_slice",
            "convert_missing_indexer",
            "_convert_scalar_indexer",
            "is_list_like_indexer",
            "maybe_convert_indices",
            "_get_setitem_indexer",
            "_getitem_iterable",
            "_handle_lowerdim_multi_index_axis0",
            "_convert_tuple",
            "_is_nested_tuple_indexer",
            "_get_loc",
            "is_label_like",
            "_convert_range",
            "need_slice",
            "_has_valid_positional_setitem_indexer",
            "_maybe_numeric_slice",
            "__getitem__",
            "convert_to_index_sliceable",
            "_getitem_tuple",
            "__init__",
            "_getitem_axis",
            "convert_from_missing_indexer_tuple",
            "is_nested_tuple",
            "__call__",
            "_tuplify",
            "_getitem_lowerdim",
            "_multi_take",
            "_slice",
            "get_indexers_list",
            "__setitem__",
            "_convert_key",
            "length_of_indexer",
            "_get_label",
            "_align_frame"
          ],
          "functions_name_all_files": [
            "pad_2d",
            "convert",
            "_vstack",
            "concatenate_join_units",
            "kind",
            "_align_panel",
            "_getbool_axis",
            "_is_valid_list_like",
            "_get_slice_axis",
            "is_view",
            "_maybe_downcast",
            "_try_fill",
            "_has_valid_tuple",
            "reindex_indexer",
            "_align_series",
            "sp_index",
            "create_block_manager_from_blocks",
            "_interp_wrapper",
            "is_bool",
            "to_native_types",
            "sparse_reindex",
            "_is_valid_integer",
            "_convert_slice_indexer",
            "pad_1d",
            "is_numeric_mixed_type",
            "eval",
            "_getitem_iterable",
            "_handle_lowerdim_multi_index_axis0",
            "_convert_tuple",
            "interpolate_1d",
            "dtype",
            "get_scalar",
            "construction_error",
            "_consolidate_check",
            "_consolidate",
            "get_mgr_concatenation_plan",
            "_has_valid_positional_setitem_indexer",
            "_block",
            "sp_values",
            "_simple_blockify",
            "fast_xs",
            "is_consolidated",
            "__getitem__",
            "_transform_index",
            "_getitem_tuple",
            "__init__",
            "is_nested_tuple",
            "_interpolate_with_fill",
            "get_bool_data",
            "ftype",
            "_consolidate_inplace",
            "_is_indexed_like",
            "shape",
            "_multi_take",
            "__setstate__",
            "setitem",
            "get_indexers_list",
            "_sparse_blockify",
            "_convert_key",
            "maybe_convert_indices",
            "_get_label",
            "as_matrix",
            "trim_join_unit",
            "_verify_integrity",
            "_convert_for_reindex",
            "_setitem_with_indexer",
            "form_blocks",
            "_getitem_nested_tuple",
            "diff",
            "downcast",
            "itemsize",
            "_values",
            "external_values",
            "take_nd",
            "shift",
            "rename_axis",
            "_possibly_compare",
            "_putmask_smart",
            "_should_validate_iterable",
            "_has_valid_type",
            "get_dtypes",
            "__contains__",
            "convert_missing_indexer",
            "_interleaved_dtype",
            "backfill_2d",
            "merge",
            "_get_loc",
            "is_label_like",
            "_convert_range",
            "take",
            "_concat_indexes",
            "_try_operate",
            "_astype",
            "convert_to_index_sliceable",
            "__getstate__",
            "get_slice",
            "_preprocess_slice_or_indexer",
            "_getitem_lowerdim",
            "_get_blkno_placements",
            "get_reindexed_values",
            "_interpolate",
            "_get_fill_func",
            "__len__",
            "__nonzero__",
            "is_categorical_astype",
            "_merge_blocks",
            "length_of_indexer",
            "get_numeric_data",
            "_multi_blockify",
            "consolidate",
            "_interpolate_scipy_wrapper",
            "getitem_block",
            "_block2d_to_blocknd",
            "needs_filling",
            "astype",
            "is_mixed_type",
            "_try_coerce_result",
            "check_bool_indexer",
            "_get_counts",
            "mgr_locs",
            "_extend_blocks",
            "interpolate",
            "_clean_fill_method",
            "maybe_droplevels",
            "to_object_block",
            "insert",
            "combine_concat_plans",
            "maybe_convert_ix",
            "_has_valid_setitem_indexer",
            "combine",
            "_multi_take_opportunity",
            "_non_reducing_slice",
            "apply",
            "replace_list",
            "should_store",
            "array_dtype",
            "is_list_like_indexer",
            "_interleave",
            "_get_setitem_indexer",
            "_factor_indexer",
            "set_axis",
            "_rebuild_blknos_and_blklocs",
            "_slice_take_blocks_ax0",
            "where",
            "_is_nested_tuple_indexer",
            "_try_cast_result",
            "make_block",
            "__unicode__",
            "items_overlap_with_suffix",
            "is_datelike",
            "concatenate_block_managers",
            "__repr__",
            "get_ftype_counts",
            "_block_shape",
            "fillna",
            "get_empty_dtype_and_na",
            "putmask",
            "_fast_count_smallints",
            "__call__",
            "get_dtype_counts",
            "isnull",
            "create_block_manager_from_arrays",
            "_tuplify",
            "copy",
            "_slice",
            "reshape_nd",
            "backfill_1d",
            "_try_coerce_and_cast_result",
            "__setitem__",
            "make_empty",
            "_clean_interp_method",
            "is_index_slice",
            "interpolate_2d",
            "set",
            "_clean_reindex_fill_method",
            "_convert_to_indexer",
            "_post_setstate",
            "_try_coerce_args",
            "add_prefix",
            "_replace_single",
            "reindex",
            "iget",
            "equals",
            "to_dense",
            "internal_values",
            "_make_na_block",
            "__iter__",
            "_convert_scalar_indexer",
            "_get_items",
            "reindex_axis",
            "nblocks",
            "fill_value",
            "_try_cast",
            "index",
            "need_slice",
            "get_ftypes",
            "make_block_same_class",
            "get",
            "_maybe_numeric_slice",
            "get_values",
            "replace",
            "ndim",
            "is_null",
            "delete",
            "convert_from_missing_indexer_tuple",
            "_getitem_axis",
            "xs",
            "_consolidate_key",
            "_stack_arrays",
            "add_suffix",
            "_can_hold_element",
            "_is_single_block",
            "_can_hold_na",
            "is_datelike_mixed_type",
            "_align_frame"
          ],
          "functions_name_co_evolved_modified_file": [
            "is_index_slice",
            "_setitem_with_indexer",
            "_getitem_nested_tuple",
            "_align_panel",
            "_is_valid_list_like",
            "_should_validate_iterable",
            "_non_reducing_slice",
            "_has_valid_type",
            "convert_missing_indexer",
            "is_list_like_indexer",
            "_getitem_iterable",
            "_convert_tuple",
            "_is_nested_tuple_indexer",
            "need_slice",
            "_has_valid_positional_setitem_indexer",
            "convert_from_missing_indexer_tuple",
            "_getitem_tuple",
            "_getitem_axis",
            "__call__",
            "_getitem_lowerdim",
            "_multi_take",
            "get_indexers_list",
            "length_of_indexer",
            "_get_label",
            "_align_frame"
          ],
          "functions_name_co_evolved_all_files": [
            "convert",
            "_align_panel",
            "_is_valid_list_like",
            "_maybe_downcast",
            "reindex_indexer",
            "create_block_manager_from_blocks",
            "_interp_wrapper",
            "to_native_types",
            "sparse_reindex",
            "eval",
            "_getitem_iterable",
            "interpolate_1d",
            "_convert_tuple",
            "get_scalar",
            "construction_error",
            "get_mgr_concatenation_plan",
            "_has_valid_positional_setitem_indexer",
            "_getitem_tuple",
            "__init__",
            "_interpolate_with_fill",
            "_is_indexed_like",
            "_multi_take",
            "setitem",
            "__setstate__",
            "get_indexers_list",
            "_sparse_blockify",
            "_get_label",
            "_verify_integrity",
            "_setitem_with_indexer",
            "form_blocks",
            "_getitem_nested_tuple",
            "diff",
            "downcast",
            "external_values",
            "take_nd",
            "shift",
            "_putmask_smart",
            "_should_validate_iterable",
            "_has_valid_type",
            "convert_missing_indexer",
            "_interleaved_dtype",
            "merge",
            "take",
            "_astype",
            "__getstate__",
            "_getitem_lowerdim",
            "get_reindexed_values",
            "_interpolate",
            "_merge_blocks",
            "length_of_indexer",
            "_multi_blockify",
            "_interpolate_scipy_wrapper",
            "getitem_block",
            "astype",
            "interpolate",
            "_clean_fill_method",
            "to_object_block",
            "insert",
            "combine_concat_plans",
            "combine",
            "apply",
            "_non_reducing_slice",
            "replace_list",
            "should_store",
            "array_dtype",
            "is_list_like_indexer",
            "set_axis",
            "_slice_take_blocks_ax0",
            "where",
            "_is_nested_tuple_indexer",
            "_try_cast_result",
            "make_block",
            "__unicode__",
            "concatenate_block_managers",
            "__repr__",
            "_block_shape",
            "fillna",
            "putmask",
            "__call__",
            "create_block_manager_from_arrays",
            "copy",
            "reshape_nd",
            "make_empty",
            "_clean_interp_method",
            "is_index_slice",
            "interpolate_2d",
            "set",
            "_try_coerce_args",
            "_replace_single",
            "reindex",
            "iget",
            "equals",
            "internal_values",
            "reindex_axis",
            "fill_value",
            "need_slice",
            "make_block_same_class",
            "get",
            "replace",
            "get_values",
            "is_null",
            "convert_from_missing_indexer_tuple",
            "_getitem_axis",
            "xs",
            "_can_hold_element",
            "_align_frame"
          ]
        },
        "file": {
          "file_name": "indexing.py",
          "file_nloc": 1190,
          "file_complexity": 481,
          "file_token_count": 8361,
          "file_before": "# pylint: disable=W0223\n\nfrom pandas.core.index import Index, MultiIndex\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nimport pandas.core.common as com\nfrom pandas.core.common import (is_bool_indexer, is_integer_dtype,\n                                _asarray_tuplesafe, is_list_like, isnull,\n                                is_null_slice, is_full_slice,\n                                ABCSeries, ABCDataFrame, ABCPanel, is_float,\n                                _values_from_object, _infer_fill_value, is_integer)\nimport numpy as np\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix',   _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc',  _LocIndexer),\n        ('at',   _AtIndexer),\n        ('iat',  _iAtIndexer),\n    ]\n\n# \"null slice\"\n_NS = slice(None, None)\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    def __getitem__(self, arg):\n        return arg\nIndexSlice = _IndexSlice()\n\nclass IndexingError(Exception):\n    pass\n\nclass _NDFrameIndexer(object):\n    _valid_types = None\n    _exception = KeyError\n\n    def __init__(self, obj, name):\n        self.obj = obj\n        self.ndim = obj.ndim\n        self.name = name\n        self.axis = None\n\n    def __call__(self, *args, **kwargs):\n        # we need to return a copy of ourselves\n        self = self.__class__(self.obj, self.name)\n\n        # set the passed in values\n        for k, v in compat.iteritems(kwargs):\n            setattr(self,k,v)\n        return self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            try:\n                values = self.obj.get_value(*key)\n                if np.isscalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _get_label(self, label, axis=0):\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            try:\n                return self.obj._xs(label, axis=axis)\n            except:\n                return self.obj[label]\n        elif (isinstance(label, tuple) and\n                isinstance(label[axis], slice)):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=0):\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=0, kind=None):\n        return self.obj._slice(obj, axis=axis, kind=kind)\n\n    def _get_setitem_indexer(self, key):\n        if self.axis is not None:\n            return self._convert_tuple(key, is_setter=True)\n\n        axis = self.obj._get_axis(0)\n        if isinstance(axis, MultiIndex):\n            try:\n                return axis.get_loc(key)\n            except Exception:\n                pass\n\n        if isinstance(key, tuple) and not self.ndim < len(key):\n            return self._convert_tuple(key, is_setter=True)\n        if isinstance(key, range):\n            return self._convert_range(key, is_setter=True)\n\n        try:\n            return self._convert_to_indexer(key, is_setter=True)\n        except TypeError:\n            raise IndexingError(key)\n\n    def __setitem__(self, key, value):\n        indexer = self._get_setitem_indexer(key)\n        self._setitem_with_indexer(indexer, value)\n\n    def _has_valid_type(self, k, axis):\n        raise NotImplementedError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            if not self._has_valid_type(k, i):\n                raise ValueError(\"Location based indexing can only have [%s] \"\n                                 \"types\" % self._valid_types)\n\n    def _should_validate_iterable(self, axis=0):\n        \"\"\" return a boolean whether this axes needs validation for a passed iterable \"\"\"\n        ax = self.obj._get_axis(axis)\n        if isinstance(ax, MultiIndex):\n            return False\n        elif ax.is_floating():\n            return False\n\n        return True\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any([ isinstance(ax, MultiIndex) for ax in self.obj.axes ]):\n            return any([ is_nested_tuple(tup,ax) for ax in self.obj.axes ])\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_range(self, key, is_setter=False):\n        \"\"\" convert a range argument \"\"\"\n        return list(key)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, kind=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, kind=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n            will raise if needed, does not modify the indexer externally \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like_indexer(i):\n                    # should check the elements?\n                    pass\n                elif is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{0} cannot enlarge its target object\"\n                                         .format(self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{0} cannot enlarge its target object\"\n                                     .format(self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        from pandas import Panel, DataFrame, Series\n        info_axis = self.obj._info_axis_number\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n\n        # if there is only one block/type, still have to take split path\n        # unless the block is one-dimensional or it can hold the value\n        if not take_split_path and self.obj._data.blocks:\n            blk, = self.obj._data.blocks\n            if 1 < blk.ndim:  # in case of dict, keys are indices\n                val = list(value.values()) if isinstance(value,dict) else value\n                take_split_path = not blk._can_hold_element(val)\n\n        if isinstance(indexer, tuple) and len(indexer) == len(self.obj.axes):\n\n            for i, ax in zip(indexer, self.obj.axes):\n\n                # if we have any multi-indexes that have non-trivial slices (not null slices)\n                # then we must take the split path, xref GH 10360\n                if isinstance(ax, MultiIndex) and not (is_integer(i) or is_null_slice(i)):\n                    take_split_path = True\n                    break\n\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any([not l for l in len_non_info_axes]):\n                            if not is_list_like_indexer(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n\n                        # add a new item with the dtype setup\n                        self.obj[key] = _infer_fill_value(value)\n\n                        new_indexer = convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = index.insert(len(index),key)\n                    self.obj._data = self.obj.reindex_axis(labels, i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj.is_copy=None\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    new_index = index.insert(len(index),indexer)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value])._values\n                    if len(self.obj._values):\n                        new_values = np.concatenate([self.obj._values,\n                                                     new_values])\n\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\n                            \"cannot set a frame with no defined columns\"\n                        )\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if is_list_like_indexer(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\n                                    \"cannot set a row with mismatched columns\"\n                                    )\n\n                        value = Series(value,index=self.obj.columns,name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        item_labels = self.obj._get_axis(info_axis)\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].axes[0], MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like_indexer(value) and np.iterable(value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\n                            \"cannot set using a multi-index selection indexer \"\n                            \"with a different length than the value\"\n                        )\n\n                    # make sure we have an ndarray\n                    value = getattr(value,'values',value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj._consolidate_inplace()\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = length_of_indexer(plane_indexer[0],\n                                                       plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice or a slice with full bounds\n                # which means essentially reassign to the columns of a multi-dim object\n                # GH6149 (null slice), GH10408 (full bounds)\n                if isinstance(pi, tuple) and all(is_null_slice(idx) or is_full_slice(idx, len(self.obj)) for idx in pi):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s._consolidate_inplace()\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if not len(labels) == 1 or not np.iterable(value):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an iterable, with a ndim of at least 1\n            # eg. don't pass through np.array(0)\n            if is_list_like_indexer(value) and getattr(value,'ndim',1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n                    sub_indexer = list(indexer)\n                    multiindex_indexer = isinstance(labels, MultiIndex)\n\n                    for item in labels:\n                        if item in value:\n                            sub_indexer[info_axis] = item\n                            v = self._align_series(\n                                tuple(sub_indexer), value[item], multiindex_indexer\n                            )\n                        else:\n                            v = np.nan\n\n                        setter(item, v)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value,dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = maybe_convert_ix(*indexer)\n\n                # if we are setting on the info axis ONLY\n                # set using those methods to avoid block-splitting\n                # logic here\n                if len(indexer) > info_axis and is_integer(indexer[info_axis]) and all(\n                    is_null_slice(idx) for i, idx in enumerate(indexer) if i != info_axis):\n                    self.obj[item_labels[indexer[info_axis]]] = value\n                    return\n\n            if isinstance(value, (ABCSeries, dict)):\n                value = self._align_series(indexer, Series(value))\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._consolidate_inplace()\n            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser, multiindex_indexer=False):\n        \"\"\"\n        Parameters\n        ----------\n        indexer : tuple, slice, scalar\n            The indexer used to get the locations that will be set to\n            `ser`\n\n        ser : pd.Series\n            The values to assign to the locations specified by `indexer`\n\n        multiindex_indexer : boolean, optional\n            Defaults to False. Should be set to True if `indexer` was from\n            a `pd.MultiIndex`, to avoid unnecessary broadcasting.\n\n\n        Returns:\n        --------\n        `np.array` of `ser` broadcast to the appropriate shape for assignment\n        to the locations selected by `indexer`\n\n        \"\"\"\n        if isinstance(indexer, (slice, np.ndarray, list, Index)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            # flatten np.ndarray indexers\n            ravel = lambda i: i.ravel() if isinstance(i, np.ndarray) else i\n            indexer = tuple(map(ravel, indexer))\n\n            aligners = [not is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all([com.is_sequence(_) for _ in indexer])):\n                ser = ser.reindex(obj.axes[0][indexer[0]], copy=True)._values\n\n                # single indexer\n                if len(indexer) > 1 and not multiindex_indexer:\n                    l = len(indexer[1])\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if com.is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like_indexer(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix)\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser._values.copy()\n\n                    return ser.reindex(new_ix)._values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser._values.copy()\n                    return ser.reindex(ax)._values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser._values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif np.isscalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser._values.copy()\n\n            return ser.reindex(ax)._values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n\n        if isinstance(indexer, tuple):\n\n            aligners = [not is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if com.is_sequence(ix) or isinstance(ix, slice):\n                    if idx is None:\n                        idx = ax[ix].ravel()\n                    elif cols is None:\n                        cols = ax[ix].ravel()\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n\n                # need to conform to the convention\n                # as we are not selecting on the items axis\n                # and we have a single indexer\n                # GH 7763\n                if len(sindexers) == 1 and sindexers[0] != 0:\n                    df = df.T\n\n                if idx is None:\n                    idx = df.index\n                if cols is None:\n                    cols = df.columns\n\n            if idx is not None and cols is not None:\n\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy()._values\n                else:\n                    val = df.reindex(idx, columns=cols)._values\n                return val\n\n        elif ((isinstance(indexer, slice) or is_list_like_indexer(indexer))\n              and is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy()._values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if isinstance(ax, MultiIndex) and isinstance(\n                    df.index, MultiIndex) and ax.nlevels != df.index.nlevels:\n                    raise TypeError(\"cannot align on a multi-index with out specifying the join levels\")\n\n                val = df.reindex(index=ax)._values\n            return val\n\n        elif np.isscalar(indexer) and is_panel:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy()._values\n\n            return df.reindex(idx, columns=cols)._values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        from pandas.core.generic import NDFrame\n\n        # ugly hack for GH #836\n        if not isinstance(self.obj, NDFrame):\n            return False\n\n        if not all(is_list_like_indexer(x) for x in tup):\n            return False\n\n        # just too complicated\n        for indexer, ax in zip(tup, self.obj._data.axes):\n            if isinstance(ax, MultiIndex):\n                return False\n            elif is_bool_indexer(indexer):\n                return False\n            elif not ax.is_unique:\n                return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\" create the reindex map for our objects, raise the _exception if we\n        can't create the indexer\n        \"\"\"\n        try:\n            o = self.obj\n            d = dict([\n                (a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n                for t, a in zip(tup, o._AXIS_ORDERS)\n            ])\n            return o.reindex(**d)\n        except:\n            raise self._exception\n\n    def _convert_for_reindex(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if is_bool_indexer(key):\n            key = check_bool_indexer(labels, key)\n            return labels[key]\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if is_integer_dtype(keyarr) and not labels.is_integer():\n                keyarr = com._ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n            return keyarr\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=0)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        if isinstance(ax0, MultiIndex):\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not is_list_like_indexer(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0\n                            and len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of selectors\n            return self._getitem_axis(tup, axis=0)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if np.isscalar(obj) or not hasattr(obj,'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=0):\n\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif is_list_like_indexer(key) and not (isinstance(key, tuple) and\n                                        isinstance(labels, MultiIndex)):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n            if is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _getitem_iterable(self, key, axis=0):\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        if is_bool_indexer(key):\n            key = check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj.take(inds, axis=axis, convert=False)\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if com.is_categorical_dtype(labels):\n                keyarr = labels._shallow_copy(keyarr)\n\n            # have the index handle the indexer and possibly return\n            # an indexer or raising\n            indexer = labels._convert_list_indexer(keyarr, kind=self.name)\n            if indexer is not None:\n                return self.obj.take(indexer, axis=axis)\n\n            # this is not the most robust, but...\n            if (isinstance(labels, MultiIndex) and len(keyarr) and\n                    not isinstance(keyarr[0], tuple)):\n                level = 0\n            else:\n                level = None\n\n            # existing labels are unique and indexer are unique\n            if labels.is_unique and Index(keyarr).is_unique:\n\n                try:\n                    result = self.obj.reindex_axis(keyarr, axis=axis, level=level)\n\n                    # this is an error as we are trying to find\n                    # keys in a multi-index that don't exist\n                    if isinstance(labels, MultiIndex) and level is not None:\n                        if hasattr(result,'ndim') and not np.prod(result.shape) and len(keyarr):\n                            raise KeyError(\"cannot index a multi-index axis with these keys\")\n\n                    return result\n\n                except AttributeError:\n\n                    # Series\n                    if axis != 0:\n                        raise AssertionError('axis must be 0')\n                    return self.obj.reindex(keyarr, level=level)\n\n            # existing labels are non-unique\n            else:\n\n                # reindex with the specified axis\n                if axis + 1 > self.obj.ndim:\n                    raise AssertionError(\"invalid indexing error with \"\n                                         \"non-unique index\")\n\n                new_target, indexer, new_indexer = labels._reindex_non_unique(keyarr)\n\n                if new_indexer is not None:\n                    result = self.obj.take(indexer[indexer!=-1], axis=axis,\n                                           convert=False)\n\n                    result = result._reindex_with_indexers({\n                        axis: [new_target, new_indexer]\n                        }, copy=True, allow_dups=True)\n\n                else:\n                    result = self.obj.take(indexer, axis=axis,\n                                           convert=False)\n\n                return result\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        \"In the face of ambiguity, refuse the temptation to guess.\"\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        labels = self.obj._get_axis(axis)\n\n        # if we are a scalar indexer and not type correct raise\n        obj = self._convert_scalar_indexer(obj, axis)\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except LookupError:\n            if isinstance(obj, tuple) and isinstance(labels, MultiIndex):\n                if is_setter and len(obj) == labels.nlevels:\n                    return {'key': obj}\n                raise\n        except TypeError:\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n        elif is_list_like_indexer(obj):\n            if is_bool_indexer(obj):\n                obj = check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                if isinstance(obj, Index):\n                    # want Index objects to pass through untouched\n                    objarr = obj\n                else:\n                    objarr = _asarray_tuplesafe(obj)\n\n                # The index may want to handle a list indexer differently\n                # by returning an indexer or raising\n                indexer = labels._convert_list_indexer(objarr, kind=self.name)\n                if indexer is not None:\n                    return indexer\n\n                # this is not the most robust, but...\n                if (isinstance(labels, MultiIndex) and\n                        not isinstance(objarr[0], tuple)):\n                    level = 0\n                    _, indexer = labels.reindex(objarr, level=level)\n\n                    # take all\n                    if indexer is None:\n                        indexer = np.arange(len(labels))\n\n                    check = labels.levels[0].get_indexer(objarr)\n                else:\n                    level = None\n\n                    # unique index\n                    if labels.is_unique:\n                        indexer = check = labels.get_indexer(objarr)\n\n                    # non-unique (dups)\n                    else:\n                        (indexer,\n                         missing) = labels.get_indexer_non_unique(objarr)\n                        check = indexer\n\n                mask = check == -1\n                if mask.any():\n                    raise KeyError('%s not in index' % objarr[mask])\n\n                return _values_from_object(indexer)\n\n        else:\n            try:\n                return labels.get_loc(obj)\n            except LookupError:\n                # allow a not found key only if we are a setter\n                if not is_list_like_indexer(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not need_slice(slice_obj):\n            return obj\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, kind='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n\n    \"\"\"A primarily label-location based indexer, with integer position\n    fallback.\n\n    ``.ix[]`` supports mixed integer and label based access. It is\n    primarily label based, but will fall back to integer positional\n    access unless the corresponding axis is of integer type.\n\n    ``.ix`` is the most general indexer and will support any of the\n    inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n    point label schemes. ``.ix`` is exceptionally useful when dealing\n    with mixed positional and label based hierachical indexes.\n\n    However, when an axis is integer based, ONLY label based access\n    and not positional access is supported. Thus, in such cases, it's\n    usually better to be explicit and use ``.iloc`` or ``.loc``.\n\n    See more at :ref:`Advanced Indexing <advanced>`.\n\n    \"\"\"\n\n    def _has_valid_type(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif is_bool_indexer(key):\n            return True\n\n        elif is_list_like_indexer(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _getitem_axis(self, key, axis=0):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n        key = check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj.take(inds, axis=axis, convert=False)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        obj = self.obj\n        if not need_slice(slice_obj):\n            return obj\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, kind='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _LocIndexer(_LocationIndexer):\n\n    \"\"\"Purely label-location based indexer for selection by label.\n\n    ``.loc[]`` is primarily label based, but may also be used with a\n    boolean array.\n\n    Allowed inputs are:\n\n    - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n      interpreted as a *label* of the index, and **never** as an\n      integer position along the index).\n    - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n    - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n      to usual python slices, **both** the start and the stop are included!).\n    - A boolean array.\n\n    ``.loc`` will raise a ``KeyError`` when the items are not found.\n\n    See more at :ref:`Selection by Label <indexing.label>`\n\n    \"\"\"\n\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    def _has_valid_type(self, key, axis):\n        ax = self.obj._get_axis(axis)\n\n        # valid for a label where all labels are in the index\n        # slice of lables (where start-end in labels)\n        # slice of integers (only if in the lables)\n        # boolean\n\n        if isinstance(key, slice):\n            return True\n\n        elif is_bool_indexer(key):\n            return True\n\n        elif is_list_like_indexer(key):\n\n            # mi is just a passthru\n            if isinstance(key, tuple) and isinstance(ax, MultiIndex):\n                return True\n\n            # TODO: don't check the entire key unless necessary\n            if len(key) and np.all(ax.get_indexer_for(key) < 0):\n\n                raise KeyError(\"None of [%s] are in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            return True\n\n        else:\n\n            def error():\n                if isnull(key):\n                    raise TypeError(\n                        \"cannot use label indexing with a null key\")\n                raise KeyError(\"the label [%s] is not in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            try:\n                key = self._convert_scalar_indexer(key, axis)\n                if not key in ax:\n                    error()\n            except (TypeError) as e:\n\n                # python 3 type errors should be raised\n                if 'unorderable' in str(e):  # pragma: no cover\n                    error()\n                raise\n            except:\n                error()\n\n        return True\n\n    def _getitem_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif is_list_like_indexer(key):\n\n            # GH 7349\n            # possibly convert a list-like into a nested tuple\n            # but don't convert a list-like of tuples\n            if isinstance(labels, MultiIndex):\n                if not isinstance(key, tuple) and len(key) > 1 and not isinstance(key[0], tuple):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and\n                    isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [ slice(None) ] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._has_valid_type(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n\n    \"\"\"Purely integer-location based indexing for selection by position.\n\n    ``.iloc[]`` is primarily integer position based (from ``0`` to\n    ``length-1`` of the axis), but may also be used with a boolean\n    array.\n\n    Allowed inputs are:\n\n    - An integer, e.g. ``5``.\n    - A list or array of integers, e.g. ``[4, 3, 0]``.\n    - A slice object with ints, e.g. ``1:7``.\n    - A boolean array.\n\n    ``.iloc`` will raise ``IndexError`` if a requested indexer is\n    out-of-bounds, except *slice* indexers which allow out-of-bounds\n    indexing (this conforms with python/numpy *slice* semantics).\n\n    See more at :ref:`Selection by Position <indexing.integer>`\n\n    \"\"\"\n\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _has_valid_type(self, key, axis):\n        if is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\n                        \"iLocation based boolean indexing on an integer type \"\n                        \"is not available\"\n                    )\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return True\n\n        if isinstance(key, slice):\n            return True\n        elif is_integer(key):\n            return self._is_valid_integer(key, axis)\n        elif is_list_like_indexer(key):\n            return self._is_valid_list_like(key, axis)\n        return False\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_valid_integer(self, key, axis):\n        # return a boolean if we have a valid integer indexer\n\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if key >= l or key < -l:\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n        return True\n\n\n    def _is_valid_list_like(self, key, axis):\n        # return a boolean if we are a valid list-like (e.g. that we dont' have out-of-bounds values)\n\n        # coerce the key to not exceed the maximum size of the index\n        arr = np.array(key)\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if len(arr) and (arr.max() >= l or arr.min() < -l):\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n        return True\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis=0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim<self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not need_slice(slice_obj):\n            return obj\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, kind='iloc')\n        else:\n            return self.obj.take(slice_obj, axis=axis, convert=False)\n\n    def _getitem_axis(self, key, axis=0):\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n\n        elif is_bool_indexer(key):\n            self._has_valid_type(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a single integer or a list of integers\n        else:\n\n            if is_list_like_indexer(key):\n\n                # validate list bounds\n                self._is_valid_list_like(key, axis)\n\n                # force an actual list\n                key = list(key)\n\n            else:\n                key = self._convert_scalar_indexer(key, axis)\n\n                if not is_integer(key):\n                    raise TypeError(\"Cannot index by location index with a \"\n                                    \"non-integer key\")\n\n                # validate the location\n                self._is_valid_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        elif self._has_valid_type(obj, axis):\n            return obj\n\n        raise ValueError(\"Can only index by location with a [%s]\" %\n                         self._valid_types)\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key, is_setter=False):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not is_list_like_indexer(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj.get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key, is_setter=True))\n        key.append(value)\n        self.obj.set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n\n    \"\"\"Fast label-based scalar accessor\n\n    Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n    You can also set using these indexers.\n\n    \"\"\"\n\n    _takeable = False\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n\n        # allow arbitrary setting\n        if is_setter:\n            return list(key)\n\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index can only have integer \"\n                                     \"indexers\")\n            else:\n                if is_integer(i):\n                    raise ValueError(\"At based indexing on an non-integer index can only have non-integer \"\n                                     \"indexers\")\n        return key\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n\n    \"\"\"Fast integer location scalar accessor.\n\n    Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n    You can also set using these indexers.\n\n    \"\"\"\n\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require  integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n# 32-bit floating point machine epsilon\n_eps = np.finfo('f4').eps\n\n\ndef length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = -step\n        return (stop - start + step-1) // step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like_indexer(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, kind='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if key in obj._data.items:\n            return None\n\n        # we need a timelike key here\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except:\n                return None\n\n    return None\n\n\ndef is_index_slice(obj):\n    def _is_valid_index(x):\n        return (is_integer(x) or is_float(x)\n                and np.allclose(x, int(x), rtol=_eps, atol=0))\n\n    def _crit(v):\n        return v is None or _is_valid_index(v)\n\n    both_none = obj.start is None and obj.stop is None\n\n    return not both_none and (_crit(obj.start) and _crit(obj.stop))\n\n\ndef check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = com.isnull(result._values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series key provided')\n\n        result = result.astype(bool)._values\n\n    else:\n        # is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n        return the scalar indexer and a boolean indicating if we converted \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key'])\n                if isinstance(_idx, dict) else _idx)\n    return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])\n\n\ndef maybe_convert_indices(indices, n):\n    \"\"\" if we have negative indicies, translate to postive here\n    if have indicies that are out-of-bounds, raise an IndexError\n    \"\"\"\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.int_)\n\n    mask = indices < 0\n    if mask.any():\n        indices[mask] += n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries, Index)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef is_nested_tuple(tup, labels):\n    # check for a compatiable nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    # are we nested tuple of: tuple,list,slice\n    for i, k in enumerate(tup):\n\n        if isinstance(k, (tuple, list, slice)):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\ndef is_list_like_indexer(key):\n    # allow a list_like, but exclude NamedTuples which can be indexers\n    return is_list_like(key) and not (isinstance(key, tuple) and type(key) is not tuple)\n\ndef is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not is_list_like_indexer(key)\n\n\ndef need_slice(obj):\n    return (obj.start is not None or\n            obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n\n\ndef _non_reducing_slice(slice_):\n    \"\"\"\n    Ensurse that a slice doesn't reduce to a Series or Scalar.\n\n    Any user-paseed `subset` should have this called on it\n    to make sure we're always working with DataFrames.\n    \"\"\"\n    # default to column slice, like DataFrame\n    # ['A', 'B'] -> IndexSlices[:, ['A', 'B']]\n    kinds = tuple(list(compat.string_types) +\n                  [ABCSeries, np.ndarray, Index, list])\n    if isinstance(slice_, kinds):\n        slice_ = IndexSlice[:, slice_]\n\n    def pred(part):\n        # true when slice does *not* reduce\n        return isinstance(part, slice) or com.is_list_like(part)\n\n    if not com.is_list_like(slice_):\n        if not isinstance(slice_, slice):\n            # a 1-d slice, like df.loc[1]\n            slice_ = [[slice_]]\n        else:\n            # slice(a, b, c)\n            slice_ = [slice_]  # to tuplize later\n    else:\n        slice_ = [part if pred(part) else [part] for part in slice_]\n    return tuple(slice_)\n\n\ndef _maybe_numeric_slice(df, slice_, include_bool=False):\n    \"\"\"\n    want nice defaults for background_gradient that don't break\n    with non-numeric data. But if slice_ is passed go with that.\n    \"\"\"\n    if slice_ is None:\n        dtypes = [np.number]\n        if include_bool:\n            dtypes.append(bool)\n        slice_ = IndexSlice[:, df.select_dtypes(include=dtypes).columns]\n    return slice_\n",
          "file_after": "# pylint: disable=W0223\n\nfrom pandas.core.index import Index, MultiIndex\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nimport pandas.core.common as com\nfrom pandas.core.common import (is_bool_indexer, is_integer_dtype,\n                                _asarray_tuplesafe, is_list_like, isnull,\n                                is_null_slice, is_full_slice, ABCSeries,\n                                ABCDataFrame, ABCPanel, is_float,\n                                _values_from_object, _infer_fill_value,\n                                is_integer)\nimport numpy as np\n\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix', _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc', _LocIndexer),\n        ('at', _AtIndexer),\n        ('iat', _iAtIndexer),\n    ]\n\n# \"null slice\"\n_NS = slice(None, None)\n\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    def __getitem__(self, arg):\n        return arg\n\n\nIndexSlice = _IndexSlice()\n\n\nclass IndexingError(Exception):\n    pass\n\n\nclass _NDFrameIndexer(object):\n    _valid_types = None\n    _exception = KeyError\n\n    def __init__(self, obj, name):\n        self.obj = obj\n        self.ndim = obj.ndim\n        self.name = name\n        self.axis = None\n\n    def __call__(self, *args, **kwargs):\n        # we need to return a copy of ourselves\n        self = self.__class__(self.obj, self.name)\n\n        # set the passed in values\n        for k, v in compat.iteritems(kwargs):\n            setattr(self, k, v)\n        return self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            try:\n                values = self.obj.get_value(*key)\n                if np.isscalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _get_label(self, label, axis=0):\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            try:\n                return self.obj._xs(label, axis=axis)\n            except:\n                return self.obj[label]\n        elif isinstance(label, tuple) and isinstance(label[axis], slice):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=0):\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=0, kind=None):\n        return self.obj._slice(obj, axis=axis, kind=kind)\n\n    def _get_setitem_indexer(self, key):\n        if self.axis is not None:\n            return self._convert_tuple(key, is_setter=True)\n\n        axis = self.obj._get_axis(0)\n        if isinstance(axis, MultiIndex):\n            try:\n                return axis.get_loc(key)\n            except Exception:\n                pass\n\n        if isinstance(key, tuple) and not self.ndim < len(key):\n            return self._convert_tuple(key, is_setter=True)\n        if isinstance(key, range):\n            return self._convert_range(key, is_setter=True)\n\n        try:\n            return self._convert_to_indexer(key, is_setter=True)\n        except TypeError:\n            raise IndexingError(key)\n\n    def __setitem__(self, key, value):\n        indexer = self._get_setitem_indexer(key)\n        self._setitem_with_indexer(indexer, value)\n\n    def _has_valid_type(self, k, axis):\n        raise NotImplementedError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            if not self._has_valid_type(k, i):\n                raise ValueError(\"Location based indexing can only have [%s] \"\n                                 \"types\" % self._valid_types)\n\n    def _should_validate_iterable(self, axis=0):\n        \"\"\" return a boolean whether this axes needs validation for a passed\n        iterable\n        \"\"\"\n        ax = self.obj._get_axis(axis)\n        if isinstance(ax, MultiIndex):\n            return False\n        elif ax.is_floating():\n            return False\n\n        return True\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any([isinstance(ax, MultiIndex) for ax in self.obj.axes]):\n            return any([is_nested_tuple(tup, ax) for ax in self.obj.axes])\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(\n                        key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_range(self, key, is_setter=False):\n        \"\"\" convert a range argument \"\"\"\n        return list(key)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, kind=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, kind=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n        will raise if needed, does not modify the indexer externally\n        \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like_indexer(i):\n                    # should check the elements?\n                    pass\n                elif is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{0} cannot enlarge its target object\"\n                                         .format(self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{0} cannot enlarge its target object\"\n                                     .format(self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        # TODO: Panel, DataFrame are not imported, remove?\n        from pandas import Panel, DataFrame, Series  # noqa\n        info_axis = self.obj._info_axis_number\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n\n        # if there is only one block/type, still have to take split path\n        # unless the block is one-dimensional or it can hold the value\n        if not take_split_path and self.obj._data.blocks:\n            blk, = self.obj._data.blocks\n            if 1 < blk.ndim:  # in case of dict, keys are indices\n                val = list(value.values()) if isinstance(value,\n                                                         dict) else value\n                take_split_path = not blk._can_hold_element(val)\n\n        if isinstance(indexer, tuple) and len(indexer) == len(self.obj.axes):\n\n            for i, ax in zip(indexer, self.obj.axes):\n\n                # if we have any multi-indexes that have non-trivial slices\n                # (not null slices) then we must take the split path, xref\n                # GH 10360\n                if (isinstance(ax, MultiIndex) and\n                        not (is_integer(i) or is_null_slice(i))):\n                    take_split_path = True\n                    break\n\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any([not l for l in len_non_info_axes]):\n                            if not is_list_like_indexer(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n                        # add a new item with the dtype setup\n                        self.obj[key] = _infer_fill_value(value)\n\n                        new_indexer = convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = index.insert(len(index), key)\n                    self.obj._data = self.obj.reindex_axis(labels, i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj.is_copy = None\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    new_index = index.insert(len(index), indexer)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value])._values\n                    if len(self.obj._values):\n                        new_values = np.concatenate([self.obj._values,\n                                                     new_values])\n\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\"cannot set a frame with no defined \"\n                                         \"columns\")\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,\n                                              copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if is_list_like_indexer(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\"cannot set a row with \"\n                                                 \"mismatched columns\")\n\n                        value = Series(value, index=self.obj.columns,\n                                       name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        item_labels = self.obj._get_axis(info_axis)\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].axes[0], MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like_indexer(value) and np.iterable(\n                        value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\"cannot set using a multi-index \"\n                                         \"selection indexer with a different \"\n                                         \"length than the value\")\n\n                    # make sure we have an ndarray\n                    value = getattr(value, 'values', value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj._consolidate_inplace()\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]),\n                                                  value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = length_of_indexer(plane_indexer[0],\n                                                       plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice or a slice with full bounds\n                # which means essentially reassign to the columns of a\n                # multi-dim object\n                # GH6149 (null slice), GH10408 (full bounds)\n                if (isinstance(pi, tuple) and\n                        all(is_null_slice(idx) or\n                            is_full_slice(idx, len(self.obj))\n                            for idx in pi)):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s._consolidate_inplace()\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if not len(labels) == 1 or not np.iterable(value):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an iterable, with a ndim of at least 1\n            # eg. don't pass through np.array(0)\n            if is_list_like_indexer(value) and getattr(value, 'ndim', 1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n                    sub_indexer = list(indexer)\n                    multiindex_indexer = isinstance(labels, MultiIndex)\n\n                    for item in labels:\n                        if item in value:\n                            sub_indexer[info_axis] = item\n                            v = self._align_series(\n                                tuple(sub_indexer), value[item],\n                                multiindex_indexer)\n                        else:\n                            v = np.nan\n\n                        setter(item, v)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value, dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = maybe_convert_ix(*indexer)\n\n                # if we are setting on the info axis ONLY\n                # set using those methods to avoid block-splitting\n                # logic here\n                if (len(indexer) > info_axis and\n                        is_integer(indexer[info_axis]) and\n                        all(is_null_slice(idx) for i, idx in enumerate(indexer)\n                            if i != info_axis)):\n                    self.obj[item_labels[indexer[info_axis]]] = value\n                    return\n\n            if isinstance(value, (ABCSeries, dict)):\n                value = self._align_series(indexer, Series(value))\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._consolidate_inplace()\n            self.obj._data = self.obj._data.setitem(indexer=indexer,\n                                                    value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser, multiindex_indexer=False):\n        \"\"\"\n        Parameters\n        ----------\n        indexer : tuple, slice, scalar\n            The indexer used to get the locations that will be set to\n            `ser`\n\n        ser : pd.Series\n            The values to assign to the locations specified by `indexer`\n\n        multiindex_indexer : boolean, optional\n            Defaults to False. Should be set to True if `indexer` was from\n            a `pd.MultiIndex`, to avoid unnecessary broadcasting.\n\n\n        Returns:\n        --------\n        `np.array` of `ser` broadcast to the appropriate shape for assignment\n        to the locations selected by `indexer`\n\n        \"\"\"\n        if isinstance(indexer, (slice, np.ndarray, list, Index)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            # flatten np.ndarray indexers\n            ravel = lambda i: i.ravel() if isinstance(i, np.ndarray) else i\n            indexer = tuple(map(ravel, indexer))\n\n            aligners = [not is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all([com.is_sequence(_) for _ in indexer])):\n                ser = ser.reindex(obj.axes[0][indexer[0]], copy=True)._values\n\n                # single indexer\n                if len(indexer) > 1 and not multiindex_indexer:\n                    l = len(indexer[1])\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if com.is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like_indexer(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix)\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser._values.copy()\n\n                    return ser.reindex(new_ix)._values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser._values.copy()\n                    return ser.reindex(ax)._values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser._values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif np.isscalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser._values.copy()\n\n            return ser.reindex(ax)._values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n\n        if isinstance(indexer, tuple):\n\n            aligners = [not is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            # TODO: single_aligner is not used\n            single_aligner = sum_aligners == 1  # noqa\n\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if com.is_sequence(ix) or isinstance(ix, slice):\n                    if idx is None:\n                        idx = ax[ix].ravel()\n                    elif cols is None:\n                        cols = ax[ix].ravel()\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n\n                # need to conform to the convention\n                # as we are not selecting on the items axis\n                # and we have a single indexer\n                # GH 7763\n                if len(sindexers) == 1 and sindexers[0] != 0:\n                    df = df.T\n\n                if idx is None:\n                    idx = df.index\n                if cols is None:\n                    cols = df.columns\n\n            if idx is not None and cols is not None:\n\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy()._values\n                else:\n                    val = df.reindex(idx, columns=cols)._values\n                return val\n\n        elif ((isinstance(indexer, slice) or is_list_like_indexer(indexer)) and\n              is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy()._values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if (isinstance(ax, MultiIndex) and\n                        isinstance(df.index, MultiIndex) and\n                        ax.nlevels != df.index.nlevels):\n                    raise TypeError(\"cannot align on a multi-index with out \"\n                                    \"specifying the join levels\")\n\n                val = df.reindex(index=ax)._values\n            return val\n\n        elif np.isscalar(indexer) and is_panel:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy()._values\n\n            return df.reindex(idx, columns=cols)._values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        # TODO: is_frame, is_panel are unused\n        is_frame = self.obj.ndim == 2  # noqa\n        is_panel = self.obj.ndim >= 3  # noqa\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        from pandas.core.generic import NDFrame\n\n        # ugly hack for GH #836\n        if not isinstance(self.obj, NDFrame):\n            return False\n\n        if not all(is_list_like_indexer(x) for x in tup):\n            return False\n\n        # just too complicated\n        for indexer, ax in zip(tup, self.obj._data.axes):\n            if isinstance(ax, MultiIndex):\n                return False\n            elif is_bool_indexer(indexer):\n                return False\n            elif not ax.is_unique:\n                return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\" create the reindex map for our objects, raise the _exception if we\n        can't create the indexer\n        \"\"\"\n        try:\n            o = self.obj\n            d = dict(\n                [(a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n                 for t, a in zip(tup, o._AXIS_ORDERS)])\n            return o.reindex(**d)\n        except:\n            raise self._exception\n\n    def _convert_for_reindex(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if is_bool_indexer(key):\n            key = check_bool_indexer(labels, key)\n            return labels[key]\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if is_integer_dtype(keyarr) and not labels.is_integer():\n                keyarr = com._ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n            return keyarr\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=0)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        if isinstance(ax0, MultiIndex):\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not is_list_like_indexer(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0 and\n                            len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of\n            # selectors\n            return self._getitem_axis(tup, axis=0)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if np.isscalar(obj) or not hasattr(obj, 'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=0):\n\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif (is_list_like_indexer(key) and\n              not (isinstance(key, tuple) and\n                   isinstance(labels, MultiIndex))):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n            if is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _getitem_iterable(self, key, axis=0):\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        if is_bool_indexer(key):\n            key = check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj.take(inds, axis=axis, convert=False)\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if com.is_categorical_dtype(labels):\n                keyarr = labels._shallow_copy(keyarr)\n\n            # have the index handle the indexer and possibly return\n            # an indexer or raising\n            indexer = labels._convert_list_indexer(keyarr, kind=self.name)\n            if indexer is not None:\n                return self.obj.take(indexer, axis=axis)\n\n            # this is not the most robust, but...\n            if (isinstance(labels, MultiIndex) and len(keyarr) and\n                    not isinstance(keyarr[0], tuple)):\n                level = 0\n            else:\n                level = None\n\n            # existing labels are unique and indexer are unique\n            if labels.is_unique and Index(keyarr).is_unique:\n\n                try:\n                    result = self.obj.reindex_axis(keyarr, axis=axis,\n                                                   level=level)\n\n                    # this is an error as we are trying to find\n                    # keys in a multi-index that don't exist\n                    if isinstance(labels, MultiIndex) and level is not None:\n                        if (hasattr(result, 'ndim') and\n                                not np.prod(result.shape) and len(keyarr)):\n                            raise KeyError(\"cannot index a multi-index axis \"\n                                           \"with these keys\")\n\n                    return result\n\n                except AttributeError:\n\n                    # Series\n                    if axis != 0:\n                        raise AssertionError('axis must be 0')\n                    return self.obj.reindex(keyarr, level=level)\n\n            # existing labels are non-unique\n            else:\n\n                # reindex with the specified axis\n                if axis + 1 > self.obj.ndim:\n                    raise AssertionError(\"invalid indexing error with \"\n                                         \"non-unique index\")\n\n                new_target, indexer, new_indexer = labels._reindex_non_unique(\n                    keyarr)\n\n                if new_indexer is not None:\n                    result = self.obj.take(indexer[indexer != -1], axis=axis,\n                                           convert=False)\n\n                    result = result._reindex_with_indexers(\n                        {axis: [new_target, new_indexer]},\n                        copy=True, allow_dups=True)\n\n                else:\n                    result = self.obj.take(indexer, axis=axis, convert=False)\n\n                return result\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        \"In the face of ambiguity, refuse the temptation to guess.\"\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        labels = self.obj._get_axis(axis)\n\n        # if we are a scalar indexer and not type correct raise\n        obj = self._convert_scalar_indexer(obj, axis)\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except LookupError:\n            if isinstance(obj, tuple) and isinstance(labels, MultiIndex):\n                if is_setter and len(obj) == labels.nlevels:\n                    return {'key': obj}\n                raise\n        except TypeError:\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n        elif is_list_like_indexer(obj):\n            if is_bool_indexer(obj):\n                obj = check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                if isinstance(obj, Index):\n                    # want Index objects to pass through untouched\n                    objarr = obj\n                else:\n                    objarr = _asarray_tuplesafe(obj)\n\n                # The index may want to handle a list indexer differently\n                # by returning an indexer or raising\n                indexer = labels._convert_list_indexer(objarr, kind=self.name)\n                if indexer is not None:\n                    return indexer\n\n                # this is not the most robust, but...\n                if (isinstance(labels, MultiIndex) and\n                        not isinstance(objarr[0], tuple)):\n                    level = 0\n                    _, indexer = labels.reindex(objarr, level=level)\n\n                    # take all\n                    if indexer is None:\n                        indexer = np.arange(len(labels))\n\n                    check = labels.levels[0].get_indexer(objarr)\n                else:\n                    level = None\n\n                    # unique index\n                    if labels.is_unique:\n                        indexer = check = labels.get_indexer(objarr)\n\n                    # non-unique (dups)\n                    else:\n                        (indexer,\n                         missing) = labels.get_indexer_non_unique(objarr)\n                        check = indexer\n\n                mask = check == -1\n                if mask.any():\n                    raise KeyError('%s not in index' % objarr[mask])\n\n                return _values_from_object(indexer)\n\n        else:\n            try:\n                return labels.get_loc(obj)\n            except LookupError:\n                # allow a not found key only if we are a setter\n                if not is_list_like_indexer(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not need_slice(slice_obj):\n            return obj\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, kind='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n    \"\"\"A primarily label-location based indexer, with integer position\n    fallback.\n\n    ``.ix[]`` supports mixed integer and label based access. It is\n    primarily label based, but will fall back to integer positional\n    access unless the corresponding axis is of integer type.\n\n    ``.ix`` is the most general indexer and will support any of the\n    inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n    point label schemes. ``.ix`` is exceptionally useful when dealing\n    with mixed positional and label based hierachical indexes.\n\n    However, when an axis is integer based, ONLY label based access\n    and not positional access is supported. Thus, in such cases, it's\n    usually better to be explicit and use ``.iloc`` or ``.loc``.\n\n    See more at :ref:`Advanced Indexing <advanced>`.\n\n    \"\"\"\n\n    def _has_valid_type(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif is_bool_indexer(key):\n            return True\n\n        elif is_list_like_indexer(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _getitem_axis(self, key, axis=0):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n        key = check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj.take(inds, axis=axis, convert=False)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        obj = self.obj\n        if not need_slice(slice_obj):\n            return obj\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, kind='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _LocIndexer(_LocationIndexer):\n    \"\"\"Purely label-location based indexer for selection by label.\n\n    ``.loc[]`` is primarily label based, but may also be used with a\n    boolean array.\n\n    Allowed inputs are:\n\n    - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n      interpreted as a *label* of the index, and **never** as an\n      integer position along the index).\n    - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n    - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n      to usual python slices, **both** the start and the stop are included!).\n    - A boolean array.\n\n    ``.loc`` will raise a ``KeyError`` when the items are not found.\n\n    See more at :ref:`Selection by Label <indexing.label>`\n\n    \"\"\"\n\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    def _has_valid_type(self, key, axis):\n        ax = self.obj._get_axis(axis)\n\n        # valid for a label where all labels are in the index\n        # slice of lables (where start-end in labels)\n        # slice of integers (only if in the lables)\n        # boolean\n\n        if isinstance(key, slice):\n            return True\n\n        elif is_bool_indexer(key):\n            return True\n\n        elif is_list_like_indexer(key):\n\n            # mi is just a passthru\n            if isinstance(key, tuple) and isinstance(ax, MultiIndex):\n                return True\n\n            # TODO: don't check the entire key unless necessary\n            if len(key) and np.all(ax.get_indexer_for(key) < 0):\n\n                raise KeyError(\"None of [%s] are in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            return True\n\n        else:\n\n            def error():\n                if isnull(key):\n                    raise TypeError(\"cannot use label indexing with a null \"\n                                    \"key\")\n                raise KeyError(\"the label [%s] is not in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            try:\n                key = self._convert_scalar_indexer(key, axis)\n                if key not in ax:\n                    error()\n            except TypeError as e:\n\n                # python 3 type errors should be raised\n                if 'unorderable' in str(e):  # pragma: no cover\n                    error()\n                raise\n            except:\n                error()\n\n        return True\n\n    def _getitem_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif is_list_like_indexer(key):\n\n            # GH 7349\n            # possibly convert a list-like into a nested tuple\n            # but don't convert a list-like of tuples\n            if isinstance(labels, MultiIndex):\n                if (not isinstance(key, tuple) and len(key) > 1 and\n                        not isinstance(key[0], tuple)):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [slice(None)] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._has_valid_type(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n    \"\"\"Purely integer-location based indexing for selection by position.\n\n    ``.iloc[]`` is primarily integer position based (from ``0`` to\n    ``length-1`` of the axis), but may also be used with a boolean\n    array.\n\n    Allowed inputs are:\n\n    - An integer, e.g. ``5``.\n    - A list or array of integers, e.g. ``[4, 3, 0]``.\n    - A slice object with ints, e.g. ``1:7``.\n    - A boolean array.\n\n    ``.iloc`` will raise ``IndexError`` if a requested indexer is\n    out-of-bounds, except *slice* indexers which allow out-of-bounds\n    indexing (this conforms with python/numpy *slice* semantics).\n\n    See more at :ref:`Selection by Position <indexing.integer>`\n\n    \"\"\"\n\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _has_valid_type(self, key, axis):\n        if is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\"iLocation based boolean \"\n                                              \"indexing on an integer type \"\n                                              \"is not available\")\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return True\n\n        if isinstance(key, slice):\n            return True\n        elif is_integer(key):\n            return self._is_valid_integer(key, axis)\n        elif is_list_like_indexer(key):\n            return self._is_valid_list_like(key, axis)\n        return False\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_valid_integer(self, key, axis):\n        # return a boolean if we have a valid integer indexer\n\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if key >= l or key < -l:\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n        return True\n\n    def _is_valid_list_like(self, key, axis):\n        # return a boolean if we are a valid list-like (e.g. that we don't\n        # have out-of-bounds values)\n\n        # coerce the key to not exceed the maximum size of the index\n        arr = np.array(key)\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if len(arr) and (arr.max() >= l or arr.min() < -l):\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n        return True\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim < self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not need_slice(slice_obj):\n            return obj\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, kind='iloc')\n        else:\n            return self.obj.take(slice_obj, axis=axis, convert=False)\n\n    def _getitem_axis(self, key, axis=0):\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n\n        elif is_bool_indexer(key):\n            self._has_valid_type(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a single integer or a list of integers\n        else:\n\n            if is_list_like_indexer(key):\n\n                # validate list bounds\n                self._is_valid_list_like(key, axis)\n\n                # force an actual list\n                key = list(key)\n\n            else:\n                key = self._convert_scalar_indexer(key, axis)\n\n                if not is_integer(key):\n                    raise TypeError(\"Cannot index by location index with a \"\n                                    \"non-integer key\")\n\n                # validate the location\n                self._is_valid_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        elif self._has_valid_type(obj, axis):\n            return obj\n\n        raise ValueError(\"Can only index by location with a [%s]\" %\n                         self._valid_types)\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key, is_setter=False):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not is_list_like_indexer(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj.get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key, is_setter=True))\n        key.append(value)\n        self.obj.set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n    \"\"\"Fast label-based scalar accessor\n\n    Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n    You can also set using these indexers.\n\n    \"\"\"\n\n    _takeable = False\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require they keys to be the same type as the index (so we don't\n        fallback)\n        \"\"\"\n\n        # allow arbitrary setting\n        if is_setter:\n            return list(key)\n\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index \"\n                                     \"can only have integer indexers\")\n            else:\n                if is_integer(i):\n                    raise ValueError(\"At based indexing on an non-integer \"\n                                     \"index can only have non-integer \"\n                                     \"indexers\")\n        return key\n\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n    \"\"\"Fast integer location scalar accessor.\n\n    Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n    You can also set using these indexers.\n\n    \"\"\"\n\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require  integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n# 32-bit floating point machine epsilon\n_eps = np.finfo('f4').eps\n\n\ndef length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = -step\n        return (stop - start + step - 1) // step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like_indexer(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, kind='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if key in obj._data.items:\n            return None\n\n        # we need a timelike key here\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except:\n                return None\n\n    return None\n\n\ndef is_index_slice(obj):\n    def _is_valid_index(x):\n        return (is_integer(x) or is_float(x) and\n                np.allclose(x, int(x), rtol=_eps, atol=0))\n\n    def _crit(v):\n        return v is None or _is_valid_index(v)\n\n    both_none = obj.start is None and obj.stop is None\n\n    return not both_none and (_crit(obj.start) and _crit(obj.stop))\n\n\ndef check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = com.isnull(result._values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series key provided')\n\n        result = result.astype(bool)._values\n\n    else:\n        # is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n    return the scalar indexer and a boolean indicating if we converted\n    \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key']) if isinstance(_idx, dict) else\n                _idx)\n\n    return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])\n\n\ndef maybe_convert_indices(indices, n):\n    \"\"\" if we have negative indicies, translate to postive here\n    if have indicies that are out-of-bounds, raise an IndexError\n    \"\"\"\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.int_)\n\n    mask = indices < 0\n    if mask.any():\n        indices[mask] += n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries, Index)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef is_nested_tuple(tup, labels):\n    # check for a compatiable nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    # are we nested tuple of: tuple,list,slice\n    for i, k in enumerate(tup):\n\n        if isinstance(k, (tuple, list, slice)):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\n\ndef is_list_like_indexer(key):\n    # allow a list_like, but exclude NamedTuples which can be indexers\n    return is_list_like(key) and not (isinstance(key, tuple) and\n                                      type(key) is not tuple)\n\n\ndef is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not is_list_like_indexer(key)\n\n\ndef need_slice(obj):\n    return (obj.start is not None or obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n\n\ndef _non_reducing_slice(slice_):\n    \"\"\"\n    Ensurse that a slice doesn't reduce to a Series or Scalar.\n\n    Any user-paseed `subset` should have this called on it\n    to make sure we're always working with DataFrames.\n    \"\"\"\n    # default to column slice, like DataFrame\n    # ['A', 'B'] -> IndexSlices[:, ['A', 'B']]\n    kinds = tuple(list(compat.string_types) + [ABCSeries, np.ndarray, Index,\n                                               list])\n    if isinstance(slice_, kinds):\n        slice_ = IndexSlice[:, slice_]\n\n    def pred(part):\n        # true when slice does *not* reduce\n        return isinstance(part, slice) or com.is_list_like(part)\n\n    if not com.is_list_like(slice_):\n        if not isinstance(slice_, slice):\n            # a 1-d slice, like df.loc[1]\n            slice_ = [[slice_]]\n        else:\n            # slice(a, b, c)\n            slice_ = [slice_]  # to tuplize later\n    else:\n        slice_ = [part if pred(part) else [part] for part in slice_]\n    return tuple(slice_)\n\n\ndef _maybe_numeric_slice(df, slice_, include_bool=False):\n    \"\"\"\n    want nice defaults for background_gradient that don't break\n    with non-numeric data. But if slice_ is passed go with that.\n    \"\"\"\n    if slice_ is None:\n        dtypes = [np.number]\n        if include_bool:\n            dtypes.append(bool)\n        slice_ = IndexSlice[:, df.select_dtypes(include=dtypes).columns]\n    return slice_\n",
          "file_patch": "@@ -6,34 +6,41 @@ import pandas.compat as compat\n import pandas.core.common as com\n from pandas.core.common import (is_bool_indexer, is_integer_dtype,\n                                 _asarray_tuplesafe, is_list_like, isnull,\n-                                is_null_slice, is_full_slice,\n-                                ABCSeries, ABCDataFrame, ABCPanel, is_float,\n-                                _values_from_object, _infer_fill_value, is_integer)\n+                                is_null_slice, is_full_slice, ABCSeries,\n+                                ABCDataFrame, ABCPanel, is_float,\n+                                _values_from_object, _infer_fill_value,\n+                                is_integer)\n import numpy as np\n \n+\n # the supported indexers\n def get_indexers_list():\n \n     return [\n-        ('ix',   _IXIndexer),\n+        ('ix', _IXIndexer),\n         ('iloc', _iLocIndexer),\n-        ('loc',  _LocIndexer),\n-        ('at',   _AtIndexer),\n-        ('iat',  _iAtIndexer),\n+        ('loc', _LocIndexer),\n+        ('at', _AtIndexer),\n+        ('iat', _iAtIndexer),\n     ]\n \n # \"null slice\"\n _NS = slice(None, None)\n \n+\n # the public IndexSlicerMaker\n class _IndexSlice(object):\n     def __getitem__(self, arg):\n         return arg\n+\n+\n IndexSlice = _IndexSlice()\n \n+\n class IndexingError(Exception):\n     pass\n \n+\n class _NDFrameIndexer(object):\n     _valid_types = None\n     _exception = KeyError\n@@ -50,7 +57,7 @@ class _NDFrameIndexer(object):\n \n         # set the passed in values\n         for k, v in compat.iteritems(kwargs):\n-            setattr(self,k,v)\n+            setattr(self, k, v)\n         return self\n \n     def __iter__(self):\n@@ -79,8 +86,7 @@ class _NDFrameIndexer(object):\n                 return self.obj._xs(label, axis=axis)\n             except:\n                 return self.obj[label]\n-        elif (isinstance(label, tuple) and\n-                isinstance(label[axis], slice)):\n+        elif isinstance(label, tuple) and isinstance(label[axis], slice):\n             raise IndexingError('no slices here, handle elsewhere')\n \n         return self.obj._xs(label, axis=axis)\n@@ -129,7 +135,9 @@ class _NDFrameIndexer(object):\n                                  \"types\" % self._valid_types)\n \n     def _should_validate_iterable(self, axis=0):\n-        \"\"\" return a boolean whether this axes needs validation for a passed iterable \"\"\"\n+        \"\"\" return a boolean whether this axes needs validation for a passed\n+        iterable\n+        \"\"\"\n         ax = self.obj._get_axis(axis)\n         if isinstance(ax, MultiIndex):\n             return False\n@@ -139,8 +147,8 @@ class _NDFrameIndexer(object):\n         return True\n \n     def _is_nested_tuple_indexer(self, tup):\n-        if any([ isinstance(ax, MultiIndex) for ax in self.obj.axes ]):\n-            return any([ is_nested_tuple(tup,ax) for ax in self.obj.axes ])\n+        if any([isinstance(ax, MultiIndex) for ax in self.obj.axes]):\n+            return any([is_nested_tuple(tup, ax) for ax in self.obj.axes])\n         return False\n \n     def _convert_tuple(self, key, is_setter=False):\n@@ -149,7 +157,8 @@ class _NDFrameIndexer(object):\n             axis = self.obj._get_axis_number(self.axis)\n             for i in range(self.ndim):\n                 if i == axis:\n-                    keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n+                    keyidx.append(self._convert_to_indexer(\n+                        key, axis=axis, is_setter=is_setter))\n                 else:\n                     keyidx.append(slice(None))\n         else:\n@@ -178,7 +187,8 @@ class _NDFrameIndexer(object):\n \n     def _has_valid_positional_setitem_indexer(self, indexer):\n         \"\"\" validate that an positional indexer cannot enlarge its target\n-            will raise if needed, does not modify the indexer externally \"\"\"\n+        will raise if needed, does not modify the indexer externally\n+        \"\"\"\n         if isinstance(indexer, dict):\n             raise IndexError(\"{0} cannot enlarge its target object\"\n                              .format(self.name))\n@@ -206,7 +216,8 @@ class _NDFrameIndexer(object):\n         self._has_valid_setitem_indexer(indexer)\n \n         # also has the side effect of consolidating in-place\n-        from pandas import Panel, DataFrame, Series\n+        # TODO: Panel, DataFrame are not imported, remove?\n+        from pandas import Panel, DataFrame, Series  # noqa\n         info_axis = self.obj._info_axis_number\n \n         # maybe partial set\n@@ -217,16 +228,19 @@ class _NDFrameIndexer(object):\n         if not take_split_path and self.obj._data.blocks:\n             blk, = self.obj._data.blocks\n             if 1 < blk.ndim:  # in case of dict, keys are indices\n-                val = list(value.values()) if isinstance(value,dict) else value\n+                val = list(value.values()) if isinstance(value,\n+                                                         dict) else value\n                 take_split_path = not blk._can_hold_element(val)\n \n         if isinstance(indexer, tuple) and len(indexer) == len(self.obj.axes):\n \n             for i, ax in zip(indexer, self.obj.axes):\n \n-                # if we have any multi-indexes that have non-trivial slices (not null slices)\n-                # then we must take the split path, xref GH 10360\n-                if isinstance(ax, MultiIndex) and not (is_integer(i) or is_null_slice(i)):\n+                # if we have any multi-indexes that have non-trivial slices\n+                # (not null slices) then we must take the split path, xref\n+                # GH 10360\n+                if (isinstance(ax, MultiIndex) and\n+                        not (is_integer(i) or is_null_slice(i))):\n                     take_split_path = True\n                     break\n \n@@ -261,7 +275,6 @@ class _NDFrameIndexer(object):\n                             self.obj[key] = value\n                             return self.obj\n \n-\n                         # add a new item with the dtype setup\n                         self.obj[key] = _infer_fill_value(value)\n \n@@ -276,10 +289,10 @@ class _NDFrameIndexer(object):\n                     # just replacing the block manager here\n                     # so the object is the same\n                     index = self.obj._get_axis(i)\n-                    labels = index.insert(len(index),key)\n+                    labels = index.insert(len(index), key)\n                     self.obj._data = self.obj.reindex_axis(labels, i)._data\n                     self.obj._maybe_update_cacher(clear=True)\n-                    self.obj.is_copy=None\n+                    self.obj.is_copy = None\n \n                     nindexer.append(labels.get_loc(key))\n \n@@ -297,7 +310,7 @@ class _NDFrameIndexer(object):\n                 # and set inplace\n                 if self.ndim == 1:\n                     index = self.obj.index\n-                    new_index = index.insert(len(index),indexer)\n+                    new_index = index.insert(len(index), indexer)\n \n                     # this preserves dtype of the value\n                     new_values = Series([value])._values\n@@ -314,14 +327,14 @@ class _NDFrameIndexer(object):\n \n                     # no columns and scalar\n                     if not len(self.obj.columns):\n-                        raise ValueError(\n-                            \"cannot set a frame with no defined columns\"\n-                        )\n+                        raise ValueError(\"cannot set a frame with no defined \"\n+                                         \"columns\")\n \n                     # append a Series\n                     if isinstance(value, Series):\n \n-                        value = value.reindex(index=self.obj.columns,copy=True)\n+                        value = value.reindex(index=self.obj.columns,\n+                                              copy=True)\n                         value.name = indexer\n \n                     # a list-list\n@@ -330,11 +343,11 @@ class _NDFrameIndexer(object):\n                         # must have conforming columns\n                         if is_list_like_indexer(value):\n                             if len(value) != len(self.obj.columns):\n-                                raise ValueError(\n-                                    \"cannot set a row with mismatched columns\"\n-                                    )\n+                                raise ValueError(\"cannot set a row with \"\n+                                                 \"mismatched columns\")\n \n-                        value = Series(value,index=self.obj.columns,name=indexer)\n+                        value = Series(value, index=self.obj.columns,\n+                                       name=indexer)\n \n                     self.obj._data = self.obj.append(value)._data\n                     self.obj._maybe_update_cacher(clear=True)\n@@ -375,23 +388,24 @@ class _NDFrameIndexer(object):\n \n                 # require that we are setting the right number of values that\n                 # we are indexing\n-                if is_list_like_indexer(value) and np.iterable(value) and lplane_indexer != len(value):\n+                if is_list_like_indexer(value) and np.iterable(\n+                        value) and lplane_indexer != len(value):\n \n                     if len(obj[idx]) != len(value):\n-                        raise ValueError(\n-                            \"cannot set using a multi-index selection indexer \"\n-                            \"with a different length than the value\"\n-                        )\n+                        raise ValueError(\"cannot set using a multi-index \"\n+                                         \"selection indexer with a different \"\n+                                         \"length than the value\")\n \n                     # make sure we have an ndarray\n-                    value = getattr(value,'values',value).ravel()\n+                    value = getattr(value, 'values', value).ravel()\n \n                     # we can directly set the series here\n                     # as we select a slice indexer on the mi\n                     idx = index._convert_slice_indexer(idx)\n                     obj._consolidate_inplace()\n                     obj = obj.copy()\n-                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n+                    obj._data = obj._data.setitem(indexer=tuple([idx]),\n+                                                  value=value)\n                     self.obj[item] = obj\n                     return\n \n@@ -411,9 +425,13 @@ class _NDFrameIndexer(object):\n \n                 # perform the equivalent of a setitem on the info axis\n                 # as we have a null slice or a slice with full bounds\n-                # which means essentially reassign to the columns of a multi-dim object\n+                # which means essentially reassign to the columns of a\n+                # multi-dim object\n                 # GH6149 (null slice), GH10408 (full bounds)\n-                if isinstance(pi, tuple) and all(is_null_slice(idx) or is_full_slice(idx, len(self.obj)) for idx in pi):\n+                if (isinstance(pi, tuple) and\n+                        all(is_null_slice(idx) or\n+                            is_full_slice(idx, len(self.obj))\n+                            for idx in pi)):\n                     s = v\n                 else:\n                     # set the item, possibly having a dtype change\n@@ -444,7 +462,7 @@ class _NDFrameIndexer(object):\n \n             # we need an iterable, with a ndim of at least 1\n             # eg. don't pass through np.array(0)\n-            if is_list_like_indexer(value) and getattr(value,'ndim',1) > 0:\n+            if is_list_like_indexer(value) and getattr(value, 'ndim', 1) > 0:\n \n                 # we have an equal len Frame\n                 if isinstance(value, ABCDataFrame) and value.ndim > 1:\n@@ -455,8 +473,8 @@ class _NDFrameIndexer(object):\n                         if item in value:\n                             sub_indexer[info_axis] = item\n                             v = self._align_series(\n-                                tuple(sub_indexer), value[item], multiindex_indexer\n-                            )\n+                                tuple(sub_indexer), value[item],\n+                                multiindex_indexer)\n                         else:\n                             v = np.nan\n \n@@ -467,7 +485,7 @@ class _NDFrameIndexer(object):\n \n                     # note that this coerces the dtype if we are mixed\n                     # GH 7551\n-                    value = np.array(value,dtype=object)\n+                    value = np.array(value, dtype=object)\n                     if len(labels) != value.shape[1]:\n                         raise ValueError('Must have equal len keys and value '\n                                          'when setting with an ndarray')\n@@ -503,8 +521,10 @@ class _NDFrameIndexer(object):\n                 # if we are setting on the info axis ONLY\n                 # set using those methods to avoid block-splitting\n                 # logic here\n-                if len(indexer) > info_axis and is_integer(indexer[info_axis]) and all(\n-                    is_null_slice(idx) for i, idx in enumerate(indexer) if i != info_axis):\n+                if (len(indexer) > info_axis and\n+                        is_integer(indexer[info_axis]) and\n+                        all(is_null_slice(idx) for i, idx in enumerate(indexer)\n+                            if i != info_axis)):\n                     self.obj[item_labels[indexer[info_axis]]] = value\n                     return\n \n@@ -522,7 +542,8 @@ class _NDFrameIndexer(object):\n \n             # actually do the set\n             self.obj._consolidate_inplace()\n-            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n+            self.obj._data = self.obj._data.setitem(indexer=indexer,\n+                                                    value=value)\n             self.obj._maybe_update_cacher(clear=True)\n \n     def _align_series(self, indexer, ser, multiindex_indexer=False):\n@@ -658,7 +679,8 @@ class _NDFrameIndexer(object):\n \n             aligners = [not is_null_slice(idx) for idx in indexer]\n             sum_aligners = sum(aligners)\n-            single_aligner = sum_aligners == 1\n+            # TODO: single_aligner is not used\n+            single_aligner = sum_aligners == 1  # noqa\n \n             idx, cols = None, None\n             sindexers = []\n@@ -697,8 +719,8 @@ class _NDFrameIndexer(object):\n                     val = df.reindex(idx, columns=cols)._values\n                 return val\n \n-        elif ((isinstance(indexer, slice) or is_list_like_indexer(indexer))\n-              and is_frame):\n+        elif ((isinstance(indexer, slice) or is_list_like_indexer(indexer)) and\n+              is_frame):\n             ax = self.obj.index[indexer]\n             if df.index.equals(ax):\n                 val = df.copy()._values\n@@ -706,9 +728,11 @@ class _NDFrameIndexer(object):\n \n                 # we have a multi-index and are trying to align\n                 # with a particular, level GH3738\n-                if isinstance(ax, MultiIndex) and isinstance(\n-                    df.index, MultiIndex) and ax.nlevels != df.index.nlevels:\n-                    raise TypeError(\"cannot align on a multi-index with out specifying the join levels\")\n+                if (isinstance(ax, MultiIndex) and\n+                        isinstance(df.index, MultiIndex) and\n+                        ax.nlevels != df.index.nlevels):\n+                    raise TypeError(\"cannot align on a multi-index with out \"\n+                                    \"specifying the join levels\")\n \n                 val = df.reindex(index=ax)._values\n             return val\n@@ -728,8 +752,9 @@ class _NDFrameIndexer(object):\n         raise ValueError('Incompatible indexer with DataFrame')\n \n     def _align_panel(self, indexer, df):\n-        is_frame = self.obj.ndim == 2\n-        is_panel = self.obj.ndim >= 3\n+        # TODO: is_frame, is_panel are unused\n+        is_frame = self.obj.ndim == 2  # noqa\n+        is_panel = self.obj.ndim >= 3  # noqa\n         raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                   \"yet!\")\n \n@@ -786,10 +811,9 @@ class _NDFrameIndexer(object):\n         \"\"\"\n         try:\n             o = self.obj\n-            d = dict([\n-                (a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n-                for t, a in zip(tup, o._AXIS_ORDERS)\n-            ])\n+            d = dict(\n+                [(a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n+                 for t, a in zip(tup, o._AXIS_ORDERS)])\n             return o.reindex(**d)\n         except:\n             raise self._exception\n@@ -876,8 +900,8 @@ class _NDFrameIndexer(object):\n \n                     # unfortunately need an odious kludge here because of\n                     # DataFrame transposing convention\n-                    if (isinstance(section, ABCDataFrame) and i > 0\n-                            and len(new_key) == 2):\n+                    if (isinstance(section, ABCDataFrame) and i > 0 and\n+                            len(new_key) == 2):\n                         a, b = new_key\n                         new_key = b, a\n \n@@ -901,7 +925,8 @@ class _NDFrameIndexer(object):\n             if result is not None:\n                 return result\n \n-            # this is a series with a multi-index specified a tuple of selectors\n+            # this is a series with a multi-index specified a tuple of\n+            # selectors\n             return self._getitem_axis(tup, axis=0)\n \n         # handle the multi-axis by taking sections and reducing\n@@ -919,7 +944,7 @@ class _NDFrameIndexer(object):\n             axis += 1\n \n             # if we have a scalar, we are done\n-            if np.isscalar(obj) or not hasattr(obj,'ndim'):\n+            if np.isscalar(obj) or not hasattr(obj, 'ndim'):\n                 break\n \n             # has the dim of the obj changed?\n@@ -944,8 +969,9 @@ class _NDFrameIndexer(object):\n         labels = self.obj._get_axis(axis)\n         if isinstance(key, slice):\n             return self._get_slice_axis(key, axis=axis)\n-        elif is_list_like_indexer(key) and not (isinstance(key, tuple) and\n-                                        isinstance(labels, MultiIndex)):\n+        elif (is_list_like_indexer(key) and\n+              not (isinstance(key, tuple) and\n+                   isinstance(labels, MultiIndex))):\n \n             if hasattr(key, 'ndim') and key.ndim > 1:\n                 raise ValueError('Cannot index with multidimensional key')\n@@ -1004,13 +1030,16 @@ class _NDFrameIndexer(object):\n             if labels.is_unique and Index(keyarr).is_unique:\n \n                 try:\n-                    result = self.obj.reindex_axis(keyarr, axis=axis, level=level)\n+                    result = self.obj.reindex_axis(keyarr, axis=axis,\n+                                                   level=level)\n \n                     # this is an error as we are trying to find\n                     # keys in a multi-index that don't exist\n                     if isinstance(labels, MultiIndex) and level is not None:\n-                        if hasattr(result,'ndim') and not np.prod(result.shape) and len(keyarr):\n-                            raise KeyError(\"cannot index a multi-index axis with these keys\")\n+                        if (hasattr(result, 'ndim') and\n+                                not np.prod(result.shape) and len(keyarr)):\n+                            raise KeyError(\"cannot index a multi-index axis \"\n+                                           \"with these keys\")\n \n                     return result\n \n@@ -1029,19 +1058,19 @@ class _NDFrameIndexer(object):\n                     raise AssertionError(\"invalid indexing error with \"\n                                          \"non-unique index\")\n \n-                new_target, indexer, new_indexer = labels._reindex_non_unique(keyarr)\n+                new_target, indexer, new_indexer = labels._reindex_non_unique(\n+                    keyarr)\n \n                 if new_indexer is not None:\n-                    result = self.obj.take(indexer[indexer!=-1], axis=axis,\n+                    result = self.obj.take(indexer[indexer != -1], axis=axis,\n                                            convert=False)\n \n-                    result = result._reindex_with_indexers({\n-                        axis: [new_target, new_indexer]\n-                        }, copy=True, allow_dups=True)\n+                    result = result._reindex_with_indexers(\n+                        {axis: [new_target, new_indexer]},\n+                        copy=True, allow_dups=True)\n \n                 else:\n-                    result = self.obj.take(indexer, axis=axis,\n-                                           convert=False)\n+                    result = self.obj.take(indexer, axis=axis, convert=False)\n \n                 return result\n \n@@ -1183,7 +1212,6 @@ class _NDFrameIndexer(object):\n \n \n class _IXIndexer(_NDFrameIndexer):\n-\n     \"\"\"A primarily label-location based indexer, with integer position\n     fallback.\n \n@@ -1259,7 +1287,6 @@ class _LocationIndexer(_NDFrameIndexer):\n \n \n class _LocIndexer(_LocationIndexer):\n-\n     \"\"\"Purely label-location based indexer for selection by label.\n \n     ``.loc[]`` is primarily label based, but may also be used with a\n@@ -1318,16 +1345,16 @@ class _LocIndexer(_LocationIndexer):\n \n             def error():\n                 if isnull(key):\n-                    raise TypeError(\n-                        \"cannot use label indexing with a null key\")\n+                    raise TypeError(\"cannot use label indexing with a null \"\n+                                    \"key\")\n                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n                                (key, self.obj._get_axis_name(axis)))\n \n             try:\n                 key = self._convert_scalar_indexer(key, axis)\n-                if not key in ax:\n+                if key not in ax:\n                     error()\n-            except (TypeError) as e:\n+            except TypeError as e:\n \n                 # python 3 type errors should be raised\n                 if 'unorderable' in str(e):  # pragma: no cover\n@@ -1352,12 +1379,12 @@ class _LocIndexer(_LocationIndexer):\n             # possibly convert a list-like into a nested tuple\n             # but don't convert a list-like of tuples\n             if isinstance(labels, MultiIndex):\n-                if not isinstance(key, tuple) and len(key) > 1 and not isinstance(key[0], tuple):\n+                if (not isinstance(key, tuple) and len(key) > 1 and\n+                        not isinstance(key[0], tuple)):\n                     key = tuple([key])\n \n             # an iterable multi-selection\n-            if not (isinstance(key, tuple) and\n-                    isinstance(labels, MultiIndex)):\n+            if not (isinstance(key, tuple) and isinstance(labels, MultiIndex)):\n \n                 if hasattr(key, 'ndim') and key.ndim > 1:\n                     raise ValueError('Cannot index with multidimensional key')\n@@ -1367,7 +1394,7 @@ class _LocIndexer(_LocationIndexer):\n             # nested tuple slicing\n             if is_nested_tuple(key, labels):\n                 locs = labels.get_locs(key)\n-                indexer = [ slice(None) ] * self.ndim\n+                indexer = [slice(None)] * self.ndim\n                 indexer[axis] = locs\n                 return self.obj.iloc[tuple(indexer)]\n \n@@ -1377,7 +1404,6 @@ class _LocIndexer(_LocationIndexer):\n \n \n class _iLocIndexer(_LocationIndexer):\n-\n     \"\"\"Purely integer-location based indexing for selection by position.\n \n     ``.iloc[]`` is primarily integer position based (from ``0`` to\n@@ -1407,10 +1433,9 @@ class _iLocIndexer(_LocationIndexer):\n         if is_bool_indexer(key):\n             if hasattr(key, 'index') and isinstance(key.index, Index):\n                 if key.index.inferred_type == 'integer':\n-                    raise NotImplementedError(\n-                        \"iLocation based boolean indexing on an integer type \"\n-                        \"is not available\"\n-                    )\n+                    raise NotImplementedError(\"iLocation based boolean \"\n+                                              \"indexing on an integer type \"\n+                                              \"is not available\")\n                 raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                  \"an indexable as a mask\")\n             return True\n@@ -1435,9 +1460,9 @@ class _iLocIndexer(_LocationIndexer):\n             raise IndexError(\"single positional indexer is out-of-bounds\")\n         return True\n \n-\n     def _is_valid_list_like(self, key, axis):\n-        # return a boolean if we are a valid list-like (e.g. that we dont' have out-of-bounds values)\n+        # return a boolean if we are a valid list-like (e.g. that we don't\n+        # have out-of-bounds values)\n \n         # coerce the key to not exceed the maximum size of the index\n         arr = np.array(key)\n@@ -1457,7 +1482,7 @@ class _iLocIndexer(_LocationIndexer):\n             pass\n \n         retval = self.obj\n-        axis=0\n+        axis = 0\n         for i, key in enumerate(tup):\n             if i >= self.obj.ndim:\n                 raise IndexingError('Too many indexers')\n@@ -1469,7 +1494,7 @@ class _iLocIndexer(_LocationIndexer):\n             retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n \n             # if the dim was reduced, then pass a lower-dim the next time\n-            if retval.ndim<self.ndim:\n+            if retval.ndim < self.ndim:\n                 axis -= 1\n \n             # try to get for the next axis\n@@ -1540,7 +1565,6 @@ class _iLocIndexer(_LocationIndexer):\n \n \n class _ScalarAccessIndexer(_NDFrameIndexer):\n-\n     \"\"\" access scalars quickly \"\"\"\n \n     def _convert_key(self, key, is_setter=False):\n@@ -1570,7 +1594,6 @@ class _ScalarAccessIndexer(_NDFrameIndexer):\n \n \n class _AtIndexer(_ScalarAccessIndexer):\n-\n     \"\"\"Fast label-based scalar accessor\n \n     Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n@@ -1581,7 +1604,9 @@ class _AtIndexer(_ScalarAccessIndexer):\n     _takeable = False\n \n     def _convert_key(self, key, is_setter=False):\n-        \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n+        \"\"\" require they keys to be the same type as the index (so we don't\n+        fallback)\n+        \"\"\"\n \n         # allow arbitrary setting\n         if is_setter:\n@@ -1590,16 +1615,17 @@ class _AtIndexer(_ScalarAccessIndexer):\n         for ax, i in zip(self.obj.axes, key):\n             if ax.is_integer():\n                 if not is_integer(i):\n-                    raise ValueError(\"At based indexing on an integer index can only have integer \"\n-                                     \"indexers\")\n+                    raise ValueError(\"At based indexing on an integer index \"\n+                                     \"can only have integer indexers\")\n             else:\n                 if is_integer(i):\n-                    raise ValueError(\"At based indexing on an non-integer index can only have non-integer \"\n+                    raise ValueError(\"At based indexing on an non-integer \"\n+                                     \"index can only have non-integer \"\n                                      \"indexers\")\n         return key\n \n-class _iAtIndexer(_ScalarAccessIndexer):\n \n+class _iAtIndexer(_ScalarAccessIndexer):\n     \"\"\"Fast integer location scalar accessor.\n \n     Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n@@ -1644,7 +1670,7 @@ def length_of_indexer(indexer, target=None):\n             step = 1\n         elif step < 0:\n             step = -step\n-        return (stop - start + step-1) // step\n+        return (stop - start + step - 1) // step\n     elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n         return len(indexer)\n     elif not is_list_like_indexer(indexer):\n@@ -1677,8 +1703,8 @@ def convert_to_index_sliceable(obj, key):\n \n def is_index_slice(obj):\n     def _is_valid_index(x):\n-        return (is_integer(x) or is_float(x)\n-                and np.allclose(x, int(x), rtol=_eps, atol=0))\n+        return (is_integer(x) or is_float(x) and\n+                np.allclose(x, int(x), rtol=_eps, atol=0))\n \n     def _crit(v):\n         return v is None or _is_valid_index(v)\n@@ -1713,7 +1739,8 @@ def check_bool_indexer(ax, key):\n \n def convert_missing_indexer(indexer):\n     \"\"\" reverse convert a missing indexer, which is a dict\n-        return the scalar indexer and a boolean indicating if we converted \"\"\"\n+    return the scalar indexer and a boolean indicating if we converted\n+    \"\"\"\n \n     if isinstance(indexer, dict):\n \n@@ -1729,9 +1756,11 @@ def convert_missing_indexer(indexer):\n \n def convert_from_missing_indexer_tuple(indexer, axes):\n     \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n+\n     def get_indexer(_i, _idx):\n-        return (axes[_i].get_loc(_idx['key'])\n-                if isinstance(_idx, dict) else _idx)\n+        return (axes[_i].get_loc(_idx['key']) if isinstance(_idx, dict) else\n+                _idx)\n+\n     return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])\n \n \n@@ -1784,9 +1813,12 @@ def is_nested_tuple(tup, labels):\n \n     return False\n \n+\n def is_list_like_indexer(key):\n     # allow a list_like, but exclude NamedTuples which can be indexers\n-    return is_list_like(key) and not (isinstance(key, tuple) and type(key) is not tuple)\n+    return is_list_like(key) and not (isinstance(key, tuple) and\n+                                      type(key) is not tuple)\n+\n \n def is_label_like(key):\n     # select a label or row\n@@ -1794,8 +1826,7 @@ def is_label_like(key):\n \n \n def need_slice(obj):\n-    return (obj.start is not None or\n-            obj.stop is not None or\n+    return (obj.start is not None or obj.stop is not None or\n             (obj.step is not None and obj.step != 1))\n \n \n@@ -1827,8 +1858,8 @@ def _non_reducing_slice(slice_):\n     \"\"\"\n     # default to column slice, like DataFrame\n     # ['A', 'B'] -> IndexSlices[:, ['A', 'B']]\n-    kinds = tuple(list(compat.string_types) +\n-                  [ABCSeries, np.ndarray, Index, list])\n+    kinds = tuple(list(compat.string_types) + [ABCSeries, np.ndarray, Index,\n+                                               list])\n     if isinstance(slice_, kinds):\n         slice_ = IndexSlice[:, slice_]\n \n",
          "files_name_in_blame_commit": [
            "internals.py",
            "missing.py",
            "indexing.py"
          ]
        }
      },
      "379e145e2733fcee8ed055dec31f282efba1bd79": {
        "commit": {
          "commit_id": "379e145e2733fcee8ed055dec31f282efba1bd79",
          "commit_message": "promote consistency among type typetesting routines\nnow all are is_*",
          "commit_author": "Jeff Reback",
          "commit_date": "2015-02-13 22:38:12",
          "commit_parent": "3f24b879e3483d7f67e451d27f4e06329745e9ab"
        },
        "function": {
          "function_name": "_convert_key",
          "function_code_before": "def _convert_key(self, key, is_setter=False):\n    \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n    if is_setter:\n        return list(key)\n    for (ax, i) in zip(self.obj.axes, key):\n        if ax.is_integer():\n            if not com.is_integer(i):\n                raise ValueError('At based indexing on an integer index can only have integer indexers')\n        elif com.is_integer(i):\n            raise ValueError('At based indexing on an non-integer index can only have non-integer indexers')\n    return key",
          "function_code_after": "def _convert_key(self, key, is_setter=False):\n    \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n    if is_setter:\n        return list(key)\n    for (ax, i) in zip(self.obj.axes, key):\n        if ax.is_integer():\n            if not is_integer(i):\n                raise ValueError('At based indexing on an integer index can only have integer indexers')\n        elif is_integer(i):\n            raise ValueError('At based indexing on an non-integer index can only have non-integer indexers')\n    return key",
          "function_before_start_line": 1520,
          "function_before_end_line": 1536,
          "function_after_start_line": 1520,
          "function_after_end_line": 1536,
          "function_before_token_count": 76,
          "function_after_token_count": 72,
          "functions_name_modified_file": [
            "_convert_for_reindex",
            "_setitem_with_indexer",
            "_getitem_nested_tuple",
            "_maybe_convert_ix",
            "_is_list_like",
            "_align_panel",
            "_convert_to_indexer",
            "_getbool_axis",
            "_is_valid_list_like",
            "_get_slice_axis",
            "_has_valid_tuple",
            "_length_of_indexer",
            "_is_null_slice",
            "_is_nested_tuple",
            "_safe_append_to_index",
            "_need_slice",
            "_align_series",
            "_has_valid_setitem_indexer",
            "_should_validate_iterable",
            "_has_valid_type",
            "_multi_take_opportunity",
            "__iter__",
            "_is_valid_integer",
            "_convert_slice_indexer",
            "_convert_to_index_sliceable",
            "_convert_scalar_indexer",
            "_check_bool_indexer",
            "_get_setitem_indexer",
            "_getitem_iterable",
            "_handle_lowerdim_multi_index_axis0",
            "_convert_tuple",
            "_is_nested_tuple_indexer",
            "_maybe_droplevels",
            "_get_loc",
            "_has_valid_positional_setitem_indexer",
            "_is_label_like",
            "__getitem__",
            "_getitem_tuple",
            "__init__",
            "_getitem_axis",
            "__call__",
            "_maybe_convert_indices",
            "_tuplify",
            "_getitem_lowerdim",
            "_multi_take",
            "_slice",
            "_convert_missing_indexer",
            "get_indexers_list",
            "_convert_from_missing_indexer_tuple",
            "__setitem__",
            "_convert_key",
            "_get_label",
            "_align_frame",
            "_is_index_slice"
          ],
          "functions_name_all_files": [
            "pad_2d",
            "_vstack",
            "get_dtype_kinds",
            "map",
            "format",
            "concatenate_join_units",
            "date_range",
            "real",
            "_getbool_axis",
            "_length_of_indexer",
            "is_floating",
            "_set_with_engine",
            "_groupby_indices",
            "_repr_html_",
            "get_loc",
            "sparse_reindex",
            "identical",
            "get_group_index",
            "stack",
            "eval",
            "date",
            "order",
            "_handle_lowerdim_multi_index_axis0",
            "_python_apply_general",
            "_box_func",
            "is_full",
            "_block",
            "_delegate_property_set",
            "to_csv",
            "unique",
            "_format_native_types",
            "_get_levels",
            "_getitem_tuple",
            "_naive_in_cache_range",
            "_maybe_coerce_indexer",
            "_utc",
            "in_qtconsole",
            "_apply_meta",
            "describe",
            "to_timestamp",
            "_post_process_cython_aggregate",
            "in_interactive_session",
            "shape",
            "_multi_take",
            "_transform_general",
            "_string_data_error",
            "_all_indexes_same",
            "ngroups",
            "_validate_join_method",
            "components",
            "is_object_dtype",
            "equal_levels",
            "drop_duplicates",
            "_convert_for_reindex",
            "timedelta_range",
            "_simple_new",
            "diff",
            "_apply_to_column_groupbys",
            "_validate_slicer",
            "_ensure_frozen",
            "indexer_between_time",
            "_update_inplace",
            "take_nd",
            "_sanitize_array",
            "is_",
            "from_product",
            "_delegate_method",
            "size",
            "_putmask_smart",
            "_count_compat",
            "is_datetime64_dtype",
            "next",
            "_ordinal_from_fields",
            "_get_splitter",
            "_should_validate_iterable",
            "__bytes__",
            "to_html",
            "argsort",
            "_new_Index",
            "__contains__",
            "_trim_front",
            "get_indexer",
            "is_datetime_or_timedelta_dtype",
            "nanmean",
            "_left_join_on_index",
            "_tuple_index",
            "drop",
            "between",
            "_join_level",
            "writerows",
            "_get_loc",
            "_join_monotonic",
            "_get_merge_data",
            "from_csv",
            "_isnull_ndarraylike_old",
            "_use_inf_as_null",
            "__xor__",
            "_try_operate",
            "__getstate__",
            "_get_level_number",
            "_isnull_old",
            "array_equivalent",
            "reset_index",
            "_getitem_lowerdim",
            "_get_fill_func",
            "inferred_type",
            "__nonzero__",
            "_convert_missing_indexer",
            "_reindex_columns",
            "ravel",
            "_block2d_to_blocknd",
            "_iterable_not_string",
            "_repr_fits_horizontal_",
            "_count_not_none",
            "iget_value",
            "make_nancomp",
            "_repr_categories_info",
            "extract_index",
            "mgr_locs",
            "_get_dtype",
            "time",
            "now",
            "_can_fast_union",
            "_iterate_slices",
            "_groupby_function",
            "decons_obs_group_ids",
            "_get_combined_index",
            "get_locs",
            "ptp",
            "_view_if_needed",
            "combine_concat_plans",
            "combine",
            "indices",
            "_has_valid_setitem_indexer",
            "_sanitize_and_check",
            "is_datetime_arraylike",
            "_get_join_info",
            "should_store",
            "is_hashable",
            "_zero_out_fperr",
            "_maybe_cast_slice_bound",
            "__array__",
            "is_float_dtype",
            "set_levels",
            "make_block",
            "split_ranges",
            "_from_elements",
            "_should_fill",
            "_get_codes_for_values",
            "_try_get_item",
            "sem",
            "is_datelike",
            "iterrows",
            "levshape",
            "_array_values",
            "icol",
            "is_datetimelike",
            "duplicated",
            "_convert_slice_indexer_getitem",
            "get_ftype_counts",
            "_maybe_box_datetimelike",
            "__call__",
            "is_bool_indexer",
            "__deepcopy__",
            "nansem",
            "_validate_specification",
            "pivot",
            "cumcount",
            "_cat_compare_op",
            "indent",
            "to_sparse",
            "to_panel",
            "_maybe_null_out",
            "_unpickle_array",
            "_flex_compare_frame",
            "_get_group_index_sorter",
            "_join_non_unique",
            "_getitem_array",
            "_quarter_to_myear",
            "_time_to_micros",
            "_tidy_repr",
            "get_splitter",
            "_make_na_block",
            "_compare_frame_evaluate",
            "_aggregate_series_pure_python",
            "_cython_agg_blocks",
            "_use_cached_range",
            "_any_none",
            "snap",
            "reindex_axis",
            "sym_diff",
            "is_number",
            "nblocks",
            "get_result",
            "put",
            "repeat",
            "_get_dtype_type",
            "_apply_broadcast",
            "to_records",
            "slice_locs",
            "_constructor",
            "_field_accessor",
            "_set_result_index_ordered",
            "_astype_nansafe",
            "ndim",
            "reorder_categories",
            "_set_categories",
            "_convert_list_indexer_for_mixed",
            "delete",
            "droplevel",
            "_maybe_promote",
            "update",
            "_get_agg_axis",
            "_stack_arrays",
            "result_index",
            "_maybe_match_name",
            "to_series",
            "add_suffix",
            "_get_indices_dict",
            "_get_categories",
            "_can_hold_element",
            "to_frame",
            "info",
            "_get_join_keys",
            "_get_dtype_from_object",
            "_set_levels",
            "view",
            "_convert_object_array",
            "_get_info_slice",
            "_define_paths",
            "nancorr",
            "_reindex_index",
            "itertuples",
            "_is_dates_only",
            "_try_fill",
            "_get_single_indexer",
            "load",
            "_safe_append_to_index",
            "_maybe_upcast_putmask",
            "_align_series",
            "_get_merge_keys",
            "is_timedelta64_ns_dtype",
            "_interp_wrapper",
            "_get_names",
            "is_boolean",
            "create_block_manager_from_blocks",
            "to_pytimedelta",
            "nanargmax",
            "_set_subtyp",
            "pad_1d",
            "is_numeric_mixed_type",
            "is_int_or_datetime_dtype",
            "__getattr__",
            "_add_numeric_methods_disabled",
            "set_index",
            "_masked_rec_array_to_mgr",
            "_process_concat_data",
            "_consolidate",
            "get_scalar",
            "_consolidate_check",
            "readline",
            "slabels",
            "_apply_standard",
            "tail",
            "_validate_categories",
            "_bounds",
            "rank",
            "_simple_blockify",
            "add_categories",
            "__getitem__",
            "__sub__",
            "_get_na_rep",
            "get_bool_data",
            "keys",
            "setitem",
            "_make_wrapper",
            "_get_names_from_index",
            "save",
            "_get_callable_name",
            "to_string",
            "_get_distinct_indexes",
            "_convert_key",
            "_get_label",
            "_ensure_datetime64",
            "get_indexer_non_unique",
            "_verify_integrity",
            "__instancecheck__",
            "_setitem_with_indexer",
            "_bn_ok_dtype",
            "_add_datelike",
            "_values",
            "reshape",
            "nanvar",
            "_join_unicode",
            "ohlc",
            "_get_comb_axis",
            "_range_from_fields",
            "_join_multi",
            "take_2d_multi",
            "_maybe_box",
            "base",
            "_maybe_convert_string_to_object",
            "get_dtypes",
            "compress",
            "_resolution",
            "_wrap_agged_blocks",
            "_factorize_keys",
            "_interleaved_dtype",
            "_add_delta",
            "_possibly_cast_to_datetime",
            "_getitem_frame",
            "backfill_2d",
            "_mut_exclusive",
            "nonzero",
            "merge",
            "_get_data_to_aggregate",
            "_concat_indexes",
            "_get_time_micros",
            "_reindex_output",
            "_is_label_like",
            "from_arrays",
            "__str__",
            "is_re",
            "is_iterator",
            "ftypes",
            "is_all_dates",
            "create_pandas_abc_type",
            "_in_range",
            "_is_convertible_to_index",
            "_box_col_values",
            "_convert_from_missing_indexer_tuple",
            "_list_of_dict_to_arrays",
            "slice_indexer",
            "_get_field",
            "_evaluate_with_datetime_like",
            "set_labels",
            "notnull",
            "_generate_regular_range",
            "_long_prod",
            "_get_multiindex_indexer",
            "pprint_thing_encoded",
            "pnow",
            "_partial_tup_index",
            "idxmin",
            "_possibly_castable",
            "aggregate",
            "tz_localize",
            "_is_nested_tuple",
            "from_codes",
            "is_lexsorted",
            "_reference_duplicate_name",
            "_possibly_downcast_to_dtype",
            "is_categorical_dtype",
            "_get_new_axes",
            "nkeys",
            "_compress_group_index",
            "_format_with_header",
            "_partial_td_slice",
            "_possibly_convert_platform",
            "normalize",
            "__hash__",
            "nankurt",
            "_possibly_promote",
            "array_dtype",
            "_factor_indexer",
            "_getitem_slice",
            "_interleave",
            "nanmax",
            "_get_result_dim",
            "_combine_series_infer",
            "is_categorical",
            "get_loc_level",
            "_get_take_nd_function",
            "idxmax",
            "get_group",
            "_try_cast_result",
            "__add__",
            "_ensure_compat_concat",
            "nanmin",
            "_cached_range",
            "_from_arraylike",
            "_concat_objects",
            "items_overlap_with_suffix",
            "_possibly_infer_to_datetimelike",
            "concatenate_block_managers",
            "__repr__",
            "fillna",
            "_get_group_keys",
            "_fast_count_smallints",
            "create_block_manager_from_arrays",
            "isnull",
            "is_type_compatible",
            "sortlevel",
            "__array_finalize__",
            "_slice",
            "reshape_nd",
            "dot",
            "__getslice__",
            "__setitem__",
            "_clean_interp_method",
            "_get_level_indexer",
            "combineAdd",
            "T",
            "UnicodeWriter",
            "get_group_levels",
            "nanskew",
            "nanoseconds",
            "interpolate_2d",
            "from_tuples",
            "_is_list_like",
            "is_numeric_dtype",
            "sentinel_factory",
            "_join_i8_wrapper",
            "_chop",
            "_convert_to_indexer",
            "get_slice_bound",
            "nanprod",
            "combineMult",
            "_unpickle_series_compat",
            "add_prefix",
            "_from_ordinal",
            "is_timedelta64_dtype",
            "_add_numeric_methods",
            "_coerce_to_dtypes",
            "set_value",
            "get_key",
            "to_dense",
            "writerow",
            "__iter__",
            "_make_dt_accessor",
            "mask_missing",
            "_reorder_by_uniques",
            "intersection",
            "_maybe_to_categorical",
            "_convert_list_indexer",
            "_needs_reindex_multi",
            "_repr_fits_vertical_",
            "_make_labels",
            "_try_cast",
            "last_valid_index",
            "get_ftypes",
            "_whitelist_method_generator",
            "make_block_same_class",
            "get",
            "__array_prepare__",
            "_evaluate_with_timedelta_like",
            "_get_with",
            "summary",
            "is_null",
            "xs",
            "_combine_series",
            "_possibly_cast_item",
            "is_re_compilable",
            "values",
            "_consolidate_key",
            "is_floating_dtype",
            "_all_none",
            "end_time",
            "_has_infs",
            "_intercept_function",
            "_can_hold_na",
            "is_datelike_mixed_type",
            "dropna",
            "needs_filling",
            "nanstd",
            "_local_timestamps",
            "convert",
            "_get_na_value",
            "groups",
            "seconds",
            "_setitem_array",
            "_get_method",
            "__or__",
            "kind",
            "period_range",
            "_get_slice_axis",
            "swaplevel",
            "_has_valid_tuple",
            "memory_usage",
            "_is_null_slice",
            "is_monotonic_decreasing",
            "is_normalized",
            "_add_logical_methods_disabled",
            "reindex_indexer",
            "_drop_from_level",
            "_set_item",
            "_cumcount_array",
            "_decide_output_index",
            "is_bool",
            "is_lexsorted_for_tuple",
            "_convert_slice_indexer",
            "_has_complex_internals",
            "nbytes",
            "_is_valid_integer",
            "_convert_to_index_sliceable",
            "tolist",
            "_indexer_from_factorized",
            "_getitem_iterable",
            "recons_labels",
            "cdate_range",
            "_convert_tuple",
            "_sanitize_index",
            "dtype",
            "is_mixed",
            "searchsorted",
            "__new__",
            "construction_error",
            "map_indices_py",
            "_has_valid_positional_setitem_indexer",
            "_infer_fill_value",
            "_get_object_array",
            "sp_values",
            "_maybe_check_integrity",
            "fast_xs",
            "codes",
            "_try_sort",
            "_apply_empty_result",
            "_transform_index",
            "__init__",
            "_is_indexed_like",
            "iterpairs",
            "_delegate_property_get",
            "_aggregate_series_fast",
            "as_matrix",
            "remove_unused_categories",
            "_is_index_slice",
            "adjoin",
            "_binop",
            "tz_convert",
            "is_numeric",
            "asfreq",
            "is_any_int_dtype",
            "form_blocks",
            "_getitem_nested_tuple",
            "_get_consensus_names",
            "_infer_dtype_from_scalar",
            "set_names",
            "truncate",
            "get_indexer_for",
            "downcast",
            "_to_arrays",
            "_possibly_compare",
            "_validate_index_level",
            "_pprint_dict",
            "console_encode",
            "_nanvar",
            "_get_repr",
            "nanmedian",
            "get_value_maybe_box",
            "_has_valid_type",
            "UnicodeReader",
            "_na_value",
            "_check_bool_indexer",
            "_take_nd_generic",
            "std",
            "asof_locs",
            "imag",
            "_transform_fast",
            "take",
            "_all_not_none",
            "filter",
            "axes",
            "_local_dir",
            "get_slice",
            "_ensure_valid_index",
            "union",
            "_generate",
            "dt64arr_to_periodarr",
            "_wrap_applied_output",
            "_python_agg_general",
            "get_reindexed_values",
            "agg",
            "_isfinite",
            "_interpolate",
            "__len__",
            "_period_field_accessor",
            "is_categorical_astype",
            "_na_ok_dtype",
            "_right_outer_join",
            "dtypes",
            "_set_freq",
            "get_numeric_data",
            "transform",
            "consolidate",
            "nth",
            "_box_item_values",
            "astype",
            "names",
            "_try_coerce_result",
            "is_time_series",
            "ensure_float",
            "_maybe_convert_ix",
            "append",
            "interpolate",
            "_lcd_dtypes",
            "_fill_zeros",
            "_convert_to_list_like",
            "_clean_fill_method",
            "corrwith",
            "_get_index",
            "var",
            "_view_wrapper",
            "_get_counts_nanvar",
            "rename_categories",
            "_getitem_multilevel",
            "_where_compat",
            "_need_slice",
            "concat",
            "apply",
            "ordered_merge",
            "to_hierarchical",
            "sort_index",
            "_validate_end_alias",
            "_convert_grouper",
            "_get_setitem_indexer",
            "group_info",
            "_slice_take_blocks_ax0",
            "where",
            "remove_na",
            "microseconds",
            "_selection_list",
            "is_list_like",
            "__unicode__",
            "is_bool_dtype",
            "to_gbq",
            "_setitem_frame",
            "_comp_method",
            "strftime",
            "_get_join_indexers",
            "_max_groupsize",
            "_convert_wrapper",
            "to_period",
            "_block_shape",
            "_coerce_method",
            "_get_binner_for_grouping",
            "get_empty_dtype_and_na",
            "_sort_labels",
            "from_array",
            "_get_compressed_labels",
            "_transform_item_by_item",
            "to_latex",
            "groupings",
            "_tuplify",
            "_make_concat_multiindex",
            "backfill_1d",
            "_mpl_repr",
            "make_empty",
            "_choose_path",
            "_init_ndarray",
            "_add_logical_methods",
            "_fast_union",
            "_to_m8",
            "max",
            "_series",
            "_reindex_axes",
            "corr",
            "lexsort_depth",
            "set",
            "_post_setstate",
            "_any",
            "_try_coerce_args",
            "from_records",
            "_replace_single",
            "lookup",
            "indexer_at_time",
            "to_pydatetime",
            "_combine_frame",
            "generate_bins_generic",
            "equals",
            "_unpickle_frame_compat",
            "_consensus_name_attr",
            "__and__",
            "is_unique",
            "_make_str_accessor",
            "_last_compat",
            "rename",
            "_dt_index_cmp",
            "_convert_scalar_indexer",
            "_set_axis",
            "levels",
            "boxplot",
            "_set_with",
            "_set_values",
            "_partial_date_slice",
            "_is_convertible_to_td",
            "_index_with_as_index",
            "_is_v1",
            "decons_group_index",
            "_sub_datelike",
            "_isnull_new",
            "_set_names",
            "_intercept_cython",
            "index",
            "get_value",
            "_getitem_column",
            "_ensure_has_len",
            "_is_mixed_type",
            "_aggregate_multiple_funcs",
            "_validate_date_like_dtype",
            "_get_ordinal_range",
            "is_object",
            "nanany",
            "_ensure_numeric",
            "_wrap_aggregated_output",
            "is_null_datelike_scalar",
            "_scalar_data_error",
            "_convert_indexer_error",
            "_is_single_block",
            "_align_frame",
            "_homogenize",
            "_index_labels_to_array",
            "start_time",
            "_align_panel",
            "_is_valid_list_like",
            "_reorder_arrays",
            "_maybe_downcast",
            "is_view",
            "_ensure_index",
            "freqstr",
            "_cleanup",
            "sp_index",
            "quantile",
            "irow",
            "_get_sorted_data",
            "is_complex_dtype",
            "to_native_types",
            "_wrap_joined_index",
            "_from_nested_dict",
            "group_index",
            "_sanitize_column",
            "getitem_block",
            "to_dict",
            "interpolate_1d",
            "tzinfo",
            "_coerce_indexer_dtype",
            "_isnull_ndarraylike",
            "_maybe_droplevels",
            "get_mgr_concatenation_plan",
            "_aggregate_item_by_item",
            "_first_compat",
            "_engine",
            "nsmallest",
            "_asarray_tuplesafe",
            "_lexsort_indexer",
            "is_consolidated",
            "in_ipython_frontend",
            "_init_dict",
            "_interpolate_with_fill",
            "is_integer_dtype",
            "nancov",
            "_generate_range",
            "_consolidate_inplace",
            "ftype",
            "_count_level",
            "isin",
            "_coerce_to_dtype",
            "_aggregate",
            "_get_fill_value",
            "_get_values_tuple",
            "_get_axes",
            "_invalidate_string_dtypes",
            "union_many",
            "__setstate__",
            "get_indexers_list",
            "_get_grouper",
            "_sparse_blockify",
            "trim_join_unit",
            "_default_index",
            "has_duplicates",
            "_maybe_make_list",
            "_td_index_cmp",
            "_reindex_multi",
            "_isnan",
            "itemsize",
            "is_period_arraylike",
            "_str_to_dt_array",
            "unique1d",
            "_maybe_add_join_keys",
            "shift",
            "rename_axis",
            "_make_field_arrays",
            "_formatter_func",
            "hasnans",
            "get_level_values",
            "nlevels",
            "numpy_groupby",
            "to_julian_date",
            "_iterate_column_groupbys",
            "median",
            "is_sequence",
            "_wrap_generic_output",
            "iteritems",
            "_to_embed",
            "autocorr",
            "_parsed_string_to_bounds",
            "_set_labels",
            "__reduce__",
            "to_stata",
            "_astype",
            "_compare_frame",
            "reorder_levels",
            "_set_codes",
            "count",
            "_wrap_union_result",
            "_preprocess_slice_or_indexer",
            "_get_aggregate_function",
            "_maybe_convert_indices",
            "holds_integer",
            "_info_repr",
            "_concat_compat",
            "_get_blkno_placements",
            "_obj_with_exclusions",
            "_sparsify",
            "_merge_blocks",
            "_set_selection_from_grouper",
            "_multi_blockify",
            "_interpolate_scipy_wrapper",
            "get_iterator",
            "_shallow_copy",
            "fast_apply",
            "_nan_idxs",
            "_ixs",
            "is_datetime64_ns_dtype",
            "labels",
            "name",
            "groupby",
            "agg_series",
            "_populate_tables",
            "asof",
            "_is_v2",
            "_get_counts",
            "_get_handle",
            "is_mixed_type",
            "cov",
            "is_monotonic",
            "_indexOp",
            "get_corr_func",
            "_format_footer",
            "read",
            "_maybe_utc_convert",
            "combine_first",
            "check",
            "unstack",
            "_put_str",
            "_maybe_upcast",
            "insert",
            "_selected_obj",
            "_cython_agg_general",
            "_nargsort",
            "asi8",
            "_get_labels",
            "remove_categories",
            "_multi_take_opportunity",
            "replace_list",
            "_make_cat_accessor",
            "mode",
            "_aggregate_generic",
            "_arrays_to_mgr",
            "_combine_match_index",
            "set_axis",
            "_rebuild_blknos_and_blklocs",
            "_reset_identity",
            "_get_values",
            "is_integer",
            "_is_nested_tuple_indexer",
            "_prep_ndarray",
            "_apply_filter",
            "nansum",
            "__eq__",
            "to_excel",
            "_list_of_series_to_arrays",
            "_get_attributes_dict",
            "difference",
            "_union_indexes",
            "first_valid_index",
            "_get_concat_axis",
            "i8_boxer",
            "putmask",
            "_assert_can_do_setop",
            "get_dtype_counts",
            "_new_DatetimeIndex",
            "mean",
            "copy",
            "applymap",
            "_try_coerce_and_cast_result",
            "_maybe_arg_null_out",
            "bind_method",
            "_repr_footer",
            "bdate_range",
            "in_ipnb",
            "_insert_inaxis_grouper_inplace",
            "select_dtypes",
            "needs_block_conversion",
            "_int64_overflow_possible",
            "_unpickle_matrix_compat",
            "_aggregate_named",
            "_take_2d_multi_generic",
            "_possibly_convert_objects",
            "nanall",
            "_reduce",
            "reindex",
            "_coerce_to_ndarray",
            "_get_freq",
            "set_categories",
            "is_monotonic_increasing",
            "iget",
            "_wrap_results",
            "nanargmin",
            "_pickle_array",
            "flatten",
            "_join_compat",
            "_get_string_slice",
            "sort_idx",
            "get_duplicates",
            "pprint_thing",
            "_setitem_slice",
            "nlargest",
            "query",
            "to_datetime",
            "_get_items",
            "round",
            "_set_grouper",
            "fill_value",
            "from_dict",
            "ax",
            "from_items",
            "__array_wrap__",
            "_period_index_cmp",
            "_reindex_indexer",
            "_combine_const",
            "_list_to_arrays",
            "transpose",
            "get_values",
            "_combine_match_columns",
            "replace",
            "_get_codes",
            "_getitem_axis",
            "_pprint_seq",
            "banner",
            "join",
            "_maybe_cast_scalar",
            "min",
            "_apply_raw",
            "__ne__",
            "_get_ordinals",
            "head",
            "days",
            "sort",
            "_from_arrays"
          ],
          "functions_name_co_evolved_modified_file": [
            "_getitem_axis",
            "_convert_for_reindex",
            "_setitem_with_indexer",
            "_has_valid_positional_setitem_indexer",
            "_has_valid_type",
            "_convert_to_indexer",
            "_multi_take_opportunity",
            "_check_bool_indexer",
            "_is_index_slice",
            "_getitem_iterable"
          ],
          "functions_name_co_evolved_all_files": [
            "set_labels",
            "nanskew",
            "_convert_for_reindex",
            "_setitem_with_indexer",
            "_is_categorical",
            "is_any_int_dtype",
            "_setitem_array",
            "form_blocks",
            "_bn_ok_dtype",
            "set_names",
            "_is_datetime_or_timedelta_dtype",
            "_convert_to_indexer",
            "_indexOp",
            "get_slice_bound",
            "set",
            "aggregate",
            "_try_coerce_args",
            "nanprod",
            "_getitem_array",
            "get_locs",
            "_view_if_needed",
            "_nanvar",
            "_is_bool_indexer",
            "_multi_take_opportunity",
            "_has_valid_type",
            "nankurt",
            "is_datetime_or_timedelta_dtype",
            "is_int_or_datetime_dtype",
            "_check_bool_indexer",
            "_factorize_keys",
            "_getitem_iterable",
            "is_categorical",
            "__new__",
            "set_levels",
            "_is_int_or_datetime_dtype",
            "make_block",
            "_has_valid_positional_setitem_indexer",
            "_convert_list_indexer_for_mixed",
            "__getitem__",
            "_getitem_axis",
            "__init__",
            "is_floating_dtype",
            "is_bool_indexer",
            "_isfinite",
            "nansem",
            "_is_any_int_dtype",
            "_is_floating_dtype",
            "is_null_datelike_scalar",
            "_na_ok_dtype",
            "__setitem__",
            "_is_null_datelike_scalar",
            "_is_index_slice"
          ]
        },
        "file": {
          "file_name": "indexing.py",
          "file_nloc": 1116,
          "file_complexity": 472,
          "file_token_count": 8326,
          "file_before": "# pylint: disable=W0223\n\nfrom datetime import datetime\nfrom pandas.core.index import Index, MultiIndex, _ensure_index\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nimport pandas.core.common as com\nfrom pandas.core.common import (_is_bool_indexer, is_integer_dtype,\n                                _asarray_tuplesafe, is_list_like, isnull,\n                                ABCSeries, ABCDataFrame, ABCPanel, is_float,\n                                _values_from_object, _infer_fill_value)\nimport pandas.lib as lib\n\nimport numpy as np\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix',   _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc',  _LocIndexer),\n        ('at',   _AtIndexer),\n        ('iat',  _iAtIndexer),\n    ]\n\n# \"null slice\"\n_NS = slice(None, None)\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    def __getitem__(self, arg):\n        return arg\nIndexSlice = _IndexSlice()\n\nclass IndexingError(Exception):\n    pass\n\nclass _NDFrameIndexer(object):\n    _valid_types = None\n    _exception = KeyError\n\n    def __init__(self, obj, name):\n        self.obj = obj\n        self.ndim = obj.ndim\n        self.name = name\n        self.axis = None\n\n    def __call__(self, *args, **kwargs):\n        # we need to return a copy of ourselves\n        self = self.__class__(self.obj, self.name)\n\n        # set the passed in values\n        for k, v in compat.iteritems(kwargs):\n            setattr(self,k,v)\n        return self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            try:\n                values = self.obj.get_value(*key)\n                if np.isscalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _get_label(self, label, axis=0):\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            try:\n                return self.obj._xs(label, axis=axis)\n            except:\n                return self.obj[label]\n        elif (isinstance(label, tuple) and\n                isinstance(label[axis], slice)):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=0):\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=0, typ=None):\n        return self.obj._slice(obj, axis=axis, typ=typ)\n\n    def _get_setitem_indexer(self, key):\n        if self.axis is not None:\n            return self._convert_tuple(key, is_setter=True)\n\n        axis = self.obj._get_axis(0)\n        if isinstance(axis, MultiIndex):\n            try:\n                return axis.get_loc(key)\n            except Exception:\n                pass\n\n        if isinstance(key, tuple) and not self.ndim < len(key):\n            return self._convert_tuple(key, is_setter=True)\n\n        try:\n            return self._convert_to_indexer(key, is_setter=True)\n        except TypeError:\n            raise IndexingError(key)\n\n    def __setitem__(self, key, value):\n        indexer = self._get_setitem_indexer(key)\n        self._setitem_with_indexer(indexer, value)\n\n    def _has_valid_type(self, k, axis):\n        raise NotImplementedError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            if not self._has_valid_type(k, i):\n                raise ValueError(\"Location based indexing can only have [%s] \"\n                                 \"types\" % self._valid_types)\n\n    def _should_validate_iterable(self, axis=0):\n        \"\"\" return a boolean whether this axes needs validation for a passed iterable \"\"\"\n        ax = self.obj._get_axis(axis)\n        if isinstance(ax, MultiIndex):\n            return False\n        elif ax.is_floating():\n            return False\n\n        return True\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any([ isinstance(ax, MultiIndex) for ax in self.obj.axes ]):\n            return any([ _is_nested_tuple(tup,ax) for ax in self.obj.axes ])\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, typ=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, typ=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n            will raise if needed, does not modify the indexer externally \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like(i):\n                    # should check the elements?\n                    pass\n                elif com.is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{0} cannot enlarge its target object\"\n                                         .format(self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{0} cannot enlarge its target object\"\n                                     .format(self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        from pandas import Panel, DataFrame, Series\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = _convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any([not l for l in len_non_info_axes]):\n                            if not is_list_like(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n\n                        # add a new item with the dtype setup\n                        self.obj[key] = _infer_fill_value(value)\n\n                        new_indexer = _convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = _safe_append_to_index(index, key)\n                    self.obj._data = self.obj.reindex_axis(labels, i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj.is_copy=None\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = _convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    if len(index) == 0:\n                        new_index = Index([indexer])\n                    else:\n                        new_index = _safe_append_to_index(index, indexer)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value]).values\n                    if len(self.obj.values):\n                        new_values = np.concatenate([self.obj.values,\n                                                     new_values])\n\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\n                            \"cannot set a frame with no defined columns\"\n                        )\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if com.is_list_like(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\n                                    \"cannot set a row with mismatched columns\"\n                                    )\n\n                        value = Series(value,index=self.obj.columns,name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        info_axis = self.obj._info_axis_number\n        item_labels = self.obj._get_axis(info_axis)\n\n        # if we have a complicated setup, take the split path\n        if (isinstance(indexer, tuple) and\n                any([isinstance(ax, MultiIndex) for ax in self.obj.axes])):\n            take_split_path = True\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if com.is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].axes[0], MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = _length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like(value) and np.iterable(value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\n                            \"cannot set using a multi-index selection indexer \"\n                            \"with a different length than the value\"\n                        )\n\n                    # make sure we have an ndarray\n                    value = getattr(value,'values',value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = _length_of_indexer(plane_indexer[0],\n                                                        plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice which means essentially reassign to the columns\n                # of a multi-dim object\n                # GH6149\n                if isinstance(pi, tuple) and all(_is_null_slice(idx) for idx in pi):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if not len(labels) == 1 or not np.iterable(value):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an interable, with a ndim of at least 1\n            # eg. don't pass thru np.array(0)\n            if _is_list_like(value) and getattr(value,'ndim',1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n\n                    for item in labels:\n                        # align to\n                        v = np.nan if item not in value else \\\n                                self._align_series(indexer[0], value[item])\n                        setter(item, v)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value,dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = _maybe_convert_ix(*indexer)\n\n                # if we are setting on the info axis ONLY\n                # set using those methods to avoid block-splitting\n                # logic here\n                if len(indexer) > info_axis and com.is_integer(indexer[info_axis]) and all(\n                    _is_null_slice(idx) for i, idx in enumerate(indexer) if i != info_axis):\n                    self.obj[item_labels[indexer[info_axis]]] = value\n                    return\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser):\n        # indexer to assign Series can be tuple, slice, scalar\n        if isinstance(indexer, (slice, np.ndarray, list)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            # flatten np.ndarray indexers\n            ravel = lambda i: i.ravel() if isinstance(i, np.ndarray) else i\n            indexer = tuple(map(ravel, indexer))\n\n            aligners = [not _is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all([com.is_sequence(_) for _ in indexer])):\n                ser = ser.reindex(obj.axes[0][indexer[0]], copy=True).values\n\n                # single indexer\n                if len(indexer) > 1:\n                    l = len(indexer[1])\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if com.is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and _is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix)\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser.values.copy()\n\n                    return ser.reindex(new_ix).values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser.values.copy()\n                    return ser.reindex(ax).values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser.values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif np.isscalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser.values.copy()\n\n            return ser.reindex(ax).values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n\n        if isinstance(indexer, tuple):\n\n            aligners = [not _is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if com.is_sequence(ix) or isinstance(ix, slice):\n                    if idx is None:\n                        idx = ax[ix].ravel()\n                    elif cols is None:\n                        cols = ax[ix].ravel()\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n\n                # need to conform to the convention\n                # as we are not selecting on the items axis\n                # and we have a single indexer\n                # GH 7763\n                if len(sindexers) == 1 and sindexers[0] != 0:\n                    df = df.T\n\n                if idx is None:\n                    idx = df.index\n                if cols is None:\n                    cols = df.columns\n\n            if idx is not None and cols is not None:\n\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy().values\n                else:\n                    val = df.reindex(idx, columns=cols).values\n                return val\n\n        elif ((isinstance(indexer, slice) or com.is_list_like(indexer))\n              and is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy().values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if isinstance(ax, MultiIndex) and isinstance(\n                    df.index, MultiIndex) and ax.nlevels != df.index.nlevels:\n                    raise TypeError(\"cannot align on a multi-index with out specifying the join levels\")\n\n                val = df.reindex(index=ax).values\n            return val\n\n        elif np.isscalar(indexer) and is_panel:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy().values\n\n            return df.reindex(idx, columns=cols).values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        from pandas.core.generic import NDFrame\n\n        # ugly hack for GH #836\n        if not isinstance(self.obj, NDFrame):\n            return False\n\n        if not all(_is_list_like(x) for x in tup):\n            return False\n\n        # just too complicated\n        for indexer, ax in zip(tup, self.obj._data.axes):\n            if isinstance(ax, MultiIndex):\n                return False\n            elif com._is_bool_indexer(indexer):\n                return False\n            elif not ax.is_unique:\n                return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\" create the reindex map for our objects, raise the _exception if we\n        can't create the indexer\n        \"\"\"\n        try:\n            o = self.obj\n            d = dict([\n                (a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n                for t, a in zip(tup, o._AXIS_ORDERS)\n            ])\n            return o.reindex(**d)\n        except:\n            raise self._exception\n\n    def _convert_for_reindex(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if com._is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            return labels[key]\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if is_integer_dtype(keyarr) and not labels.is_integer():\n                keyarr = com._ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n            return keyarr\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=0)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        if isinstance(ax0, MultiIndex):\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if _is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not _is_list_like(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0\n                            and len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of selectors\n            return self._getitem_axis(tup, axis=0)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if np.isscalar(obj) or not hasattr(obj,'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=0):\n\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif _is_list_like(key) and not (isinstance(key, tuple) and\n                                         isinstance(labels, MultiIndex)):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n            if com.is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _getitem_iterable(self, key, axis=0):\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        def _reindex(keys, level=None):\n\n            try:\n                result = self.obj.reindex_axis(keys, axis=axis, level=level)\n            except AttributeError:\n                # Series\n                if axis != 0:\n                    raise AssertionError('axis must be 0')\n                return self.obj.reindex(keys, level=level)\n\n            # this is an error as we are trying to find\n            # keys in a multi-index that don't exist\n            if isinstance(labels, MultiIndex) and level is not None:\n                if hasattr(result,'ndim') and not np.prod(result.shape) and len(keys):\n                    raise KeyError(\"cannot index a multi-index axis with these keys\")\n\n            return result\n\n        if com._is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj.take(inds, axis=axis, convert=False)\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            # handle a mixed integer scenario\n            indexer = labels._convert_list_indexer_for_mixed(keyarr, typ=self.name)\n            if indexer is not None:\n                return self.obj.take(indexer, axis=axis)\n\n            # this is not the most robust, but...\n            if (isinstance(labels, MultiIndex) and len(keyarr) and\n                    not isinstance(keyarr[0], tuple)):\n                level = 0\n            else:\n                level = None\n\n            keyarr_is_unique = Index(keyarr).is_unique\n\n            # existing labels are unique and indexer is unique\n            if labels.is_unique and keyarr_is_unique:\n                return _reindex(keyarr, level=level)\n\n            else:\n                indexer, missing = labels.get_indexer_non_unique(keyarr)\n                check = indexer != -1\n                result = self.obj.take(indexer[check], axis=axis,\n                                       convert=False)\n\n                # need to merge the result labels and the missing labels\n                if len(missing):\n                    l = np.arange(len(indexer))\n\n                    missing = com._ensure_platform_int(missing)\n                    missing_labels = keyarr.take(missing)\n                    missing_indexer = com._ensure_int64(l[~check])\n                    cur_labels = result._get_axis(axis).values\n                    cur_indexer = com._ensure_int64(l[check])\n\n                    new_labels = np.empty(tuple([len(indexer)]), dtype=object)\n                    new_labels[cur_indexer] = cur_labels\n                    new_labels[missing_indexer] = missing_labels\n\n                    # reindex with the specified axis\n                    ndim = self.obj.ndim\n                    if axis + 1 > ndim:\n                        raise AssertionError(\"invalid indexing error with \"\n                                             \"non-unique index\")\n\n                    # a unique indexer\n                    if keyarr_is_unique:\n\n                        # see GH5553, make sure we use the right indexer\n                        new_indexer = np.arange(len(indexer))\n                        new_indexer[cur_indexer] = np.arange(\n                            len(result._get_axis(axis))\n                        )\n                        new_indexer[missing_indexer] = -1\n\n                    # we have a non_unique selector, need to use the original\n                    # indexer here\n                    else:\n\n                        # need to retake to have the same size as the indexer\n                        rindexer = indexer.values\n                        rindexer[~check] = 0\n                        result = self.obj.take(rindexer, axis=axis,\n                                               convert=False)\n\n                        # reset the new indexer to account for the new size\n                        new_indexer = np.arange(len(result))\n                        new_indexer[~check] = -1\n\n                    result = result._reindex_with_indexers({\n                        axis: [new_labels, new_indexer]\n                    }, copy=True, allow_dups=True)\n\n                return result\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        \"In the face of ambiguity, refuse the temptation to guess.\"\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        labels = self.obj._get_axis(axis)\n\n        # if we are a scalar indexer and not type correct raise\n        obj = self._convert_scalar_indexer(obj, axis)\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = com.is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except KeyError:\n            if isinstance(obj, tuple) and isinstance(labels, MultiIndex):\n                if is_setter and len(obj) == labels.nlevels:\n                    return {'key': obj}\n                raise\n        except TypeError:\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif _is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n        elif _is_list_like(obj):\n            if com._is_bool_indexer(obj):\n                obj = _check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                if isinstance(obj, Index):\n                    objarr = obj.values\n                else:\n                    objarr = _asarray_tuplesafe(obj)\n\n                # If have integer labels, defer to label-based indexing\n                indexer = labels._convert_list_indexer_for_mixed(objarr, typ=self.name)\n                if indexer is not None:\n                    return indexer\n\n                # this is not the most robust, but...\n                if (isinstance(labels, MultiIndex) and\n                        not isinstance(objarr[0], tuple)):\n                    level = 0\n                    _, indexer = labels.reindex(objarr, level=level)\n\n                    # take all\n                    if indexer is None:\n                        indexer = np.arange(len(labels))\n\n                    check = labels.levels[0].get_indexer(objarr)\n                else:\n                    level = None\n\n                    # unique index\n                    if labels.is_unique:\n                        indexer = check = labels.get_indexer(objarr)\n\n                    # non-unique (dups)\n                    else:\n                        (indexer,\n                         missing) = labels.get_indexer_non_unique(objarr)\n                        check = indexer\n\n                mask = check == -1\n                if mask.any():\n                    raise KeyError('%s not in index' % objarr[mask])\n\n                return _values_from_object(indexer)\n\n        else:\n            try:\n                return labels.get_loc(obj)\n            except KeyError:\n                # allow a not found key only if we are a setter\n                if not is_list_like(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n\n    \"\"\" A primarily location based indexer, with integer fallback \"\"\"\n\n    def _has_valid_type(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif com._is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _getitem_axis(self, key, axis=0):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n        key = _check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj.take(inds, axis=axis, convert=False)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        obj = self.obj\n        if not _need_slice(slice_obj):\n            return obj\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _LocIndexer(_LocationIndexer):\n\n    \"\"\" purely label based location based indexing \"\"\"\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    def _has_valid_type(self, key, axis):\n        ax = self.obj._get_axis(axis)\n\n        # valid for a label where all labels are in the index\n        # slice of lables (where start-end in labels)\n        # slice of integers (only if in the lables)\n        # boolean\n\n        if isinstance(key, slice):\n\n            if ax.is_floating():\n\n                # allowing keys to be slicers with no fallback\n                pass\n\n            else:\n                if key.start is not None:\n                    if key.start not in ax:\n                        raise KeyError(\n                            \"start bound [%s] is not the [%s]\" %\n                            (key.start, self.obj._get_axis_name(axis))\n                        )\n                if key.stop is not None:\n                    if key.stop not in ax:\n                        raise KeyError(\n                            \"stop bound [%s] is not in the [%s]\" %\n                            (key.stop, self.obj._get_axis_name(axis))\n                        )\n\n        elif com._is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n\n            # mi is just a passthru\n            if isinstance(key, tuple) and isinstance(ax, MultiIndex):\n                return True\n\n            # TODO: don't check the entire key unless necessary\n            if len(key) and np.all(ax.get_indexer_for(key) < 0):\n\n                raise KeyError(\"None of [%s] are in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            return True\n\n        else:\n\n            def error():\n                if isnull(key):\n                    raise ValueError(\n                        \"cannot use label indexing with a null key\")\n                raise KeyError(\"the label [%s] is not in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            try:\n                key = self._convert_scalar_indexer(key, axis)\n                if not key in ax:\n                    error()\n            except (TypeError) as e:\n\n                # python 3 type errors should be raised\n                if 'unorderable' in str(e):  # pragma: no cover\n                    error()\n                raise\n            except:\n                error()\n\n        return True\n\n    def _getitem_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif com._is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif _is_list_like(key):\n\n            # GH 7349\n            # possibly convert a list-like into a nested tuple\n            # but don't convert a list-like of tuples\n            if isinstance(labels, MultiIndex):\n                if not isinstance(key, tuple) and len(key) > 1 and not isinstance(key[0], tuple):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and\n                    isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if _is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [ slice(None) ] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._has_valid_type(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n\n    \"\"\" purely integer based location based indexing \"\"\"\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _has_valid_type(self, key, axis):\n        if com._is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\n                        \"iLocation based boolean indexing on an integer type \"\n                        \"is not available\"\n                    )\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return True\n\n        if isinstance(key, slice):\n            return True\n        elif com.is_integer(key):\n            return self._is_valid_integer(key, axis)\n        elif (_is_list_like(key)):\n            return self._is_valid_list_like(key, axis)\n        return False\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_valid_integer(self, key, axis):\n        # return a boolean if we have a valid integer indexer\n\n        ax = self.obj._get_axis(axis)\n        if key > len(ax):\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n        return True\n\n\n    def _is_valid_list_like(self, key, axis):\n        # return a boolean if we are a valid list-like (e.g. that we dont' have out-of-bounds values)\n\n        # coerce the key to not exceed the maximum size of the index\n        arr = np.array(key)\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if len(arr) and (arr.max() >= l or arr.min() <= -l):\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n        return True\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis=0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim<self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(slice_obj, axis=axis, convert=False)\n\n    def _getitem_axis(self, key, axis=0):\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n\n        elif com._is_bool_indexer(key):\n            self._has_valid_type(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a single integer or a list of integers\n        else:\n\n            if _is_list_like(key):\n\n                # validate list bounds\n                self._is_valid_list_like(key, axis)\n\n                # force an actual list\n                key = list(key)\n\n            else:\n                key = self._convert_scalar_indexer(key, axis)\n\n                if not com.is_integer(key):\n                    raise TypeError(\"Cannot index by location index with a \"\n                                    \"non-integer key\")\n\n                # validate the location\n                self._is_valid_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        elif self._has_valid_type(obj, axis):\n            return obj\n\n        raise ValueError(\"Can only index by location with a [%s]\" %\n                         self._valid_types)\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key, is_setter=False):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not _is_list_like(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj.get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key, is_setter=True))\n        key.append(value)\n        self.obj.set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" label based scalar accessor \"\"\"\n    _takeable = False\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n\n        # allow arbitrary setting\n        if is_setter:\n            return list(key)\n\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not com.is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index can only have integer \"\n                                     \"indexers\")\n            else:\n                if com.is_integer(i):\n                    raise ValueError(\"At based indexing on an non-integer index can only have non-integer \"\n                                     \"indexers\")\n        return key\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" integer based scalar accessor \"\"\"\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require  integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not com.is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n# 32-bit floating point machine epsilon\n_eps = np.finfo('f4').eps\n\n\ndef _length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = abs(step)\n        return (stop - start) / step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef _convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, typ='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if key in obj._data.items:\n            return None\n\n        # we need a timelike key here\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except:\n                return None\n\n    return None\n\n\ndef _is_index_slice(obj):\n    def _is_valid_index(x):\n        return (com.is_integer(x) or com.is_float(x)\n                and np.allclose(x, int(x), rtol=_eps, atol=0))\n\n    def _crit(v):\n        return v is None or _is_valid_index(v)\n\n    both_none = obj.start is None and obj.stop is None\n\n    return not both_none and (_crit(obj.start) and _crit(obj.stop))\n\n\ndef _check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that com._is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = com.isnull(result.values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series key provided')\n\n        result = result.astype(bool).values\n\n    else:\n        # com._is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef _convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n        return the scalar indexer and a boolean indicating if we converted \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef _convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key'])\n                if isinstance(_idx, dict) else _idx)\n    return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])\n\n\ndef _safe_append_to_index(index, key):\n    \"\"\" a safe append to an index, if incorrect type, then catch and recreate\n    \"\"\"\n    try:\n        return index.insert(len(index), key)\n    except:\n\n        # raise here as this is basically an unsafe operation and we want\n        # it to be obvious that you are doing something wrong\n        raise ValueError(\"unsafe appending to index of type {0} with a key \"\n                         \"{1}\".format(index.__class__.__name__, key))\n\n\ndef _maybe_convert_indices(indices, n):\n    \"\"\" if we have negative indicies, translate to postive here\n    if have indicies that are out-of-bounds, raise an IndexError\n    \"\"\"\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.int_)\n\n    mask = indices < 0\n    if mask.any():\n        indices[mask] += n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef _maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef _is_nested_tuple(tup, labels):\n    # check for a compatiable nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    # are we nested tuple of: tuple,list,slice\n    for i, k in enumerate(tup):\n\n        if isinstance(k, (tuple, list, slice)):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\n\ndef _is_null_slice(obj):\n    return (isinstance(obj, slice) and obj.start is None and\n            obj.stop is None and obj.step is None)\n\n\ndef _is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not _is_list_like(key)\n\n\ndef _is_list_like(obj):\n    # Consider namedtuples to be not list like as they are useful as indices\n    return (hasattr(obj, '__iter__')\n            and not isinstance(obj, compat.string_types)\n            and not (isinstance(obj, tuple) and type(obj) is not tuple))\n\n\ndef _need_slice(obj):\n    return (obj.start is not None or\n            obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef _maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n",
          "file_after": "# pylint: disable=W0223\n\nfrom datetime import datetime\nfrom pandas.core.index import Index, MultiIndex, _ensure_index\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nimport pandas.core.common as com\nfrom pandas.core.common import (is_bool_indexer, is_integer_dtype,\n                                _asarray_tuplesafe, is_list_like, isnull,\n                                ABCSeries, ABCDataFrame, ABCPanel, is_float,\n                                _values_from_object, _infer_fill_value, is_integer)\nimport pandas.lib as lib\n\nimport numpy as np\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix',   _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc',  _LocIndexer),\n        ('at',   _AtIndexer),\n        ('iat',  _iAtIndexer),\n    ]\n\n# \"null slice\"\n_NS = slice(None, None)\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    def __getitem__(self, arg):\n        return arg\nIndexSlice = _IndexSlice()\n\nclass IndexingError(Exception):\n    pass\n\nclass _NDFrameIndexer(object):\n    _valid_types = None\n    _exception = KeyError\n\n    def __init__(self, obj, name):\n        self.obj = obj\n        self.ndim = obj.ndim\n        self.name = name\n        self.axis = None\n\n    def __call__(self, *args, **kwargs):\n        # we need to return a copy of ourselves\n        self = self.__class__(self.obj, self.name)\n\n        # set the passed in values\n        for k, v in compat.iteritems(kwargs):\n            setattr(self,k,v)\n        return self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            try:\n                values = self.obj.get_value(*key)\n                if np.isscalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _get_label(self, label, axis=0):\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            try:\n                return self.obj._xs(label, axis=axis)\n            except:\n                return self.obj[label]\n        elif (isinstance(label, tuple) and\n                isinstance(label[axis], slice)):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=0):\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=0, typ=None):\n        return self.obj._slice(obj, axis=axis, typ=typ)\n\n    def _get_setitem_indexer(self, key):\n        if self.axis is not None:\n            return self._convert_tuple(key, is_setter=True)\n\n        axis = self.obj._get_axis(0)\n        if isinstance(axis, MultiIndex):\n            try:\n                return axis.get_loc(key)\n            except Exception:\n                pass\n\n        if isinstance(key, tuple) and not self.ndim < len(key):\n            return self._convert_tuple(key, is_setter=True)\n\n        try:\n            return self._convert_to_indexer(key, is_setter=True)\n        except TypeError:\n            raise IndexingError(key)\n\n    def __setitem__(self, key, value):\n        indexer = self._get_setitem_indexer(key)\n        self._setitem_with_indexer(indexer, value)\n\n    def _has_valid_type(self, k, axis):\n        raise NotImplementedError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            if not self._has_valid_type(k, i):\n                raise ValueError(\"Location based indexing can only have [%s] \"\n                                 \"types\" % self._valid_types)\n\n    def _should_validate_iterable(self, axis=0):\n        \"\"\" return a boolean whether this axes needs validation for a passed iterable \"\"\"\n        ax = self.obj._get_axis(axis)\n        if isinstance(ax, MultiIndex):\n            return False\n        elif ax.is_floating():\n            return False\n\n        return True\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any([ isinstance(ax, MultiIndex) for ax in self.obj.axes ]):\n            return any([ _is_nested_tuple(tup,ax) for ax in self.obj.axes ])\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, typ=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, typ=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n            will raise if needed, does not modify the indexer externally \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like(i):\n                    # should check the elements?\n                    pass\n                elif is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{0} cannot enlarge its target object\"\n                                         .format(self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{0} cannot enlarge its target object\"\n                                     .format(self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        from pandas import Panel, DataFrame, Series\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = _convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any([not l for l in len_non_info_axes]):\n                            if not is_list_like(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n\n                        # add a new item with the dtype setup\n                        self.obj[key] = _infer_fill_value(value)\n\n                        new_indexer = _convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = _safe_append_to_index(index, key)\n                    self.obj._data = self.obj.reindex_axis(labels, i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj.is_copy=None\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = _convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    if len(index) == 0:\n                        new_index = Index([indexer])\n                    else:\n                        new_index = _safe_append_to_index(index, indexer)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value]).values\n                    if len(self.obj.values):\n                        new_values = np.concatenate([self.obj.values,\n                                                     new_values])\n\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\n                            \"cannot set a frame with no defined columns\"\n                        )\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if com.is_list_like(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\n                                    \"cannot set a row with mismatched columns\"\n                                    )\n\n                        value = Series(value,index=self.obj.columns,name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        info_axis = self.obj._info_axis_number\n        item_labels = self.obj._get_axis(info_axis)\n\n        # if we have a complicated setup, take the split path\n        if (isinstance(indexer, tuple) and\n                any([isinstance(ax, MultiIndex) for ax in self.obj.axes])):\n            take_split_path = True\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].axes[0], MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = _length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like(value) and np.iterable(value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\n                            \"cannot set using a multi-index selection indexer \"\n                            \"with a different length than the value\"\n                        )\n\n                    # make sure we have an ndarray\n                    value = getattr(value,'values',value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = _length_of_indexer(plane_indexer[0],\n                                                        plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice which means essentially reassign to the columns\n                # of a multi-dim object\n                # GH6149\n                if isinstance(pi, tuple) and all(_is_null_slice(idx) for idx in pi):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if not len(labels) == 1 or not np.iterable(value):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an interable, with a ndim of at least 1\n            # eg. don't pass thru np.array(0)\n            if _is_list_like(value) and getattr(value,'ndim',1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n\n                    for item in labels:\n                        # align to\n                        v = np.nan if item not in value else \\\n                                self._align_series(indexer[0], value[item])\n                        setter(item, v)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value,dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = _maybe_convert_ix(*indexer)\n\n                # if we are setting on the info axis ONLY\n                # set using those methods to avoid block-splitting\n                # logic here\n                if len(indexer) > info_axis and is_integer(indexer[info_axis]) and all(\n                    _is_null_slice(idx) for i, idx in enumerate(indexer) if i != info_axis):\n                    self.obj[item_labels[indexer[info_axis]]] = value\n                    return\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser):\n        # indexer to assign Series can be tuple, slice, scalar\n        if isinstance(indexer, (slice, np.ndarray, list)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            # flatten np.ndarray indexers\n            ravel = lambda i: i.ravel() if isinstance(i, np.ndarray) else i\n            indexer = tuple(map(ravel, indexer))\n\n            aligners = [not _is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all([com.is_sequence(_) for _ in indexer])):\n                ser = ser.reindex(obj.axes[0][indexer[0]], copy=True).values\n\n                # single indexer\n                if len(indexer) > 1:\n                    l = len(indexer[1])\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if com.is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and _is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix)\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser.values.copy()\n\n                    return ser.reindex(new_ix).values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser.values.copy()\n                    return ser.reindex(ax).values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser.values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif np.isscalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser.values.copy()\n\n            return ser.reindex(ax).values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n\n        if isinstance(indexer, tuple):\n\n            aligners = [not _is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if com.is_sequence(ix) or isinstance(ix, slice):\n                    if idx is None:\n                        idx = ax[ix].ravel()\n                    elif cols is None:\n                        cols = ax[ix].ravel()\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n\n                # need to conform to the convention\n                # as we are not selecting on the items axis\n                # and we have a single indexer\n                # GH 7763\n                if len(sindexers) == 1 and sindexers[0] != 0:\n                    df = df.T\n\n                if idx is None:\n                    idx = df.index\n                if cols is None:\n                    cols = df.columns\n\n            if idx is not None and cols is not None:\n\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy().values\n                else:\n                    val = df.reindex(idx, columns=cols).values\n                return val\n\n        elif ((isinstance(indexer, slice) or com.is_list_like(indexer))\n              and is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy().values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if isinstance(ax, MultiIndex) and isinstance(\n                    df.index, MultiIndex) and ax.nlevels != df.index.nlevels:\n                    raise TypeError(\"cannot align on a multi-index with out specifying the join levels\")\n\n                val = df.reindex(index=ax).values\n            return val\n\n        elif np.isscalar(indexer) and is_panel:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy().values\n\n            return df.reindex(idx, columns=cols).values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        from pandas.core.generic import NDFrame\n\n        # ugly hack for GH #836\n        if not isinstance(self.obj, NDFrame):\n            return False\n\n        if not all(_is_list_like(x) for x in tup):\n            return False\n\n        # just too complicated\n        for indexer, ax in zip(tup, self.obj._data.axes):\n            if isinstance(ax, MultiIndex):\n                return False\n            elif is_bool_indexer(indexer):\n                return False\n            elif not ax.is_unique:\n                return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\" create the reindex map for our objects, raise the _exception if we\n        can't create the indexer\n        \"\"\"\n        try:\n            o = self.obj\n            d = dict([\n                (a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n                for t, a in zip(tup, o._AXIS_ORDERS)\n            ])\n            return o.reindex(**d)\n        except:\n            raise self._exception\n\n    def _convert_for_reindex(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            return labels[key]\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if is_integer_dtype(keyarr) and not labels.is_integer():\n                keyarr = com._ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n            return keyarr\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=0)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        if isinstance(ax0, MultiIndex):\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if _is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not _is_list_like(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0\n                            and len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of selectors\n            return self._getitem_axis(tup, axis=0)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if np.isscalar(obj) or not hasattr(obj,'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=0):\n\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif _is_list_like(key) and not (isinstance(key, tuple) and\n                                         isinstance(labels, MultiIndex)):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n            if is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _getitem_iterable(self, key, axis=0):\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        def _reindex(keys, level=None):\n\n            try:\n                result = self.obj.reindex_axis(keys, axis=axis, level=level)\n            except AttributeError:\n                # Series\n                if axis != 0:\n                    raise AssertionError('axis must be 0')\n                return self.obj.reindex(keys, level=level)\n\n            # this is an error as we are trying to find\n            # keys in a multi-index that don't exist\n            if isinstance(labels, MultiIndex) and level is not None:\n                if hasattr(result,'ndim') and not np.prod(result.shape) and len(keys):\n                    raise KeyError(\"cannot index a multi-index axis with these keys\")\n\n            return result\n\n        if is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj.take(inds, axis=axis, convert=False)\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            # handle a mixed integer scenario\n            indexer = labels._convert_list_indexer_for_mixed(keyarr, typ=self.name)\n            if indexer is not None:\n                return self.obj.take(indexer, axis=axis)\n\n            # this is not the most robust, but...\n            if (isinstance(labels, MultiIndex) and len(keyarr) and\n                    not isinstance(keyarr[0], tuple)):\n                level = 0\n            else:\n                level = None\n\n            keyarr_is_unique = Index(keyarr).is_unique\n\n            # existing labels are unique and indexer is unique\n            if labels.is_unique and keyarr_is_unique:\n                return _reindex(keyarr, level=level)\n\n            else:\n                indexer, missing = labels.get_indexer_non_unique(keyarr)\n                check = indexer != -1\n                result = self.obj.take(indexer[check], axis=axis,\n                                       convert=False)\n\n                # need to merge the result labels and the missing labels\n                if len(missing):\n                    l = np.arange(len(indexer))\n\n                    missing = com._ensure_platform_int(missing)\n                    missing_labels = keyarr.take(missing)\n                    missing_indexer = com._ensure_int64(l[~check])\n                    cur_labels = result._get_axis(axis).values\n                    cur_indexer = com._ensure_int64(l[check])\n\n                    new_labels = np.empty(tuple([len(indexer)]), dtype=object)\n                    new_labels[cur_indexer] = cur_labels\n                    new_labels[missing_indexer] = missing_labels\n\n                    # reindex with the specified axis\n                    ndim = self.obj.ndim\n                    if axis + 1 > ndim:\n                        raise AssertionError(\"invalid indexing error with \"\n                                             \"non-unique index\")\n\n                    # a unique indexer\n                    if keyarr_is_unique:\n\n                        # see GH5553, make sure we use the right indexer\n                        new_indexer = np.arange(len(indexer))\n                        new_indexer[cur_indexer] = np.arange(\n                            len(result._get_axis(axis))\n                        )\n                        new_indexer[missing_indexer] = -1\n\n                    # we have a non_unique selector, need to use the original\n                    # indexer here\n                    else:\n\n                        # need to retake to have the same size as the indexer\n                        rindexer = indexer.values\n                        rindexer[~check] = 0\n                        result = self.obj.take(rindexer, axis=axis,\n                                               convert=False)\n\n                        # reset the new indexer to account for the new size\n                        new_indexer = np.arange(len(result))\n                        new_indexer[~check] = -1\n\n                    result = result._reindex_with_indexers({\n                        axis: [new_labels, new_indexer]\n                    }, copy=True, allow_dups=True)\n\n                return result\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        \"In the face of ambiguity, refuse the temptation to guess.\"\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        labels = self.obj._get_axis(axis)\n\n        # if we are a scalar indexer and not type correct raise\n        obj = self._convert_scalar_indexer(obj, axis)\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except KeyError:\n            if isinstance(obj, tuple) and isinstance(labels, MultiIndex):\n                if is_setter and len(obj) == labels.nlevels:\n                    return {'key': obj}\n                raise\n        except TypeError:\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif _is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n        elif _is_list_like(obj):\n            if is_bool_indexer(obj):\n                obj = _check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                if isinstance(obj, Index):\n                    objarr = obj.values\n                else:\n                    objarr = _asarray_tuplesafe(obj)\n\n                # If have integer labels, defer to label-based indexing\n                indexer = labels._convert_list_indexer_for_mixed(objarr, typ=self.name)\n                if indexer is not None:\n                    return indexer\n\n                # this is not the most robust, but...\n                if (isinstance(labels, MultiIndex) and\n                        not isinstance(objarr[0], tuple)):\n                    level = 0\n                    _, indexer = labels.reindex(objarr, level=level)\n\n                    # take all\n                    if indexer is None:\n                        indexer = np.arange(len(labels))\n\n                    check = labels.levels[0].get_indexer(objarr)\n                else:\n                    level = None\n\n                    # unique index\n                    if labels.is_unique:\n                        indexer = check = labels.get_indexer(objarr)\n\n                    # non-unique (dups)\n                    else:\n                        (indexer,\n                         missing) = labels.get_indexer_non_unique(objarr)\n                        check = indexer\n\n                mask = check == -1\n                if mask.any():\n                    raise KeyError('%s not in index' % objarr[mask])\n\n                return _values_from_object(indexer)\n\n        else:\n            try:\n                return labels.get_loc(obj)\n            except KeyError:\n                # allow a not found key only if we are a setter\n                if not is_list_like(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n\n    \"\"\" A primarily location based indexer, with integer fallback \"\"\"\n\n    def _has_valid_type(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _getitem_axis(self, key, axis=0):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n        key = _check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj.take(inds, axis=axis, convert=False)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        obj = self.obj\n        if not _need_slice(slice_obj):\n            return obj\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _LocIndexer(_LocationIndexer):\n\n    \"\"\" purely label based location based indexing \"\"\"\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    def _has_valid_type(self, key, axis):\n        ax = self.obj._get_axis(axis)\n\n        # valid for a label where all labels are in the index\n        # slice of lables (where start-end in labels)\n        # slice of integers (only if in the lables)\n        # boolean\n\n        if isinstance(key, slice):\n\n            if ax.is_floating():\n\n                # allowing keys to be slicers with no fallback\n                pass\n\n            else:\n                if key.start is not None:\n                    if key.start not in ax:\n                        raise KeyError(\n                            \"start bound [%s] is not the [%s]\" %\n                            (key.start, self.obj._get_axis_name(axis))\n                        )\n                if key.stop is not None:\n                    if key.stop not in ax:\n                        raise KeyError(\n                            \"stop bound [%s] is not in the [%s]\" %\n                            (key.stop, self.obj._get_axis_name(axis))\n                        )\n\n        elif is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n\n            # mi is just a passthru\n            if isinstance(key, tuple) and isinstance(ax, MultiIndex):\n                return True\n\n            # TODO: don't check the entire key unless necessary\n            if len(key) and np.all(ax.get_indexer_for(key) < 0):\n\n                raise KeyError(\"None of [%s] are in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            return True\n\n        else:\n\n            def error():\n                if isnull(key):\n                    raise ValueError(\n                        \"cannot use label indexing with a null key\")\n                raise KeyError(\"the label [%s] is not in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            try:\n                key = self._convert_scalar_indexer(key, axis)\n                if not key in ax:\n                    error()\n            except (TypeError) as e:\n\n                # python 3 type errors should be raised\n                if 'unorderable' in str(e):  # pragma: no cover\n                    error()\n                raise\n            except:\n                error()\n\n        return True\n\n    def _getitem_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif _is_list_like(key):\n\n            # GH 7349\n            # possibly convert a list-like into a nested tuple\n            # but don't convert a list-like of tuples\n            if isinstance(labels, MultiIndex):\n                if not isinstance(key, tuple) and len(key) > 1 and not isinstance(key[0], tuple):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and\n                    isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if _is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [ slice(None) ] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._has_valid_type(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n\n    \"\"\" purely integer based location based indexing \"\"\"\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _has_valid_type(self, key, axis):\n        if is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\n                        \"iLocation based boolean indexing on an integer type \"\n                        \"is not available\"\n                    )\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return True\n\n        if isinstance(key, slice):\n            return True\n        elif is_integer(key):\n            return self._is_valid_integer(key, axis)\n        elif _is_list_like(key):\n            return self._is_valid_list_like(key, axis)\n        return False\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_valid_integer(self, key, axis):\n        # return a boolean if we have a valid integer indexer\n\n        ax = self.obj._get_axis(axis)\n        if key > len(ax):\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n        return True\n\n\n    def _is_valid_list_like(self, key, axis):\n        # return a boolean if we are a valid list-like (e.g. that we dont' have out-of-bounds values)\n\n        # coerce the key to not exceed the maximum size of the index\n        arr = np.array(key)\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if len(arr) and (arr.max() >= l or arr.min() <= -l):\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n        return True\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis=0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim<self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(slice_obj, axis=axis, convert=False)\n\n    def _getitem_axis(self, key, axis=0):\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n\n        elif is_bool_indexer(key):\n            self._has_valid_type(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a single integer or a list of integers\n        else:\n\n            if _is_list_like(key):\n\n                # validate list bounds\n                self._is_valid_list_like(key, axis)\n\n                # force an actual list\n                key = list(key)\n\n            else:\n                key = self._convert_scalar_indexer(key, axis)\n\n                if not is_integer(key):\n                    raise TypeError(\"Cannot index by location index with a \"\n                                    \"non-integer key\")\n\n                # validate the location\n                self._is_valid_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        elif self._has_valid_type(obj, axis):\n            return obj\n\n        raise ValueError(\"Can only index by location with a [%s]\" %\n                         self._valid_types)\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key, is_setter=False):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not _is_list_like(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj.get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key, is_setter=True))\n        key.append(value)\n        self.obj.set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" label based scalar accessor \"\"\"\n    _takeable = False\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n\n        # allow arbitrary setting\n        if is_setter:\n            return list(key)\n\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index can only have integer \"\n                                     \"indexers\")\n            else:\n                if is_integer(i):\n                    raise ValueError(\"At based indexing on an non-integer index can only have non-integer \"\n                                     \"indexers\")\n        return key\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" integer based scalar accessor \"\"\"\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require  integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n# 32-bit floating point machine epsilon\n_eps = np.finfo('f4').eps\n\n\ndef _length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = abs(step)\n        return (stop - start) / step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef _convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, typ='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if key in obj._data.items:\n            return None\n\n        # we need a timelike key here\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except:\n                return None\n\n    return None\n\n\ndef _is_index_slice(obj):\n    def _is_valid_index(x):\n        return (is_integer(x) or is_float(x)\n                and np.allclose(x, int(x), rtol=_eps, atol=0))\n\n    def _crit(v):\n        return v is None or _is_valid_index(v)\n\n    both_none = obj.start is None and obj.stop is None\n\n    return not both_none and (_crit(obj.start) and _crit(obj.stop))\n\n\ndef _check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = com.isnull(result.values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series key provided')\n\n        result = result.astype(bool).values\n\n    else:\n        # is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef _convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n        return the scalar indexer and a boolean indicating if we converted \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef _convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key'])\n                if isinstance(_idx, dict) else _idx)\n    return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])\n\n\ndef _safe_append_to_index(index, key):\n    \"\"\" a safe append to an index, if incorrect type, then catch and recreate\n    \"\"\"\n    try:\n        return index.insert(len(index), key)\n    except:\n\n        # raise here as this is basically an unsafe operation and we want\n        # it to be obvious that you are doing something wrong\n        raise ValueError(\"unsafe appending to index of type {0} with a key \"\n                         \"{1}\".format(index.__class__.__name__, key))\n\n\ndef _maybe_convert_indices(indices, n):\n    \"\"\" if we have negative indicies, translate to postive here\n    if have indicies that are out-of-bounds, raise an IndexError\n    \"\"\"\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.int_)\n\n    mask = indices < 0\n    if mask.any():\n        indices[mask] += n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef _maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef _is_nested_tuple(tup, labels):\n    # check for a compatiable nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    # are we nested tuple of: tuple,list,slice\n    for i, k in enumerate(tup):\n\n        if isinstance(k, (tuple, list, slice)):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\n\ndef _is_null_slice(obj):\n    return (isinstance(obj, slice) and obj.start is None and\n            obj.stop is None and obj.step is None)\n\n\ndef _is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not _is_list_like(key)\n\n\ndef _is_list_like(obj):\n    # Consider namedtuples to be not list like as they are useful as indices\n    return (hasattr(obj, '__iter__')\n            and not isinstance(obj, compat.string_types)\n            and not (isinstance(obj, tuple) and type(obj) is not tuple))\n\n\ndef _need_slice(obj):\n    return (obj.start is not None or\n            obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef _maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n",
          "file_patch": "@@ -5,10 +5,10 @@ from pandas.core.index import Index, MultiIndex, _ensure_index\n from pandas.compat import range, zip\n import pandas.compat as compat\n import pandas.core.common as com\n-from pandas.core.common import (_is_bool_indexer, is_integer_dtype,\n+from pandas.core.common import (is_bool_indexer, is_integer_dtype,\n                                 _asarray_tuplesafe, is_list_like, isnull,\n                                 ABCSeries, ABCDataFrame, ABCPanel, is_float,\n-                                _values_from_object, _infer_fill_value)\n+                                _values_from_object, _infer_fill_value, is_integer)\n import pandas.lib as lib\n \n import numpy as np\n@@ -188,7 +188,7 @@ class _NDFrameIndexer(object):\n                 elif is_list_like(i):\n                     # should check the elements?\n                     pass\n-                elif com.is_integer(i):\n+                elif is_integer(i):\n                     if i >= len(ax):\n                         raise IndexError(\"{0} cannot enlarge its target object\"\n                                          .format(self.name))\n@@ -342,7 +342,7 @@ class _NDFrameIndexer(object):\n                 value = self._align_series(indexer, value)\n \n             info_idx = indexer[info_axis]\n-            if com.is_integer(info_idx):\n+            if is_integer(info_idx):\n                 info_idx = [info_idx]\n             labels = item_labels[info_idx]\n \n@@ -479,7 +479,7 @@ class _NDFrameIndexer(object):\n                 # if we are setting on the info axis ONLY\n                 # set using those methods to avoid block-splitting\n                 # logic here\n-                if len(indexer) > info_axis and com.is_integer(indexer[info_axis]) and all(\n+                if len(indexer) > info_axis and is_integer(indexer[info_axis]) and all(\n                     _is_null_slice(idx) for i, idx in enumerate(indexer) if i != info_axis):\n                     self.obj[item_labels[indexer[info_axis]]] = value\n                     return\n@@ -728,7 +728,7 @@ class _NDFrameIndexer(object):\n         for indexer, ax in zip(tup, self.obj._data.axes):\n             if isinstance(ax, MultiIndex):\n                 return False\n-            elif com._is_bool_indexer(indexer):\n+            elif is_bool_indexer(indexer):\n                 return False\n             elif not ax.is_unique:\n                 return False\n@@ -752,7 +752,7 @@ class _NDFrameIndexer(object):\n     def _convert_for_reindex(self, key, axis=0):\n         labels = self.obj._get_axis(axis)\n \n-        if com._is_bool_indexer(key):\n+        if is_bool_indexer(key):\n             key = _check_bool_indexer(labels, key)\n             return labels[key]\n         else:\n@@ -907,7 +907,7 @@ class _NDFrameIndexer(object):\n \n             return self._getitem_iterable(key, axis=axis)\n         else:\n-            if com.is_integer(key):\n+            if is_integer(key):\n                 if axis == 0 and isinstance(labels, MultiIndex):\n                     try:\n                         return self._get_label(key, axis=axis)\n@@ -945,7 +945,7 @@ class _NDFrameIndexer(object):\n \n             return result\n \n-        if com._is_bool_indexer(key):\n+        if is_bool_indexer(key):\n             key = _check_bool_indexer(labels, key)\n             inds, = key.nonzero()\n             return self.obj.take(inds, axis=axis, convert=False)\n@@ -1053,7 +1053,7 @@ class _NDFrameIndexer(object):\n \n         # see if we are positional in nature\n         is_int_index = labels.is_integer()\n-        is_int_positional = com.is_integer(obj) and not is_int_index\n+        is_int_positional = is_integer(obj) and not is_int_index\n \n         # if we are a label return me\n         try:\n@@ -1094,7 +1094,7 @@ class _NDFrameIndexer(object):\n         elif _is_nested_tuple(obj, labels):\n             return labels.get_locs(obj)\n         elif _is_list_like(obj):\n-            if com._is_bool_indexer(obj):\n+            if is_bool_indexer(obj):\n                 obj = _check_bool_indexer(labels, obj)\n                 inds, = obj.nonzero()\n                 return inds\n@@ -1174,7 +1174,7 @@ class _IXIndexer(_NDFrameIndexer):\n         if isinstance(key, slice):\n             return True\n \n-        elif com._is_bool_indexer(key):\n+        elif is_bool_indexer(key):\n             return True\n \n         elif _is_list_like(key):\n@@ -1261,7 +1261,7 @@ class _LocIndexer(_LocationIndexer):\n                             (key.stop, self.obj._get_axis_name(axis))\n                         )\n \n-        elif com._is_bool_indexer(key):\n+        elif is_bool_indexer(key):\n             return True\n \n         elif _is_list_like(key):\n@@ -1308,7 +1308,7 @@ class _LocIndexer(_LocationIndexer):\n         if isinstance(key, slice):\n             self._has_valid_type(key, axis)\n             return self._get_slice_axis(key, axis=axis)\n-        elif com._is_bool_indexer(key):\n+        elif is_bool_indexer(key):\n             return self._getbool_axis(key, axis=axis)\n         elif _is_list_like(key):\n \n@@ -1348,7 +1348,7 @@ class _iLocIndexer(_LocationIndexer):\n     _exception = IndexError\n \n     def _has_valid_type(self, key, axis):\n-        if com._is_bool_indexer(key):\n+        if is_bool_indexer(key):\n             if hasattr(key, 'index') and isinstance(key.index, Index):\n                 if key.index.inferred_type == 'integer':\n                     raise NotImplementedError(\n@@ -1361,9 +1361,9 @@ class _iLocIndexer(_LocationIndexer):\n \n         if isinstance(key, slice):\n             return True\n-        elif com.is_integer(key):\n+        elif is_integer(key):\n             return self._is_valid_integer(key, axis)\n-        elif (_is_list_like(key)):\n+        elif _is_list_like(key):\n             return self._is_valid_list_like(key, axis)\n         return False\n \n@@ -1438,7 +1438,7 @@ class _iLocIndexer(_LocationIndexer):\n             self._has_valid_type(key, axis)\n             return self._get_slice_axis(key, axis=axis)\n \n-        elif com._is_bool_indexer(key):\n+        elif is_bool_indexer(key):\n             self._has_valid_type(key, axis)\n             return self._getbool_axis(key, axis=axis)\n \n@@ -1456,7 +1456,7 @@ class _iLocIndexer(_LocationIndexer):\n             else:\n                 key = self._convert_scalar_indexer(key, axis)\n \n-                if not com.is_integer(key):\n+                if not is_integer(key):\n                     raise TypeError(\"Cannot index by location index with a \"\n                                     \"non-integer key\")\n \n@@ -1526,11 +1526,11 @@ class _AtIndexer(_ScalarAccessIndexer):\n \n         for ax, i in zip(self.obj.axes, key):\n             if ax.is_integer():\n-                if not com.is_integer(i):\n+                if not is_integer(i):\n                     raise ValueError(\"At based indexing on an integer index can only have integer \"\n                                      \"indexers\")\n             else:\n-                if com.is_integer(i):\n+                if is_integer(i):\n                     raise ValueError(\"At based indexing on an non-integer index can only have non-integer \"\n                                      \"indexers\")\n         return key\n@@ -1546,7 +1546,7 @@ class _iAtIndexer(_ScalarAccessIndexer):\n     def _convert_key(self, key, is_setter=False):\n         \"\"\" require  integer args (and convert to label arguments) \"\"\"\n         for a, i in zip(self.obj.axes, key):\n-            if not com.is_integer(i):\n+            if not is_integer(i):\n                 raise ValueError(\"iAt based indexing can only have integer \"\n                                  \"indexers\")\n         return key\n@@ -1608,7 +1608,7 @@ def _convert_to_index_sliceable(obj, key):\n \n def _is_index_slice(obj):\n     def _is_valid_index(x):\n-        return (com.is_integer(x) or com.is_float(x)\n+        return (is_integer(x) or is_float(x)\n                 and np.allclose(x, int(x), rtol=_eps, atol=0))\n \n     def _crit(v):\n@@ -1623,7 +1623,7 @@ def _check_bool_indexer(ax, key):\n     # boolean indexing, need to check that the data are aligned, otherwise\n     # disallowed\n \n-    # this function assumes that com._is_bool_indexer(key) == True\n+    # this function assumes that is_bool_indexer(key) == True\n \n     result = key\n     if isinstance(key, ABCSeries) and not key.index.equals(ax):\n@@ -1635,7 +1635,7 @@ def _check_bool_indexer(ax, key):\n         result = result.astype(bool).values\n \n     else:\n-        # com._is_bool_indexer has already checked for nulls in the case of an\n+        # is_bool_indexer has already checked for nulls in the case of an\n         # object array key, so no check needed here\n         result = np.asarray(result, dtype=bool)\n \n",
          "files_name_in_blame_commit": [
            "common.py",
            "groupby.py",
            "series.py",
            "period.py",
            "categorical.py",
            "nanops.py",
            "merge.py",
            "internals.py",
            "index.py",
            "tdi.py",
            "indexing.py",
            "frame.py"
          ]
        }
      },
      "8c51d868ed19dcd8ed346cd4f61e7494eb18aa05": {
        "commit": {
          "commit_id": "8c51d868ed19dcd8ed346cd4f61e7494eb18aa05",
          "commit_message": "BUG: .at indexing should allow enlargement scalars w/o regards to the type of index (GH8473)",
          "commit_author": "jreback",
          "commit_date": "2014-10-05 16:47:20",
          "commit_parent": "4e439d97709ab3b0b78d7c93d4962317a31f605e"
        },
        "function": {
          "function_name": "_convert_key",
          "function_code_before": "def _convert_key(self, key):\n    \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n    for (ax, i) in zip(self.obj.axes, key):\n        if ax.is_integer():\n            if not com.is_integer(i):\n                raise ValueError('At based indexing on an integer index can only have integer indexers')\n        elif com.is_integer(i):\n            raise ValueError('At based indexing on an non-integer index can only have non-integer indexers')\n    return key",
          "function_code_after": "def _convert_key(self, key, is_setter=False):\n    \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n    if is_setter:\n        return list(key)\n    for (ax, i) in zip(self.obj.axes, key):\n        if ax.is_integer():\n            if not com.is_integer(i):\n                raise ValueError('At based indexing on an integer index can only have integer indexers')\n        elif com.is_integer(i):\n            raise ValueError('At based indexing on an non-integer index can only have non-integer indexers')\n    return key",
          "function_before_start_line": 1518,
          "function_before_end_line": 1529,
          "function_after_start_line": 1518,
          "function_after_end_line": 1534,
          "function_before_token_count": 64,
          "function_after_token_count": 0,
          "functions_name_modified_file": [
            "_convert_for_reindex",
            "_setitem_with_indexer",
            "_getitem_nested_tuple",
            "_maybe_convert_ix",
            "_is_list_like",
            "_align_panel",
            "_convert_to_indexer",
            "_getbool_axis",
            "_is_valid_list_like",
            "_get_slice_axis",
            "_has_valid_tuple",
            "_length_of_indexer",
            "_is_null_slice",
            "_is_nested_tuple",
            "_safe_append_to_index",
            "_need_slice",
            "_align_series",
            "_has_valid_setitem_indexer",
            "_should_validate_iterable",
            "_has_valid_type",
            "_multi_take_opportunity",
            "__iter__",
            "_is_valid_integer",
            "_convert_slice_indexer",
            "_convert_to_index_sliceable",
            "_convert_scalar_indexer",
            "_check_bool_indexer",
            "_getitem_iterable",
            "_handle_lowerdim_multi_index_axis0",
            "_convert_tuple",
            "_is_nested_tuple_indexer",
            "_maybe_droplevels",
            "_get_loc",
            "_has_valid_positional_setitem_indexer",
            "_is_label_like",
            "__getitem__",
            "_getitem_tuple",
            "__init__",
            "_getitem_axis",
            "__call__",
            "_maybe_convert_indices",
            "_tuplify",
            "_getitem_lowerdim",
            "_multi_take",
            "_slice",
            "_convert_missing_indexer",
            "get_indexers_list",
            "_convert_from_missing_indexer_tuple",
            "__setitem__",
            "_convert_key",
            "_get_label",
            "_align_frame",
            "_is_index_slice"
          ],
          "functions_name_all_files": [
            "test_none_coercion_mixed_dtypes",
            "test_iloc_getitem_list_int",
            "_align_panel",
            "test_indexing_mixed_frame_bug",
            "_getbool_axis",
            "_is_valid_list_like",
            "_get_slice_axis",
            "test_setitem_chained_setfault",
            "test_detect_chained_assignment_warnings",
            "_has_valid_tuple",
            "_length_of_indexer",
            "_is_null_slice",
            "test_iloc_getitem_doc_issue",
            "_get_value",
            "test_iloc_getitem_int",
            "_safe_append_to_index",
            "test_iloc_getitem_slice_dups",
            "_align_series",
            "_is_valid_integer",
            "_convert_slice_indexer",
            "_convert_to_index_sliceable",
            "test_iloc_setitem_list_of_lists",
            "test_dups_fancy_indexing",
            "_getitem_iterable",
            "_handle_lowerdim_multi_index_axis0",
            "_convert_tuple",
            "_maybe_droplevels",
            "test_multiindex_slicers_edges",
            "_has_valid_positional_setitem_indexer",
            "test_series_getitem_multiindex",
            "test_mi_access",
            "test_setitem_dtype_upcast",
            "__getitem__",
            "test_coercion_with_loc_setitem",
            "_getitem_tuple",
            "__init__",
            "setUp",
            "test_ix_slicing_strings",
            "test_float_index_non_scalar_assignment",
            "_multi_take",
            "test_setitem_list",
            "test_deprecate_float_indexers",
            "test_xs_multiindex",
            "get_indexers_list",
            "test_dups_loc",
            "_convert_key",
            "test_imethods_with_dups",
            "test_ix_weird_slicing",
            "_get_label",
            "test_loc_setitem_frame_multiples",
            "test_panel_assignment",
            "_is_index_slice",
            "test_loc_getitem_label_list",
            "test_partial_setting",
            "_convert_for_reindex",
            "_setitem_with_indexer",
            "_getitem_nested_tuple",
            "test_non_unique_loc",
            "check_result",
            "test_setitem_iloc",
            "test_at_and_iat_set",
            "test_loc_name",
            "test_non_unique_loc_memory_error",
            "test_iloc_exceeds_bounds",
            "test_loc_multiindex",
            "test_loc_setitem_consistency",
            "_axify",
            "test_iloc_getitem_array",
            "test_multi_assign",
            "test_series_partial_set",
            "test_coercion_with_setitem_and_dataframe",
            "_should_validate_iterable",
            "_has_valid_type",
            "test_loc_general",
            "test_set_index_nan",
            "_check_bool_indexer",
            "test_loc_getitem_label_out_of_range",
            "test_at_and_iat_get",
            "test_iloc_setitem",
            "test_loc_setitem_dups",
            "test_iat_invalid_args",
            "test_iloc_getitem_panel",
            "_get_loc",
            "test_loc_empty_list_indexer_is_ok",
            "test_rhs_alignment",
            "test_iloc_getitem_neg_int",
            "_is_label_like",
            "test_float_index_to_mixed",
            "test_detect_chained_assignment",
            "_maybe_convert_indices",
            "test_loc_getitem_int",
            "_getitem_lowerdim",
            "test_coercion_with_loc_and_series",
            "_convert_missing_indexer",
            "test_iloc_setitem_series",
            "_convert_from_missing_indexer_tuple",
            "test_cache_updating",
            "test_loc_getitem_bool",
            "test_iloc_non_unique_indexing",
            "_maybe_convert_ix",
            "test_floating_index",
            "test_set_ix_out_of_bounds_axis_0",
            "test_iloc_getitem_bool",
            "_is_nested_tuple",
            "test_loc_getitem_int_slice",
            "_need_slice",
            "_has_valid_setitem_indexer",
            "test_slice_consolidate_invalidate_item_cache",
            "test_chained_getitem_with_lists",
            "_multi_take_opportunity",
            "test_iloc_getitem_slice",
            "test_loc_to_fail",
            "test_loc_setitem",
            "test_slice_indexer",
            "test_partial_setting_mixed_dtype",
            "test_loc_setitem_multiindex",
            "test_per_axis_per_level_getitem",
            "test_ix_get_set_consistency",
            "_is_nested_tuple_indexer",
            "test_float64index_slicing_bug",
            "test_partial_set_invalid",
            "test_coercion_with_setitem_and_series",
            "__call__",
            "test_ix_empty_list_indexer_is_ok",
            "_tuplify",
            "test_loc_arguments",
            "_slice",
            "test_iloc_getitem_multiindex",
            "__setitem__",
            "test_per_axis_per_level_doc_examples",
            "test_loc_getitem_label",
            "test_loc_setitem_frame",
            "test_panel_setitem",
            "test_setitem_cache_updating",
            "test_getitem_multiindex",
            "test_multiindex_slicers_non_unique",
            "_is_list_like",
            "test_partial_set_empty",
            "test_set_ix_out_of_bounds_axis_1",
            "_convert_to_indexer",
            "test_none_coercion_loc_and_dataframe",
            "test_repeated_getitem_dups",
            "test_iloc_setitem_dups",
            "test_ix_general",
            "test_multiindex_setitem",
            "check_values",
            "test_per_axis_per_level_setitem",
            "_mklbl",
            "test_coercion_with_loc",
            "test_iloc_mask",
            "__iter__",
            "test_iloc_empty_list_indexer_is_ok",
            "test_scalar_indexer",
            "_convert_scalar_indexer",
            "test_ix_assign_column_mixed",
            "test_astype_assignment",
            "test_floating_index_doc_example",
            "test_setitem_ndarray_1d",
            "test_loc_getitem_label_slice",
            "test_coercion_with_setitem",
            "test_astype_assignment_with_dups",
            "test_at_iat_coercion",
            "test_duplicate_ix_returns_series",
            "_getitem_axis",
            "test_multi_nan_indexing",
            "test_multiindex_assignment",
            "_get_result",
            "test_iloc_panel_issue",
            "test_iloc_getitem_frame",
            "test_panel_getitem",
            "test_float_index_at_iat",
            "test_indexer_caching",
            "test_iloc_getitem_dups",
            "_generate_indices",
            "_align_frame",
            "test_multiindex_slicers_datetimelike"
          ],
          "functions_name_co_evolved_modified_file": [
            "__setitem__"
          ],
          "functions_name_co_evolved_all_files": [
            "test_partial_setting",
            "__setitem__"
          ]
        },
        "file": {
          "file_name": "indexing.py",
          "file_nloc": 1115,
          "file_complexity": 463,
          "file_token_count": 8323,
          "file_before": "# pylint: disable=W0223\n\nfrom datetime import datetime\nfrom pandas.core.index import Index, MultiIndex, _ensure_index\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nimport pandas.core.common as com\nfrom pandas.core.common import (_is_bool_indexer, is_integer_dtype,\n                                _asarray_tuplesafe, is_list_like, isnull,\n                                ABCSeries, ABCDataFrame, ABCPanel, is_float,\n                                _values_from_object)\nimport pandas.lib as lib\n\nimport numpy as np\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix',   _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc',  _LocIndexer),\n        ('at',   _AtIndexer),\n        ('iat',  _iAtIndexer),\n    ]\n\n# \"null slice\"\n_NS = slice(None, None)\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    def __getitem__(self, arg):\n        return arg\nIndexSlice = _IndexSlice()\n\nclass IndexingError(Exception):\n    pass\n\nclass _NDFrameIndexer(object):\n    _valid_types = None\n    _exception = KeyError\n\n    def __init__(self, obj, name):\n        self.obj = obj\n        self.ndim = obj.ndim\n        self.name = name\n        self.axis = None\n\n    def __call__(self, *args, **kwargs):\n        # we need to return a copy of ourselves\n        self = self.__class__(self.obj, self.name)\n\n        # set the passed in values\n        for k, v in compat.iteritems(kwargs):\n            setattr(self,k,v)\n        return self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            try:\n                values = self.obj.get_value(*key)\n                if np.isscalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _get_label(self, label, axis=0):\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            try:\n                return self.obj._xs(label, axis=axis)\n            except:\n                return self.obj[label]\n        elif (isinstance(label, tuple) and\n                isinstance(label[axis], slice)):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=0):\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=0, typ=None):\n        return self.obj._slice(obj, axis=axis, typ=typ)\n\n    def __setitem__(self, key, value):\n\n        if self.axis is not None:\n            indexer = self._convert_tuple(key, is_setter=True)\n\n        else:\n\n            # kludgetastic\n            ax = self.obj._get_axis(0)\n            if isinstance(ax, MultiIndex):\n                try:\n                    indexer = ax.get_loc(key)\n                    self._setitem_with_indexer(indexer, value)\n                    return\n                except Exception:\n                    pass\n\n            if isinstance(key, tuple):\n                if len(key) > self.ndim:\n                    raise IndexingError('only tuples of length <= %d supported' %\n                                        self.ndim)\n                indexer = self._convert_tuple(key, is_setter=True)\n            else:\n                indexer = self._convert_to_indexer(key, is_setter=True)\n\n        self._setitem_with_indexer(indexer, value)\n\n    def _has_valid_type(self, k, axis):\n        raise NotImplementedError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            if not self._has_valid_type(k, i):\n                raise ValueError(\"Location based indexing can only have [%s] \"\n                                 \"types\" % self._valid_types)\n\n    def _should_validate_iterable(self, axis=0):\n        \"\"\" return a boolean whether this axes needs validation for a passed iterable \"\"\"\n        ax = self.obj._get_axis(axis)\n        if isinstance(ax, MultiIndex):\n            return False\n        elif ax.is_floating():\n            return False\n\n        return True\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any([ isinstance(ax, MultiIndex) for ax in self.obj.axes ]):\n            return any([ _is_nested_tuple(tup,ax) for ax in self.obj.axes ])\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, typ=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, typ=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n            will raise if needed, does not modify the indexer externally \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like(i):\n                    # should check the elements?\n                    pass\n                elif com.is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{0} cannot enlarge its target object\"\n                                         .format(self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{0} cannot enlarge its target object\"\n                                     .format(self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        from pandas import Panel, DataFrame, Series\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = _convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any([not l for l in len_non_info_axes]):\n                            if not is_list_like(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n                        self.obj[key] = np.nan\n\n                        new_indexer = _convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = _safe_append_to_index(index, key)\n                    self.obj._data = self.obj.reindex_axis(labels, i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj.is_copy=None\n\n                    if isinstance(labels, MultiIndex):\n                        self.obj.sortlevel(inplace=True)\n                        labels = self.obj._get_axis(i)\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = _convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    if len(index) == 0:\n                        new_index = Index([indexer])\n                    else:\n                        new_index = _safe_append_to_index(index, indexer)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value]).values\n                    if len(self.obj.values):\n                        new_values = np.concatenate([self.obj.values,\n                                                     new_values])\n\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\n                            \"cannot set a frame with no defined columns\"\n                        )\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if com.is_list_like(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\n                                    \"cannot set a row with mismatched columns\"\n                                    )\n\n                        value = Series(value,index=self.obj.columns,name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        info_axis = self.obj._info_axis_number\n        item_labels = self.obj._get_axis(info_axis)\n\n        # if we have a complicated setup, take the split path\n        if (isinstance(indexer, tuple) and\n                any([isinstance(ax, MultiIndex) for ax in self.obj.axes])):\n            take_split_path = True\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if com.is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].index, MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = _length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like(value) and np.iterable(value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\n                            \"cannot set using a multi-index selection indexer \"\n                            \"with a different length than the value\"\n                        )\n\n                    # make sure we have an ndarray\n                    value = getattr(value,'values',value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = _length_of_indexer(plane_indexer[0],\n                                                        plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice which means essentially reassign to the columns\n                # of a multi-dim object\n                # GH6149\n                if isinstance(pi, tuple) and all(_is_null_slice(idx) for idx in pi):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if not len(labels) == 1 or not np.iterable(value):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an interable, with a ndim of at least 1\n            # eg. don't pass thru np.array(0)\n            if _is_list_like(value) and getattr(value,'ndim',1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n\n                    for item in labels:\n                        # align to\n                        v = np.nan if item not in value else \\\n                                self._align_series(indexer[0], value[item])\n                        setter(item, v)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value,dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = _maybe_convert_ix(*indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser):\n        # indexer to assign Series can be tuple, slice, scalar\n        if isinstance(indexer, (slice, np.ndarray, list)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            # flatten np.ndarray indexers\n            ravel = lambda i: i.ravel() if isinstance(i, np.ndarray) else i\n            indexer = tuple(map(ravel, indexer))\n\n            aligners = [not _is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all([com._is_sequence(_) for _ in indexer])):\n                ser = ser.reindex(obj.axes[0][indexer[0]], copy=True).values\n\n                # single indexer\n                if len(indexer) > 1:\n                    l = len(indexer[1])\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if com._is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and _is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix)\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser.values.copy()\n\n                    return ser.reindex(new_ix).values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser.values.copy()\n                    return ser.reindex(ax).values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser.values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif np.isscalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser.values.copy()\n\n            return ser.reindex(ax).values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n\n        if isinstance(indexer, tuple):\n\n            aligners = [not _is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if com._is_sequence(ix) or isinstance(ix, slice):\n                    if idx is None:\n                        idx = ax[ix].ravel()\n                    elif cols is None:\n                        cols = ax[ix].ravel()\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n\n                # need to conform to the convention\n                # as we are not selecting on the items axis\n                # and we have a single indexer\n                # GH 7763\n                if len(sindexers) == 1 and sindexers[0] != 0:\n                    df = df.T\n\n                if idx is None:\n                    idx = df.index\n                if cols is None:\n                    cols = df.columns\n\n            if idx is not None and cols is not None:\n\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy().values\n                else:\n                    val = df.reindex(idx, columns=cols).values\n                return val\n\n        elif ((isinstance(indexer, slice) or com.is_list_like(indexer))\n              and is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy().values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if isinstance(ax, MultiIndex) and isinstance(\n                    df.index, MultiIndex) and ax.nlevels != df.index.nlevels:\n                    raise TypeError(\"cannot align on a multi-index with out specifying the join levels\")\n\n                val = df.reindex(index=ax).values\n            return val\n\n        elif np.isscalar(indexer) and is_panel:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy().values\n\n            return df.reindex(idx, columns=cols).values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        from pandas.core.generic import NDFrame\n\n        # ugly hack for GH #836\n        if not isinstance(self.obj, NDFrame):\n            return False\n\n        if not all(_is_list_like(x) for x in tup):\n            return False\n\n        # just too complicated\n        for indexer, ax in zip(tup, self.obj._data.axes):\n            if isinstance(ax, MultiIndex):\n                return False\n            elif com._is_bool_indexer(indexer):\n                return False\n            elif not ax.is_unique:\n                return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\" create the reindex map for our objects, raise the _exception if we\n        can't create the indexer\n        \"\"\"\n        try:\n            o = self.obj\n            d = dict([\n                (a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n                for t, a in zip(tup, o._AXIS_ORDERS)\n            ])\n            return o.reindex(**d)\n        except:\n            raise self._exception\n\n    def _convert_for_reindex(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if com._is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            return labels[key]\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if is_integer_dtype(keyarr) and not labels.is_integer():\n                keyarr = com._ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n            return keyarr\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=0)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        if isinstance(ax0, MultiIndex):\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if _is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not _is_list_like(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0\n                            and len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of selectors\n            return self._getitem_axis(tup, axis=0)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if np.isscalar(obj) or not hasattr(obj,'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=0):\n\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif _is_list_like(key) and not (isinstance(key, tuple) and\n                                         isinstance(labels, MultiIndex)):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n            if com.is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _getitem_iterable(self, key, axis=0):\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        def _reindex(keys, level=None):\n\n            try:\n                result = self.obj.reindex_axis(keys, axis=axis, level=level)\n            except AttributeError:\n                # Series\n                if axis != 0:\n                    raise AssertionError('axis must be 0')\n                return self.obj.reindex(keys, level=level)\n\n            # this is an error as we are trying to find\n            # keys in a multi-index that don't exist\n            if isinstance(labels, MultiIndex) and level is not None:\n                if hasattr(result,'ndim') and not np.prod(result.shape) and len(keys):\n                    raise KeyError(\"cannot index a multi-index axis with these keys\")\n\n            return result\n\n        if com._is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj.take(inds, axis=axis, convert=False)\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            # handle a mixed integer scenario\n            indexer = labels._convert_list_indexer_for_mixed(keyarr, typ=self.name)\n            if indexer is not None:\n                return self.obj.take(indexer, axis=axis)\n\n            # this is not the most robust, but...\n            if (isinstance(labels, MultiIndex) and len(keyarr) and\n                    not isinstance(keyarr[0], tuple)):\n                level = 0\n            else:\n                level = None\n\n            keyarr_is_unique = Index(keyarr).is_unique\n\n            # existing labels are unique and indexer is unique\n            if labels.is_unique and keyarr_is_unique:\n                return _reindex(keyarr, level=level)\n\n            else:\n                indexer, missing = labels.get_indexer_non_unique(keyarr)\n                check = indexer != -1\n                result = self.obj.take(indexer[check], axis=axis,\n                                       convert=False)\n\n                # need to merge the result labels and the missing labels\n                if len(missing):\n                    l = np.arange(len(indexer))\n\n                    missing = com._ensure_platform_int(missing)\n                    missing_labels = keyarr.take(missing)\n                    missing_indexer = com._ensure_int64(l[~check])\n                    cur_labels = result._get_axis(axis).values\n                    cur_indexer = com._ensure_int64(l[check])\n\n                    new_labels = np.empty(tuple([len(indexer)]), dtype=object)\n                    new_labels[cur_indexer] = cur_labels\n                    new_labels[missing_indexer] = missing_labels\n\n                    # reindex with the specified axis\n                    ndim = self.obj.ndim\n                    if axis + 1 > ndim:\n                        raise AssertionError(\"invalid indexing error with \"\n                                             \"non-unique index\")\n\n                    # a unique indexer\n                    if keyarr_is_unique:\n\n                        # see GH5553, make sure we use the right indexer\n                        new_indexer = np.arange(len(indexer))\n                        new_indexer[cur_indexer] = np.arange(\n                            len(result._get_axis(axis))\n                        )\n                        new_indexer[missing_indexer] = -1\n\n                    # we have a non_unique selector, need to use the original\n                    # indexer here\n                    else:\n\n                        # need to retake to have the same size as the indexer\n                        rindexer = indexer.values\n                        rindexer[~check] = 0\n                        result = self.obj.take(rindexer, axis=axis,\n                                               convert=False)\n\n                        # reset the new indexer to account for the new size\n                        new_indexer = np.arange(len(result))\n                        new_indexer[~check] = -1\n\n                    result = result._reindex_with_indexers({\n                        axis: [new_labels, new_indexer]\n                    }, copy=True, allow_dups=True)\n\n                return result\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        \"In the face of ambiguity, refuse the temptation to guess.\"\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        labels = self.obj._get_axis(axis)\n\n        # if we are a scalar indexer and not type correct raise\n        obj = self._convert_scalar_indexer(obj, axis)\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = com.is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except (KeyError, TypeError):\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif _is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n        elif _is_list_like(obj):\n            if com._is_bool_indexer(obj):\n                obj = _check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                if isinstance(obj, Index):\n                    objarr = obj.values\n                else:\n                    objarr = _asarray_tuplesafe(obj)\n\n                # If have integer labels, defer to label-based indexing\n                indexer = labels._convert_list_indexer_for_mixed(objarr, typ=self.name)\n                if indexer is not None:\n                    return indexer\n\n                # this is not the most robust, but...\n                if (isinstance(labels, MultiIndex) and\n                        not isinstance(objarr[0], tuple)):\n                    level = 0\n                    _, indexer = labels.reindex(objarr, level=level)\n\n                    # take all\n                    if indexer is None:\n                        indexer = np.arange(len(labels))\n\n                    check = labels.levels[0].get_indexer(objarr)\n                else:\n                    level = None\n\n                    # unique index\n                    if labels.is_unique:\n                        indexer = check = labels.get_indexer(objarr)\n\n                    # non-unique (dups)\n                    else:\n                        (indexer,\n                         missing) = labels.get_indexer_non_unique(objarr)\n                        check = indexer\n\n                mask = check == -1\n                if mask.any():\n\n                    # mi here\n                    if isinstance(obj, tuple) and is_setter:\n                        return {'key': obj}\n                    raise KeyError('%s not in index' % objarr[mask])\n\n                return _values_from_object(indexer)\n\n        else:\n            try:\n                return labels.get_loc(obj)\n            except KeyError:\n                # allow a not found key only if we are a setter\n                if not is_list_like(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n\n    \"\"\" A primarily location based indexer, with integer fallback \"\"\"\n\n    def _has_valid_type(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif com._is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _getitem_axis(self, key, axis=0):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n        key = _check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj.take(inds, axis=axis, convert=False)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        obj = self.obj\n        if not _need_slice(slice_obj):\n            return obj\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _LocIndexer(_LocationIndexer):\n\n    \"\"\" purely label based location based indexing \"\"\"\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    def _has_valid_type(self, key, axis):\n        ax = self.obj._get_axis(axis)\n\n        # valid for a label where all labels are in the index\n        # slice of lables (where start-end in labels)\n        # slice of integers (only if in the lables)\n        # boolean\n\n        if isinstance(key, slice):\n\n            if ax.is_floating():\n\n                # allowing keys to be slicers with no fallback\n                pass\n\n            else:\n                if key.start is not None:\n                    if key.start not in ax:\n                        raise KeyError(\n                            \"start bound [%s] is not the [%s]\" %\n                            (key.start, self.obj._get_axis_name(axis))\n                        )\n                if key.stop is not None:\n                    if key.stop not in ax:\n                        raise KeyError(\n                            \"stop bound [%s] is not in the [%s]\" %\n                            (key.stop, self.obj._get_axis_name(axis))\n                        )\n\n        elif com._is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n\n            # mi is just a passthru\n            if isinstance(key, tuple) and isinstance(ax, MultiIndex):\n                return True\n\n            # require at least 1 element in the index\n            idx = _ensure_index(key)\n            if len(idx) and not idx.isin(ax).any():\n\n                raise KeyError(\"None of [%s] are in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            return True\n\n        else:\n\n            def error():\n                if isnull(key):\n                    raise ValueError(\n                        \"cannot use label indexing with a null key\")\n                raise KeyError(\"the label [%s] is not in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            try:\n                key = self._convert_scalar_indexer(key, axis)\n                if not key in ax:\n                    error()\n            except (TypeError) as e:\n\n                # python 3 type errors should be raised\n                if 'unorderable' in str(e):  # pragma: no cover\n                    error()\n                raise\n            except:\n                error()\n\n        return True\n\n    def _getitem_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif com._is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif _is_list_like(key):\n\n            # GH 7349\n            # possibly convert a list-like into a nested tuple\n            # but don't convert a list-like of tuples\n            if isinstance(labels, MultiIndex):\n                if not isinstance(key, tuple) and len(key) > 1 and not isinstance(key[0], tuple):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and\n                    isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if _is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [ slice(None) ] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._has_valid_type(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n\n    \"\"\" purely integer based location based indexing \"\"\"\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _has_valid_type(self, key, axis):\n        if com._is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\n                        \"iLocation based boolean indexing on an integer type \"\n                        \"is not available\"\n                    )\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return True\n\n        if isinstance(key, slice):\n            return True\n        elif com.is_integer(key):\n            return self._is_valid_integer(key, axis)\n        elif (_is_list_like(key)):\n            return self._is_valid_list_like(key, axis)\n        return False\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_valid_integer(self, key, axis):\n        # return a boolean if we have a valid integer indexer\n\n        ax = self.obj._get_axis(axis)\n        if key > len(ax):\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n        return True\n\n\n    def _is_valid_list_like(self, key, axis):\n        # return a boolean if we are a valid list-like (e.g. that we dont' have out-of-bounds values)\n\n        # coerce the key to not exceed the maximum size of the index\n        arr = np.array(key)\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if len(arr) and (arr.max() >= l or arr.min() <= -l):\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n        return True\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis=0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim<self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(slice_obj, axis=axis, convert=False)\n\n    def _getitem_axis(self, key, axis=0):\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n\n        elif com._is_bool_indexer(key):\n            self._has_valid_type(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a single integer or a list of integers\n        else:\n\n            if _is_list_like(key):\n\n                # validate list bounds\n                self._is_valid_list_like(key, axis)\n\n                # force an actual list\n                key = list(key)\n\n            else:\n                key = self._convert_scalar_indexer(key, axis)\n\n                if not com.is_integer(key):\n                    raise TypeError(\"Cannot index by location index with a \"\n                                    \"non-integer key\")\n\n                # validate the location\n                self._is_valid_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        elif self._has_valid_type(obj, axis):\n            return obj\n\n        raise ValueError(\"Can only index by location with a [%s]\" %\n                         self._valid_types)\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not _is_list_like(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj.get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key))\n        key.append(value)\n        self.obj.set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" label based scalar accessor \"\"\"\n    _takeable = False\n\n    def _convert_key(self, key):\n        \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not com.is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index can only have integer \"\n                                     \"indexers\")\n            else:\n                if com.is_integer(i):\n                    raise ValueError(\"At based indexing on an non-integer index can only have non-integer \"\n                                     \"indexers\")\n        return key\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" integer based scalar accessor \"\"\"\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key):\n        \"\"\" require  integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not com.is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n# 32-bit floating point machine epsilon\n_eps = np.finfo('f4').eps\n\n\ndef _length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = abs(step)\n        return (stop - start) / step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef _convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, typ='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if key in obj._data.items:\n            return None\n\n        # we need a timelike key here\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except:\n                return None\n\n    return None\n\n\ndef _is_index_slice(obj):\n    def _is_valid_index(x):\n        return (com.is_integer(x) or com.is_float(x)\n                and np.allclose(x, int(x), rtol=_eps, atol=0))\n\n    def _crit(v):\n        return v is None or _is_valid_index(v)\n\n    both_none = obj.start is None and obj.stop is None\n\n    return not both_none and (_crit(obj.start) and _crit(obj.stop))\n\n\ndef _check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that com._is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = com.isnull(result.values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series key provided')\n\n        result = result.astype(bool).values\n\n    else:\n        # com._is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef _convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n        return the scalar indexer and a boolean indicating if we converted \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef _convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key'])\n                if isinstance(_idx, dict) else _idx)\n    return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])\n\n\ndef _safe_append_to_index(index, key):\n    \"\"\" a safe append to an index, if incorrect type, then catch and recreate\n    \"\"\"\n    try:\n        return index.insert(len(index), key)\n    except:\n\n        # raise here as this is basically an unsafe operation and we want\n        # it to be obvious that you are doing something wrong\n        raise ValueError(\"unsafe appending to index of type {0} with a key \"\n                         \"{1}\".format(index.__class__.__name__, key))\n\n\ndef _maybe_convert_indices(indices, n):\n    \"\"\" if we have negative indicies, translate to postive here\n    if have indicies that are out-of-bounds, raise an IndexError\n    \"\"\"\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.int_)\n\n    mask = indices < 0\n    if mask.any():\n        indices[mask] += n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef _maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef _is_nested_tuple(tup, labels):\n    # check for a compatiable nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    # are we nested tuple of: tuple,list,slice\n    for i, k in enumerate(tup):\n\n        if isinstance(k, (tuple, list, slice)):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\n\ndef _is_null_slice(obj):\n    return (isinstance(obj, slice) and obj.start is None and\n            obj.stop is None and obj.step is None)\n\n\ndef _is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not _is_list_like(key)\n\n\ndef _is_list_like(obj):\n    # Consider namedtuples to be not list like as they are useful as indices\n    return (hasattr(obj, '__iter__')\n            and not isinstance(obj, compat.string_types)\n            and not (isinstance(obj, tuple) and type(obj) is not tuple))\n\n\ndef _need_slice(obj):\n    return (obj.start is not None or\n            obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef _maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n",
          "file_after": "# pylint: disable=W0223\n\nfrom datetime import datetime\nfrom pandas.core.index import Index, MultiIndex, _ensure_index\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nimport pandas.core.common as com\nfrom pandas.core.common import (_is_bool_indexer, is_integer_dtype,\n                                _asarray_tuplesafe, is_list_like, isnull,\n                                ABCSeries, ABCDataFrame, ABCPanel, is_float,\n                                _values_from_object)\nimport pandas.lib as lib\n\nimport numpy as np\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix',   _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc',  _LocIndexer),\n        ('at',   _AtIndexer),\n        ('iat',  _iAtIndexer),\n    ]\n\n# \"null slice\"\n_NS = slice(None, None)\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    def __getitem__(self, arg):\n        return arg\nIndexSlice = _IndexSlice()\n\nclass IndexingError(Exception):\n    pass\n\nclass _NDFrameIndexer(object):\n    _valid_types = None\n    _exception = KeyError\n\n    def __init__(self, obj, name):\n        self.obj = obj\n        self.ndim = obj.ndim\n        self.name = name\n        self.axis = None\n\n    def __call__(self, *args, **kwargs):\n        # we need to return a copy of ourselves\n        self = self.__class__(self.obj, self.name)\n\n        # set the passed in values\n        for k, v in compat.iteritems(kwargs):\n            setattr(self,k,v)\n        return self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            try:\n                values = self.obj.get_value(*key)\n                if np.isscalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _get_label(self, label, axis=0):\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            try:\n                return self.obj._xs(label, axis=axis)\n            except:\n                return self.obj[label]\n        elif (isinstance(label, tuple) and\n                isinstance(label[axis], slice)):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=0):\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=0, typ=None):\n        return self.obj._slice(obj, axis=axis, typ=typ)\n\n    def __setitem__(self, key, value):\n\n        if self.axis is not None:\n            indexer = self._convert_tuple(key, is_setter=True)\n\n        else:\n\n            # kludgetastic\n            ax = self.obj._get_axis(0)\n            if isinstance(ax, MultiIndex):\n                try:\n                    indexer = ax.get_loc(key)\n                    self._setitem_with_indexer(indexer, value)\n                    return\n                except Exception:\n                    pass\n\n            if isinstance(key, tuple):\n                if len(key) > self.ndim:\n                    raise IndexingError('only tuples of length <= %d supported' %\n                                        self.ndim)\n                indexer = self._convert_tuple(key, is_setter=True)\n            else:\n                indexer = self._convert_to_indexer(key, is_setter=True)\n\n        self._setitem_with_indexer(indexer, value)\n\n    def _has_valid_type(self, k, axis):\n        raise NotImplementedError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            if not self._has_valid_type(k, i):\n                raise ValueError(\"Location based indexing can only have [%s] \"\n                                 \"types\" % self._valid_types)\n\n    def _should_validate_iterable(self, axis=0):\n        \"\"\" return a boolean whether this axes needs validation for a passed iterable \"\"\"\n        ax = self.obj._get_axis(axis)\n        if isinstance(ax, MultiIndex):\n            return False\n        elif ax.is_floating():\n            return False\n\n        return True\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any([ isinstance(ax, MultiIndex) for ax in self.obj.axes ]):\n            return any([ _is_nested_tuple(tup,ax) for ax in self.obj.axes ])\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, typ=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, typ=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n            will raise if needed, does not modify the indexer externally \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like(i):\n                    # should check the elements?\n                    pass\n                elif com.is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{0} cannot enlarge its target object\"\n                                         .format(self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{0} cannot enlarge its target object\"\n                                     .format(self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        from pandas import Panel, DataFrame, Series\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = _convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any([not l for l in len_non_info_axes]):\n                            if not is_list_like(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n                        self.obj[key] = np.nan\n\n                        new_indexer = _convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = _safe_append_to_index(index, key)\n                    self.obj._data = self.obj.reindex_axis(labels, i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj.is_copy=None\n\n                    if isinstance(labels, MultiIndex):\n                        self.obj.sortlevel(inplace=True)\n                        labels = self.obj._get_axis(i)\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = _convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    if len(index) == 0:\n                        new_index = Index([indexer])\n                    else:\n                        new_index = _safe_append_to_index(index, indexer)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value]).values\n                    if len(self.obj.values):\n                        new_values = np.concatenate([self.obj.values,\n                                                     new_values])\n\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\n                            \"cannot set a frame with no defined columns\"\n                        )\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if com.is_list_like(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\n                                    \"cannot set a row with mismatched columns\"\n                                    )\n\n                        value = Series(value,index=self.obj.columns,name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        info_axis = self.obj._info_axis_number\n        item_labels = self.obj._get_axis(info_axis)\n\n        # if we have a complicated setup, take the split path\n        if (isinstance(indexer, tuple) and\n                any([isinstance(ax, MultiIndex) for ax in self.obj.axes])):\n            take_split_path = True\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if com.is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].index, MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = _length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like(value) and np.iterable(value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\n                            \"cannot set using a multi-index selection indexer \"\n                            \"with a different length than the value\"\n                        )\n\n                    # make sure we have an ndarray\n                    value = getattr(value,'values',value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = _length_of_indexer(plane_indexer[0],\n                                                        plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice which means essentially reassign to the columns\n                # of a multi-dim object\n                # GH6149\n                if isinstance(pi, tuple) and all(_is_null_slice(idx) for idx in pi):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if not len(labels) == 1 or not np.iterable(value):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an interable, with a ndim of at least 1\n            # eg. don't pass thru np.array(0)\n            if _is_list_like(value) and getattr(value,'ndim',1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n\n                    for item in labels:\n                        # align to\n                        v = np.nan if item not in value else \\\n                                self._align_series(indexer[0], value[item])\n                        setter(item, v)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value,dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = _maybe_convert_ix(*indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser):\n        # indexer to assign Series can be tuple, slice, scalar\n        if isinstance(indexer, (slice, np.ndarray, list)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            # flatten np.ndarray indexers\n            ravel = lambda i: i.ravel() if isinstance(i, np.ndarray) else i\n            indexer = tuple(map(ravel, indexer))\n\n            aligners = [not _is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all([com._is_sequence(_) for _ in indexer])):\n                ser = ser.reindex(obj.axes[0][indexer[0]], copy=True).values\n\n                # single indexer\n                if len(indexer) > 1:\n                    l = len(indexer[1])\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if com._is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and _is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix)\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser.values.copy()\n\n                    return ser.reindex(new_ix).values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser.values.copy()\n                    return ser.reindex(ax).values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser.values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif np.isscalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser.values.copy()\n\n            return ser.reindex(ax).values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n\n        if isinstance(indexer, tuple):\n\n            aligners = [not _is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if com._is_sequence(ix) or isinstance(ix, slice):\n                    if idx is None:\n                        idx = ax[ix].ravel()\n                    elif cols is None:\n                        cols = ax[ix].ravel()\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n\n                # need to conform to the convention\n                # as we are not selecting on the items axis\n                # and we have a single indexer\n                # GH 7763\n                if len(sindexers) == 1 and sindexers[0] != 0:\n                    df = df.T\n\n                if idx is None:\n                    idx = df.index\n                if cols is None:\n                    cols = df.columns\n\n            if idx is not None and cols is not None:\n\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy().values\n                else:\n                    val = df.reindex(idx, columns=cols).values\n                return val\n\n        elif ((isinstance(indexer, slice) or com.is_list_like(indexer))\n              and is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy().values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if isinstance(ax, MultiIndex) and isinstance(\n                    df.index, MultiIndex) and ax.nlevels != df.index.nlevels:\n                    raise TypeError(\"cannot align on a multi-index with out specifying the join levels\")\n\n                val = df.reindex(index=ax).values\n            return val\n\n        elif np.isscalar(indexer) and is_panel:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy().values\n\n            return df.reindex(idx, columns=cols).values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        from pandas.core.generic import NDFrame\n\n        # ugly hack for GH #836\n        if not isinstance(self.obj, NDFrame):\n            return False\n\n        if not all(_is_list_like(x) for x in tup):\n            return False\n\n        # just too complicated\n        for indexer, ax in zip(tup, self.obj._data.axes):\n            if isinstance(ax, MultiIndex):\n                return False\n            elif com._is_bool_indexer(indexer):\n                return False\n            elif not ax.is_unique:\n                return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\" create the reindex map for our objects, raise the _exception if we\n        can't create the indexer\n        \"\"\"\n        try:\n            o = self.obj\n            d = dict([\n                (a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n                for t, a in zip(tup, o._AXIS_ORDERS)\n            ])\n            return o.reindex(**d)\n        except:\n            raise self._exception\n\n    def _convert_for_reindex(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if com._is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            return labels[key]\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if is_integer_dtype(keyarr) and not labels.is_integer():\n                keyarr = com._ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n            return keyarr\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=0)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        if isinstance(ax0, MultiIndex):\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if _is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not _is_list_like(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0\n                            and len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of selectors\n            return self._getitem_axis(tup, axis=0)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if np.isscalar(obj) or not hasattr(obj,'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=0):\n\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif _is_list_like(key) and not (isinstance(key, tuple) and\n                                         isinstance(labels, MultiIndex)):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n            if com.is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _getitem_iterable(self, key, axis=0):\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        def _reindex(keys, level=None):\n\n            try:\n                result = self.obj.reindex_axis(keys, axis=axis, level=level)\n            except AttributeError:\n                # Series\n                if axis != 0:\n                    raise AssertionError('axis must be 0')\n                return self.obj.reindex(keys, level=level)\n\n            # this is an error as we are trying to find\n            # keys in a multi-index that don't exist\n            if isinstance(labels, MultiIndex) and level is not None:\n                if hasattr(result,'ndim') and not np.prod(result.shape) and len(keys):\n                    raise KeyError(\"cannot index a multi-index axis with these keys\")\n\n            return result\n\n        if com._is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj.take(inds, axis=axis, convert=False)\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            # handle a mixed integer scenario\n            indexer = labels._convert_list_indexer_for_mixed(keyarr, typ=self.name)\n            if indexer is not None:\n                return self.obj.take(indexer, axis=axis)\n\n            # this is not the most robust, but...\n            if (isinstance(labels, MultiIndex) and len(keyarr) and\n                    not isinstance(keyarr[0], tuple)):\n                level = 0\n            else:\n                level = None\n\n            keyarr_is_unique = Index(keyarr).is_unique\n\n            # existing labels are unique and indexer is unique\n            if labels.is_unique and keyarr_is_unique:\n                return _reindex(keyarr, level=level)\n\n            else:\n                indexer, missing = labels.get_indexer_non_unique(keyarr)\n                check = indexer != -1\n                result = self.obj.take(indexer[check], axis=axis,\n                                       convert=False)\n\n                # need to merge the result labels and the missing labels\n                if len(missing):\n                    l = np.arange(len(indexer))\n\n                    missing = com._ensure_platform_int(missing)\n                    missing_labels = keyarr.take(missing)\n                    missing_indexer = com._ensure_int64(l[~check])\n                    cur_labels = result._get_axis(axis).values\n                    cur_indexer = com._ensure_int64(l[check])\n\n                    new_labels = np.empty(tuple([len(indexer)]), dtype=object)\n                    new_labels[cur_indexer] = cur_labels\n                    new_labels[missing_indexer] = missing_labels\n\n                    # reindex with the specified axis\n                    ndim = self.obj.ndim\n                    if axis + 1 > ndim:\n                        raise AssertionError(\"invalid indexing error with \"\n                                             \"non-unique index\")\n\n                    # a unique indexer\n                    if keyarr_is_unique:\n\n                        # see GH5553, make sure we use the right indexer\n                        new_indexer = np.arange(len(indexer))\n                        new_indexer[cur_indexer] = np.arange(\n                            len(result._get_axis(axis))\n                        )\n                        new_indexer[missing_indexer] = -1\n\n                    # we have a non_unique selector, need to use the original\n                    # indexer here\n                    else:\n\n                        # need to retake to have the same size as the indexer\n                        rindexer = indexer.values\n                        rindexer[~check] = 0\n                        result = self.obj.take(rindexer, axis=axis,\n                                               convert=False)\n\n                        # reset the new indexer to account for the new size\n                        new_indexer = np.arange(len(result))\n                        new_indexer[~check] = -1\n\n                    result = result._reindex_with_indexers({\n                        axis: [new_labels, new_indexer]\n                    }, copy=True, allow_dups=True)\n\n                return result\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        \"In the face of ambiguity, refuse the temptation to guess.\"\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        labels = self.obj._get_axis(axis)\n\n        # if we are a scalar indexer and not type correct raise\n        obj = self._convert_scalar_indexer(obj, axis)\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = com.is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except (KeyError, TypeError):\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif _is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n        elif _is_list_like(obj):\n            if com._is_bool_indexer(obj):\n                obj = _check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                if isinstance(obj, Index):\n                    objarr = obj.values\n                else:\n                    objarr = _asarray_tuplesafe(obj)\n\n                # If have integer labels, defer to label-based indexing\n                indexer = labels._convert_list_indexer_for_mixed(objarr, typ=self.name)\n                if indexer is not None:\n                    return indexer\n\n                # this is not the most robust, but...\n                if (isinstance(labels, MultiIndex) and\n                        not isinstance(objarr[0], tuple)):\n                    level = 0\n                    _, indexer = labels.reindex(objarr, level=level)\n\n                    # take all\n                    if indexer is None:\n                        indexer = np.arange(len(labels))\n\n                    check = labels.levels[0].get_indexer(objarr)\n                else:\n                    level = None\n\n                    # unique index\n                    if labels.is_unique:\n                        indexer = check = labels.get_indexer(objarr)\n\n                    # non-unique (dups)\n                    else:\n                        (indexer,\n                         missing) = labels.get_indexer_non_unique(objarr)\n                        check = indexer\n\n                mask = check == -1\n                if mask.any():\n\n                    # mi here\n                    if isinstance(obj, tuple) and is_setter:\n                        return {'key': obj}\n                    raise KeyError('%s not in index' % objarr[mask])\n\n                return _values_from_object(indexer)\n\n        else:\n            try:\n                return labels.get_loc(obj)\n            except KeyError:\n                # allow a not found key only if we are a setter\n                if not is_list_like(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n\n    \"\"\" A primarily location based indexer, with integer fallback \"\"\"\n\n    def _has_valid_type(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif com._is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _getitem_axis(self, key, axis=0):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n        key = _check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj.take(inds, axis=axis, convert=False)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        obj = self.obj\n        if not _need_slice(slice_obj):\n            return obj\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _LocIndexer(_LocationIndexer):\n\n    \"\"\" purely label based location based indexing \"\"\"\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    def _has_valid_type(self, key, axis):\n        ax = self.obj._get_axis(axis)\n\n        # valid for a label where all labels are in the index\n        # slice of lables (where start-end in labels)\n        # slice of integers (only if in the lables)\n        # boolean\n\n        if isinstance(key, slice):\n\n            if ax.is_floating():\n\n                # allowing keys to be slicers with no fallback\n                pass\n\n            else:\n                if key.start is not None:\n                    if key.start not in ax:\n                        raise KeyError(\n                            \"start bound [%s] is not the [%s]\" %\n                            (key.start, self.obj._get_axis_name(axis))\n                        )\n                if key.stop is not None:\n                    if key.stop not in ax:\n                        raise KeyError(\n                            \"stop bound [%s] is not in the [%s]\" %\n                            (key.stop, self.obj._get_axis_name(axis))\n                        )\n\n        elif com._is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n\n            # mi is just a passthru\n            if isinstance(key, tuple) and isinstance(ax, MultiIndex):\n                return True\n\n            # require at least 1 element in the index\n            idx = _ensure_index(key)\n            if len(idx) and not idx.isin(ax).any():\n\n                raise KeyError(\"None of [%s] are in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            return True\n\n        else:\n\n            def error():\n                if isnull(key):\n                    raise ValueError(\n                        \"cannot use label indexing with a null key\")\n                raise KeyError(\"the label [%s] is not in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            try:\n                key = self._convert_scalar_indexer(key, axis)\n                if not key in ax:\n                    error()\n            except (TypeError) as e:\n\n                # python 3 type errors should be raised\n                if 'unorderable' in str(e):  # pragma: no cover\n                    error()\n                raise\n            except:\n                error()\n\n        return True\n\n    def _getitem_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif com._is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif _is_list_like(key):\n\n            # GH 7349\n            # possibly convert a list-like into a nested tuple\n            # but don't convert a list-like of tuples\n            if isinstance(labels, MultiIndex):\n                if not isinstance(key, tuple) and len(key) > 1 and not isinstance(key[0], tuple):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and\n                    isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if _is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [ slice(None) ] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._has_valid_type(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n\n    \"\"\" purely integer based location based indexing \"\"\"\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _has_valid_type(self, key, axis):\n        if com._is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\n                        \"iLocation based boolean indexing on an integer type \"\n                        \"is not available\"\n                    )\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return True\n\n        if isinstance(key, slice):\n            return True\n        elif com.is_integer(key):\n            return self._is_valid_integer(key, axis)\n        elif (_is_list_like(key)):\n            return self._is_valid_list_like(key, axis)\n        return False\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_valid_integer(self, key, axis):\n        # return a boolean if we have a valid integer indexer\n\n        ax = self.obj._get_axis(axis)\n        if key > len(ax):\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n        return True\n\n\n    def _is_valid_list_like(self, key, axis):\n        # return a boolean if we are a valid list-like (e.g. that we dont' have out-of-bounds values)\n\n        # coerce the key to not exceed the maximum size of the index\n        arr = np.array(key)\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if len(arr) and (arr.max() >= l or arr.min() <= -l):\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n        return True\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis=0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim<self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(slice_obj, axis=axis, convert=False)\n\n    def _getitem_axis(self, key, axis=0):\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n\n        elif com._is_bool_indexer(key):\n            self._has_valid_type(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a single integer or a list of integers\n        else:\n\n            if _is_list_like(key):\n\n                # validate list bounds\n                self._is_valid_list_like(key, axis)\n\n                # force an actual list\n                key = list(key)\n\n            else:\n                key = self._convert_scalar_indexer(key, axis)\n\n                if not com.is_integer(key):\n                    raise TypeError(\"Cannot index by location index with a \"\n                                    \"non-integer key\")\n\n                # validate the location\n                self._is_valid_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        elif self._has_valid_type(obj, axis):\n            return obj\n\n        raise ValueError(\"Can only index by location with a [%s]\" %\n                         self._valid_types)\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key, is_setter=False):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not _is_list_like(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj.get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key, is_setter=True))\n        key.append(value)\n        self.obj.set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" label based scalar accessor \"\"\"\n    _takeable = False\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n\n        # allow arbitrary setting\n        if is_setter:\n            return list(key)\n\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not com.is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index can only have integer \"\n                                     \"indexers\")\n            else:\n                if com.is_integer(i):\n                    raise ValueError(\"At based indexing on an non-integer index can only have non-integer \"\n                                     \"indexers\")\n        return key\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" integer based scalar accessor \"\"\"\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key, is_setter=False):\n        \"\"\" require  integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not com.is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n# 32-bit floating point machine epsilon\n_eps = np.finfo('f4').eps\n\n\ndef _length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = abs(step)\n        return (stop - start) / step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef _convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, typ='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if key in obj._data.items:\n            return None\n\n        # we need a timelike key here\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except:\n                return None\n\n    return None\n\n\ndef _is_index_slice(obj):\n    def _is_valid_index(x):\n        return (com.is_integer(x) or com.is_float(x)\n                and np.allclose(x, int(x), rtol=_eps, atol=0))\n\n    def _crit(v):\n        return v is None or _is_valid_index(v)\n\n    both_none = obj.start is None and obj.stop is None\n\n    return not both_none and (_crit(obj.start) and _crit(obj.stop))\n\n\ndef _check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that com._is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = com.isnull(result.values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series key provided')\n\n        result = result.astype(bool).values\n\n    else:\n        # com._is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef _convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n        return the scalar indexer and a boolean indicating if we converted \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef _convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key'])\n                if isinstance(_idx, dict) else _idx)\n    return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])\n\n\ndef _safe_append_to_index(index, key):\n    \"\"\" a safe append to an index, if incorrect type, then catch and recreate\n    \"\"\"\n    try:\n        return index.insert(len(index), key)\n    except:\n\n        # raise here as this is basically an unsafe operation and we want\n        # it to be obvious that you are doing something wrong\n        raise ValueError(\"unsafe appending to index of type {0} with a key \"\n                         \"{1}\".format(index.__class__.__name__, key))\n\n\ndef _maybe_convert_indices(indices, n):\n    \"\"\" if we have negative indicies, translate to postive here\n    if have indicies that are out-of-bounds, raise an IndexError\n    \"\"\"\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.int_)\n\n    mask = indices < 0\n    if mask.any():\n        indices[mask] += n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef _maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef _is_nested_tuple(tup, labels):\n    # check for a compatiable nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    # are we nested tuple of: tuple,list,slice\n    for i, k in enumerate(tup):\n\n        if isinstance(k, (tuple, list, slice)):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\n\ndef _is_null_slice(obj):\n    return (isinstance(obj, slice) and obj.start is None and\n            obj.stop is None and obj.step is None)\n\n\ndef _is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not _is_list_like(key)\n\n\ndef _is_list_like(obj):\n    # Consider namedtuples to be not list like as they are useful as indices\n    return (hasattr(obj, '__iter__')\n            and not isinstance(obj, compat.string_types)\n            and not (isinstance(obj, tuple) and type(obj) is not tuple))\n\n\ndef _need_slice(obj):\n    return (obj.start is not None or\n            obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef _maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n",
          "file_patch": "@@ -1484,7 +1484,7 @@ class _ScalarAccessIndexer(_NDFrameIndexer):\n \n     \"\"\" access scalars quickly \"\"\"\n \n-    def _convert_key(self, key):\n+    def _convert_key(self, key, is_setter=False):\n         return list(key)\n \n     def __getitem__(self, key):\n@@ -1505,7 +1505,7 @@ class _ScalarAccessIndexer(_NDFrameIndexer):\n         if len(key) != self.obj.ndim:\n             raise ValueError('Not enough indexers for scalar access '\n                              '(setting)!')\n-        key = list(self._convert_key(key))\n+        key = list(self._convert_key(key, is_setter=True))\n         key.append(value)\n         self.obj.set_value(*key, takeable=self._takeable)\n \n@@ -1515,8 +1515,13 @@ class _AtIndexer(_ScalarAccessIndexer):\n     \"\"\" label based scalar accessor \"\"\"\n     _takeable = False\n \n-    def _convert_key(self, key):\n+    def _convert_key(self, key, is_setter=False):\n         \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n+\n+        # allow arbitrary setting\n+        if is_setter:\n+            return list(key)\n+\n         for ax, i in zip(self.obj.axes, key):\n             if ax.is_integer():\n                 if not com.is_integer(i):\n@@ -1536,7 +1541,7 @@ class _iAtIndexer(_ScalarAccessIndexer):\n     def _has_valid_setitem_indexer(self, indexer):\n         self._has_valid_positional_setitem_indexer(indexer)\n \n-    def _convert_key(self, key):\n+    def _convert_key(self, key, is_setter=False):\n         \"\"\" require  integer args (and convert to label arguments) \"\"\"\n         for a, i in zip(self.obj.axes, key):\n             if not com.is_integer(i):\n",
          "files_name_in_blame_commit": [
            "test_indexing.py",
            "indexing.py"
          ]
        }
      },
      "2dce536d9a4bf1a9e6b18ae117ca54f3fdc5d2bb": {
        "commit": {
          "commit_id": "2dce536d9a4bf1a9e6b18ae117ca54f3fdc5d2bb",
          "commit_message": "BUG: Bug in .at that would accept integer indexers on a non-integer index and do fallback (GH7814)",
          "commit_author": "jreback",
          "commit_date": "2014-09-19 11:03:23",
          "commit_parent": "8c60b3de3af4fec3012ab02940e209d401aa8a86"
        },
        "function": {
          "function_name": "_convert_key",
          "function_code_before": "def _convert_key(self, key):\n    return list(key)",
          "function_code_after": "def _convert_key(self, key):\n    \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n    for (ax, i) in zip(self.obj.axes, key):\n        if ax.is_integer():\n            if not com.is_integer(i):\n                raise ValueError('At based indexing on an integer index can only have integer indexers')\n        elif com.is_integer(i):\n            raise ValueError('At based indexing on an non-integer index can only have non-integer indexers')\n    return key",
          "function_before_start_line": 1482,
          "function_before_end_line": 1483,
          "function_after_start_line": 1513,
          "function_after_end_line": 1524,
          "function_before_token_count": 12,
          "function_after_token_count": 64,
          "functions_name_modified_file": [
            "_convert_for_reindex",
            "_setitem_with_indexer",
            "_getitem_nested_tuple",
            "_maybe_convert_ix",
            "_is_list_like",
            "_align_panel",
            "_convert_to_indexer",
            "_getbool_axis",
            "_is_valid_list_like",
            "_get_slice_axis",
            "_has_valid_tuple",
            "_length_of_indexer",
            "_is_null_slice",
            "_is_nested_tuple",
            "_safe_append_to_index",
            "_need_slice",
            "_align_series",
            "_has_valid_setitem_indexer",
            "_should_validate_iterable",
            "_has_valid_type",
            "_multi_take_opportunity",
            "__iter__",
            "_is_valid_integer",
            "_convert_slice_indexer",
            "_convert_to_index_sliceable",
            "_convert_scalar_indexer",
            "_check_bool_indexer",
            "_getitem_iterable",
            "_handle_lowerdim_multi_index_axis0",
            "_convert_tuple",
            "_is_nested_tuple_indexer",
            "_maybe_droplevels",
            "_get_loc",
            "_has_valid_positional_setitem_indexer",
            "_is_label_like",
            "__getitem__",
            "_getitem_tuple",
            "__init__",
            "_getitem_axis",
            "__call__",
            "_maybe_convert_indices",
            "_tuplify",
            "_getitem_lowerdim",
            "_multi_take",
            "_slice",
            "_convert_missing_indexer",
            "get_indexers_list",
            "_convert_from_missing_indexer_tuple",
            "__setitem__",
            "_convert_key",
            "_get_label",
            "_align_frame",
            "_is_index_slice"
          ],
          "functions_name_all_files": [
            "test_none_coercion_mixed_dtypes",
            "test_iloc_getitem_list_int",
            "_align_panel",
            "test_indexing_mixed_frame_bug",
            "_getbool_axis",
            "_is_valid_list_like",
            "_get_slice_axis",
            "test_setitem_chained_setfault",
            "test_detect_chained_assignment_warnings",
            "_has_valid_tuple",
            "_length_of_indexer",
            "_is_null_slice",
            "test_iloc_getitem_doc_issue",
            "_get_value",
            "test_iloc_getitem_int",
            "_safe_append_to_index",
            "test_iloc_getitem_slice_dups",
            "_align_series",
            "_is_valid_integer",
            "_convert_slice_indexer",
            "_convert_to_index_sliceable",
            "test_iloc_setitem_list_of_lists",
            "test_dups_fancy_indexing",
            "_getitem_iterable",
            "_handle_lowerdim_multi_index_axis0",
            "_convert_tuple",
            "_maybe_droplevels",
            "test_multiindex_slicers_edges",
            "_has_valid_positional_setitem_indexer",
            "test_series_getitem_multiindex",
            "test_mi_access",
            "test_setitem_dtype_upcast",
            "__getitem__",
            "test_coercion_with_loc_setitem",
            "_getitem_tuple",
            "__init__",
            "setUp",
            "test_ix_slicing_strings",
            "test_float_index_non_scalar_assignment",
            "_multi_take",
            "test_setitem_list",
            "test_deprecate_float_indexers",
            "test_xs_multiindex",
            "get_indexers_list",
            "test_dups_loc",
            "_convert_key",
            "test_imethods_with_dups",
            "test_ix_weird_slicing",
            "_get_label",
            "test_loc_setitem_frame_multiples",
            "test_panel_assignment",
            "_is_index_slice",
            "test_loc_getitem_label_list",
            "test_partial_setting",
            "_convert_for_reindex",
            "_setitem_with_indexer",
            "_getitem_nested_tuple",
            "test_non_unique_loc",
            "check_result",
            "test_setitem_iloc",
            "test_at_and_iat_set",
            "test_loc_name",
            "test_non_unique_loc_memory_error",
            "test_iloc_exceeds_bounds",
            "test_loc_multiindex",
            "test_loc_setitem_consistency",
            "_axify",
            "test_iloc_getitem_array",
            "test_multi_assign",
            "test_series_partial_set",
            "test_coercion_with_setitem_and_dataframe",
            "_should_validate_iterable",
            "_has_valid_type",
            "test_loc_general",
            "test_set_index_nan",
            "_check_bool_indexer",
            "test_loc_getitem_label_out_of_range",
            "test_at_and_iat_get",
            "test_iloc_setitem",
            "test_loc_setitem_dups",
            "test_iat_invalid_args",
            "test_iloc_getitem_panel",
            "_get_loc",
            "test_loc_empty_list_indexer_is_ok",
            "test_iloc_getitem_neg_int",
            "_is_label_like",
            "test_float_index_to_mixed",
            "test_detect_chained_assignment",
            "_maybe_convert_indices",
            "test_loc_getitem_int",
            "_getitem_lowerdim",
            "test_coercion_with_loc_and_series",
            "_convert_missing_indexer",
            "test_iloc_setitem_series",
            "_convert_from_missing_indexer_tuple",
            "test_cache_updating",
            "test_loc_getitem_bool",
            "test_iloc_non_unique_indexing",
            "_maybe_convert_ix",
            "test_floating_index",
            "test_set_ix_out_of_bounds_axis_0",
            "test_iloc_getitem_bool",
            "_is_nested_tuple",
            "test_loc_getitem_int_slice",
            "_need_slice",
            "_has_valid_setitem_indexer",
            "test_slice_consolidate_invalidate_item_cache",
            "test_chained_getitem_with_lists",
            "_multi_take_opportunity",
            "test_iloc_getitem_slice",
            "test_loc_to_fail",
            "test_loc_setitem",
            "test_slice_indexer",
            "test_partial_setting_mixed_dtype",
            "test_loc_setitem_multiindex",
            "test_per_axis_per_level_getitem",
            "test_ix_get_set_consistency",
            "_is_nested_tuple_indexer",
            "test_float64index_slicing_bug",
            "test_partial_set_invalid",
            "test_coercion_with_setitem_and_series",
            "__call__",
            "test_ix_empty_list_indexer_is_ok",
            "_tuplify",
            "test_loc_arguments",
            "_slice",
            "test_iloc_getitem_multiindex",
            "__setitem__",
            "test_per_axis_per_level_doc_examples",
            "test_loc_getitem_label",
            "test_loc_setitem_frame",
            "test_setitem_cache_updating",
            "test_getitem_multiindex",
            "test_multiindex_slicers_non_unique",
            "_is_list_like",
            "test_partial_set_empty",
            "test_set_ix_out_of_bounds_axis_1",
            "_convert_to_indexer",
            "test_none_coercion_loc_and_dataframe",
            "test_repeated_getitem_dups",
            "test_iloc_setitem_dups",
            "test_ix_general",
            "test_multiindex_setitem",
            "check_values",
            "test_per_axis_per_level_setitem",
            "_mklbl",
            "test_coercion_with_loc",
            "test_iloc_mask",
            "__iter__",
            "test_iloc_empty_list_indexer_is_ok",
            "test_scalar_indexer",
            "_convert_scalar_indexer",
            "test_ix_assign_column_mixed",
            "test_astype_assignment",
            "test_floating_index_doc_example",
            "test_setitem_ndarray_1d",
            "test_loc_getitem_label_slice",
            "test_coercion_with_setitem",
            "test_astype_assignment_with_dups",
            "test_at_iat_coercion",
            "test_duplicate_ix_returns_series",
            "_getitem_axis",
            "test_multi_nan_indexing",
            "test_multiindex_assignment",
            "_get_result",
            "test_iloc_panel_issue",
            "test_iloc_getitem_frame",
            "test_panel_getitem",
            "test_float_index_at_iat",
            "test_indexer_caching",
            "test_iloc_getitem_dups",
            "_generate_indices",
            "_align_frame",
            "test_multiindex_slicers_datetimelike"
          ],
          "functions_name_co_evolved_modified_file": [],
          "functions_name_co_evolved_all_files": [
            "test_loc_to_fail"
          ]
        },
        "file": {
          "file_name": "indexing.py",
          "file_nloc": 1116,
          "file_complexity": 463,
          "file_token_count": 8322,
          "file_before": "# pylint: disable=W0223\n\nfrom datetime import datetime\nfrom pandas.core.index import Index, MultiIndex, _ensure_index\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nimport pandas.core.common as com\nfrom pandas.core.common import (_is_bool_indexer, is_integer_dtype,\n                                _asarray_tuplesafe, is_list_like, isnull,\n                                ABCSeries, ABCDataFrame, ABCPanel, is_float,\n                                _values_from_object)\nimport pandas.lib as lib\n\nimport numpy as np\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix',   _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc',  _LocIndexer),\n        ('at',   _AtIndexer),\n        ('iat',  _iAtIndexer),\n    ]\n\n# \"null slice\"\n_NS = slice(None, None)\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    def __getitem__(self, arg):\n        return arg\nIndexSlice = _IndexSlice()\n\nclass IndexingError(Exception):\n    pass\n\nclass _NDFrameIndexer(object):\n    _valid_types = None\n    _exception = KeyError\n\n    def __init__(self, obj, name):\n        self.obj = obj\n        self.ndim = obj.ndim\n        self.name = name\n        self.axis = None\n\n    def __call__(self, *args, **kwargs):\n        # we need to return a copy of ourselves\n        self = self.__class__(self.obj, self.name)\n\n        # set the passed in values\n        for k, v in compat.iteritems(kwargs):\n            setattr(self,k,v)\n        return self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            try:\n                values = self.obj.get_value(*key)\n                if np.isscalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _get_label(self, label, axis=0):\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            try:\n                return self.obj._xs(label, axis=axis)\n            except:\n                return self.obj[label]\n        elif (isinstance(label, tuple) and\n                isinstance(label[axis], slice)):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=0):\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=0, typ=None):\n        return self.obj._slice(obj, axis=axis, typ=typ)\n\n    def __setitem__(self, key, value):\n\n        if self.axis is not None:\n            indexer = self._convert_tuple(key, is_setter=True)\n\n        else:\n\n            # kludgetastic\n            ax = self.obj._get_axis(0)\n            if isinstance(ax, MultiIndex):\n                try:\n                    indexer = ax.get_loc(key)\n                    self._setitem_with_indexer(indexer, value)\n                    return\n                except Exception:\n                    pass\n\n            if isinstance(key, tuple):\n                if len(key) > self.ndim:\n                    raise IndexingError('only tuples of length <= %d supported' %\n                                        self.ndim)\n                indexer = self._convert_tuple(key, is_setter=True)\n            else:\n                indexer = self._convert_to_indexer(key, is_setter=True)\n\n        self._setitem_with_indexer(indexer, value)\n\n    def _has_valid_type(self, k, axis):\n        raise NotImplementedError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            if not self._has_valid_type(k, i):\n                raise ValueError(\"Location based indexing can only have [%s] \"\n                                 \"types\" % self._valid_types)\n\n    def _should_validate_iterable(self, axis=0):\n        \"\"\" return a boolean whether this axes needs validation for a passed iterable \"\"\"\n        ax = self.obj._get_axis(axis)\n        if isinstance(ax, MultiIndex):\n            return False\n        elif ax.is_floating():\n            return False\n\n        return True\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any([ isinstance(ax, MultiIndex) for ax in self.obj.axes ]):\n            return any([ _is_nested_tuple(tup,ax) for ax in self.obj.axes ])\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, typ=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, typ=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n            will raise if needed, does not modify the indexer externally \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like(i):\n                    # should check the elements?\n                    pass\n                elif com.is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{0} cannot enlarge its target object\"\n                                         .format(self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{0} cannot enlarge its target object\"\n                                     .format(self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        from pandas import Panel, DataFrame, Series\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = _convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any([not l for l in len_non_info_axes]):\n                            if not is_list_like(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n                        self.obj[key] = np.nan\n\n                        new_indexer = _convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = _safe_append_to_index(index, key)\n                    self.obj._data = self.obj.reindex_axis(labels, i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj.is_copy=None\n\n                    if isinstance(labels, MultiIndex):\n                        self.obj.sortlevel(inplace=True)\n                        labels = self.obj._get_axis(i)\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = _convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    if len(index) == 0:\n                        new_index = Index([indexer])\n                    else:\n                        new_index = _safe_append_to_index(index, indexer)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value]).values\n                    if len(self.obj.values):\n                        new_values = np.concatenate([self.obj.values,\n                                                     new_values])\n\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\n                            \"cannot set a frame with no defined columns\"\n                        )\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if com.is_list_like(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\n                                    \"cannot set a row with mismatched columns\"\n                                    )\n\n                        value = Series(value,index=self.obj.columns,name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        info_axis = self.obj._info_axis_number\n        item_labels = self.obj._get_axis(info_axis)\n\n        # if we have a complicated setup, take the split path\n        if (isinstance(indexer, tuple) and\n                any([isinstance(ax, MultiIndex) for ax in self.obj.axes])):\n            take_split_path = True\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if com.is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].index, MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = _length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like(value) and np.iterable(value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\n                            \"cannot set using a multi-index selection indexer \"\n                            \"with a different length than the value\"\n                        )\n\n                    # make sure we have an ndarray\n                    value = getattr(value,'values',value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = _length_of_indexer(plane_indexer[0],\n                                                        plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice which means essentially reassign to the columns\n                # of a multi-dim object\n                # GH6149\n                if isinstance(pi, tuple) and all(_is_null_slice(idx) for idx in pi):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if not len(labels) == 1 or not np.iterable(value):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an interable, with a ndim of at least 1\n            # eg. don't pass thru np.array(0)\n            if _is_list_like(value) and getattr(value,'ndim',1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n\n                    for item in labels:\n\n                        # align to\n                        if item in value:\n                            v = value[item]\n                            i = self.obj[item].index\n                            v = v.reindex(i & v.index)\n\n                            setter(item, v.values)\n                        else:\n                            setter(item, np.nan)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value,dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = _maybe_convert_ix(*indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser):\n        # indexer to assign Series can be tuple, slice, scalar\n        if isinstance(indexer, (slice, np.ndarray, list)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            aligners = [not _is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all([com._is_sequence(_) for _ in indexer])):\n                ser = ser.reindex(obj.axes[0][indexer[0].ravel()],\n                                  copy=True).values\n\n                # single indexer\n                if len(indexer) > 1:\n                    l = len(indexer[1].ravel())\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if com._is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and _is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix.ravel())\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser.values.copy()\n\n                    return ser.reindex(new_ix).values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser.values.copy()\n                    return ser.reindex(ax).values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser.values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif np.isscalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser.values.copy()\n\n            return ser.reindex(ax).values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n        if isinstance(indexer, tuple):\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if com._is_sequence(ix) or isinstance(ix, slice):\n                    if idx is None:\n                        idx = ax[ix].ravel()\n                    elif cols is None:\n                        cols = ax[ix].ravel()\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n                if len(sindexers) == 1 and idx is None and cols is None:\n                    if sindexers[0] == 0:\n                        df = df.T\n                    return self.obj.conform(df, axis=sindexers[0])\n                df = df.T\n\n            if idx is not None and cols is not None:\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy().values\n                else:\n                    val = df.reindex(idx, columns=cols).values\n                return val\n\n        elif ((isinstance(indexer, slice) or com.is_list_like(indexer))\n              and is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy().values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if isinstance(ax, MultiIndex) and isinstance(\n                    df.index, MultiIndex) and ax.nlevels != df.index.nlevels:\n                    raise TypeError(\"cannot align on a multi-index with out specifying the join levels\")\n\n                val = df.reindex(index=ax).values\n            return val\n\n        elif np.isscalar(indexer) and not is_frame:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            if is_panel:\n                df = df.T\n\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy().values\n\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            elif idx.equals(df.columns) and cols.equals(df.index):\n                return df.T.copy().values\n\n            return df.reindex(idx, columns=cols).values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        from pandas.core.generic import NDFrame\n\n        # ugly hack for GH #836\n        if not isinstance(self.obj, NDFrame):\n            return False\n\n        if not all(_is_list_like(x) for x in tup):\n            return False\n\n        # just too complicated\n        for indexer, ax in zip(tup, self.obj._data.axes):\n            if isinstance(ax, MultiIndex):\n                return False\n            elif com._is_bool_indexer(indexer):\n                return False\n            elif not ax.is_unique:\n                return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\" create the reindex map for our objects, raise the _exception if we\n        can't create the indexer\n        \"\"\"\n        try:\n            o = self.obj\n            d = dict([\n                (a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n                for t, a in zip(tup, o._AXIS_ORDERS)\n            ])\n            return o.reindex(**d)\n        except:\n            raise self._exception\n\n    def _convert_for_reindex(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if com._is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            return labels[key]\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if is_integer_dtype(keyarr) and not labels.is_integer():\n                keyarr = com._ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n            return keyarr\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=0)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        if isinstance(ax0, MultiIndex):\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if _is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not _is_list_like(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0\n                            and len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of selectors\n            return self._getitem_axis(tup, axis=0)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if np.isscalar(obj) or not hasattr(obj,'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=0):\n\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif _is_list_like(key) and not (isinstance(key, tuple) and\n                                         isinstance(labels, MultiIndex)):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n            if com.is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _getitem_iterable(self, key, axis=0):\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        def _reindex(keys, level=None):\n\n            try:\n                result = self.obj.reindex_axis(keys, axis=axis, level=level)\n            except AttributeError:\n                # Series\n                if axis != 0:\n                    raise AssertionError('axis must be 0')\n                return self.obj.reindex(keys, level=level)\n\n            # this is an error as we are trying to find\n            # keys in a multi-index that don't exist\n            if isinstance(labels, MultiIndex) and level is not None:\n                if hasattr(result,'ndim') and not np.prod(result.shape) and len(keys):\n                    raise KeyError(\"cannot index a multi-index axis with these keys\")\n\n            return result\n\n        if com._is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj.take(inds, axis=axis, convert=False)\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            # handle a mixed integer scenario\n            indexer = labels._convert_list_indexer_for_mixed(keyarr, typ=self.name)\n            if indexer is not None:\n                return self.obj.take(indexer, axis=axis)\n\n            # this is not the most robust, but...\n            if (isinstance(labels, MultiIndex) and len(keyarr) and\n                    not isinstance(keyarr[0], tuple)):\n                level = 0\n            else:\n                level = None\n\n            keyarr_is_unique = Index(keyarr).is_unique\n\n            # existing labels are unique and indexer is unique\n            if labels.is_unique and keyarr_is_unique:\n                return _reindex(keyarr, level=level)\n\n            else:\n                indexer, missing = labels.get_indexer_non_unique(keyarr)\n                check = indexer != -1\n                result = self.obj.take(indexer[check], axis=axis,\n                                       convert=False)\n\n                # need to merge the result labels and the missing labels\n                if len(missing):\n                    l = np.arange(len(indexer))\n\n                    missing = com._ensure_platform_int(missing)\n                    missing_labels = keyarr.take(missing)\n                    missing_indexer = com._ensure_int64(l[~check])\n                    cur_labels = result._get_axis(axis).values\n                    cur_indexer = com._ensure_int64(l[check])\n\n                    new_labels = np.empty(tuple([len(indexer)]), dtype=object)\n                    new_labels[cur_indexer] = cur_labels\n                    new_labels[missing_indexer] = missing_labels\n\n                    # reindex with the specified axis\n                    ndim = self.obj.ndim\n                    if axis + 1 > ndim:\n                        raise AssertionError(\"invalid indexing error with \"\n                                             \"non-unique index\")\n\n                    # a unique indexer\n                    if keyarr_is_unique:\n\n                        # see GH5553, make sure we use the right indexer\n                        new_indexer = np.arange(len(indexer))\n                        new_indexer[cur_indexer] = np.arange(\n                            len(result._get_axis(axis))\n                        )\n                        new_indexer[missing_indexer] = -1\n\n                    # we have a non_unique selector, need to use the original\n                    # indexer here\n                    else:\n\n                        # need to retake to have the same size as the indexer\n                        rindexer = indexer.values\n                        rindexer[~check] = 0\n                        result = self.obj.take(rindexer, axis=axis,\n                                               convert=False)\n\n                        # reset the new indexer to account for the new size\n                        new_indexer = np.arange(len(result))\n                        new_indexer[~check] = -1\n\n                    result = result._reindex_with_indexers({\n                        axis: [new_labels, new_indexer]\n                    }, copy=True, allow_dups=True)\n\n                return result\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        \"In the face of ambiguity, refuse the temptation to guess.\"\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        labels = self.obj._get_axis(axis)\n\n        # if we are a scalar indexer and not type correct raise\n        obj = self._convert_scalar_indexer(obj, axis)\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = com.is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except (KeyError, TypeError):\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif _is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n        elif _is_list_like(obj):\n            if com._is_bool_indexer(obj):\n                obj = _check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                if isinstance(obj, Index):\n                    objarr = obj.values\n                else:\n                    objarr = _asarray_tuplesafe(obj)\n\n                # If have integer labels, defer to label-based indexing\n                indexer = labels._convert_list_indexer_for_mixed(objarr, typ=self.name)\n                if indexer is not None:\n                    return indexer\n\n                # this is not the most robust, but...\n                if (isinstance(labels, MultiIndex) and\n                        not isinstance(objarr[0], tuple)):\n                    level = 0\n                    _, indexer = labels.reindex(objarr, level=level)\n\n                    # take all\n                    if indexer is None:\n                        indexer = np.arange(len(labels))\n\n                    check = labels.levels[0].get_indexer(objarr)\n                else:\n                    level = None\n\n                    # unique index\n                    if labels.is_unique:\n                        indexer = check = labels.get_indexer(objarr)\n\n                    # non-unique (dups)\n                    else:\n                        (indexer,\n                         missing) = labels.get_indexer_non_unique(objarr)\n                        check = indexer\n\n                mask = check == -1\n                if mask.any():\n\n                    # mi here\n                    if isinstance(obj, tuple) and is_setter:\n                        return {'key': obj}\n                    raise KeyError('%s not in index' % objarr[mask])\n\n                return _values_from_object(indexer)\n\n        else:\n            try:\n                return labels.get_loc(obj)\n            except KeyError:\n                # allow a not found key only if we are a setter\n                if not is_list_like(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n\n    \"\"\" A primarily location based indexer, with integer fallback \"\"\"\n\n    def _has_valid_type(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif com._is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _getitem_axis(self, key, axis=0):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n        key = _check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj.take(inds, axis=axis, convert=False)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        obj = self.obj\n        if not _need_slice(slice_obj):\n            return obj\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _LocIndexer(_LocationIndexer):\n\n    \"\"\" purely label based location based indexing \"\"\"\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    def _has_valid_type(self, key, axis):\n        ax = self.obj._get_axis(axis)\n\n        # valid for a label where all labels are in the index\n        # slice of lables (where start-end in labels)\n        # slice of integers (only if in the lables)\n        # boolean\n\n        if isinstance(key, slice):\n\n            if ax.is_floating():\n\n                # allowing keys to be slicers with no fallback\n                pass\n\n            else:\n                if key.start is not None:\n                    if key.start not in ax:\n                        raise KeyError(\n                            \"start bound [%s] is not the [%s]\" %\n                            (key.start, self.obj._get_axis_name(axis))\n                        )\n                if key.stop is not None:\n                    if key.stop not in ax:\n                        raise KeyError(\n                            \"stop bound [%s] is not in the [%s]\" %\n                            (key.stop, self.obj._get_axis_name(axis))\n                        )\n\n        elif com._is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n\n            # mi is just a passthru\n            if isinstance(key, tuple) and isinstance(ax, MultiIndex):\n                return True\n\n            # require at least 1 element in the index\n            idx = _ensure_index(key)\n            if len(idx) and not idx.isin(ax).any():\n\n                raise KeyError(\"None of [%s] are in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            return True\n\n        else:\n\n            def error():\n                if isnull(key):\n                    raise ValueError(\n                        \"cannot use label indexing with a null key\")\n                raise KeyError(\"the label [%s] is not in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            try:\n                key = self._convert_scalar_indexer(key, axis)\n                if not key in ax:\n                    error()\n            except (TypeError) as e:\n\n                # python 3 type errors should be raised\n                if 'unorderable' in str(e):  # pragma: no cover\n                    error()\n                raise\n            except:\n                error()\n\n        return True\n\n    def _getitem_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif com._is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif _is_list_like(key):\n\n            # GH 7349\n            # possibly convert a list-like into a nested tuple\n            # but don't convert a list-like of tuples\n            if isinstance(labels, MultiIndex):\n                if not isinstance(key, tuple) and len(key) > 1 and not isinstance(key[0], tuple):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and\n                    isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if _is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [ slice(None) ] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._has_valid_type(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n\n    \"\"\" purely integer based location based indexing \"\"\"\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _has_valid_type(self, key, axis):\n        if com._is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\n                        \"iLocation based boolean indexing on an integer type \"\n                        \"is not available\"\n                    )\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return True\n\n        if isinstance(key, slice):\n            return True\n        elif com.is_integer(key):\n            return self._is_valid_integer(key, axis)\n        elif (_is_list_like(key)):\n            return self._is_valid_list_like(key, axis)\n        return False\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_valid_integer(self, key, axis):\n        # return a boolean if we have a valid integer indexer\n\n        ax = self.obj._get_axis(axis)\n        if key > len(ax):\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n        return True\n\n\n    def _is_valid_list_like(self, key, axis):\n        # return a boolean if we are a valid list-like (e.g. that we dont' have out-of-bounds values)\n\n        # coerce the key to not exceed the maximum size of the index\n        arr = np.array(key)\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if len(arr) and (arr.max() >= l or arr.min() <= -l):\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n        return True\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis=0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim<self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(slice_obj, axis=axis, convert=False)\n\n    def _getitem_axis(self, key, axis=0):\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n\n        elif com._is_bool_indexer(key):\n            self._has_valid_type(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a single integer or a list of integers\n        else:\n\n            if _is_list_like(key):\n\n                # validate list bounds\n                self._is_valid_list_like(key, axis)\n\n                # force an actual list\n                key = list(key)\n\n            else:\n                key = self._convert_scalar_indexer(key, axis)\n\n                if not com.is_integer(key):\n                    raise TypeError(\"Cannot index by location index with a \"\n                                    \"non-integer key\")\n\n                # validate the location\n                self._is_valid_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        elif self._has_valid_type(obj, axis):\n            return obj\n\n        raise ValueError(\"Can only index by location with a [%s]\" %\n                         self._valid_types)\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not _is_list_like(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj.get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key))\n        key.append(value)\n        self.obj.set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" label based scalar accessor \"\"\"\n    _takeable = False\n\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" integer based scalar accessor \"\"\"\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key):\n        \"\"\" require  integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not com.is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n# 32-bit floating point machine epsilon\n_eps = np.finfo('f4').eps\n\n\ndef _length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = abs(step)\n        return (stop - start) / step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef _convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, typ='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if key in obj._data.items:\n            return None\n\n        # we need a timelike key here\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except:\n                return None\n\n    return None\n\n\ndef _is_index_slice(obj):\n    def _is_valid_index(x):\n        return (com.is_integer(x) or com.is_float(x)\n                and np.allclose(x, int(x), rtol=_eps, atol=0))\n\n    def _crit(v):\n        return v is None or _is_valid_index(v)\n\n    both_none = obj.start is None and obj.stop is None\n\n    return not both_none and (_crit(obj.start) and _crit(obj.stop))\n\n\ndef _check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that com._is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = com.isnull(result.values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series key provided')\n\n        result = result.astype(bool).values\n\n    else:\n        # com._is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef _convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n        return the scalar indexer and a boolean indicating if we converted \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef _convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key'])\n                if isinstance(_idx, dict) else _idx)\n    return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])\n\n\ndef _safe_append_to_index(index, key):\n    \"\"\" a safe append to an index, if incorrect type, then catch and recreate\n    \"\"\"\n    try:\n        return index.insert(len(index), key)\n    except:\n\n        # raise here as this is basically an unsafe operation and we want\n        # it to be obvious that you are doing something wrong\n        raise ValueError(\"unsafe appending to index of type {0} with a key \"\n                         \"{1}\".format(index.__class__.__name__, key))\n\n\ndef _maybe_convert_indices(indices, n):\n    \"\"\" if we have negative indicies, translate to postive here\n    if have indicies that are out-of-bounds, raise an IndexError\n    \"\"\"\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.int_)\n\n    mask = indices < 0\n    if mask.any():\n        indices[mask] += n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef _maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef _is_nested_tuple(tup, labels):\n    # check for a compatiable nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    # are we nested tuple of: tuple,list,slice\n    for i, k in enumerate(tup):\n\n        if isinstance(k, (tuple, list, slice)):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\n\ndef _is_null_slice(obj):\n    return (isinstance(obj, slice) and obj.start is None and\n            obj.stop is None and obj.step is None)\n\n\ndef _is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not _is_list_like(key)\n\n\ndef _is_list_like(obj):\n    # Consider namedtuples to be not list like as they are useful as indices\n    return (hasattr(obj, '__iter__')\n            and not isinstance(obj, compat.string_types)\n            and not (isinstance(obj, tuple) and type(obj) is not tuple))\n\n\ndef _need_slice(obj):\n    return (obj.start is not None or\n            obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef _maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n\n",
          "file_after": "# pylint: disable=W0223\n\nfrom datetime import datetime\nfrom pandas.core.index import Index, MultiIndex, _ensure_index\nfrom pandas.compat import range, zip\nimport pandas.compat as compat\nimport pandas.core.common as com\nfrom pandas.core.common import (_is_bool_indexer, is_integer_dtype,\n                                _asarray_tuplesafe, is_list_like, isnull,\n                                ABCSeries, ABCDataFrame, ABCPanel, is_float,\n                                _values_from_object)\nimport pandas.lib as lib\n\nimport numpy as np\n\n# the supported indexers\ndef get_indexers_list():\n\n    return [\n        ('ix',   _IXIndexer),\n        ('iloc', _iLocIndexer),\n        ('loc',  _LocIndexer),\n        ('at',   _AtIndexer),\n        ('iat',  _iAtIndexer),\n    ]\n\n# \"null slice\"\n_NS = slice(None, None)\n\n# the public IndexSlicerMaker\nclass _IndexSlice(object):\n    def __getitem__(self, arg):\n        return arg\nIndexSlice = _IndexSlice()\n\nclass IndexingError(Exception):\n    pass\n\nclass _NDFrameIndexer(object):\n    _valid_types = None\n    _exception = KeyError\n\n    def __init__(self, obj, name):\n        self.obj = obj\n        self.ndim = obj.ndim\n        self.name = name\n        self.axis = None\n\n    def __call__(self, *args, **kwargs):\n        # we need to return a copy of ourselves\n        self = self.__class__(self.obj, self.name)\n\n        # set the passed in values\n        for k, v in compat.iteritems(kwargs):\n            setattr(self,k,v)\n        return self\n\n    def __iter__(self):\n        raise NotImplementedError('ix is not iterable')\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            try:\n                values = self.obj.get_value(*key)\n                if np.isscalar(values):\n                    return values\n            except Exception:\n                pass\n\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _get_label(self, label, axis=0):\n        if self.ndim == 1:\n            # for perf reasons we want to try _xs first\n            # as its basically direct indexing\n            # but will fail when the index is not present\n            # see GH5667\n            try:\n                return self.obj._xs(label, axis=axis)\n            except:\n                return self.obj[label]\n        elif (isinstance(label, tuple) and\n                isinstance(label[axis], slice)):\n            raise IndexingError('no slices here, handle elsewhere')\n\n        return self.obj._xs(label, axis=axis)\n\n    def _get_loc(self, key, axis=0):\n        return self.obj._ixs(key, axis=axis)\n\n    def _slice(self, obj, axis=0, typ=None):\n        return self.obj._slice(obj, axis=axis, typ=typ)\n\n    def __setitem__(self, key, value):\n\n        if self.axis is not None:\n            indexer = self._convert_tuple(key, is_setter=True)\n\n        else:\n\n            # kludgetastic\n            ax = self.obj._get_axis(0)\n            if isinstance(ax, MultiIndex):\n                try:\n                    indexer = ax.get_loc(key)\n                    self._setitem_with_indexer(indexer, value)\n                    return\n                except Exception:\n                    pass\n\n            if isinstance(key, tuple):\n                if len(key) > self.ndim:\n                    raise IndexingError('only tuples of length <= %d supported' %\n                                        self.ndim)\n                indexer = self._convert_tuple(key, is_setter=True)\n            else:\n                indexer = self._convert_to_indexer(key, is_setter=True)\n\n        self._setitem_with_indexer(indexer, value)\n\n    def _has_valid_type(self, k, axis):\n        raise NotImplementedError()\n\n    def _has_valid_tuple(self, key):\n        \"\"\" check the key for valid keys across my indexer \"\"\"\n        for i, k in enumerate(key):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n            if not self._has_valid_type(k, i):\n                raise ValueError(\"Location based indexing can only have [%s] \"\n                                 \"types\" % self._valid_types)\n\n    def _should_validate_iterable(self, axis=0):\n        \"\"\" return a boolean whether this axes needs validation for a passed iterable \"\"\"\n        ax = self.obj._get_axis(axis)\n        if isinstance(ax, MultiIndex):\n            return False\n        elif ax.is_floating():\n            return False\n\n        return True\n\n    def _is_nested_tuple_indexer(self, tup):\n        if any([ isinstance(ax, MultiIndex) for ax in self.obj.axes ]):\n            return any([ _is_nested_tuple(tup,ax) for ax in self.obj.axes ])\n        return False\n\n    def _convert_tuple(self, key, is_setter=False):\n        keyidx = []\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            for i in range(self.ndim):\n                if i == axis:\n                    keyidx.append(self._convert_to_indexer(key, axis=axis, is_setter=is_setter))\n                else:\n                    keyidx.append(slice(None))\n        else:\n            for i, k in enumerate(key):\n                idx = self._convert_to_indexer(k, axis=i, is_setter=is_setter)\n                keyidx.append(idx)\n        return tuple(keyidx)\n\n    def _convert_scalar_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        # a scalar\n        return ax._convert_scalar_indexer(key, typ=self.name)\n\n    def _convert_slice_indexer(self, key, axis):\n        # if we are accessing via lowered dim, use the last dim\n        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n        return ax._convert_slice_indexer(key, typ=self.name)\n\n    def _has_valid_setitem_indexer(self, indexer):\n        return True\n\n    def _has_valid_positional_setitem_indexer(self, indexer):\n        \"\"\" validate that an positional indexer cannot enlarge its target\n            will raise if needed, does not modify the indexer externally \"\"\"\n        if isinstance(indexer, dict):\n            raise IndexError(\"{0} cannot enlarge its target object\"\n                             .format(self.name))\n        else:\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n            for ax, i in zip(self.obj.axes, indexer):\n                if isinstance(i, slice):\n                    # should check the stop slice?\n                    pass\n                elif is_list_like(i):\n                    # should check the elements?\n                    pass\n                elif com.is_integer(i):\n                    if i >= len(ax):\n                        raise IndexError(\"{0} cannot enlarge its target object\"\n                                         .format(self.name))\n                elif isinstance(i, dict):\n                    raise IndexError(\"{0} cannot enlarge its target object\"\n                                     .format(self.name))\n\n        return True\n\n    def _setitem_with_indexer(self, indexer, value):\n\n        self._has_valid_setitem_indexer(indexer)\n\n        # also has the side effect of consolidating in-place\n        from pandas import Panel, DataFrame, Series\n\n        # maybe partial set\n        take_split_path = self.obj._is_mixed_type\n        if isinstance(indexer, tuple):\n            nindexer = []\n            for i, idx in enumerate(indexer):\n                if isinstance(idx, dict):\n\n                    # reindex the axis to the new value\n                    # and set inplace\n                    key, _ = _convert_missing_indexer(idx)\n\n                    # if this is the items axes, then take the main missing\n                    # path first\n                    # this correctly sets the dtype and avoids cache issues\n                    # essentially this separates out the block that is needed\n                    # to possibly be modified\n                    if self.ndim > 1 and i == self.obj._info_axis_number:\n\n                        # add the new item, and set the value\n                        # must have all defined axes if we have a scalar\n                        # or a list-like on the non-info axes if we have a\n                        # list-like\n                        len_non_info_axes = [\n                            len(_ax) for _i, _ax in enumerate(self.obj.axes)\n                            if _i != i\n                        ]\n                        if any([not l for l in len_non_info_axes]):\n                            if not is_list_like(value):\n                                raise ValueError(\"cannot set a frame with no \"\n                                                 \"defined index and a scalar\")\n                            self.obj[key] = value\n                            return self.obj\n\n                        self.obj[key] = np.nan\n\n                        new_indexer = _convert_from_missing_indexer_tuple(\n                            indexer, self.obj.axes)\n                        self._setitem_with_indexer(new_indexer, value)\n                        return self.obj\n\n                    # reindex the axis\n                    # make sure to clear the cache because we are\n                    # just replacing the block manager here\n                    # so the object is the same\n                    index = self.obj._get_axis(i)\n                    labels = _safe_append_to_index(index, key)\n                    self.obj._data = self.obj.reindex_axis(labels, i)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    self.obj.is_copy=None\n\n                    if isinstance(labels, MultiIndex):\n                        self.obj.sortlevel(inplace=True)\n                        labels = self.obj._get_axis(i)\n\n                    nindexer.append(labels.get_loc(key))\n\n                else:\n                    nindexer.append(idx)\n\n            indexer = tuple(nindexer)\n        else:\n\n            indexer, missing = _convert_missing_indexer(indexer)\n\n            if missing:\n\n                # reindex the axis to the new value\n                # and set inplace\n                if self.ndim == 1:\n                    index = self.obj.index\n                    if len(index) == 0:\n                        new_index = Index([indexer])\n                    else:\n                        new_index = _safe_append_to_index(index, indexer)\n\n                    # this preserves dtype of the value\n                    new_values = Series([value]).values\n                    if len(self.obj.values):\n                        new_values = np.concatenate([self.obj.values,\n                                                     new_values])\n\n                    self.obj._data = self.obj._constructor(\n                        new_values, index=new_index, name=self.obj.name)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                elif self.ndim == 2:\n\n                    # no columns and scalar\n                    if not len(self.obj.columns):\n                        raise ValueError(\n                            \"cannot set a frame with no defined columns\"\n                        )\n\n                    # append a Series\n                    if isinstance(value, Series):\n\n                        value = value.reindex(index=self.obj.columns,copy=True)\n                        value.name = indexer\n\n                    # a list-list\n                    else:\n\n                        # must have conforming columns\n                        if com.is_list_like(value):\n                            if len(value) != len(self.obj.columns):\n                                raise ValueError(\n                                    \"cannot set a row with mismatched columns\"\n                                    )\n\n                        value = Series(value,index=self.obj.columns,name=indexer)\n\n                    self.obj._data = self.obj.append(value)._data\n                    self.obj._maybe_update_cacher(clear=True)\n                    return self.obj\n\n                # set using setitem (Panel and > dims)\n                elif self.ndim >= 3:\n                    return self.obj.__setitem__(indexer, value)\n\n        # set\n        info_axis = self.obj._info_axis_number\n        item_labels = self.obj._get_axis(info_axis)\n\n        # if we have a complicated setup, take the split path\n        if (isinstance(indexer, tuple) and\n                any([isinstance(ax, MultiIndex) for ax in self.obj.axes])):\n            take_split_path = True\n\n        # align and set the values\n        if take_split_path:\n\n            if not isinstance(indexer, tuple):\n                indexer = self._tuplify(indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            info_idx = indexer[info_axis]\n            if com.is_integer(info_idx):\n                info_idx = [info_idx]\n            labels = item_labels[info_idx]\n\n            # if we have a partial multiindex, then need to adjust the plane\n            # indexer here\n            if (len(labels) == 1 and\n                    isinstance(self.obj[labels[0]].index, MultiIndex)):\n                item = labels[0]\n                obj = self.obj[item]\n                index = obj.index\n                idx = indexer[:info_axis][0]\n\n                plane_indexer = tuple([idx]) + indexer[info_axis + 1:]\n                lplane_indexer = _length_of_indexer(plane_indexer[0], index)\n\n                # require that we are setting the right number of values that\n                # we are indexing\n                if is_list_like(value) and np.iterable(value) and lplane_indexer != len(value):\n\n                    if len(obj[idx]) != len(value):\n                        raise ValueError(\n                            \"cannot set using a multi-index selection indexer \"\n                            \"with a different length than the value\"\n                        )\n\n                    # make sure we have an ndarray\n                    value = getattr(value,'values',value).ravel()\n\n                    # we can directly set the series here\n                    # as we select a slice indexer on the mi\n                    idx = index._convert_slice_indexer(idx)\n                    obj = obj.copy()\n                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n                    self.obj[item] = obj\n                    return\n\n            # non-mi\n            else:\n                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1:]\n                if info_axis > 0:\n                    plane_axis = self.obj.axes[:info_axis][0]\n                    lplane_indexer = _length_of_indexer(plane_indexer[0],\n                                                        plane_axis)\n                else:\n                    lplane_indexer = 0\n\n            def setter(item, v):\n                s = self.obj[item]\n                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n\n                # perform the equivalent of a setitem on the info axis\n                # as we have a null slice which means essentially reassign to the columns\n                # of a multi-dim object\n                # GH6149\n                if isinstance(pi, tuple) and all(_is_null_slice(idx) for idx in pi):\n                    s = v\n                else:\n                    # set the item, possibly having a dtype change\n                    s = s.copy()\n                    s._data = s._data.setitem(indexer=pi, value=v)\n                    s._maybe_update_cacher(clear=True)\n\n                # reset the sliced object if unique\n                self.obj[item] = s\n\n            def can_do_equal_len():\n                \"\"\" return True if we have an equal len settable \"\"\"\n                if not len(labels) == 1 or not np.iterable(value):\n                    return False\n\n                l = len(value)\n                item = labels[0]\n                index = self.obj[item].index\n\n                # equal len list/ndarray\n                if len(index) == l:\n                    return True\n                elif lplane_indexer == l:\n                    return True\n\n                return False\n\n            # we need an interable, with a ndim of at least 1\n            # eg. don't pass thru np.array(0)\n            if _is_list_like(value) and getattr(value,'ndim',1) > 0:\n\n                # we have an equal len Frame\n                if isinstance(value, ABCDataFrame) and value.ndim > 1:\n\n                    for item in labels:\n\n                        # align to\n                        if item in value:\n                            v = value[item]\n                            i = self.obj[item].index\n                            v = v.reindex(i & v.index)\n\n                            setter(item, v.values)\n                        else:\n                            setter(item, np.nan)\n\n                # we have an equal len ndarray/convertible to our labels\n                elif np.array(value).ndim == 2:\n\n                    # note that this coerces the dtype if we are mixed\n                    # GH 7551\n                    value = np.array(value,dtype=object)\n                    if len(labels) != value.shape[1]:\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an ndarray')\n\n                    for i, item in enumerate(labels):\n\n                        # setting with a list, recoerces\n                        setter(item, value[:, i].tolist())\n\n                # we have an equal len list/ndarray\n                elif can_do_equal_len():\n                    setter(labels[0], value)\n\n                # per label values\n                else:\n\n                    if len(labels) != len(value):\n                        raise ValueError('Must have equal len keys and value '\n                                         'when setting with an iterable')\n\n                    for item, v in zip(labels, value):\n                        setter(item, v)\n            else:\n\n                # scalar\n                for item in labels:\n                    setter(item, value)\n\n        else:\n            if isinstance(indexer, tuple):\n                indexer = _maybe_convert_ix(*indexer)\n\n            if isinstance(value, ABCSeries):\n                value = self._align_series(indexer, value)\n\n            elif isinstance(value, ABCDataFrame):\n                value = self._align_frame(indexer, value)\n\n            if isinstance(value, ABCPanel):\n                value = self._align_panel(indexer, value)\n\n            # check for chained assignment\n            self.obj._check_is_chained_assignment_possible()\n\n            # actually do the set\n            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n            self.obj._maybe_update_cacher(clear=True)\n\n    def _align_series(self, indexer, ser):\n        # indexer to assign Series can be tuple, slice, scalar\n        if isinstance(indexer, (slice, np.ndarray, list)):\n            indexer = tuple([indexer])\n\n        if isinstance(indexer, tuple):\n\n            aligners = [not _is_null_slice(idx) for idx in indexer]\n            sum_aligners = sum(aligners)\n            single_aligner = sum_aligners == 1\n            is_frame = self.obj.ndim == 2\n            is_panel = self.obj.ndim >= 3\n            obj = self.obj\n\n            # are we a single alignable value on a non-primary\n            # dim (e.g. panel: 1,2, or frame: 0) ?\n            # hence need to align to a single axis dimension\n            # rather that find all valid dims\n\n            # frame\n            if is_frame:\n                single_aligner = single_aligner and aligners[0]\n\n            # panel\n            elif is_panel:\n                single_aligner = (single_aligner and\n                                  (aligners[1] or aligners[2]))\n\n            # we have a frame, with multiple indexers on both axes; and a\n            # series, so need to broadcast (see GH5206)\n            if (sum_aligners == self.ndim and\n                    all([com._is_sequence(_) for _ in indexer])):\n                ser = ser.reindex(obj.axes[0][indexer[0].ravel()],\n                                  copy=True).values\n\n                # single indexer\n                if len(indexer) > 1:\n                    l = len(indexer[1].ravel())\n                    ser = np.tile(ser, l).reshape(l, -1).T\n\n                return ser\n\n            for i, idx in enumerate(indexer):\n                ax = obj.axes[i]\n\n                # multiple aligners (or null slices)\n                if com._is_sequence(idx) or isinstance(idx, slice):\n                    if single_aligner and _is_null_slice(idx):\n                        continue\n                    new_ix = ax[idx]\n                    if not is_list_like(new_ix):\n                        new_ix = Index([new_ix])\n                    else:\n                        new_ix = Index(new_ix.ravel())\n                    if ser.index.equals(new_ix) or not len(new_ix):\n                        return ser.values.copy()\n\n                    return ser.reindex(new_ix).values\n\n                # 2 dims\n                elif single_aligner and is_frame:\n\n                    # reindex along index\n                    ax = self.obj.axes[1]\n                    if ser.index.equals(ax) or not len(ax):\n                        return ser.values.copy()\n                    return ser.reindex(ax).values\n\n                # >2 dims\n                elif single_aligner:\n\n                    broadcast = []\n                    for n, labels in enumerate(self.obj._get_plane_axes(i)):\n\n                        # reindex along the matching dimensions\n                        if len(labels & ser.index):\n                            ser = ser.reindex(labels)\n                        else:\n                            broadcast.append((n, len(labels)))\n\n                    # broadcast along other dims\n                    ser = ser.values.copy()\n                    for (axis, l) in broadcast:\n                        shape = [-1] * (len(broadcast) + 1)\n                        shape[axis] = l\n                        ser = np.tile(ser, l).reshape(shape)\n\n                    if self.obj.ndim == 3:\n                        ser = ser.T\n\n                    return ser\n\n        elif np.isscalar(indexer):\n            ax = self.obj._get_axis(1)\n\n            if ser.index.equals(ax):\n                return ser.values.copy()\n\n            return ser.reindex(ax).values\n\n        raise ValueError('Incompatible indexer with Series')\n\n    def _align_frame(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n        if isinstance(indexer, tuple):\n            idx, cols = None, None\n            sindexers = []\n            for i, ix in enumerate(indexer):\n                ax = self.obj.axes[i]\n                if com._is_sequence(ix) or isinstance(ix, slice):\n                    if idx is None:\n                        idx = ax[ix].ravel()\n                    elif cols is None:\n                        cols = ax[ix].ravel()\n                    else:\n                        break\n                else:\n                    sindexers.append(i)\n\n            # panel\n            if is_panel:\n                if len(sindexers) == 1 and idx is None and cols is None:\n                    if sindexers[0] == 0:\n                        df = df.T\n                    return self.obj.conform(df, axis=sindexers[0])\n                df = df.T\n\n            if idx is not None and cols is not None:\n                if df.index.equals(idx) and df.columns.equals(cols):\n                    val = df.copy().values\n                else:\n                    val = df.reindex(idx, columns=cols).values\n                return val\n\n        elif ((isinstance(indexer, slice) or com.is_list_like(indexer))\n              and is_frame):\n            ax = self.obj.index[indexer]\n            if df.index.equals(ax):\n                val = df.copy().values\n            else:\n\n                # we have a multi-index and are trying to align\n                # with a particular, level GH3738\n                if isinstance(ax, MultiIndex) and isinstance(\n                    df.index, MultiIndex) and ax.nlevels != df.index.nlevels:\n                    raise TypeError(\"cannot align on a multi-index with out specifying the join levels\")\n\n                val = df.reindex(index=ax).values\n            return val\n\n        elif np.isscalar(indexer) and not is_frame:\n            idx = self.obj.axes[1]\n            cols = self.obj.axes[2]\n\n            # by definition we are indexing on the 0th axis\n            if is_panel:\n                df = df.T\n\n            if idx.equals(df.index) and cols.equals(df.columns):\n                return df.copy().values\n\n            # a passed in dataframe which is actually a transpose\n            # of what is needed\n            elif idx.equals(df.columns) and cols.equals(df.index):\n                return df.T.copy().values\n\n            return df.reindex(idx, columns=cols).values\n\n        raise ValueError('Incompatible indexer with DataFrame')\n\n    def _align_panel(self, indexer, df):\n        is_frame = self.obj.ndim == 2\n        is_panel = self.obj.ndim >= 3\n        raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n                                  \"yet!\")\n\n    def _getitem_tuple(self, tup):\n        try:\n            return self._getitem_lowerdim(tup)\n        except IndexingError:\n            pass\n\n        # no multi-index, so validate all of the indexers\n        self._has_valid_tuple(tup)\n\n        # ugly hack for GH #836\n        if self._multi_take_opportunity(tup):\n            return self._multi_take(tup)\n\n        # no shortcut needed\n        retval = self.obj\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n\n        return retval\n\n    def _multi_take_opportunity(self, tup):\n        from pandas.core.generic import NDFrame\n\n        # ugly hack for GH #836\n        if not isinstance(self.obj, NDFrame):\n            return False\n\n        if not all(_is_list_like(x) for x in tup):\n            return False\n\n        # just too complicated\n        for indexer, ax in zip(tup, self.obj._data.axes):\n            if isinstance(ax, MultiIndex):\n                return False\n            elif com._is_bool_indexer(indexer):\n                return False\n            elif not ax.is_unique:\n                return False\n\n        return True\n\n    def _multi_take(self, tup):\n        \"\"\" create the reindex map for our objects, raise the _exception if we\n        can't create the indexer\n        \"\"\"\n        try:\n            o = self.obj\n            d = dict([\n                (a, self._convert_for_reindex(t, axis=o._get_axis_number(a)))\n                for t, a in zip(tup, o._AXIS_ORDERS)\n            ])\n            return o.reindex(**d)\n        except:\n            raise self._exception\n\n    def _convert_for_reindex(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if com._is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            return labels[key]\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            if is_integer_dtype(keyarr) and not labels.is_integer():\n                keyarr = com._ensure_platform_int(keyarr)\n                return labels.take(keyarr)\n\n            return keyarr\n\n    def _handle_lowerdim_multi_index_axis0(self, tup):\n        # we have an axis0 multi-index, handle or raise\n\n        try:\n            # fast path for series or for tup devoid of slices\n            return self._get_label(tup, axis=0)\n        except TypeError:\n            # slices are unhashable\n            pass\n        except Exception as e1:\n            if isinstance(tup[0], (slice, Index)):\n                raise IndexingError(\"Handle elsewhere\")\n\n            # raise the error if we are not sorted\n            ax0 = self.obj._get_axis(0)\n            if not ax0.is_lexsorted_for_tuple(tup):\n                raise e1\n\n        return None\n\n    def _getitem_lowerdim(self, tup):\n\n        # we can directly get the axis result since the axis is specified\n        if self.axis is not None:\n            axis = self.obj._get_axis_number(self.axis)\n            return self._getitem_axis(tup, axis=axis)\n\n        # we may have a nested tuples indexer here\n        if self._is_nested_tuple_indexer(tup):\n            return self._getitem_nested_tuple(tup)\n\n        # we maybe be using a tuple to represent multiple dimensions here\n        ax0 = self.obj._get_axis(0)\n        if isinstance(ax0, MultiIndex):\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n        if len(tup) > self.obj.ndim:\n            raise IndexingError(\"Too many indexers. handle elsewhere\")\n\n        # to avoid wasted computation\n        # df.ix[d1:d2, 0] -> columns first (True)\n        # df.ix[0, ['C', 'B', A']] -> rows first (False)\n        for i, key in enumerate(tup):\n            if _is_label_like(key) or isinstance(key, tuple):\n                section = self._getitem_axis(key, axis=i)\n\n                # we have yielded a scalar ?\n                if not _is_list_like(section):\n                    return section\n\n                elif section.ndim == self.ndim:\n                    # we're in the middle of slicing through a MultiIndex\n                    # revise the key wrt to `section` by inserting an _NS\n                    new_key = tup[:i] + (_NS,) + tup[i + 1:]\n\n                else:\n                    new_key = tup[:i] + tup[i + 1:]\n\n                    # unfortunately need an odious kludge here because of\n                    # DataFrame transposing convention\n                    if (isinstance(section, ABCDataFrame) and i > 0\n                            and len(new_key) == 2):\n                        a, b = new_key\n                        new_key = b, a\n\n                    if len(new_key) == 1:\n                        new_key, = new_key\n\n                # This is an elided recursive call to iloc/loc/etc'\n                return getattr(section, self.name)[new_key]\n\n        raise IndexingError('not applicable')\n\n    def _getitem_nested_tuple(self, tup):\n        # we have a nested tuple so have at least 1 multi-index level\n        # we should be able to match up the dimensionaility here\n\n        # we have too many indexers for our dim, but have at least 1\n        # multi-index dimension, try to see if we have something like\n        # a tuple passed to a series with a multi-index\n        if len(tup) > self.ndim:\n            result = self._handle_lowerdim_multi_index_axis0(tup)\n            if result is not None:\n                return result\n\n            # this is a series with a multi-index specified a tuple of selectors\n            return self._getitem_axis(tup, axis=0)\n\n        # handle the multi-axis by taking sections and reducing\n        # this is iterative\n        obj = self.obj\n        axis = 0\n        for i, key in enumerate(tup):\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            current_ndim = obj.ndim\n            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n            axis += 1\n\n            # if we have a scalar, we are done\n            if np.isscalar(obj) or not hasattr(obj,'ndim'):\n                break\n\n            # has the dim of the obj changed?\n            # GH 7199\n            if obj.ndim < current_ndim:\n\n                # GH 7516\n                # if had a 3 dim and are going to a 2d\n                # axes are reversed on a DataFrame\n                if i >= 1 and current_ndim == 3 and obj.ndim == 2:\n                    obj = obj.T\n\n                axis -= 1\n\n        return obj\n\n    def _getitem_axis(self, key, axis=0):\n\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n        if isinstance(key, slice):\n            return self._get_slice_axis(key, axis=axis)\n        elif _is_list_like(key) and not (isinstance(key, tuple) and\n                                         isinstance(labels, MultiIndex)):\n\n            if hasattr(key, 'ndim') and key.ndim > 1:\n                raise ValueError('Cannot index with multidimensional key')\n\n            return self._getitem_iterable(key, axis=axis)\n        else:\n            if com.is_integer(key):\n                if axis == 0 and isinstance(labels, MultiIndex):\n                    try:\n                        return self._get_label(key, axis=axis)\n                    except (KeyError, TypeError):\n                        if self.obj.index.levels[0].is_integer():\n                            raise\n\n                # this is the fallback! (for a non-float, non-integer index)\n                if not labels.is_floating() and not labels.is_integer():\n                    return self._get_loc(key, axis=axis)\n\n            return self._get_label(key, axis=axis)\n\n    def _getitem_iterable(self, key, axis=0):\n        if self._should_validate_iterable(axis):\n            self._has_valid_type(key, axis)\n\n        labels = self.obj._get_axis(axis)\n\n        def _reindex(keys, level=None):\n\n            try:\n                result = self.obj.reindex_axis(keys, axis=axis, level=level)\n            except AttributeError:\n                # Series\n                if axis != 0:\n                    raise AssertionError('axis must be 0')\n                return self.obj.reindex(keys, level=level)\n\n            # this is an error as we are trying to find\n            # keys in a multi-index that don't exist\n            if isinstance(labels, MultiIndex) and level is not None:\n                if hasattr(result,'ndim') and not np.prod(result.shape) and len(keys):\n                    raise KeyError(\"cannot index a multi-index axis with these keys\")\n\n            return result\n\n        if com._is_bool_indexer(key):\n            key = _check_bool_indexer(labels, key)\n            inds, = key.nonzero()\n            return self.obj.take(inds, axis=axis, convert=False)\n        else:\n            if isinstance(key, Index):\n                # want Index objects to pass through untouched\n                keyarr = key\n            else:\n                # asarray can be unsafe, NumPy strings are weird\n                keyarr = _asarray_tuplesafe(key)\n\n            # handle a mixed integer scenario\n            indexer = labels._convert_list_indexer_for_mixed(keyarr, typ=self.name)\n            if indexer is not None:\n                return self.obj.take(indexer, axis=axis)\n\n            # this is not the most robust, but...\n            if (isinstance(labels, MultiIndex) and len(keyarr) and\n                    not isinstance(keyarr[0], tuple)):\n                level = 0\n            else:\n                level = None\n\n            keyarr_is_unique = Index(keyarr).is_unique\n\n            # existing labels are unique and indexer is unique\n            if labels.is_unique and keyarr_is_unique:\n                return _reindex(keyarr, level=level)\n\n            else:\n                indexer, missing = labels.get_indexer_non_unique(keyarr)\n                check = indexer != -1\n                result = self.obj.take(indexer[check], axis=axis,\n                                       convert=False)\n\n                # need to merge the result labels and the missing labels\n                if len(missing):\n                    l = np.arange(len(indexer))\n\n                    missing = com._ensure_platform_int(missing)\n                    missing_labels = keyarr.take(missing)\n                    missing_indexer = com._ensure_int64(l[~check])\n                    cur_labels = result._get_axis(axis).values\n                    cur_indexer = com._ensure_int64(l[check])\n\n                    new_labels = np.empty(tuple([len(indexer)]), dtype=object)\n                    new_labels[cur_indexer] = cur_labels\n                    new_labels[missing_indexer] = missing_labels\n\n                    # reindex with the specified axis\n                    ndim = self.obj.ndim\n                    if axis + 1 > ndim:\n                        raise AssertionError(\"invalid indexing error with \"\n                                             \"non-unique index\")\n\n                    # a unique indexer\n                    if keyarr_is_unique:\n\n                        # see GH5553, make sure we use the right indexer\n                        new_indexer = np.arange(len(indexer))\n                        new_indexer[cur_indexer] = np.arange(\n                            len(result._get_axis(axis))\n                        )\n                        new_indexer[missing_indexer] = -1\n\n                    # we have a non_unique selector, need to use the original\n                    # indexer here\n                    else:\n\n                        # need to retake to have the same size as the indexer\n                        rindexer = indexer.values\n                        rindexer[~check] = 0\n                        result = self.obj.take(rindexer, axis=axis,\n                                               convert=False)\n\n                        # reset the new indexer to account for the new size\n                        new_indexer = np.arange(len(result))\n                        new_indexer[~check] = -1\n\n                    result = result._reindex_with_indexers({\n                        axis: [new_labels, new_indexer]\n                    }, copy=True, allow_dups=True)\n\n                return result\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\"\n        Convert indexing key into something we can use to do actual fancy\n        indexing on an ndarray\n\n        Examples\n        ix[:5] -> slice(0, 5)\n        ix[[1,2,3]] -> [1,2,3]\n        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n\n        Going by Zen of Python?\n        \"In the face of ambiguity, refuse the temptation to guess.\"\n        raise AmbiguousIndexError with integer labels?\n        - No, prefer label-based indexing\n        \"\"\"\n        labels = self.obj._get_axis(axis)\n\n        # if we are a scalar indexer and not type correct raise\n        obj = self._convert_scalar_indexer(obj, axis)\n\n        # see if we are positional in nature\n        is_int_index = labels.is_integer()\n        is_int_positional = com.is_integer(obj) and not is_int_index\n\n        # if we are a label return me\n        try:\n            return labels.get_loc(obj)\n        except (KeyError, TypeError):\n            pass\n        except (ValueError):\n            if not is_int_positional:\n                raise\n\n        # a positional\n        if is_int_positional:\n\n            # if we are setting and its not a valid location\n            # its an insert which fails by definition\n            if is_setter:\n\n                # always valid\n                if self.name == 'loc':\n                    return {'key': obj}\n\n                # a positional\n                if (obj >= self.obj.shape[axis] and\n                        not isinstance(labels, MultiIndex)):\n                    raise ValueError(\"cannot set by positional indexing with \"\n                                     \"enlargement\")\n\n            return obj\n\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif _is_nested_tuple(obj, labels):\n            return labels.get_locs(obj)\n        elif _is_list_like(obj):\n            if com._is_bool_indexer(obj):\n                obj = _check_bool_indexer(labels, obj)\n                inds, = obj.nonzero()\n                return inds\n            else:\n                if isinstance(obj, Index):\n                    objarr = obj.values\n                else:\n                    objarr = _asarray_tuplesafe(obj)\n\n                # If have integer labels, defer to label-based indexing\n                indexer = labels._convert_list_indexer_for_mixed(objarr, typ=self.name)\n                if indexer is not None:\n                    return indexer\n\n                # this is not the most robust, but...\n                if (isinstance(labels, MultiIndex) and\n                        not isinstance(objarr[0], tuple)):\n                    level = 0\n                    _, indexer = labels.reindex(objarr, level=level)\n\n                    # take all\n                    if indexer is None:\n                        indexer = np.arange(len(labels))\n\n                    check = labels.levels[0].get_indexer(objarr)\n                else:\n                    level = None\n\n                    # unique index\n                    if labels.is_unique:\n                        indexer = check = labels.get_indexer(objarr)\n\n                    # non-unique (dups)\n                    else:\n                        (indexer,\n                         missing) = labels.get_indexer_non_unique(objarr)\n                        check = indexer\n\n                mask = check == -1\n                if mask.any():\n\n                    # mi here\n                    if isinstance(obj, tuple) and is_setter:\n                        return {'key': obj}\n                    raise KeyError('%s not in index' % objarr[mask])\n\n                return _values_from_object(indexer)\n\n        else:\n            try:\n                return labels.get_loc(obj)\n            except KeyError:\n                # allow a not found key only if we are a setter\n                if not is_list_like(obj) and is_setter:\n                    return {'key': obj}\n                raise\n\n    def _tuplify(self, loc):\n        tup = [slice(None, None) for _ in range(self.ndim)]\n        tup[0] = loc\n        return tuple(tup)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n        indexer = self._convert_slice_indexer(slice_obj, axis)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _IXIndexer(_NDFrameIndexer):\n\n    \"\"\" A primarily location based indexer, with integer fallback \"\"\"\n\n    def _has_valid_type(self, key, axis):\n        if isinstance(key, slice):\n            return True\n\n        elif com._is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n            return True\n\n        else:\n\n            self._convert_scalar_indexer(key, axis)\n\n        return True\n\n\nclass _LocationIndexer(_NDFrameIndexer):\n    _exception = Exception\n\n    def __getitem__(self, key):\n        if type(key) is tuple:\n            return self._getitem_tuple(key)\n        else:\n            return self._getitem_axis(key, axis=0)\n\n    def _getitem_axis(self, key, axis=0):\n        raise NotImplementedError()\n\n    def _getbool_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n        key = _check_bool_indexer(labels, key)\n        inds, = key.nonzero()\n        try:\n            return self.obj.take(inds, axis=axis, convert=False)\n        except Exception as detail:\n            raise self._exception(detail)\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\n        obj = self.obj\n        if not _need_slice(slice_obj):\n            return obj\n\n        labels = obj._get_axis(axis)\n        indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n                                       slice_obj.step)\n\n        if isinstance(indexer, slice):\n            return self._slice(indexer, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(indexer, axis=axis, convert=False)\n\n\nclass _LocIndexer(_LocationIndexer):\n\n    \"\"\" purely label based location based indexing \"\"\"\n    _valid_types = (\"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n                    \"endpoints included! Can be slices of integers if the \"\n                    \"index is integers), listlike of labels, boolean\")\n    _exception = KeyError\n\n    def _has_valid_type(self, key, axis):\n        ax = self.obj._get_axis(axis)\n\n        # valid for a label where all labels are in the index\n        # slice of lables (where start-end in labels)\n        # slice of integers (only if in the lables)\n        # boolean\n\n        if isinstance(key, slice):\n\n            if ax.is_floating():\n\n                # allowing keys to be slicers with no fallback\n                pass\n\n            else:\n                if key.start is not None:\n                    if key.start not in ax:\n                        raise KeyError(\n                            \"start bound [%s] is not the [%s]\" %\n                            (key.start, self.obj._get_axis_name(axis))\n                        )\n                if key.stop is not None:\n                    if key.stop not in ax:\n                        raise KeyError(\n                            \"stop bound [%s] is not in the [%s]\" %\n                            (key.stop, self.obj._get_axis_name(axis))\n                        )\n\n        elif com._is_bool_indexer(key):\n            return True\n\n        elif _is_list_like(key):\n\n            # mi is just a passthru\n            if isinstance(key, tuple) and isinstance(ax, MultiIndex):\n                return True\n\n            # require at least 1 element in the index\n            idx = _ensure_index(key)\n            if len(idx) and not idx.isin(ax).any():\n\n                raise KeyError(\"None of [%s] are in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            return True\n\n        else:\n\n            def error():\n                if isnull(key):\n                    raise ValueError(\n                        \"cannot use label indexing with a null key\")\n                raise KeyError(\"the label [%s] is not in the [%s]\" %\n                               (key, self.obj._get_axis_name(axis)))\n\n            try:\n                key = self._convert_scalar_indexer(key, axis)\n                if not key in ax:\n                    error()\n            except (TypeError) as e:\n\n                # python 3 type errors should be raised\n                if 'unorderable' in str(e):  # pragma: no cover\n                    error()\n                raise\n            except:\n                error()\n\n        return True\n\n    def _getitem_axis(self, key, axis=0):\n        labels = self.obj._get_axis(axis)\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n        elif com._is_bool_indexer(key):\n            return self._getbool_axis(key, axis=axis)\n        elif _is_list_like(key):\n\n            # GH 7349\n            # possibly convert a list-like into a nested tuple\n            # but don't convert a list-like of tuples\n            if isinstance(labels, MultiIndex):\n                if not isinstance(key, tuple) and len(key) > 1 and not isinstance(key[0], tuple):\n                    key = tuple([key])\n\n            # an iterable multi-selection\n            if not (isinstance(key, tuple) and\n                    isinstance(labels, MultiIndex)):\n\n                if hasattr(key, 'ndim') and key.ndim > 1:\n                    raise ValueError('Cannot index with multidimensional key')\n\n                return self._getitem_iterable(key, axis=axis)\n\n            # nested tuple slicing\n            if _is_nested_tuple(key, labels):\n                locs = labels.get_locs(key)\n                indexer = [ slice(None) ] * self.ndim\n                indexer[axis] = locs\n                return self.obj.iloc[tuple(indexer)]\n\n        # fall thru to straight lookup\n        self._has_valid_type(key, axis)\n        return self._get_label(key, axis=axis)\n\n\nclass _iLocIndexer(_LocationIndexer):\n\n    \"\"\" purely integer based location based indexing \"\"\"\n    _valid_types = (\"integer, integer slice (START point is INCLUDED, END \"\n                    \"point is EXCLUDED), listlike of integers, boolean array\")\n    _exception = IndexError\n\n    def _has_valid_type(self, key, axis):\n        if com._is_bool_indexer(key):\n            if hasattr(key, 'index') and isinstance(key.index, Index):\n                if key.index.inferred_type == 'integer':\n                    raise NotImplementedError(\n                        \"iLocation based boolean indexing on an integer type \"\n                        \"is not available\"\n                    )\n                raise ValueError(\"iLocation based boolean indexing cannot use \"\n                                 \"an indexable as a mask\")\n            return True\n\n        if isinstance(key, slice):\n            return True\n        elif com.is_integer(key):\n            return self._is_valid_integer(key, axis)\n        elif (_is_list_like(key)):\n            return self._is_valid_list_like(key, axis)\n        return False\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _is_valid_integer(self, key, axis):\n        # return a boolean if we have a valid integer indexer\n\n        ax = self.obj._get_axis(axis)\n        if key > len(ax):\n            raise IndexError(\"single positional indexer is out-of-bounds\")\n        return True\n\n\n    def _is_valid_list_like(self, key, axis):\n        # return a boolean if we are a valid list-like (e.g. that we dont' have out-of-bounds values)\n\n        # coerce the key to not exceed the maximum size of the index\n        arr = np.array(key)\n        ax = self.obj._get_axis(axis)\n        l = len(ax)\n        if len(arr) and (arr.max() >= l or arr.min() <= -l):\n            raise IndexError(\"positional indexers are out-of-bounds\")\n\n        return True\n\n    def _getitem_tuple(self, tup):\n\n        self._has_valid_tuple(tup)\n        try:\n            return self._getitem_lowerdim(tup)\n        except:\n            pass\n\n        retval = self.obj\n        axis=0\n        for i, key in enumerate(tup):\n            if i >= self.obj.ndim:\n                raise IndexingError('Too many indexers')\n\n            if _is_null_slice(key):\n                axis += 1\n                continue\n\n            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n\n            # if the dim was reduced, then pass a lower-dim the next time\n            if retval.ndim<self.ndim:\n                axis -= 1\n\n            # try to get for the next axis\n            axis += 1\n\n        return retval\n\n    def _get_slice_axis(self, slice_obj, axis=0):\n        obj = self.obj\n\n        if not _need_slice(slice_obj):\n            return obj\n\n        slice_obj = self._convert_slice_indexer(slice_obj, axis)\n        if isinstance(slice_obj, slice):\n            return self._slice(slice_obj, axis=axis, typ='iloc')\n        else:\n            return self.obj.take(slice_obj, axis=axis, convert=False)\n\n    def _getitem_axis(self, key, axis=0):\n\n        if isinstance(key, slice):\n            self._has_valid_type(key, axis)\n            return self._get_slice_axis(key, axis=axis)\n\n        elif com._is_bool_indexer(key):\n            self._has_valid_type(key, axis)\n            return self._getbool_axis(key, axis=axis)\n\n        # a single integer or a list of integers\n        else:\n\n            if _is_list_like(key):\n\n                # validate list bounds\n                self._is_valid_list_like(key, axis)\n\n                # force an actual list\n                key = list(key)\n\n            else:\n                key = self._convert_scalar_indexer(key, axis)\n\n                if not com.is_integer(key):\n                    raise TypeError(\"Cannot index by location index with a \"\n                                    \"non-integer key\")\n\n                # validate the location\n                self._is_valid_integer(key, axis)\n\n            return self._get_loc(key, axis=axis)\n\n    def _convert_to_indexer(self, obj, axis=0, is_setter=False):\n        \"\"\" much simpler as we only have to deal with our valid types \"\"\"\n\n        # make need to convert a float key\n        if isinstance(obj, slice):\n            return self._convert_slice_indexer(obj, axis)\n\n        elif is_float(obj):\n            return self._convert_scalar_indexer(obj, axis)\n\n        elif self._has_valid_type(obj, axis):\n            return obj\n\n        raise ValueError(\"Can only index by location with a [%s]\" %\n                         self._valid_types)\n\n\nclass _ScalarAccessIndexer(_NDFrameIndexer):\n\n    \"\"\" access scalars quickly \"\"\"\n\n    def _convert_key(self, key):\n        return list(key)\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n\n            # we could have a convertible item here (e.g. Timestamp)\n            if not _is_list_like(key):\n                key = tuple([key])\n            else:\n                raise ValueError('Invalid call for scalar access (getting)!')\n\n        key = self._convert_key(key)\n        return self.obj.get_value(*key, takeable=self._takeable)\n\n    def __setitem__(self, key, value):\n        if not isinstance(key, tuple):\n            key = self._tuplify(key)\n        if len(key) != self.obj.ndim:\n            raise ValueError('Not enough indexers for scalar access '\n                             '(setting)!')\n        key = list(self._convert_key(key))\n        key.append(value)\n        self.obj.set_value(*key, takeable=self._takeable)\n\n\nclass _AtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" label based scalar accessor \"\"\"\n    _takeable = False\n\n    def _convert_key(self, key):\n        \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not com.is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index can only have integer \"\n                                     \"indexers\")\n            else:\n                if com.is_integer(i):\n                    raise ValueError(\"At based indexing on an non-integer index can only have non-integer \"\n                                     \"indexers\")\n        return key\n\nclass _iAtIndexer(_ScalarAccessIndexer):\n\n    \"\"\" integer based scalar accessor \"\"\"\n    _takeable = True\n\n    def _has_valid_setitem_indexer(self, indexer):\n        self._has_valid_positional_setitem_indexer(indexer)\n\n    def _convert_key(self, key):\n        \"\"\" require  integer args (and convert to label arguments) \"\"\"\n        for a, i in zip(self.obj.axes, key):\n            if not com.is_integer(i):\n                raise ValueError(\"iAt based indexing can only have integer \"\n                                 \"indexers\")\n        return key\n\n# 32-bit floating point machine epsilon\n_eps = np.finfo('f4').eps\n\n\ndef _length_of_indexer(indexer, target=None):\n    \"\"\"return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        l = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += l\n        if stop is None or stop > l:\n            stop = l\n        elif stop < 0:\n            stop += l\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = abs(step)\n        return (stop - start) / step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")\n\n\ndef _convert_to_index_sliceable(obj, key):\n    \"\"\"if we are index sliceable, then return my slicer, otherwise return None\n    \"\"\"\n    idx = obj.index\n    if isinstance(key, slice):\n        return idx._convert_slice_indexer(key, typ='getitem')\n\n    elif isinstance(key, compat.string_types):\n\n        # we are an actual column\n        if key in obj._data.items:\n            return None\n\n        # we need a timelike key here\n        if idx.is_all_dates:\n            try:\n                return idx._get_string_slice(key)\n            except:\n                return None\n\n    return None\n\n\ndef _is_index_slice(obj):\n    def _is_valid_index(x):\n        return (com.is_integer(x) or com.is_float(x)\n                and np.allclose(x, int(x), rtol=_eps, atol=0))\n\n    def _crit(v):\n        return v is None or _is_valid_index(v)\n\n    both_none = obj.start is None and obj.stop is None\n\n    return not both_none and (_crit(obj.start) and _crit(obj.stop))\n\n\ndef _check_bool_indexer(ax, key):\n    # boolean indexing, need to check that the data are aligned, otherwise\n    # disallowed\n\n    # this function assumes that com._is_bool_indexer(key) == True\n\n    result = key\n    if isinstance(key, ABCSeries) and not key.index.equals(ax):\n        result = result.reindex(ax)\n        mask = com.isnull(result.values)\n        if mask.any():\n            raise IndexingError('Unalignable boolean Series key provided')\n\n        result = result.astype(bool).values\n\n    else:\n        # com._is_bool_indexer has already checked for nulls in the case of an\n        # object array key, so no check needed here\n        result = np.asarray(result, dtype=bool)\n\n    return result\n\n\ndef _convert_missing_indexer(indexer):\n    \"\"\" reverse convert a missing indexer, which is a dict\n        return the scalar indexer and a boolean indicating if we converted \"\"\"\n\n    if isinstance(indexer, dict):\n\n        # a missing key (but not a tuple indexer)\n        indexer = indexer['key']\n\n        if isinstance(indexer, bool):\n            raise KeyError(\"cannot use a single bool to index into setitem\")\n        return indexer, True\n\n    return indexer, False\n\n\ndef _convert_from_missing_indexer_tuple(indexer, axes):\n    \"\"\" create a filtered indexer that doesn't have any missing indexers \"\"\"\n    def get_indexer(_i, _idx):\n        return (axes[_i].get_loc(_idx['key'])\n                if isinstance(_idx, dict) else _idx)\n    return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])\n\n\ndef _safe_append_to_index(index, key):\n    \"\"\" a safe append to an index, if incorrect type, then catch and recreate\n    \"\"\"\n    try:\n        return index.insert(len(index), key)\n    except:\n\n        # raise here as this is basically an unsafe operation and we want\n        # it to be obvious that you are doing something wrong\n        raise ValueError(\"unsafe appending to index of type {0} with a key \"\n                         \"{1}\".format(index.__class__.__name__, key))\n\n\ndef _maybe_convert_indices(indices, n):\n    \"\"\" if we have negative indicies, translate to postive here\n    if have indicies that are out-of-bounds, raise an IndexError\n    \"\"\"\n    if isinstance(indices, list):\n        indices = np.array(indices)\n        if len(indices) == 0:\n            # If list is empty, np.array will return float and cause indexing\n            # errors.\n            return np.empty(0, dtype=np.int_)\n\n    mask = indices < 0\n    if mask.any():\n        indices[mask] += n\n    mask = (indices >= n) | (indices < 0)\n    if mask.any():\n        raise IndexError(\"indices are out-of-bounds\")\n    return indices\n\n\ndef _maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args\n\n\ndef _is_nested_tuple(tup, labels):\n    # check for a compatiable nested tuple and multiindexes among the axes\n    if not isinstance(tup, tuple):\n        return False\n\n    # are we nested tuple of: tuple,list,slice\n    for i, k in enumerate(tup):\n\n        if isinstance(k, (tuple, list, slice)):\n            return isinstance(labels, MultiIndex)\n\n    return False\n\n\ndef _is_null_slice(obj):\n    return (isinstance(obj, slice) and obj.start is None and\n            obj.stop is None and obj.step is None)\n\n\ndef _is_label_like(key):\n    # select a label or row\n    return not isinstance(key, slice) and not _is_list_like(key)\n\n\ndef _is_list_like(obj):\n    # Consider namedtuples to be not list like as they are useful as indices\n    return (hasattr(obj, '__iter__')\n            and not isinstance(obj, compat.string_types)\n            and not (isinstance(obj, tuple) and type(obj) is not tuple))\n\n\ndef _need_slice(obj):\n    return (obj.start is not None or\n            obj.stop is not None or\n            (obj.step is not None and obj.step != 1))\n\n\ndef _maybe_droplevels(index, key):\n    # drop levels\n    original_index = index\n    if isinstance(key, tuple):\n        for _ in key:\n            try:\n                index = index.droplevel(0)\n            except:\n                # we have dropped too much, so back out\n                return original_index\n    else:\n        try:\n            index = index.droplevel(0)\n        except:\n            pass\n\n    return index\n\n",
          "file_patch": "@@ -1510,6 +1510,18 @@ class _AtIndexer(_ScalarAccessIndexer):\n     \"\"\" label based scalar accessor \"\"\"\n     _takeable = False\n \n+    def _convert_key(self, key):\n+        \"\"\" require they keys to be the same type as the index (so we don't fallback) \"\"\"\n+        for ax, i in zip(self.obj.axes, key):\n+            if ax.is_integer():\n+                if not com.is_integer(i):\n+                    raise ValueError(\"At based indexing on an integer index can only have integer \"\n+                                     \"indexers\")\n+            else:\n+                if com.is_integer(i):\n+                    raise ValueError(\"At based indexing on an non-integer index can only have non-integer \"\n+                                     \"indexers\")\n+        return key\n \n class _iAtIndexer(_ScalarAccessIndexer):\n \n",
          "files_name_in_blame_commit": [
            "test_indexing.py",
            "indexing.py"
          ]
        }
      }
    }
  }
}