{
  "id": "30",
  "blame_commit": {
    "commit": {
      "commit_id": "716efd3f1e08d81743edcb7422fa5eb05523b58d",
      "commit_message": "[REF] separate blocks.py out of internals.__init__ (#22014)",
      "commit_author": "jbrockmendel",
      "commit_date": "2018-07-23 07:24:00",
      "commit_parent": "68ac291401dd7e690d512b3524e57593c568a387"
    },
    "function": {
      "function_name": "putmask",
      "function_code_before": "",
      "function_code_after": "def putmask(self, mask, new, align=True, inplace=False, axis=0, transpose=False, mgr=None):\n    \"\"\" putmask the data to the block; it is possible that we may create a\n        new dtype of block\n\n        return the resulting block(s)\n\n        Parameters\n        ----------\n        mask  : the condition to respect\n        new : a ndarray/object\n        align : boolean, perform alignment on other/cond, default is True\n        inplace : perform inplace modification, default is False\n        axis : int\n        transpose : boolean\n            Set to True if self is stored with axes reversed\n\n        Returns\n        -------\n        a list of new blocks, the result of the putmask\n        \"\"\"\n    new_values = self.values if inplace else self.values.copy()\n    new = getattr(new, 'values', new)\n    mask = getattr(mask, 'values', mask)\n    if not is_list_like(new) and isna(new) and (not self.is_object):\n        new = self.fill_value\n    if self._can_hold_element(new):\n        (_, _, new, _) = self._try_coerce_args(new_values, new)\n        if transpose:\n            new_values = new_values.T\n        if getattr(new, 'ndim', 0) >= 1:\n            if self.ndim - 1 == new.ndim and axis == 1:\n                new = np.repeat(new, new_values.shape[-1]).reshape(self.shape)\n            new = new.astype(new_values.dtype)\n        if is_list_like(new) and np.any(mask[mask]) and (getattr(new, 'ndim', 1) == 1):\n            if not (mask.shape[-1] == len(new) or mask[mask].shape[-1] == len(new) or len(new) == 1):\n                raise ValueError('cannot assign mismatch length to masked array')\n        np.putmask(new_values, mask, new)\n    elif mask.any():\n        if transpose:\n            mask = mask.T\n            if isinstance(new, np.ndarray):\n                new = new.T\n            axis = new_values.ndim - axis - 1\n        if getattr(new, 'ndim', 0) >= 1:\n            if self.ndim - 1 == new.ndim:\n                new_shape = list(new.shape)\n                new_shape.insert(axis, 1)\n                new = new.reshape(tuple(new_shape))\n\n        def f(m, v, i):\n            if i is None:\n                n = new\n            else:\n                if isinstance(new, np.ndarray):\n                    n = np.squeeze(new[i % new.shape[0]])\n                else:\n                    n = np.array(new)\n                (dtype, _) = maybe_promote(n.dtype)\n                n = n.astype(dtype)\n            nv = _putmask_smart(v, m, n)\n            return nv\n        new_blocks = self.split_and_operate(mask, f, inplace)\n        return new_blocks\n    if inplace:\n        return [self]\n    if transpose:\n        new_values = new_values.T\n    return [self.make_block(new_values)]",
      "function_before_start_line": "",
      "function_before_end_line": "",
      "function_after_start_line": 944,
      "function_after_end_line": 1054,
      "function_before_token_count": 0,
      "function_after_token_count": 395,
      "functions_name_modified_file": [
        "convert",
        "_vstack",
        "kind",
        "_maybe_downcast",
        "is_view",
        "sp_index",
        "quantile",
        "is_bool",
        "to_native_types",
        "sparse_reindex",
        "eval",
        "_maybe_coerce_values",
        "dtype",
        "_box_func",
        "sp_values",
        "__init__",
        "_interpolate_with_fill",
        "ftype",
        "shape",
        "_holder",
        "__setstate__",
        "setitem",
        "diff",
        "get_block_type",
        "downcast",
        "external_values",
        "take_nd",
        "shift",
        "_putmask_smart",
        "split_and_operate",
        "_na_value",
        "merge",
        "formatting_values",
        "_astype",
        "__getstate__",
        "_interpolate",
        "_check_ndim",
        "__len__",
        "is_categorical_astype",
        "_merge_blocks",
        "getitem_block",
        "_block2d_to_blocknd",
        "astype",
        "_try_coerce_result",
        "coerce_to_target_dtype",
        "mgr_locs",
        "_extend_blocks",
        "interpolate",
        "apply",
        "should_store",
        "array_dtype",
        "_factor_indexer",
        "_unstack",
        "where",
        "_try_cast_result",
        "make_block",
        "__unicode__",
        "_safe_reshape",
        "is_datelike",
        "make_block_scalar",
        "concat_same_type",
        "_block_shape",
        "fillna",
        "putmask",
        "copy",
        "_slice",
        "reshape_nd",
        "_try_coerce_and_cast_result",
        "set",
        "_try_coerce_args",
        "_replace_single",
        "iget",
        "equals",
        "to_dense",
        "internal_values",
        "fill_value",
        "make_block_same_class",
        "get_values",
        "replace",
        "delete",
        "_consolidate_key",
        "_can_hold_element",
        "_is_single_block",
        "_can_hold_na"
      ],
      "functions_name_all_files": [
        "convert",
        "_vstack",
        "concatenate_join_units",
        "kind",
        "_maybe_downcast",
        "is_view",
        "reindex_indexer",
        "sp_index",
        "quantile",
        "create_block_manager_from_blocks",
        "any_extension_types",
        "is_bool",
        "to_native_types",
        "sparse_reindex",
        "is_numeric_mixed_type",
        "eval",
        "to_dict",
        "_maybe_coerce_values",
        "dtype",
        "get_scalar",
        "construction_error",
        "_consolidate_check",
        "_consolidate",
        "get_mgr_concatenation_plan",
        "_box_func",
        "_block",
        "_simple_blockify",
        "sp_values",
        "fast_xs",
        "is_consolidated",
        "_transform_index",
        "__init__",
        "_interpolate_with_fill",
        "get_bool_data",
        "_consolidate_inplace",
        "ftype",
        "_is_indexed_like",
        "df",
        "shape",
        "_holder",
        "__setstate__",
        "setitem",
        "_sparse_blockify",
        "trim_join_unit",
        "_verify_integrity",
        "is_na",
        "form_blocks",
        "diff",
        "get_block_type",
        "downcast",
        "_values",
        "external_values",
        "test_concat_series",
        "take_nd",
        "shift",
        "rename_axis",
        "_putmask_smart",
        "split_and_operate",
        "get_dtypes",
        "__contains__",
        "is_uniform_reindex",
        "_na_value",
        "_interleaved_dtype",
        "asobject",
        "test_concat_axis1",
        "merge",
        "take",
        "formatting_values",
        "_concat_indexes",
        "as_array",
        "_astype",
        "_preprocess_slice_or_indexer",
        "__getstate__",
        "get_slice",
        "get_reindexed_values",
        "_get_blkno_placements",
        "_interpolate",
        "_check_ndim",
        "__nonzero__",
        "__len__",
        "is_categorical_astype",
        "_merge_blocks",
        "get_numeric_data",
        "_multi_blockify",
        "consolidate",
        "getitem_block",
        "_block2d_to_blocknd",
        "astype",
        "is_mixed_type",
        "_get_counts",
        "_try_coerce_result",
        "coerce_to_target_dtype",
        "mgr_locs",
        "_extend_blocks",
        "interpolate",
        "unstack",
        "insert",
        "combine_concat_plans",
        "combine",
        "concat",
        "apply",
        "replace_list",
        "isna",
        "should_store",
        "array_dtype",
        "_factor_indexer",
        "_interleave",
        "_unstack",
        "_rebuild_blknos_and_blklocs",
        "set_axis",
        "_slice_take_blocks_ax0",
        "where",
        "_try_cast_result",
        "make_block",
        "__unicode__",
        "_safe_reshape",
        "items_overlap_with_suffix",
        "is_datelike",
        "_maybe_compare",
        "make_block_scalar",
        "concatenate_block_managers",
        "concat_same_type",
        "__repr__",
        "get_ftype_counts",
        "_block_shape",
        "fillna",
        "get_empty_dtype_and_na",
        "putmask",
        "_fast_count_smallints",
        "get_dtype_counts",
        "create_block_manager_from_arrays",
        "copy",
        "reshape_nd",
        "_slice",
        "_try_coerce_and_cast_result",
        "_blknos",
        "make_empty",
        "is_uniform_join_units",
        "set",
        "_blklocs",
        "_post_setstate",
        "test_concat_dataframe",
        "_try_coerce_args",
        "add_prefix",
        "_replace_single",
        "reduction",
        "test_custom_repr",
        "iget",
        "equals",
        "to_dense",
        "_make_na_block",
        "internal_values",
        "_get_items",
        "reindex_axis",
        "nblocks",
        "fill_value",
        "index",
        "get_ftypes",
        "make_block_same_class",
        "get",
        "replace",
        "ndim",
        "get_values",
        "delete",
        "xs",
        "_consolidate_key",
        "_stack_arrays",
        "add_suffix",
        "_can_hold_na",
        "_is_single_block",
        "_can_hold_element",
        "is_datelike_mixed_type",
        "needs_filling"
      ],
      "functions_name_co_evolved_modified_file": [
        "convert",
        "_vstack",
        "kind",
        "_maybe_downcast",
        "is_view",
        "sp_index",
        "quantile",
        "is_bool",
        "to_native_types",
        "sparse_reindex",
        "eval",
        "_maybe_coerce_values",
        "dtype",
        "_box_func",
        "sp_values",
        "_interpolate_with_fill",
        "__init__",
        "ftype",
        "shape",
        "_holder",
        "setitem",
        "__setstate__",
        "diff",
        "get_block_type",
        "downcast",
        "external_values",
        "take_nd",
        "shift",
        "_putmask_smart",
        "split_and_operate",
        "_na_value",
        "merge",
        "formatting_values",
        "_astype",
        "__getstate__",
        "_interpolate",
        "_check_ndim",
        "__len__",
        "is_categorical_astype",
        "_merge_blocks",
        "getitem_block",
        "_block2d_to_blocknd",
        "astype",
        "_try_coerce_result",
        "coerce_to_target_dtype",
        "mgr_locs",
        "_extend_blocks",
        "interpolate",
        "apply",
        "should_store",
        "_factor_indexer",
        "array_dtype",
        "_unstack",
        "where",
        "_try_cast_result",
        "_safe_reshape",
        "make_block",
        "__unicode__",
        "is_datelike",
        "make_block_scalar",
        "concat_same_type",
        "_block_shape",
        "fillna",
        "copy",
        "reshape_nd",
        "_slice",
        "_try_coerce_and_cast_result",
        "set",
        "_try_coerce_args",
        "_replace_single",
        "iget",
        "equals",
        "to_dense",
        "internal_values",
        "fill_value",
        "make_block_same_class",
        "replace",
        "get_values",
        "delete",
        "_consolidate_key",
        "_can_hold_na",
        "_is_single_block",
        "_can_hold_element"
      ],
      "functions_name_co_evolved_all_files": [
        "convert",
        "_vstack",
        "kind",
        "_maybe_downcast",
        "is_view",
        "sp_index",
        "quantile",
        "is_bool",
        "to_native_types",
        "sparse_reindex",
        "eval",
        "_maybe_coerce_values",
        "dtype",
        "_box_func",
        "sp_values",
        "_interpolate_with_fill",
        "__init__",
        "ftype",
        "shape",
        "_holder",
        "setitem",
        "__setstate__",
        "diff",
        "get_block_type",
        "downcast",
        "external_values",
        "take_nd",
        "shift",
        "_putmask_smart",
        "split_and_operate",
        "_na_value",
        "merge",
        "formatting_values",
        "_astype",
        "__getstate__",
        "_interpolate",
        "_check_ndim",
        "__len__",
        "is_categorical_astype",
        "_merge_blocks",
        "getitem_block",
        "_block2d_to_blocknd",
        "astype",
        "_try_coerce_result",
        "coerce_to_target_dtype",
        "mgr_locs",
        "_extend_blocks",
        "interpolate",
        "apply",
        "should_store",
        "_factor_indexer",
        "array_dtype",
        "_unstack",
        "where",
        "_try_cast_result",
        "_safe_reshape",
        "make_block",
        "__unicode__",
        "is_datelike",
        "make_block_scalar",
        "concat_same_type",
        "_block_shape",
        "fillna",
        "copy",
        "reshape_nd",
        "_slice",
        "_try_coerce_and_cast_result",
        "set",
        "_try_coerce_args",
        "_replace_single",
        "iget",
        "equals",
        "to_dense",
        "internal_values",
        "fill_value",
        "make_block_same_class",
        "replace",
        "get_values",
        "delete",
        "_consolidate_key",
        "_can_hold_na",
        "_is_single_block",
        "_can_hold_element"
      ]
    },
    "file": {
      "file_name": "blocks.py",
      "file_nloc": 2028,
      "file_complexity": 717,
      "file_token_count": 15458,
      "file_before": null,
      "file_after": "# -*- coding: utf-8 -*-\nimport warnings\nimport inspect\nimport re\nfrom datetime import datetime, timedelta, date\n\nimport numpy as np\n\nfrom pandas._libs import lib, tslib, tslibs, internals as libinternals\nfrom pandas._libs.tslibs import conversion, Timedelta\n\nfrom pandas import compat\nfrom pandas.compat import range, zip\n\nfrom pandas.util._validators import validate_bool_kwarg\n\nfrom pandas.core.dtypes.dtypes import (\n    ExtensionDtype, DatetimeTZDtype,\n    PandasExtensionDtype,\n    CategoricalDtype)\nfrom pandas.core.dtypes.common import (\n    _TD_DTYPE, _NS_DTYPE,\n    ensure_platform_int,\n    is_integer,\n    is_dtype_equal,\n    is_timedelta64_dtype,\n    is_datetime64_dtype, is_datetimetz, is_sparse,\n    is_categorical, is_categorical_dtype,\n    is_integer_dtype,\n    is_datetime64tz_dtype,\n    is_bool_dtype,\n    is_object_dtype,\n    is_float_dtype,\n    is_numeric_v_string_like, is_extension_type,\n    is_extension_array_dtype,\n    is_list_like,\n    is_re,\n    is_re_compilable,\n    pandas_dtype)\nfrom pandas.core.dtypes.cast import (\n    maybe_downcast_to_dtype,\n    maybe_upcast,\n    maybe_promote,\n    infer_dtype_from,\n    infer_dtype_from_scalar,\n    soft_convert_objects,\n    maybe_convert_objects,\n    astype_nansafe,\n    find_common_type,\n    maybe_infer_dtype_type)\nfrom pandas.core.dtypes.missing import (\n    isna, notna, array_equivalent,\n    _isna_compat,\n    is_null_datelike_scalar)\nimport pandas.core.dtypes.concat as _concat\nfrom pandas.core.dtypes.generic import (\n    ABCSeries,\n    ABCDatetimeIndex,\n    ABCExtensionArray,\n    ABCIndexClass)\n\nimport pandas.core.common as com\nimport pandas.core.algorithms as algos\nimport pandas.core.missing as missing\nfrom pandas.core.base import PandasObject\n\nfrom pandas.core.arrays import Categorical\nfrom pandas.core.sparse.array import SparseArray\n\nfrom pandas.core.indexes.datetimes import DatetimeIndex\nfrom pandas.core.indexes.timedeltas import TimedeltaIndex\nfrom pandas.core.indexing import check_setitem_lengths\n\nfrom pandas.io.formats.printing import pprint_thing\n\n\nclass Block(PandasObject):\n    \"\"\"\n    Canonical n-dimensional unit of homogeneous dtype contained in a pandas\n    data structure\n\n    Index-ignorant; let the container take care of that\n    \"\"\"\n    __slots__ = ['_mgr_locs', 'values', 'ndim']\n    is_numeric = False\n    is_float = False\n    is_integer = False\n    is_complex = False\n    is_datetime = False\n    is_datetimetz = False\n    is_timedelta = False\n    is_bool = False\n    is_object = False\n    is_categorical = False\n    is_sparse = False\n    is_extension = False\n    _box_to_block_values = True\n    _can_hold_na = False\n    _can_consolidate = True\n    _verify_integrity = True\n    _validate_ndim = True\n    _ftype = 'dense'\n    _concatenator = staticmethod(np.concatenate)\n\n    def __init__(self, values, placement, ndim=None):\n        self.ndim = self._check_ndim(values, ndim)\n        self.mgr_locs = placement\n        self.values = values\n\n        if (self._validate_ndim and self.ndim and\n                len(self.mgr_locs) != len(self.values)):\n            raise ValueError(\n                'Wrong number of items passed {val}, placement implies '\n                '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))\n\n    def _check_ndim(self, values, ndim):\n        \"\"\"ndim inference and validation.\n\n        Infers ndim from 'values' if not provided to __init__.\n        Validates that values.ndim and ndim are consistent if and only if\n        the class variable '_validate_ndim' is True.\n\n        Parameters\n        ----------\n        values : array-like\n        ndim : int or None\n\n        Returns\n        -------\n        ndim : int\n\n        Raises\n        ------\n        ValueError : the number of dimensions do not match\n        \"\"\"\n        if ndim is None:\n            ndim = values.ndim\n\n        if self._validate_ndim and values.ndim != ndim:\n            msg = (\"Wrong number of dimensions. values.ndim != ndim \"\n                   \"[{} != {}]\")\n            raise ValueError(msg.format(values.ndim, ndim))\n\n        return ndim\n\n    @property\n    def _holder(self):\n        \"\"\"The array-like that can hold the underlying values.\n\n        None for 'Block', overridden by subclasses that don't\n        use an ndarray.\n        \"\"\"\n        return None\n\n    @property\n    def _consolidate_key(self):\n        return (self._can_consolidate, self.dtype.name)\n\n    @property\n    def _is_single_block(self):\n        return self.ndim == 1\n\n    @property\n    def is_view(self):\n        \"\"\" return a boolean if I am possibly a view \"\"\"\n        return self.values.base is not None\n\n    @property\n    def is_datelike(self):\n        \"\"\" return True if I am a non-datelike \"\"\"\n        return self.is_datetime or self.is_timedelta\n\n    def is_categorical_astype(self, dtype):\n        \"\"\"\n        validate that we have a astypeable to categorical,\n        returns a boolean if we are a categorical\n        \"\"\"\n        if dtype is Categorical or dtype is CategoricalDtype:\n            # this is a pd.Categorical, but is not\n            # a valid type for astypeing\n            raise TypeError(\"invalid type {0} for astype\".format(dtype))\n\n        elif is_categorical_dtype(dtype):\n            return True\n\n        return False\n\n    def external_values(self, dtype=None):\n        \"\"\" return an outside world format, currently just the ndarray \"\"\"\n        return self.values\n\n    def internal_values(self, dtype=None):\n        \"\"\" return an internal format, currently just the ndarray\n        this should be the pure internal API format\n        \"\"\"\n        return self.values\n\n    def formatting_values(self):\n        \"\"\"Return the internal values used by the DataFrame/SeriesFormatter\"\"\"\n        return self.internal_values()\n\n    def get_values(self, dtype=None):\n        \"\"\"\n        return an internal format, currently just the ndarray\n        this is often overridden to handle to_dense like operations\n        \"\"\"\n        if is_object_dtype(dtype):\n            return self.values.astype(object)\n        return self.values\n\n    def to_dense(self):\n        return self.values.view()\n\n    @property\n    def _na_value(self):\n        return np.nan\n\n    @property\n    def fill_value(self):\n        return np.nan\n\n    @property\n    def mgr_locs(self):\n        return self._mgr_locs\n\n    @mgr_locs.setter\n    def mgr_locs(self, new_mgr_locs):\n        if not isinstance(new_mgr_locs, libinternals.BlockPlacement):\n            new_mgr_locs = libinternals.BlockPlacement(new_mgr_locs)\n\n        self._mgr_locs = new_mgr_locs\n\n    @property\n    def array_dtype(self):\n        \"\"\" the dtype to return if I want to construct this block as an\n        array\n        \"\"\"\n        return self.dtype\n\n    def make_block(self, values, placement=None, ndim=None):\n        \"\"\"\n        Create a new block, with type inference propagate any values that are\n        not specified\n        \"\"\"\n        if placement is None:\n            placement = self.mgr_locs\n        if ndim is None:\n            ndim = self.ndim\n\n        return make_block(values, placement=placement, ndim=ndim)\n\n    def make_block_scalar(self, values):\n        \"\"\"\n        Create a ScalarBlock\n        \"\"\"\n        return ScalarBlock(values)\n\n    def make_block_same_class(self, values, placement=None, ndim=None,\n                              dtype=None):\n        \"\"\" Wrap given values in a block of same type as self. \"\"\"\n        if dtype is not None:\n            # issue 19431 fastparquet is passing this\n            warnings.warn(\"dtype argument is deprecated, will be removed \"\n                          \"in a future release.\", DeprecationWarning)\n        if placement is None:\n            placement = self.mgr_locs\n        return make_block(values, placement=placement, ndim=ndim,\n                          klass=self.__class__, dtype=dtype)\n\n    def __unicode__(self):\n\n        # don't want to print out all of the items here\n        name = pprint_thing(self.__class__.__name__)\n        if self._is_single_block:\n\n            result = '{name}: {len} dtype: {dtype}'.format(\n                name=name, len=len(self), dtype=self.dtype)\n\n        else:\n\n            shape = ' x '.join(pprint_thing(s) for s in self.shape)\n            result = '{name}: {index}, {shape}, dtype: {dtype}'.format(\n                name=name, index=pprint_thing(self.mgr_locs.indexer),\n                shape=shape, dtype=self.dtype)\n\n        return result\n\n    def __len__(self):\n        return len(self.values)\n\n    def __getstate__(self):\n        return self.mgr_locs.indexer, self.values\n\n    def __setstate__(self, state):\n        self.mgr_locs = libinternals.BlockPlacement(state[0])\n        self.values = state[1]\n        self.ndim = self.values.ndim\n\n    def _slice(self, slicer):\n        \"\"\" return a slice of my values \"\"\"\n        return self.values[slicer]\n\n    def reshape_nd(self, labels, shape, ref_items, mgr=None):\n        \"\"\"\n        Parameters\n        ----------\n        labels : list of new axis labels\n        shape : new shape\n        ref_items : new ref_items\n\n        return a new block that is transformed to a nd block\n        \"\"\"\n        return _block2d_to_blocknd(values=self.get_values().T,\n                                   placement=self.mgr_locs, shape=shape,\n                                   labels=labels, ref_items=ref_items)\n\n    def getitem_block(self, slicer, new_mgr_locs=None):\n        \"\"\"\n        Perform __getitem__-like, return result as block.\n\n        As of now, only supports slices that preserve dimensionality.\n        \"\"\"\n        if new_mgr_locs is None:\n            if isinstance(slicer, tuple):\n                axis0_slicer = slicer[0]\n            else:\n                axis0_slicer = slicer\n            new_mgr_locs = self.mgr_locs[axis0_slicer]\n\n        new_values = self._slice(slicer)\n\n        if self._validate_ndim and new_values.ndim != self.ndim:\n            raise ValueError(\"Only same dim slicing is allowed\")\n\n        return self.make_block_same_class(new_values, new_mgr_locs)\n\n    @property\n    def shape(self):\n        return self.values.shape\n\n    @property\n    def dtype(self):\n        return self.values.dtype\n\n    @property\n    def ftype(self):\n        return \"{dtype}:{ftype}\".format(dtype=self.dtype, ftype=self._ftype)\n\n    def merge(self, other):\n        return _merge_blocks([self, other])\n\n    def concat_same_type(self, to_concat, placement=None):\n        \"\"\"\n        Concatenate list of single blocks of the same type.\n        \"\"\"\n        values = self._concatenator([blk.values for blk in to_concat],\n                                    axis=self.ndim - 1)\n        return self.make_block_same_class(\n            values, placement=placement or slice(0, len(values), 1))\n\n    def iget(self, i):\n        return self.values[i]\n\n    def set(self, locs, values, check=False):\n        \"\"\"\n        Modify Block in-place with new item value\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self.values[locs] = values\n\n    def delete(self, loc):\n        \"\"\"\n        Delete given loc(-s) from block in-place.\n        \"\"\"\n        self.values = np.delete(self.values, loc, 0)\n        self.mgr_locs = self.mgr_locs.delete(loc)\n\n    def apply(self, func, mgr=None, **kwargs):\n        \"\"\" apply the function to my values; return a block if we are not\n        one\n        \"\"\"\n        with np.errstate(all='ignore'):\n            result = func(self.values, **kwargs)\n        if not isinstance(result, Block):\n            result = self.make_block(values=_block_shape(result,\n                                                         ndim=self.ndim))\n\n        return result\n\n    def fillna(self, value, limit=None, inplace=False, downcast=None,\n               mgr=None):\n        \"\"\" fillna on the block with the value. If we fail, then convert to\n        ObjectBlock and try again\n        \"\"\"\n        inplace = validate_bool_kwarg(inplace, 'inplace')\n\n        if not self._can_hold_na:\n            if inplace:\n                return self\n            else:\n                return self.copy()\n\n        mask = isna(self.values)\n        if limit is not None:\n            if not is_integer(limit):\n                raise ValueError('Limit must be an integer')\n            if limit < 1:\n                raise ValueError('Limit must be greater than 0')\n            if self.ndim > 2:\n                raise NotImplementedError(\"number of dimensions for 'fillna' \"\n                                          \"is currently limited to 2\")\n            mask[mask.cumsum(self.ndim - 1) > limit] = False\n\n        # fillna, but if we cannot coerce, then try again as an ObjectBlock\n        try:\n            values, _, _, _ = self._try_coerce_args(self.values, value)\n            blocks = self.putmask(mask, value, inplace=inplace)\n            blocks = [b.make_block(values=self._try_coerce_result(b.values))\n                      for b in blocks]\n            return self._maybe_downcast(blocks, downcast)\n        except (TypeError, ValueError):\n\n            # we can't process the value, but nothing to do\n            if not mask.any():\n                return self if inplace else self.copy()\n\n            # operate column-by-column\n            def f(m, v, i):\n                block = self.coerce_to_target_dtype(value)\n\n                # slice out our block\n                if i is not None:\n                    block = block.getitem_block(slice(i, i + 1))\n                return block.fillna(value,\n                                    limit=limit,\n                                    inplace=inplace,\n                                    downcast=None)\n\n            return self.split_and_operate(mask, f, inplace)\n\n    def split_and_operate(self, mask, f, inplace):\n        \"\"\"\n        split the block per-column, and apply the callable f\n        per-column, return a new block for each. Handle\n        masking which will not change a block unless needed.\n\n        Parameters\n        ----------\n        mask : 2-d boolean mask\n        f : callable accepting (1d-mask, 1d values, indexer)\n        inplace : boolean\n\n        Returns\n        -------\n        list of blocks\n        \"\"\"\n\n        if mask is None:\n            mask = np.ones(self.shape, dtype=bool)\n        new_values = self.values\n\n        def make_a_block(nv, ref_loc):\n            if isinstance(nv, Block):\n                block = nv\n            elif isinstance(nv, list):\n                block = nv[0]\n            else:\n                # Put back the dimension that was taken from it and make\n                # a block out of the result.\n                try:\n                    nv = _block_shape(nv, ndim=self.ndim)\n                except (AttributeError, NotImplementedError):\n                    pass\n                block = self.make_block(values=nv,\n                                        placement=ref_loc)\n            return block\n\n        # ndim == 1\n        if self.ndim == 1:\n            if mask.any():\n                nv = f(mask, new_values, None)\n            else:\n                nv = new_values if inplace else new_values.copy()\n            block = make_a_block(nv, self.mgr_locs)\n            return [block]\n\n        # ndim > 1\n        new_blocks = []\n        for i, ref_loc in enumerate(self.mgr_locs):\n            m = mask[i]\n            v = new_values[i]\n\n            # need a new block\n            if m.any():\n                nv = f(m, v, i)\n            else:\n                nv = v if inplace else v.copy()\n\n            block = make_a_block(nv, [ref_loc])\n            new_blocks.append(block)\n\n        return new_blocks\n\n    def _maybe_downcast(self, blocks, downcast=None):\n\n        # no need to downcast our float\n        # unless indicated\n        if downcast is None and self.is_float:\n            return blocks\n        elif downcast is None and (self.is_timedelta or self.is_datetime):\n            return blocks\n\n        if not isinstance(blocks, list):\n            blocks = [blocks]\n        return _extend_blocks([b.downcast(downcast) for b in blocks])\n\n    def downcast(self, dtypes=None, mgr=None):\n        \"\"\" try to downcast each item to the dict of dtypes if present \"\"\"\n\n        # turn it off completely\n        if dtypes is False:\n            return self\n\n        values = self.values\n\n        # single block handling\n        if self._is_single_block:\n\n            # try to cast all non-floats here\n            if dtypes is None:\n                dtypes = 'infer'\n\n            nv = maybe_downcast_to_dtype(values, dtypes)\n            return self.make_block(nv)\n\n        # ndim > 1\n        if dtypes is None:\n            return self\n\n        if not (dtypes == 'infer' or isinstance(dtypes, dict)):\n            raise ValueError(\"downcast must have a dictionary or 'infer' as \"\n                             \"its argument\")\n\n        # operate column-by-column\n        # this is expensive as it splits the blocks items-by-item\n        def f(m, v, i):\n\n            if dtypes == 'infer':\n                dtype = 'infer'\n            else:\n                raise AssertionError(\"dtypes as dict is not supported yet\")\n\n            if dtype is not None:\n                v = maybe_downcast_to_dtype(v, dtype)\n            return v\n\n        return self.split_and_operate(None, f, False)\n\n    def astype(self, dtype, copy=False, errors='raise', values=None, **kwargs):\n        return self._astype(dtype, copy=copy, errors=errors, values=values,\n                            **kwargs)\n\n    def _astype(self, dtype, copy=False, errors='raise', values=None,\n                klass=None, mgr=None, **kwargs):\n        \"\"\"Coerce to the new type\n\n        Parameters\n        ----------\n        dtype : str, dtype convertible\n        copy : boolean, default False\n            copy if indicated\n        errors : str, {'raise', 'ignore'}, default 'ignore'\n            - ``raise`` : allow exceptions to be raised\n            - ``ignore`` : suppress exceptions. On error return original object\n\n        Returns\n        -------\n        Block\n        \"\"\"\n        errors_legal_values = ('raise', 'ignore')\n\n        if errors not in errors_legal_values:\n            invalid_arg = (\"Expected value of kwarg 'errors' to be one of {}. \"\n                           \"Supplied value is '{}'\".format(\n                               list(errors_legal_values), errors))\n            raise ValueError(invalid_arg)\n\n        if (inspect.isclass(dtype) and\n                issubclass(dtype, (PandasExtensionDtype, ExtensionDtype))):\n            msg = (\"Expected an instance of {}, but got the class instead. \"\n                   \"Try instantiating 'dtype'.\".format(dtype.__name__))\n            raise TypeError(msg)\n\n        # may need to convert to categorical\n        if self.is_categorical_astype(dtype):\n\n            # deprecated 17636\n            if ('categories' in kwargs or 'ordered' in kwargs):\n                if isinstance(dtype, CategoricalDtype):\n                    raise TypeError(\n                        \"Cannot specify a CategoricalDtype and also \"\n                        \"`categories` or `ordered`. Use \"\n                        \"`dtype=CategoricalDtype(categories, ordered)`\"\n                        \" instead.\")\n                warnings.warn(\"specifying 'categories' or 'ordered' in \"\n                              \".astype() is deprecated; pass a \"\n                              \"CategoricalDtype instead\",\n                              FutureWarning, stacklevel=7)\n\n            categories = kwargs.get('categories', None)\n            ordered = kwargs.get('ordered', None)\n            if com._any_not_none(categories, ordered):\n                dtype = CategoricalDtype(categories, ordered)\n\n            if is_categorical_dtype(self.values):\n                # GH 10696/18593: update an existing categorical efficiently\n                return self.make_block(self.values.astype(dtype, copy=copy))\n\n            return self.make_block(Categorical(self.values, dtype=dtype))\n\n        # convert dtypes if needed\n        dtype = pandas_dtype(dtype)\n\n        # astype processing\n        if is_dtype_equal(self.dtype, dtype):\n            if copy:\n                return self.copy()\n            return self\n\n        if klass is None:\n            if dtype == np.object_:\n                klass = ObjectBlock\n        try:\n            # force the copy here\n            if values is None:\n\n                if issubclass(dtype.type,\n                              (compat.text_type, compat.string_types)):\n\n                    # use native type formatting for datetime/tz/timedelta\n                    if self.is_datelike:\n                        values = self.to_native_types()\n\n                    # astype formatting\n                    else:\n                        values = self.get_values()\n\n                else:\n                    values = self.get_values(dtype=dtype)\n\n                # _astype_nansafe works fine with 1-d only\n                values = astype_nansafe(values.ravel(), dtype, copy=True)\n\n                # TODO(extension)\n                # should we make this attribute?\n                try:\n                    values = values.reshape(self.shape)\n                except AttributeError:\n                    pass\n\n            newb = make_block(values, placement=self.mgr_locs,\n                              klass=klass)\n        except:\n            if errors == 'raise':\n                raise\n            newb = self.copy() if copy else self\n\n        if newb.is_numeric and self.is_numeric:\n            if newb.shape != self.shape:\n                raise TypeError(\n                    \"cannot set astype for copy = [{copy}] for dtype \"\n                    \"({dtype} [{itemsize}]) with smaller itemsize than \"\n                    \"current ({newb_dtype} [{newb_size}])\".format(\n                        copy=copy, dtype=self.dtype.name,\n                        itemsize=self.itemsize, newb_dtype=newb.dtype.name,\n                        newb_size=newb.itemsize))\n        return newb\n\n    def convert(self, copy=True, **kwargs):\n        \"\"\" attempt to coerce any object types to better types return a copy\n        of the block (if copy = True) by definition we are not an ObjectBlock\n        here!\n        \"\"\"\n\n        return self.copy() if copy else self\n\n    def _can_hold_element(self, element):\n        \"\"\" require the same dtype as ourselves \"\"\"\n        dtype = self.values.dtype.type\n        tipo = maybe_infer_dtype_type(element)\n        if tipo is not None:\n            return issubclass(tipo.type, dtype)\n        return isinstance(element, dtype)\n\n    def _try_cast_result(self, result, dtype=None):\n        \"\"\" try to cast the result to our original type, we may have\n        roundtripped thru object in the mean-time\n        \"\"\"\n        if dtype is None:\n            dtype = self.dtype\n\n        if self.is_integer or self.is_bool or self.is_datetime:\n            pass\n        elif self.is_float and result.dtype == self.dtype:\n\n            # protect against a bool/object showing up here\n            if isinstance(dtype, compat.string_types) and dtype == 'infer':\n                return result\n            if not isinstance(dtype, type):\n                dtype = dtype.type\n            if issubclass(dtype, (np.bool_, np.object_)):\n                if issubclass(dtype, np.bool_):\n                    if isna(result).all():\n                        return result.astype(np.bool_)\n                    else:\n                        result = result.astype(np.object_)\n                        result[result == 1] = True\n                        result[result == 0] = False\n                        return result\n                else:\n                    return result.astype(np.object_)\n\n            return result\n\n        # may need to change the dtype here\n        return maybe_downcast_to_dtype(result, dtype)\n\n    def _try_coerce_args(self, values, other):\n        \"\"\" provide coercion to our input arguments \"\"\"\n\n        if np.any(notna(other)) and not self._can_hold_element(other):\n            # coercion issues\n            # let higher levels handle\n            raise TypeError(\"cannot convert {} to an {}\".format(\n                type(other).__name__,\n                type(self).__name__.lower().replace('Block', '')))\n\n        return values, False, other, False\n\n    def _try_coerce_result(self, result):\n        \"\"\" reverse of try_coerce_args \"\"\"\n        return result\n\n    def _try_coerce_and_cast_result(self, result, dtype=None):\n        result = self._try_coerce_result(result)\n        result = self._try_cast_result(result, dtype=dtype)\n        return result\n\n    def to_native_types(self, slicer=None, na_rep='nan', quoting=None,\n                        **kwargs):\n        \"\"\" convert to our native types format, slicing if desired \"\"\"\n\n        values = self.get_values()\n\n        if slicer is not None:\n            values = values[:, slicer]\n        mask = isna(values)\n\n        if not self.is_object and not quoting:\n            values = values.astype(str)\n        else:\n            values = np.array(values, dtype='object')\n\n        values[mask] = na_rep\n        return values\n\n    # block actions ####\n    def copy(self, deep=True, mgr=None):\n        \"\"\" copy constructor \"\"\"\n        values = self.values\n        if deep:\n            values = values.copy()\n        return self.make_block_same_class(values)\n\n    def replace(self, to_replace, value, inplace=False, filter=None,\n                regex=False, convert=True, mgr=None):\n        \"\"\" replace the to_replace value with value, possible to create new\n        blocks here this is just a call to putmask. regex is not used here.\n        It is used in ObjectBlocks.  It is here for API\n        compatibility.\n        \"\"\"\n\n        inplace = validate_bool_kwarg(inplace, 'inplace')\n        original_to_replace = to_replace\n\n        # try to replace, if we raise an error, convert to ObjectBlock and\n        # retry\n        try:\n            values, _, to_replace, _ = self._try_coerce_args(self.values,\n                                                             to_replace)\n            mask = missing.mask_missing(values, to_replace)\n            if filter is not None:\n                filtered_out = ~self.mgr_locs.isin(filter)\n                mask[filtered_out.nonzero()[0]] = False\n\n            blocks = self.putmask(mask, value, inplace=inplace)\n            if convert:\n                blocks = [b.convert(by_item=True, numeric=False,\n                                    copy=not inplace) for b in blocks]\n            return blocks\n        except (TypeError, ValueError):\n\n            # try again with a compatible block\n            block = self.astype(object)\n            return block.replace(\n                to_replace=original_to_replace, value=value, inplace=inplace,\n                filter=filter, regex=regex, convert=convert)\n\n    def _replace_single(self, *args, **kwargs):\n        \"\"\" no-op on a non-ObjectBlock \"\"\"\n        return self if kwargs['inplace'] else self.copy()\n\n    def setitem(self, indexer, value, mgr=None):\n        \"\"\"Set the value inplace, returning a a maybe different typed block.\n\n        Parameters\n        ----------\n        indexer : tuple, list-like, array-like, slice\n            The subset of self.values to set\n        value : object\n            The value being set\n        mgr : BlockPlacement, optional\n\n        Returns\n        -------\n        Block\n\n        Notes\n        -----\n        `indexer` is a direct slice/positional indexer. `value` must\n        be a compatible shape.\n        \"\"\"\n        # coerce None values, if appropriate\n        if value is None:\n            if self.is_numeric:\n                value = np.nan\n\n        # coerce if block dtype can store value\n        values = self.values\n        try:\n            values, _, value, _ = self._try_coerce_args(values, value)\n            # can keep its own dtype\n            if hasattr(value, 'dtype') and is_dtype_equal(values.dtype,\n                                                          value.dtype):\n                dtype = self.dtype\n            else:\n                dtype = 'infer'\n\n        except (TypeError, ValueError):\n            # current dtype cannot store value, coerce to common dtype\n            find_dtype = False\n\n            if hasattr(value, 'dtype'):\n                dtype = value.dtype\n                find_dtype = True\n\n            elif lib.is_scalar(value):\n                if isna(value):\n                    # NaN promotion is handled in latter path\n                    dtype = False\n                else:\n                    dtype, _ = infer_dtype_from_scalar(value,\n                                                       pandas_dtype=True)\n                    find_dtype = True\n            else:\n                dtype = 'infer'\n\n            if find_dtype:\n                dtype = find_common_type([values.dtype, dtype])\n                if not is_dtype_equal(self.dtype, dtype):\n                    b = self.astype(dtype)\n                    return b.setitem(indexer, value, mgr=mgr)\n\n        # value must be storeable at this moment\n        arr_value = np.array(value)\n\n        # cast the values to a type that can hold nan (if necessary)\n        if not self._can_hold_element(value):\n            dtype, _ = maybe_promote(arr_value.dtype)\n            values = values.astype(dtype)\n\n        transf = (lambda x: x.T) if self.ndim == 2 else (lambda x: x)\n        values = transf(values)\n\n        # length checking\n        check_setitem_lengths(indexer, value, values)\n\n        def _is_scalar_indexer(indexer):\n            # return True if we are all scalar indexers\n\n            if arr_value.ndim == 1:\n                if not isinstance(indexer, tuple):\n                    indexer = tuple([indexer])\n                    return any(isinstance(idx, np.ndarray) and len(idx) == 0\n                               for idx in indexer)\n            return False\n\n        def _is_empty_indexer(indexer):\n            # return a boolean if we have an empty indexer\n\n            if is_list_like(indexer) and not len(indexer):\n                return True\n            if arr_value.ndim == 1:\n                if not isinstance(indexer, tuple):\n                    indexer = tuple([indexer])\n                return any(isinstance(idx, np.ndarray) and len(idx) == 0\n                           for idx in indexer)\n            return False\n\n        # empty indexers\n        # 8669 (empty)\n        if _is_empty_indexer(indexer):\n            pass\n\n        # setting a single element for each dim and with a rhs that could\n        # be say a list\n        # GH 6043\n        elif _is_scalar_indexer(indexer):\n            values[indexer] = value\n\n        # if we are an exact match (ex-broadcasting),\n        # then use the resultant dtype\n        elif (len(arr_value.shape) and\n              arr_value.shape[0] == values.shape[0] and\n              np.prod(arr_value.shape) == np.prod(values.shape)):\n            values[indexer] = value\n            try:\n                values = values.astype(arr_value.dtype)\n            except ValueError:\n                pass\n\n        # set\n        else:\n            values[indexer] = value\n\n        # coerce and try to infer the dtypes of the result\n        values = self._try_coerce_and_cast_result(values, dtype)\n        block = self.make_block(transf(values))\n        return block\n\n    def putmask(self, mask, new, align=True, inplace=False, axis=0,\n                transpose=False, mgr=None):\n        \"\"\" putmask the data to the block; it is possible that we may create a\n        new dtype of block\n\n        return the resulting block(s)\n\n        Parameters\n        ----------\n        mask  : the condition to respect\n        new : a ndarray/object\n        align : boolean, perform alignment on other/cond, default is True\n        inplace : perform inplace modification, default is False\n        axis : int\n        transpose : boolean\n            Set to True if self is stored with axes reversed\n\n        Returns\n        -------\n        a list of new blocks, the result of the putmask\n        \"\"\"\n\n        new_values = self.values if inplace else self.values.copy()\n\n        new = getattr(new, 'values', new)\n        mask = getattr(mask, 'values', mask)\n\n        # if we are passed a scalar None, convert it here\n        if not is_list_like(new) and isna(new) and not self.is_object:\n            new = self.fill_value\n\n        if self._can_hold_element(new):\n            _, _, new, _ = self._try_coerce_args(new_values, new)\n\n            if transpose:\n                new_values = new_values.T\n\n            # If the default repeat behavior in np.putmask would go in the\n            # wrong direction, then explicitly repeat and reshape new instead\n            if getattr(new, 'ndim', 0) >= 1:\n                if self.ndim - 1 == new.ndim and axis == 1:\n                    new = np.repeat(\n                        new, new_values.shape[-1]).reshape(self.shape)\n                new = new.astype(new_values.dtype)\n\n            # we require exact matches between the len of the\n            # values we are setting (or is compat). np.putmask\n            # doesn't check this and will simply truncate / pad\n            # the output, but we want sane error messages\n            #\n            # TODO: this prob needs some better checking\n            # for 2D cases\n            if ((is_list_like(new) and\n                 np.any(mask[mask]) and\n                 getattr(new, 'ndim', 1) == 1)):\n\n                if not (mask.shape[-1] == len(new) or\n                        mask[mask].shape[-1] == len(new) or\n                        len(new) == 1):\n                    raise ValueError(\"cannot assign mismatch \"\n                                     \"length to masked array\")\n\n            np.putmask(new_values, mask, new)\n\n        # maybe upcast me\n        elif mask.any():\n            if transpose:\n                mask = mask.T\n                if isinstance(new, np.ndarray):\n                    new = new.T\n                axis = new_values.ndim - axis - 1\n\n            # Pseudo-broadcast\n            if getattr(new, 'ndim', 0) >= 1:\n                if self.ndim - 1 == new.ndim:\n                    new_shape = list(new.shape)\n                    new_shape.insert(axis, 1)\n                    new = new.reshape(tuple(new_shape))\n\n            # operate column-by-column\n            def f(m, v, i):\n\n                if i is None:\n                    # ndim==1 case.\n                    n = new\n                else:\n\n                    if isinstance(new, np.ndarray):\n                        n = np.squeeze(new[i % new.shape[0]])\n                    else:\n                        n = np.array(new)\n\n                    # type of the new block\n                    dtype, _ = maybe_promote(n.dtype)\n\n                    # we need to explicitly astype here to make a copy\n                    n = n.astype(dtype)\n\n                nv = _putmask_smart(v, m, n)\n                return nv\n\n            new_blocks = self.split_and_operate(mask, f, inplace)\n            return new_blocks\n\n        if inplace:\n            return [self]\n\n        if transpose:\n            new_values = new_values.T\n\n        return [self.make_block(new_values)]\n\n    def coerce_to_target_dtype(self, other):\n        \"\"\"\n        coerce the current block to a dtype compat for other\n        we will return a block, possibly object, and not raise\n\n        we can also safely try to coerce to the same dtype\n        and will receive the same block\n        \"\"\"\n\n        # if we cannot then coerce to object\n        dtype, _ = infer_dtype_from(other, pandas_dtype=True)\n\n        if is_dtype_equal(self.dtype, dtype):\n            return self\n\n        if self.is_bool or is_object_dtype(dtype) or is_bool_dtype(dtype):\n            # we don't upcast to bool\n            return self.astype(object)\n\n        elif ((self.is_float or self.is_complex) and\n              (is_integer_dtype(dtype) or is_float_dtype(dtype))):\n            # don't coerce float/complex to int\n            return self\n\n        elif (self.is_datetime or\n              is_datetime64_dtype(dtype) or\n              is_datetime64tz_dtype(dtype)):\n\n            # not a datetime\n            if not ((is_datetime64_dtype(dtype) or\n                     is_datetime64tz_dtype(dtype)) and self.is_datetime):\n                return self.astype(object)\n\n            # don't upcast timezone with different timezone or no timezone\n            mytz = getattr(self.dtype, 'tz', None)\n            othertz = getattr(dtype, 'tz', None)\n\n            if str(mytz) != str(othertz):\n                return self.astype(object)\n\n            raise AssertionError(\"possible recursion in \"\n                                 \"coerce_to_target_dtype: {} {}\".format(\n                                     self, other))\n\n        elif (self.is_timedelta or is_timedelta64_dtype(dtype)):\n\n            # not a timedelta\n            if not (is_timedelta64_dtype(dtype) and self.is_timedelta):\n                return self.astype(object)\n\n            raise AssertionError(\"possible recursion in \"\n                                 \"coerce_to_target_dtype: {} {}\".format(\n                                     self, other))\n\n        try:\n            return self.astype(dtype)\n        except (ValueError, TypeError):\n            pass\n\n        return self.astype(object)\n\n    def interpolate(self, method='pad', axis=0, index=None, values=None,\n                    inplace=False, limit=None, limit_direction='forward',\n                    limit_area=None, fill_value=None, coerce=False,\n                    downcast=None, mgr=None, **kwargs):\n\n        inplace = validate_bool_kwarg(inplace, 'inplace')\n\n        def check_int_bool(self, inplace):\n            # Only FloatBlocks will contain NaNs.\n            # timedelta subclasses IntBlock\n            if (self.is_bool or self.is_integer) and not self.is_timedelta:\n                if inplace:\n                    return self\n                else:\n                    return self.copy()\n\n        # a fill na type method\n        try:\n            m = missing.clean_fill_method(method)\n        except:\n            m = None\n\n        if m is not None:\n            r = check_int_bool(self, inplace)\n            if r is not None:\n                return r\n            return self._interpolate_with_fill(method=m, axis=axis,\n                                               inplace=inplace, limit=limit,\n                                               fill_value=fill_value,\n                                               coerce=coerce,\n                                               downcast=downcast, mgr=mgr)\n        # try an interp method\n        try:\n            m = missing.clean_interp_method(method, **kwargs)\n        except:\n            m = None\n\n        if m is not None:\n            r = check_int_bool(self, inplace)\n            if r is not None:\n                return r\n            return self._interpolate(method=m, index=index, values=values,\n                                     axis=axis, limit=limit,\n                                     limit_direction=limit_direction,\n                                     limit_area=limit_area,\n                                     fill_value=fill_value, inplace=inplace,\n                                     downcast=downcast, mgr=mgr, **kwargs)\n\n        raise ValueError(\"invalid method '{0}' to interpolate.\".format(method))\n\n    def _interpolate_with_fill(self, method='pad', axis=0, inplace=False,\n                               limit=None, fill_value=None, coerce=False,\n                               downcast=None, mgr=None):\n        \"\"\" fillna but using the interpolate machinery \"\"\"\n\n        inplace = validate_bool_kwarg(inplace, 'inplace')\n\n        # if we are coercing, then don't force the conversion\n        # if the block can't hold the type\n        if coerce:\n            if not self._can_hold_na:\n                if inplace:\n                    return [self]\n                else:\n                    return [self.copy()]\n\n        values = self.values if inplace else self.values.copy()\n        values, _, fill_value, _ = self._try_coerce_args(values, fill_value)\n        values = missing.interpolate_2d(values, method=method, axis=axis,\n                                        limit=limit, fill_value=fill_value,\n                                        dtype=self.dtype)\n        values = self._try_coerce_result(values)\n\n        blocks = [self.make_block_same_class(values, ndim=self.ndim)]\n        return self._maybe_downcast(blocks, downcast)\n\n    def _interpolate(self, method=None, index=None, values=None,\n                     fill_value=None, axis=0, limit=None,\n                     limit_direction='forward', limit_area=None,\n                     inplace=False, downcast=None, mgr=None, **kwargs):\n        \"\"\" interpolate using scipy wrappers \"\"\"\n\n        inplace = validate_bool_kwarg(inplace, 'inplace')\n        data = self.values if inplace else self.values.copy()\n\n        # only deal with floats\n        if not self.is_float:\n            if not self.is_integer:\n                return self\n            data = data.astype(np.float64)\n\n        if fill_value is None:\n            fill_value = self.fill_value\n\n        if method in ('krogh', 'piecewise_polynomial', 'pchip'):\n            if not index.is_monotonic:\n                raise ValueError(\"{0} interpolation requires that the \"\n                                 \"index be monotonic.\".format(method))\n        # process 1-d slices in the axis direction\n\n        def func(x):\n\n            # process a 1-d slice, returning it\n            # should the axis argument be handled below in apply_along_axis?\n            # i.e. not an arg to missing.interpolate_1d\n            return missing.interpolate_1d(index, x, method=method, limit=limit,\n                                          limit_direction=limit_direction,\n                                          limit_area=limit_area,\n                                          fill_value=fill_value,\n                                          bounds_error=False, **kwargs)\n\n        # interp each column independently\n        interp_values = np.apply_along_axis(func, axis, data)\n\n        blocks = [self.make_block_same_class(interp_values)]\n        return self._maybe_downcast(blocks, downcast)\n\n    def take_nd(self, indexer, axis, new_mgr_locs=None, fill_tuple=None):\n        \"\"\"\n        Take values according to indexer and return them as a block.bb\n\n        \"\"\"\n\n        # algos.take_nd dispatches for DatetimeTZBlock, CategoricalBlock\n        # so need to preserve types\n        # sparse is treated like an ndarray, but needs .get_values() shaping\n\n        values = self.values\n        if self.is_sparse:\n            values = self.get_values()\n\n        if fill_tuple is None:\n            fill_value = self.fill_value\n            new_values = algos.take_nd(values, indexer, axis=axis,\n                                       allow_fill=False)\n        else:\n            fill_value = fill_tuple[0]\n            new_values = algos.take_nd(values, indexer, axis=axis,\n                                       allow_fill=True, fill_value=fill_value)\n\n        if new_mgr_locs is None:\n            if axis == 0:\n                slc = libinternals.indexer_as_slice(indexer)\n                if slc is not None:\n                    new_mgr_locs = self.mgr_locs[slc]\n                else:\n                    new_mgr_locs = self.mgr_locs[indexer]\n            else:\n                new_mgr_locs = self.mgr_locs\n\n        if not is_dtype_equal(new_values.dtype, self.dtype):\n            return self.make_block(new_values, new_mgr_locs)\n        else:\n            return self.make_block_same_class(new_values, new_mgr_locs)\n\n    def diff(self, n, axis=1, mgr=None):\n        \"\"\" return block for the diff of the values \"\"\"\n        new_values = algos.diff(self.values, n, axis=axis)\n        return [self.make_block(values=new_values)]\n\n    def shift(self, periods, axis=0, mgr=None):\n        \"\"\" shift the block by periods, possibly upcast \"\"\"\n\n        # convert integer to float if necessary. need to do a lot more than\n        # that, handle boolean etc also\n        new_values, fill_value = maybe_upcast(self.values)\n\n        # make sure array sent to np.roll is c_contiguous\n        f_ordered = new_values.flags.f_contiguous\n        if f_ordered:\n            new_values = new_values.T\n            axis = new_values.ndim - axis - 1\n\n        if np.prod(new_values.shape):\n            new_values = np.roll(new_values, ensure_platform_int(periods),\n                                 axis=axis)\n\n        axis_indexer = [slice(None)] * self.ndim\n        if periods > 0:\n            axis_indexer[axis] = slice(None, periods)\n        else:\n            axis_indexer[axis] = slice(periods, None)\n        new_values[tuple(axis_indexer)] = fill_value\n\n        # restore original order\n        if f_ordered:\n            new_values = new_values.T\n\n        return [self.make_block(new_values)]\n\n    def eval(self, func, other, errors='raise', try_cast=False, mgr=None):\n        \"\"\"\n        evaluate the block; return result block from the result\n\n        Parameters\n        ----------\n        func  : how to combine self, other\n        other : a ndarray/object\n        errors : str, {'raise', 'ignore'}, default 'raise'\n            - ``raise`` : allow exceptions to be raised\n            - ``ignore`` : suppress exceptions. On error return original object\n\n        try_cast : try casting the results to the input type\n\n        Returns\n        -------\n        a new block, the result of the func\n        \"\"\"\n        orig_other = other\n        values = self.values\n\n        other = getattr(other, 'values', other)\n\n        # make sure that we can broadcast\n        is_transposed = False\n        if hasattr(other, 'ndim') and hasattr(values, 'ndim'):\n            if values.ndim != other.ndim:\n                is_transposed = True\n            else:\n                if values.shape == other.shape[::-1]:\n                    is_transposed = True\n                elif values.shape[0] == other.shape[-1]:\n                    is_transposed = True\n                else:\n                    # this is a broadcast error heree\n                    raise ValueError(\n                        \"cannot broadcast shape [{t_shape}] with \"\n                        \"block values [{oth_shape}]\".format(\n                            t_shape=values.T.shape, oth_shape=other.shape))\n\n        transf = (lambda x: x.T) if is_transposed else (lambda x: x)\n\n        # coerce/transpose the args if needed\n        try:\n            values, values_mask, other, other_mask = self._try_coerce_args(\n                transf(values), other)\n        except TypeError:\n            block = self.coerce_to_target_dtype(orig_other)\n            return block.eval(func, orig_other,\n                              errors=errors,\n                              try_cast=try_cast, mgr=mgr)\n\n        # get the result, may need to transpose the other\n        def get_result(other):\n\n            # avoid numpy warning of comparisons again None\n            if other is None:\n                result = not func.__name__ == 'eq'\n\n            # avoid numpy warning of elementwise comparisons to object\n            elif is_numeric_v_string_like(values, other):\n                result = False\n\n            # avoid numpy warning of elementwise comparisons\n            elif func.__name__ == 'eq':\n                if is_list_like(other) and not isinstance(other, np.ndarray):\n                    other = np.asarray(other)\n\n                    # if we can broadcast, then ok\n                    if values.shape[-1] != other.shape[-1]:\n                        return False\n                result = func(values, other)\n            else:\n                result = func(values, other)\n\n            # mask if needed\n            if isinstance(values_mask, np.ndarray) and values_mask.any():\n                result = result.astype('float64', copy=False)\n                result[values_mask] = np.nan\n            if other_mask is True:\n                result = result.astype('float64', copy=False)\n                result[:] = np.nan\n            elif isinstance(other_mask, np.ndarray) and other_mask.any():\n                result = result.astype('float64', copy=False)\n                result[other_mask.ravel()] = np.nan\n\n            return result\n\n        # error handler if we have an issue operating with the function\n        def handle_error():\n\n            if errors == 'raise':\n                # The 'detail' variable is defined in outer scope.\n                raise TypeError(\n                    'Could not operate {other!r} with block values '\n                    '{detail!s}'.format(other=other, detail=detail))  # noqa\n            else:\n                # return the values\n                result = np.empty(values.shape, dtype='O')\n                result.fill(np.nan)\n                return result\n\n        # get the result\n        try:\n            with np.errstate(all='ignore'):\n                result = get_result(other)\n\n        # if we have an invalid shape/broadcast error\n        # GH4576, so raise instead of allowing to pass through\n        except ValueError as detail:\n            raise\n        except Exception as detail:\n            result = handle_error()\n\n        # technically a broadcast error in numpy can 'work' by returning a\n        # boolean False\n        if not isinstance(result, np.ndarray):\n            if not isinstance(result, np.ndarray):\n\n                # differentiate between an invalid ndarray-ndarray comparison\n                # and an invalid type comparison\n                if isinstance(values, np.ndarray) and is_list_like(other):\n                    raise ValueError(\n                        'Invalid broadcasting comparison [{other!r}] with '\n                        'block values'.format(other=other))\n\n                raise TypeError('Could not compare [{other!r}] '\n                                'with block values'.format(other=other))\n\n        # transpose if needed\n        result = transf(result)\n\n        # try to cast if requested\n        if try_cast:\n            result = self._try_cast_result(result)\n\n        result = _block_shape(result, ndim=self.ndim)\n        return [self.make_block(result)]\n\n    def where(self, other, cond, align=True, errors='raise',\n              try_cast=False, axis=0, transpose=False, mgr=None):\n        \"\"\"\n        evaluate the block; return result block(s) from the result\n\n        Parameters\n        ----------\n        other : a ndarray/object\n        cond  : the condition to respect\n        align : boolean, perform alignment on other/cond\n        errors : str, {'raise', 'ignore'}, default 'raise'\n            - ``raise`` : allow exceptions to be raised\n            - ``ignore`` : suppress exceptions. On error return original object\n\n        axis : int\n        transpose : boolean\n            Set to True if self is stored with axes reversed\n\n        Returns\n        -------\n        a new block(s), the result of the func\n        \"\"\"\n        import pandas.core.computation.expressions as expressions\n        assert errors in ['raise', 'ignore']\n\n        values = self.values\n        orig_other = other\n        if transpose:\n            values = values.T\n\n        other = getattr(other, '_values', getattr(other, 'values', other))\n        cond = getattr(cond, 'values', cond)\n\n        # If the default broadcasting would go in the wrong direction, then\n        # explicitly reshape other instead\n        if getattr(other, 'ndim', 0) >= 1:\n            if values.ndim - 1 == other.ndim and axis == 1:\n                other = other.reshape(tuple(other.shape + (1, )))\n            elif transpose and values.ndim == self.ndim - 1:\n                cond = cond.T\n\n        if not hasattr(cond, 'shape'):\n            raise ValueError(\"where must have a condition that is ndarray \"\n                             \"like\")\n\n        # our where function\n        def func(cond, values, other):\n            if cond.ravel().all():\n                return values\n\n            values, values_mask, other, other_mask = self._try_coerce_args(\n                values, other)\n\n            try:\n                return self._try_coerce_result(expressions.where(\n                    cond, values, other))\n            except Exception as detail:\n                if errors == 'raise':\n                    raise TypeError(\n                        'Could not operate [{other!r}] with block values '\n                        '[{detail!s}]'.format(other=other, detail=detail))\n                else:\n                    # return the values\n                    result = np.empty(values.shape, dtype='float64')\n                    result.fill(np.nan)\n                    return result\n\n        # see if we can operate on the entire block, or need item-by-item\n        # or if we are a single block (ndim == 1)\n        try:\n            result = func(cond, values, other)\n        except TypeError:\n\n            # we cannot coerce, return a compat dtype\n            # we are explicitly ignoring errors\n            block = self.coerce_to_target_dtype(other)\n            blocks = block.where(orig_other, cond, align=align,\n                                 errors=errors,\n                                 try_cast=try_cast, axis=axis,\n                                 transpose=transpose)\n            return self._maybe_downcast(blocks, 'infer')\n\n        if self._can_hold_na or self.ndim == 1:\n\n            if transpose:\n                result = result.T\n\n            # try to cast if requested\n            if try_cast:\n                result = self._try_cast_result(result)\n\n            return self.make_block(result)\n\n        # might need to separate out blocks\n        axis = cond.ndim - 1\n        cond = cond.swapaxes(axis, 0)\n        mask = np.array([cond[i].all() for i in range(cond.shape[0])],\n                        dtype=bool)\n\n        result_blocks = []\n        for m in [mask, ~mask]:\n            if m.any():\n                r = self._try_cast_result(result.take(m.nonzero()[0],\n                                                      axis=axis))\n                result_blocks.append(\n                    self.make_block(r.T, placement=self.mgr_locs[m]))\n\n        return result_blocks\n\n    def equals(self, other):\n        if self.dtype != other.dtype or self.shape != other.shape:\n            return False\n        return array_equivalent(self.values, other.values)\n\n    def _unstack(self, unstacker_func, new_columns):\n        \"\"\"Return a list of unstacked blocks of self\n\n        Parameters\n        ----------\n        unstacker_func : callable\n            Partially applied unstacker.\n        new_columns : Index\n            All columns of the unstacked BlockManager.\n\n        Returns\n        -------\n        blocks : list of Block\n            New blocks of unstacked values.\n        mask : array_like of bool\n            The mask of columns of `blocks` we should keep.\n        \"\"\"\n        unstacker = unstacker_func(self.values.T)\n        new_items = unstacker.get_new_columns()\n        new_placement = new_columns.get_indexer(new_items)\n        new_values, mask = unstacker.get_new_values()\n\n        mask = mask.any(0)\n        new_values = new_values.T[mask]\n        new_placement = new_placement[mask]\n\n        blocks = [make_block(new_values, placement=new_placement)]\n        return blocks, mask\n\n    def quantile(self, qs, interpolation='linear', axis=0, mgr=None):\n        \"\"\"\n        compute the quantiles of the\n\n        Parameters\n        ----------\n        qs: a scalar or list of the quantiles to be computed\n        interpolation: type of interpolation, default 'linear'\n        axis: axis to compute, default 0\n\n        Returns\n        -------\n        tuple of (axis, block)\n\n        \"\"\"\n        kw = {'interpolation': interpolation}\n        values = self.get_values()\n        values, _, _, _ = self._try_coerce_args(values, values)\n\n        def _nanpercentile1D(values, mask, q, **kw):\n            values = values[~mask]\n\n            if len(values) == 0:\n                if lib.is_scalar(q):\n                    return self._na_value\n                else:\n                    return np.array([self._na_value] * len(q),\n                                    dtype=values.dtype)\n\n            return np.percentile(values, q, **kw)\n\n        def _nanpercentile(values, q, axis, **kw):\n\n            mask = isna(self.values)\n            if not lib.is_scalar(mask) and mask.any():\n                if self.ndim == 1:\n                    return _nanpercentile1D(values, mask, q, **kw)\n                else:\n                    # for nonconsolidatable blocks mask is 1D, but values 2D\n                    if mask.ndim < values.ndim:\n                        mask = mask.reshape(values.shape)\n                    if axis == 0:\n                        values = values.T\n                        mask = mask.T\n                    result = [_nanpercentile1D(val, m, q, **kw) for (val, m)\n                              in zip(list(values), list(mask))]\n                    result = np.array(result, dtype=values.dtype, copy=False).T\n                    return result\n            else:\n                return np.percentile(values, q, axis=axis, **kw)\n\n        from pandas import Float64Index\n        is_empty = values.shape[axis] == 0\n        if is_list_like(qs):\n            ax = Float64Index(qs)\n\n            if is_empty:\n                if self.ndim == 1:\n                    result = self._na_value\n                else:\n                    # create the array of na_values\n                    # 2d len(values) * len(qs)\n                    result = np.repeat(np.array([self._na_value] * len(qs)),\n                                       len(values)).reshape(len(values),\n                                                            len(qs))\n            else:\n\n                try:\n                    result = _nanpercentile(values, np.array(qs) * 100,\n                                            axis=axis, **kw)\n                except ValueError:\n\n                    # older numpies don't handle an array for q\n                    result = [_nanpercentile(values, q * 100,\n                                             axis=axis, **kw) for q in qs]\n\n                result = np.array(result, copy=False)\n                if self.ndim > 1:\n                    result = result.T\n\n        else:\n\n            if self.ndim == 1:\n                ax = Float64Index([qs])\n            else:\n                ax = mgr.axes[0]\n\n            if is_empty:\n                if self.ndim == 1:\n                    result = self._na_value\n                else:\n                    result = np.array([self._na_value] * len(self))\n            else:\n                result = _nanpercentile(values, qs * 100, axis=axis, **kw)\n\n        ndim = getattr(result, 'ndim', None) or 0\n        result = self._try_coerce_result(result)\n        if lib.is_scalar(result):\n            return ax, self.make_block_scalar(result)\n        return ax, make_block(result,\n                              placement=np.arange(len(result)),\n                              ndim=ndim)\n\n\nclass ScalarBlock(Block):\n    \"\"\"\n    a scalar compat Block\n    \"\"\"\n    __slots__ = ['_mgr_locs', 'values', 'ndim']\n\n    def __init__(self, values):\n        self.ndim = 0\n        self.mgr_locs = [0]\n        self.values = values\n\n    @property\n    def dtype(self):\n        return type(self.values)\n\n    @property\n    def shape(self):\n        return tuple([0])\n\n    def __len__(self):\n        return 0\n\n\nclass NonConsolidatableMixIn(object):\n    \"\"\" hold methods for the nonconsolidatable blocks \"\"\"\n    _can_consolidate = False\n    _verify_integrity = False\n    _validate_ndim = False\n\n    def __init__(self, values, placement, ndim=None):\n        \"\"\"Initialize a non-consolidatable block.\n\n        'ndim' may be inferred from 'placement'.\n\n        This will call continue to call __init__ for the other base\n        classes mixed in with this Mixin.\n        \"\"\"\n        # Placement must be converted to BlockPlacement so that we can check\n        # its length\n        if not isinstance(placement, libinternals.BlockPlacement):\n            placement = libinternals.BlockPlacement(placement)\n\n        # Maybe infer ndim from placement\n        if ndim is None:\n            if len(placement) != 1:\n                ndim = 1\n            else:\n                ndim = 2\n        super(NonConsolidatableMixIn, self).__init__(values, placement,\n                                                     ndim=ndim)\n\n    @property\n    def shape(self):\n        if self.ndim == 1:\n            return (len(self.values)),\n        return (len(self.mgr_locs), len(self.values))\n\n    def get_values(self, dtype=None):\n        \"\"\" need to to_dense myself (and always return a ndim sized object) \"\"\"\n        values = self.values.to_dense()\n        if values.ndim == self.ndim - 1:\n            values = values.reshape((1,) + values.shape)\n        return values\n\n    def iget(self, col):\n\n        if self.ndim == 2 and isinstance(col, tuple):\n            col, loc = col\n            if not com.is_null_slice(col) and col != 0:\n                raise IndexError(\"{0} only contains one item\".format(self))\n            return self.values[loc]\n        else:\n            if col != 0:\n                raise IndexError(\"{0} only contains one item\".format(self))\n            return self.values\n\n    def should_store(self, value):\n        return isinstance(value, self._holder)\n\n    def set(self, locs, values, check=False):\n        assert locs.tolist() == [0]\n        self.values = values\n\n    def putmask(self, mask, new, align=True, inplace=False, axis=0,\n                transpose=False, mgr=None):\n        \"\"\"\n        putmask the data to the block; we must be a single block and not\n        generate other blocks\n\n        return the resulting block\n\n        Parameters\n        ----------\n        mask  : the condition to respect\n        new : a ndarray/object\n        align : boolean, perform alignment on other/cond, default is True\n        inplace : perform inplace modification, default is False\n\n        Returns\n        -------\n        a new block, the result of the putmask\n        \"\"\"\n        inplace = validate_bool_kwarg(inplace, 'inplace')\n\n        # use block's copy logic.\n        # .values may be an Index which does shallow copy by default\n        new_values = self.values if inplace else self.copy().values\n        new_values, _, new, _ = self._try_coerce_args(new_values, new)\n\n        if isinstance(new, np.ndarray) and len(new) == len(mask):\n            new = new[mask]\n\n        mask = _safe_reshape(mask, new_values.shape)\n\n        new_values[mask] = new\n        new_values = self._try_coerce_result(new_values)\n        return [self.make_block(values=new_values)]\n\n    def _slice(self, slicer):\n        \"\"\" return a slice of my values (but densify first) \"\"\"\n        return self.get_values()[slicer]\n\n    def _try_cast_result(self, result, dtype=None):\n        return result\n\n    def _unstack(self, unstacker_func, new_columns):\n        \"\"\"Return a list of unstacked blocks of self\n\n        Parameters\n        ----------\n        unstacker_func : callable\n            Partially applied unstacker.\n        new_columns : Index\n            All columns of the unstacked BlockManager.\n\n        Returns\n        -------\n        blocks : list of Block\n            New blocks of unstacked values.\n        mask : array_like of bool\n            The mask of columns of `blocks` we should keep.\n        \"\"\"\n        # NonConsolidatable blocks can have a single item only, so we return\n        # one block per item\n        unstacker = unstacker_func(self.values.T)\n        new_items = unstacker.get_new_columns()\n        new_placement = new_columns.get_indexer(new_items)\n        new_values, mask = unstacker.get_new_values()\n\n        mask = mask.any(0)\n        new_values = new_values.T[mask]\n        new_placement = new_placement[mask]\n\n        blocks = [self.make_block_same_class(vals, [place])\n                  for vals, place in zip(new_values, new_placement)]\n        return blocks, mask\n\n\nclass ExtensionBlock(NonConsolidatableMixIn, Block):\n    \"\"\"Block for holding extension types.\n\n    Notes\n    -----\n    This holds all 3rd-party extension array types. It's also the immediate\n    parent class for our internal extension types' blocks, CategoricalBlock.\n\n    ExtensionArrays are limited to 1-D.\n    \"\"\"\n    is_extension = True\n\n    def __init__(self, values, placement, ndim=None):\n        values = self._maybe_coerce_values(values)\n        super(ExtensionBlock, self).__init__(values, placement, ndim)\n\n    def _maybe_coerce_values(self, values):\n        \"\"\"Unbox to an extension array.\n\n        This will unbox an ExtensionArray stored in an Index or Series.\n        ExtensionArrays pass through. No dtype coercion is done.\n\n        Parameters\n        ----------\n        values : Index, Series, ExtensionArray\n\n        Returns\n        -------\n        ExtensionArray\n        \"\"\"\n        if isinstance(values, (ABCIndexClass, ABCSeries)):\n            values = values._values\n        return values\n\n    @property\n    def _holder(self):\n        # For extension blocks, the holder is values-dependent.\n        return type(self.values)\n\n    @property\n    def fill_value(self):\n        # Used in reindex_indexer\n        return self.values.dtype.na_value\n\n    @property\n    def _can_hold_na(self):\n        # The default ExtensionArray._can_hold_na is True\n        return self._holder._can_hold_na\n\n    @property\n    def is_view(self):\n        \"\"\"Extension arrays are never treated as views.\"\"\"\n        return False\n\n    def setitem(self, indexer, value, mgr=None):\n        \"\"\"Set the value inplace, returning a same-typed block.\n\n        This differs from Block.setitem by not allowing setitem to change\n        the dtype of the Block.\n\n        Parameters\n        ----------\n        indexer : tuple, list-like, array-like, slice\n            The subset of self.values to set\n        value : object\n            The value being set\n        mgr : BlockPlacement, optional\n\n        Returns\n        -------\n        Block\n\n        Notes\n        -----\n        `indexer` is a direct slice/positional indexer. `value` must\n        be a compatible shape.\n        \"\"\"\n        if isinstance(indexer, tuple):\n            # we are always 1-D\n            indexer = indexer[0]\n\n        check_setitem_lengths(indexer, value, self.values)\n        self.values[indexer] = value\n        return self\n\n    def get_values(self, dtype=None):\n        # ExtensionArrays must be iterable, so this works.\n        values = np.asarray(self.values)\n        if values.ndim == self.ndim - 1:\n            values = values.reshape((1,) + values.shape)\n        return values\n\n    def to_dense(self):\n        return np.asarray(self.values)\n\n    def take_nd(self, indexer, axis=0, new_mgr_locs=None, fill_tuple=None):\n        \"\"\"\n        Take values according to indexer and return them as a block.\n        \"\"\"\n        if fill_tuple is None:\n            fill_value = None\n        else:\n            fill_value = fill_tuple[0]\n\n        # axis doesn't matter; we are really a single-dim object\n        # but are passed the axis depending on the calling routing\n        # if its REALLY axis 0, then this will be a reindex and not a take\n        new_values = self.values.take(indexer, fill_value=fill_value,\n                                      allow_fill=True)\n\n        # if we are a 1-dim object, then always place at 0\n        if self.ndim == 1:\n            new_mgr_locs = [0]\n        else:\n            if new_mgr_locs is None:\n                new_mgr_locs = self.mgr_locs\n\n        return self.make_block_same_class(new_values, new_mgr_locs)\n\n    def _can_hold_element(self, element):\n        # XXX: We may need to think about pushing this onto the array.\n        # We're doing the same as CategoricalBlock here.\n        return True\n\n    def _slice(self, slicer):\n        \"\"\" return a slice of my values \"\"\"\n\n        # slice the category\n        # return same dims as we currently have\n\n        if isinstance(slicer, tuple) and len(slicer) == 2:\n            if not com.is_null_slice(slicer[0]):\n                raise AssertionError(\"invalid slicing for a 1-ndim \"\n                                     \"categorical\")\n            slicer = slicer[1]\n\n        return self.values[slicer]\n\n    def formatting_values(self):\n        return self.values._formatting_values()\n\n    def concat_same_type(self, to_concat, placement=None):\n        \"\"\"\n        Concatenate list of single blocks of the same type.\n        \"\"\"\n        values = self._holder._concat_same_type(\n            [blk.values for blk in to_concat])\n        placement = placement or slice(0, len(values), 1)\n        return self.make_block_same_class(values, ndim=self.ndim,\n                                          placement=placement)\n\n    def fillna(self, value, limit=None, inplace=False, downcast=None,\n               mgr=None):\n        values = self.values if inplace else self.values.copy()\n        values = values.fillna(value=value, limit=limit)\n        return [self.make_block_same_class(values=values,\n                                           placement=self.mgr_locs,\n                                           ndim=self.ndim)]\n\n    def interpolate(self, method='pad', axis=0, inplace=False, limit=None,\n                    fill_value=None, **kwargs):\n\n        values = self.values if inplace else self.values.copy()\n        return self.make_block_same_class(\n            values=values.fillna(value=fill_value, method=method,\n                                 limit=limit),\n            placement=self.mgr_locs)\n\n\nclass NumericBlock(Block):\n    __slots__ = ()\n    is_numeric = True\n    _can_hold_na = True\n\n\nclass FloatOrComplexBlock(NumericBlock):\n    __slots__ = ()\n\n    def equals(self, other):\n        if self.dtype != other.dtype or self.shape != other.shape:\n            return False\n        left, right = self.values, other.values\n        return ((left == right) | (np.isnan(left) & np.isnan(right))).all()\n\n\nclass FloatBlock(FloatOrComplexBlock):\n    __slots__ = ()\n    is_float = True\n\n    def _can_hold_element(self, element):\n        tipo = maybe_infer_dtype_type(element)\n        if tipo is not None:\n            return (issubclass(tipo.type, (np.floating, np.integer)) and\n                    not issubclass(tipo.type, (np.datetime64, np.timedelta64)))\n        return (\n            isinstance(\n                element, (float, int, np.floating, np.int_, compat.long))\n            and not isinstance(element, (bool, np.bool_, datetime, timedelta,\n                                         np.datetime64, np.timedelta64)))\n\n    def to_native_types(self, slicer=None, na_rep='', float_format=None,\n                        decimal='.', quoting=None, **kwargs):\n        \"\"\" convert to our native types format, slicing if desired \"\"\"\n\n        values = self.values\n        if slicer is not None:\n            values = values[:, slicer]\n\n        # see gh-13418: no special formatting is desired at the\n        # output (important for appropriate 'quoting' behaviour),\n        # so do not pass it through the FloatArrayFormatter\n        if float_format is None and decimal == '.':\n            mask = isna(values)\n\n            if not quoting:\n                values = values.astype(str)\n            else:\n                values = np.array(values, dtype='object')\n\n            values[mask] = na_rep\n            return values\n\n        from pandas.io.formats.format import FloatArrayFormatter\n        formatter = FloatArrayFormatter(values, na_rep=na_rep,\n                                        float_format=float_format,\n                                        decimal=decimal, quoting=quoting,\n                                        fixed_width=False)\n        return formatter.get_result_as_array()\n\n    def should_store(self, value):\n        # when inserting a column should not coerce integers to floats\n        # unnecessarily\n        return (issubclass(value.dtype.type, np.floating) and\n                value.dtype == self.dtype)\n\n\nclass ComplexBlock(FloatOrComplexBlock):\n    __slots__ = ()\n    is_complex = True\n\n    def _can_hold_element(self, element):\n        tipo = maybe_infer_dtype_type(element)\n        if tipo is not None:\n            return issubclass(tipo.type,\n                              (np.floating, np.integer, np.complexfloating))\n        return (\n            isinstance(\n                element,\n                (float, int, complex, np.float_, np.int_, compat.long))\n            and not isinstance(element, (bool, np.bool_)))\n\n    def should_store(self, value):\n        return issubclass(value.dtype.type, np.complexfloating)\n\n\nclass IntBlock(NumericBlock):\n    __slots__ = ()\n    is_integer = True\n    _can_hold_na = False\n\n    def _can_hold_element(self, element):\n        tipo = maybe_infer_dtype_type(element)\n        if tipo is not None:\n            return (issubclass(tipo.type, np.integer) and\n                    not issubclass(tipo.type, (np.datetime64,\n                                               np.timedelta64)) and\n                    self.dtype.itemsize >= tipo.itemsize)\n        return is_integer(element)\n\n    def should_store(self, value):\n        return is_integer_dtype(value) and value.dtype == self.dtype\n\n\nclass DatetimeLikeBlockMixin(object):\n    \"\"\"Mixin class for DatetimeBlock and DatetimeTZBlock.\"\"\"\n\n    @property\n    def _holder(self):\n        return DatetimeIndex\n\n    @property\n    def _na_value(self):\n        return tslibs.NaT\n\n    @property\n    def fill_value(self):\n        return tslibs.iNaT\n\n    def get_values(self, dtype=None):\n        \"\"\"\n        return object dtype as boxed values, such as Timestamps/Timedelta\n        \"\"\"\n        if is_object_dtype(dtype):\n            return lib.map_infer(self.values.ravel(),\n                                 self._box_func).reshape(self.values.shape)\n        return self.values\n\n\nclass TimeDeltaBlock(DatetimeLikeBlockMixin, IntBlock):\n    __slots__ = ()\n    is_timedelta = True\n    _can_hold_na = True\n    is_numeric = False\n\n    def __init__(self, values, placement, ndim=None):\n        if values.dtype != _TD_DTYPE:\n            values = conversion.ensure_timedelta64ns(values)\n\n        super(TimeDeltaBlock, self).__init__(values,\n                                             placement=placement, ndim=ndim)\n\n    @property\n    def _holder(self):\n        return TimedeltaIndex\n\n    @property\n    def _box_func(self):\n        return lambda x: Timedelta(x, unit='ns')\n\n    def _can_hold_element(self, element):\n        tipo = maybe_infer_dtype_type(element)\n        if tipo is not None:\n            return issubclass(tipo.type, np.timedelta64)\n        return is_integer(element) or isinstance(\n            element, (timedelta, np.timedelta64))\n\n    def fillna(self, value, **kwargs):\n\n        # allow filling with integers to be\n        # interpreted as seconds\n        if is_integer(value) and not isinstance(value, np.timedelta64):\n            value = Timedelta(value, unit='s')\n        return super(TimeDeltaBlock, self).fillna(value, **kwargs)\n\n    def _try_coerce_args(self, values, other):\n        \"\"\"\n        Coerce values and other to int64, with null values converted to\n        iNaT. values is always ndarray-like, other may not be\n\n        Parameters\n        ----------\n        values : ndarray-like\n        other : ndarray-like or scalar\n\n        Returns\n        -------\n        base-type values, values mask, base-type other, other mask\n        \"\"\"\n\n        values_mask = isna(values)\n        values = values.view('i8')\n        other_mask = False\n\n        if isinstance(other, bool):\n            raise TypeError\n        elif is_null_datelike_scalar(other):\n            other = tslibs.iNaT\n            other_mask = True\n        elif isinstance(other, Timedelta):\n            other_mask = isna(other)\n            other = other.value\n        elif isinstance(other, timedelta):\n            other = Timedelta(other).value\n        elif isinstance(other, np.timedelta64):\n            other_mask = isna(other)\n            other = Timedelta(other).value\n        elif hasattr(other, 'dtype') and is_timedelta64_dtype(other):\n            other_mask = isna(other)\n            other = other.astype('i8', copy=False).view('i8')\n        else:\n            # coercion issues\n            # let higher levels handle\n            raise TypeError\n\n        return values, values_mask, other, other_mask\n\n    def _try_coerce_result(self, result):\n        \"\"\" reverse of try_coerce_args / try_operate \"\"\"\n        if isinstance(result, np.ndarray):\n            mask = isna(result)\n            if result.dtype.kind in ['i', 'f', 'O']:\n                result = result.astype('m8[ns]')\n            result[mask] = tslibs.iNaT\n        elif isinstance(result, (np.integer, np.float)):\n            result = self._box_func(result)\n        return result\n\n    def should_store(self, value):\n        return issubclass(value.dtype.type, np.timedelta64)\n\n    def to_native_types(self, slicer=None, na_rep=None, quoting=None,\n                        **kwargs):\n        \"\"\" convert to our native types format, slicing if desired \"\"\"\n\n        values = self.values\n        if slicer is not None:\n            values = values[:, slicer]\n        mask = isna(values)\n\n        rvalues = np.empty(values.shape, dtype=object)\n        if na_rep is None:\n            na_rep = 'NaT'\n        rvalues[mask] = na_rep\n        imask = (~mask).ravel()\n\n        # FIXME:\n        # should use the formats.format.Timedelta64Formatter here\n        # to figure what format to pass to the Timedelta\n        # e.g. to not show the decimals say\n        rvalues.flat[imask] = np.array([Timedelta(val)._repr_base(format='all')\n                                        for val in values.ravel()[imask]],\n                                       dtype=object)\n        return rvalues\n\n\nclass BoolBlock(NumericBlock):\n    __slots__ = ()\n    is_bool = True\n    _can_hold_na = False\n\n    def _can_hold_element(self, element):\n        tipo = maybe_infer_dtype_type(element)\n        if tipo is not None:\n            return issubclass(tipo.type, np.bool_)\n        return isinstance(element, (bool, np.bool_))\n\n    def should_store(self, value):\n        return issubclass(value.dtype.type, np.bool_)\n\n    def replace(self, to_replace, value, inplace=False, filter=None,\n                regex=False, convert=True, mgr=None):\n        inplace = validate_bool_kwarg(inplace, 'inplace')\n        to_replace_values = np.atleast_1d(to_replace)\n        if not np.can_cast(to_replace_values, bool):\n            return self\n        return super(BoolBlock, self).replace(to_replace, value,\n                                              inplace=inplace, filter=filter,\n                                              regex=regex, convert=convert,\n                                              mgr=mgr)\n\n\nclass ObjectBlock(Block):\n    __slots__ = ()\n    is_object = True\n    _can_hold_na = True\n\n    def __init__(self, values, placement=None, ndim=2):\n        if issubclass(values.dtype.type, compat.string_types):\n            values = np.array(values, dtype=object)\n\n        super(ObjectBlock, self).__init__(values, ndim=ndim,\n                                          placement=placement)\n\n    @property\n    def is_bool(self):\n        \"\"\" we can be a bool if we have only bool values but are of type\n        object\n        \"\"\"\n        return lib.is_bool_array(self.values.ravel())\n\n    # TODO: Refactor when convert_objects is removed since there will be 1 path\n    def convert(self, *args, **kwargs):\n        \"\"\" attempt to coerce any object types to better types return a copy of\n        the block (if copy = True) by definition we ARE an ObjectBlock!!!!!\n\n        can return multiple blocks!\n        \"\"\"\n\n        if args:\n            raise NotImplementedError\n        by_item = True if 'by_item' not in kwargs else kwargs['by_item']\n\n        new_inputs = ['coerce', 'datetime', 'numeric', 'timedelta']\n        new_style = False\n        for kw in new_inputs:\n            new_style |= kw in kwargs\n\n        if new_style:\n            fn = soft_convert_objects\n            fn_inputs = new_inputs\n        else:\n            fn = maybe_convert_objects\n            fn_inputs = ['convert_dates', 'convert_numeric',\n                         'convert_timedeltas']\n        fn_inputs += ['copy']\n\n        fn_kwargs = {}\n        for key in fn_inputs:\n            if key in kwargs:\n                fn_kwargs[key] = kwargs[key]\n\n        # operate column-by-column\n        def f(m, v, i):\n            shape = v.shape\n            values = fn(v.ravel(), **fn_kwargs)\n            try:\n                values = values.reshape(shape)\n                values = _block_shape(values, ndim=self.ndim)\n            except (AttributeError, NotImplementedError):\n                pass\n\n            return values\n\n        if by_item and not self._is_single_block:\n            blocks = self.split_and_operate(None, f, False)\n        else:\n            values = f(None, self.values.ravel(), None)\n            blocks = [make_block(values, ndim=self.ndim,\n                                 placement=self.mgr_locs)]\n\n        return blocks\n\n    def set(self, locs, values, check=False):\n        \"\"\"\n        Modify Block in-place with new item value\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        # GH6026\n        if check:\n            try:\n                if (self.values[locs] == values).all():\n                    return\n            except:\n                pass\n        try:\n            self.values[locs] = values\n        except (ValueError):\n\n            # broadcasting error\n            # see GH6171\n            new_shape = list(values.shape)\n            new_shape[0] = len(self.items)\n            self.values = np.empty(tuple(new_shape), dtype=self.dtype)\n            self.values.fill(np.nan)\n            self.values[locs] = values\n\n    def _maybe_downcast(self, blocks, downcast=None):\n\n        if downcast is not None:\n            return blocks\n\n        # split and convert the blocks\n        return _extend_blocks([b.convert(datetime=True, numeric=False)\n                               for b in blocks])\n\n    def _can_hold_element(self, element):\n        return True\n\n    def _try_coerce_args(self, values, other):\n        \"\"\" provide coercion to our input arguments \"\"\"\n\n        if isinstance(other, ABCDatetimeIndex):\n            # to store DatetimeTZBlock as object\n            other = other.astype(object).values\n\n        return values, False, other, False\n\n    def should_store(self, value):\n        return not (issubclass(value.dtype.type,\n                               (np.integer, np.floating, np.complexfloating,\n                                np.datetime64, np.bool_)) or\n                    # TODO(ExtensionArray): remove is_extension_type\n                    # when all extension arrays have been ported.\n                    is_extension_type(value) or\n                    is_extension_array_dtype(value))\n\n    def replace(self, to_replace, value, inplace=False, filter=None,\n                regex=False, convert=True, mgr=None):\n        to_rep_is_list = is_list_like(to_replace)\n        value_is_list = is_list_like(value)\n        both_lists = to_rep_is_list and value_is_list\n        either_list = to_rep_is_list or value_is_list\n\n        result_blocks = []\n        blocks = [self]\n\n        if not either_list and is_re(to_replace):\n            return self._replace_single(to_replace, value, inplace=inplace,\n                                        filter=filter, regex=True,\n                                        convert=convert, mgr=mgr)\n        elif not (either_list or regex):\n            return super(ObjectBlock, self).replace(to_replace, value,\n                                                    inplace=inplace,\n                                                    filter=filter, regex=regex,\n                                                    convert=convert, mgr=mgr)\n        elif both_lists:\n            for to_rep, v in zip(to_replace, value):\n                result_blocks = []\n                for b in blocks:\n                    result = b._replace_single(to_rep, v, inplace=inplace,\n                                               filter=filter, regex=regex,\n                                               convert=convert, mgr=mgr)\n                    result_blocks = _extend_blocks(result, result_blocks)\n                blocks = result_blocks\n            return result_blocks\n\n        elif to_rep_is_list and regex:\n            for to_rep in to_replace:\n                result_blocks = []\n                for b in blocks:\n                    result = b._replace_single(to_rep, value, inplace=inplace,\n                                               filter=filter, regex=regex,\n                                               convert=convert, mgr=mgr)\n                    result_blocks = _extend_blocks(result, result_blocks)\n                blocks = result_blocks\n            return result_blocks\n\n        return self._replace_single(to_replace, value, inplace=inplace,\n                                    filter=filter, convert=convert,\n                                    regex=regex, mgr=mgr)\n\n    def _replace_single(self, to_replace, value, inplace=False, filter=None,\n                        regex=False, convert=True, mgr=None):\n\n        inplace = validate_bool_kwarg(inplace, 'inplace')\n\n        # to_replace is regex compilable\n        to_rep_re = regex and is_re_compilable(to_replace)\n\n        # regex is regex compilable\n        regex_re = is_re_compilable(regex)\n\n        # only one will survive\n        if to_rep_re and regex_re:\n            raise AssertionError('only one of to_replace and regex can be '\n                                 'regex compilable')\n\n        # if regex was passed as something that can be a regex (rather than a\n        # boolean)\n        if regex_re:\n            to_replace = regex\n\n        regex = regex_re or to_rep_re\n\n        # try to get the pattern attribute (compiled re) or it's a string\n        try:\n            pattern = to_replace.pattern\n        except AttributeError:\n            pattern = to_replace\n\n        # if the pattern is not empty and to_replace is either a string or a\n        # regex\n        if regex and pattern:\n            rx = re.compile(to_replace)\n        else:\n            # if the thing to replace is not a string or compiled regex call\n            # the superclass method -> to_replace is some kind of object\n            return super(ObjectBlock, self).replace(to_replace, value,\n                                                    inplace=inplace,\n                                                    filter=filter, regex=regex,\n                                                    mgr=mgr)\n\n        new_values = self.values if inplace else self.values.copy()\n\n        # deal with replacing values with objects (strings) that match but\n        # whose replacement is not a string (numeric, nan, object)\n        if isna(value) or not isinstance(value, compat.string_types):\n\n            def re_replacer(s):\n                try:\n                    return value if rx.search(s) is not None else s\n                except TypeError:\n                    return s\n        else:\n            # value is guaranteed to be a string here, s can be either a string\n            # or null if it's null it gets returned\n            def re_replacer(s):\n                try:\n                    return rx.sub(value, s)\n                except TypeError:\n                    return s\n\n        f = np.vectorize(re_replacer, otypes=[self.dtype])\n\n        if filter is None:\n            filt = slice(None)\n        else:\n            filt = self.mgr_locs.isin(filter).nonzero()[0]\n\n        new_values[filt] = f(new_values[filt])\n\n        # convert\n        block = self.make_block(new_values)\n        if convert:\n            block = block.convert(by_item=True, numeric=False)\n\n        return block\n\n\nclass CategoricalBlock(ExtensionBlock):\n    __slots__ = ()\n    is_categorical = True\n    _verify_integrity = True\n    _can_hold_na = True\n    _concatenator = staticmethod(_concat._concat_categorical)\n\n    def __init__(self, values, placement, ndim=None):\n        from pandas.core.arrays.categorical import _maybe_to_categorical\n\n        # coerce to categorical if we can\n        super(CategoricalBlock, self).__init__(_maybe_to_categorical(values),\n                                               placement=placement,\n                                               ndim=ndim)\n\n    @property\n    def _holder(self):\n        return Categorical\n\n    @property\n    def array_dtype(self):\n        \"\"\" the dtype to return if I want to construct this block as an\n        array\n        \"\"\"\n        return np.object_\n\n    def _try_coerce_result(self, result):\n        \"\"\" reverse of try_coerce_args \"\"\"\n\n        # GH12564: CategoricalBlock is 1-dim only\n        # while returned results could be any dim\n        if ((not is_categorical_dtype(result)) and\n                isinstance(result, np.ndarray)):\n            result = _block_shape(result, ndim=self.ndim)\n\n        return result\n\n    def shift(self, periods, axis=0, mgr=None):\n        return self.make_block_same_class(values=self.values.shift(periods),\n                                          placement=self.mgr_locs)\n\n    def to_dense(self):\n        # Categorical.get_values returns a DatetimeIndex for datetime\n        # categories, so we can't simply use `np.asarray(self.values)` like\n        # other types.\n        return self.values.get_values()\n\n    def to_native_types(self, slicer=None, na_rep='', quoting=None, **kwargs):\n        \"\"\" convert to our native types format, slicing if desired \"\"\"\n\n        values = self.values\n        if slicer is not None:\n            # Categorical is always one dimension\n            values = values[slicer]\n        mask = isna(values)\n        values = np.array(values, dtype='object')\n        values[mask] = na_rep\n\n        # we are expected to return a 2-d ndarray\n        return values.reshape(1, len(values))\n\n    def concat_same_type(self, to_concat, placement=None):\n        \"\"\"\n        Concatenate list of single blocks of the same type.\n\n        Note that this CategoricalBlock._concat_same_type *may* not\n        return a CategoricalBlock. When the categories in `to_concat`\n        differ, this will return an object ndarray.\n\n        If / when we decide we don't like that behavior:\n\n        1. Change Categorical._concat_same_type to use union_categoricals\n        2. Delete this method.\n        \"\"\"\n        values = self._concatenator([blk.values for blk in to_concat],\n                                    axis=self.ndim - 1)\n        # not using self.make_block_same_class as values can be object dtype\n        return make_block(\n            values, placement=placement or slice(0, len(values), 1),\n            ndim=self.ndim)\n\n\nclass DatetimeBlock(DatetimeLikeBlockMixin, Block):\n    __slots__ = ()\n    is_datetime = True\n    _can_hold_na = True\n\n    def __init__(self, values, placement, ndim=None):\n        values = self._maybe_coerce_values(values)\n        super(DatetimeBlock, self).__init__(values,\n                                            placement=placement, ndim=ndim)\n\n    def _maybe_coerce_values(self, values):\n        \"\"\"Input validation for values passed to __init__. Ensure that\n        we have datetime64ns, coercing if necessary.\n\n        Parameters\n        ----------\n        values : array-like\n            Must be convertible to datetime64\n\n        Returns\n        -------\n        values : ndarray[datetime64ns]\n\n        Overridden by DatetimeTZBlock.\n        \"\"\"\n        if values.dtype != _NS_DTYPE:\n            values = conversion.ensure_datetime64ns(values)\n        return values\n\n    def _astype(self, dtype, mgr=None, **kwargs):\n        \"\"\"\n        these automatically copy, so copy=True has no effect\n        raise on an except if raise == True\n        \"\"\"\n\n        # if we are passed a datetime64[ns, tz]\n        if is_datetime64tz_dtype(dtype):\n            dtype = DatetimeTZDtype(dtype)\n\n            values = self.values\n            if getattr(values, 'tz', None) is None:\n                values = DatetimeIndex(values).tz_localize('UTC')\n            values = values.tz_convert(dtype.tz)\n            return self.make_block(values)\n\n        # delegate\n        return super(DatetimeBlock, self)._astype(dtype=dtype, **kwargs)\n\n    def _can_hold_element(self, element):\n        tipo = maybe_infer_dtype_type(element)\n        if tipo is not None:\n            # TODO: this still uses asarray, instead of dtype.type\n            element = np.array(element)\n            return element.dtype == _NS_DTYPE or element.dtype == np.int64\n        return (is_integer(element) or isinstance(element, datetime) or\n                isna(element))\n\n    def _try_coerce_args(self, values, other):\n        \"\"\"\n        Coerce values and other to dtype 'i8'. NaN and NaT convert to\n        the smallest i8, and will correctly round-trip to NaT if converted\n        back in _try_coerce_result. values is always ndarray-like, other\n        may not be\n\n        Parameters\n        ----------\n        values : ndarray-like\n        other : ndarray-like or scalar\n\n        Returns\n        -------\n        base-type values, values mask, base-type other, other mask\n        \"\"\"\n\n        values_mask = isna(values)\n        values = values.view('i8')\n        other_mask = False\n\n        if isinstance(other, bool):\n            raise TypeError\n        elif is_null_datelike_scalar(other):\n            other = tslibs.iNaT\n            other_mask = True\n        elif isinstance(other, (datetime, np.datetime64, date)):\n            other = self._box_func(other)\n            if getattr(other, 'tz') is not None:\n                raise TypeError(\"cannot coerce a Timestamp with a tz on a \"\n                                \"naive Block\")\n            other_mask = isna(other)\n            other = other.asm8.view('i8')\n        elif hasattr(other, 'dtype') and is_datetime64_dtype(other):\n            other_mask = isna(other)\n            other = other.astype('i8', copy=False).view('i8')\n        else:\n            # coercion issues\n            # let higher levels handle\n            raise TypeError\n\n        return values, values_mask, other, other_mask\n\n    def _try_coerce_result(self, result):\n        \"\"\" reverse of try_coerce_args \"\"\"\n        if isinstance(result, np.ndarray):\n            if result.dtype.kind in ['i', 'f', 'O']:\n                try:\n                    result = result.astype('M8[ns]')\n                except ValueError:\n                    pass\n        elif isinstance(result, (np.integer, np.float, np.datetime64)):\n            result = self._box_func(result)\n        return result\n\n    @property\n    def _box_func(self):\n        return tslibs.Timestamp\n\n    def to_native_types(self, slicer=None, na_rep=None, date_format=None,\n                        quoting=None, **kwargs):\n        \"\"\" convert to our native types format, slicing if desired \"\"\"\n\n        values = self.values\n        if slicer is not None:\n            values = values[..., slicer]\n\n        from pandas.io.formats.format import _get_format_datetime64_from_values\n        format = _get_format_datetime64_from_values(values, date_format)\n\n        result = tslib.format_array_from_datetime(\n            values.view('i8').ravel(), tz=getattr(self.values, 'tz', None),\n            format=format, na_rep=na_rep).reshape(values.shape)\n        return np.atleast_2d(result)\n\n    def should_store(self, value):\n        return (issubclass(value.dtype.type, np.datetime64) and\n                not is_datetimetz(value))\n\n    def set(self, locs, values, check=False):\n        \"\"\"\n        Modify Block in-place with new item value\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if values.dtype != _NS_DTYPE:\n            # Workaround for numpy 1.6 bug\n            values = conversion.ensure_datetime64ns(values)\n\n        self.values[locs] = values\n\n\nclass DatetimeTZBlock(NonConsolidatableMixIn, DatetimeBlock):\n    \"\"\" implement a datetime64 block with a tz attribute \"\"\"\n    __slots__ = ()\n    _concatenator = staticmethod(_concat._concat_datetime)\n    is_datetimetz = True\n\n    def __init__(self, values, placement, ndim=2, dtype=None):\n        # XXX: This will end up calling _maybe_coerce_values twice\n        # when dtype is not None. It's relatively cheap (just an isinstance)\n        # but it'd nice to avoid.\n        #\n        # If we can remove dtype from __init__, and push that conversion\n        # push onto the callers, then we can remove this entire __init__\n        # and just use DatetimeBlock's.\n        if dtype is not None:\n            values = self._maybe_coerce_values(values, dtype=dtype)\n        super(DatetimeTZBlock, self).__init__(values, placement=placement,\n                                              ndim=ndim)\n\n    def _maybe_coerce_values(self, values, dtype=None):\n        \"\"\"Input validation for values passed to __init__. Ensure that\n        we have datetime64TZ, coercing if necessary.\n\n        Parametetrs\n        -----------\n        values : array-like\n            Must be convertible to datetime64\n        dtype : string or DatetimeTZDtype, optional\n            Does a shallow copy to this tz\n\n        Returns\n        -------\n        values : ndarray[datetime64ns]\n        \"\"\"\n        if not isinstance(values, self._holder):\n            values = self._holder(values)\n\n        if dtype is not None:\n            if isinstance(dtype, compat.string_types):\n                dtype = DatetimeTZDtype.construct_from_string(dtype)\n            values = values._shallow_copy(tz=dtype.tz)\n\n        if values.tz is None:\n            raise ValueError(\"cannot create a DatetimeTZBlock without a tz\")\n\n        return values\n\n    @property\n    def is_view(self):\n        \"\"\" return a boolean if I am possibly a view \"\"\"\n        # check the ndarray values of the DatetimeIndex values\n        return self.values.values.base is not None\n\n    def copy(self, deep=True, mgr=None):\n        \"\"\" copy constructor \"\"\"\n        values = self.values\n        if deep:\n            values = values.copy(deep=True)\n        return self.make_block_same_class(values)\n\n    def external_values(self):\n        \"\"\" we internally represent the data as a DatetimeIndex, but for\n        external compat with ndarray, export as a ndarray of Timestamps\n        \"\"\"\n        return self.values.astype('datetime64[ns]').values\n\n    def get_values(self, dtype=None):\n        # return object dtype as Timestamps with the zones\n        if is_object_dtype(dtype):\n            return lib.map_infer(\n                self.values.ravel(), self._box_func).reshape(self.values.shape)\n        return self.values\n\n    def _slice(self, slicer):\n        \"\"\" return a slice of my values \"\"\"\n        if isinstance(slicer, tuple):\n            col, loc = slicer\n            if not com.is_null_slice(col) and col != 0:\n                raise IndexError(\"{0} only contains one item\".format(self))\n            return self.values[loc]\n        return self.values[slicer]\n\n    def _try_coerce_args(self, values, other):\n        \"\"\"\n        localize and return i8 for the values\n\n        Parameters\n        ----------\n        values : ndarray-like\n        other : ndarray-like or scalar\n\n        Returns\n        -------\n        base-type values, values mask, base-type other, other mask\n        \"\"\"\n        values_mask = _block_shape(isna(values), ndim=self.ndim)\n        # asi8 is a view, needs copy\n        values = _block_shape(values.asi8, ndim=self.ndim)\n        other_mask = False\n\n        if isinstance(other, ABCSeries):\n            other = self._holder(other)\n            other_mask = isna(other)\n\n        if isinstance(other, bool):\n            raise TypeError\n        elif (is_null_datelike_scalar(other) or\n              (lib.is_scalar(other) and isna(other))):\n            other = tslibs.iNaT\n            other_mask = True\n        elif isinstance(other, self._holder):\n            if other.tz != self.values.tz:\n                raise ValueError(\"incompatible or non tz-aware value\")\n            other_mask = _block_shape(isna(other), ndim=self.ndim)\n            other = _block_shape(other.asi8, ndim=self.ndim)\n        elif isinstance(other, (np.datetime64, datetime, date)):\n            other = tslibs.Timestamp(other)\n            tz = getattr(other, 'tz', None)\n\n            # test we can have an equal time zone\n            if tz is None or str(tz) != str(self.values.tz):\n                raise ValueError(\"incompatible or non tz-aware value\")\n            other_mask = isna(other)\n            other = other.value\n        else:\n            raise TypeError\n\n        return values, values_mask, other, other_mask\n\n    def _try_coerce_result(self, result):\n        \"\"\" reverse of try_coerce_args \"\"\"\n        if isinstance(result, np.ndarray):\n            if result.dtype.kind in ['i', 'f', 'O']:\n                result = result.astype('M8[ns]')\n        elif isinstance(result, (np.integer, np.float, np.datetime64)):\n            result = tslibs.Timestamp(result, tz=self.values.tz)\n        if isinstance(result, np.ndarray):\n            # allow passing of > 1dim if its trivial\n            if result.ndim > 1:\n                result = result.reshape(np.prod(result.shape))\n            result = self.values._shallow_copy(result)\n\n        return result\n\n    @property\n    def _box_func(self):\n        return lambda x: tslibs.Timestamp(x, tz=self.dtype.tz)\n\n    def shift(self, periods, axis=0, mgr=None):\n        \"\"\" shift the block by periods \"\"\"\n\n        # think about moving this to the DatetimeIndex. This is a non-freq\n        # (number of periods) shift ###\n\n        N = len(self)\n        indexer = np.zeros(N, dtype=int)\n        if periods > 0:\n            indexer[periods:] = np.arange(N - periods)\n        else:\n            indexer[:periods] = np.arange(-periods, N)\n\n        new_values = self.values.asi8.take(indexer)\n\n        if periods > 0:\n            new_values[:periods] = tslibs.iNaT\n        else:\n            new_values[periods:] = tslibs.iNaT\n\n        new_values = self.values._shallow_copy(new_values)\n        return [self.make_block_same_class(new_values,\n                                           placement=self.mgr_locs)]\n\n    def diff(self, n, axis=0, mgr=None):\n        \"\"\"1st discrete difference\n\n        Parameters\n        ----------\n        n : int, number of periods to diff\n        axis : int, axis to diff upon. default 0\n        mgr : default None\n\n        Return\n        ------\n        A list with a new TimeDeltaBlock.\n\n        Note\n        ----\n        The arguments here are mimicking shift so they are called correctly\n        by apply.\n        \"\"\"\n        if axis == 0:\n            # Cannot currently calculate diff across multiple blocks since this\n            # function is invoked via apply\n            raise NotImplementedError\n        new_values = (self.values - self.shift(n, axis=axis)[0].values).asi8\n\n        # Reshape the new_values like how algos.diff does for timedelta data\n        new_values = new_values.reshape(1, len(new_values))\n        new_values = new_values.astype('timedelta64[ns]')\n        return [TimeDeltaBlock(new_values, placement=self.mgr_locs.indexer)]\n\n    def concat_same_type(self, to_concat, placement=None):\n        \"\"\"\n        Concatenate list of single blocks of the same type.\n        \"\"\"\n        values = self._concatenator([blk.values for blk in to_concat],\n                                    axis=self.ndim - 1)\n        # not using self.make_block_same_class as values can be non-tz dtype\n        return make_block(\n            values, placement=placement or slice(0, len(values), 1))\n\n\nclass SparseBlock(NonConsolidatableMixIn, Block):\n    \"\"\" implement as a list of sparse arrays of the same dtype \"\"\"\n    __slots__ = ()\n    is_sparse = True\n    is_numeric = True\n    _box_to_block_values = False\n    _can_hold_na = True\n    _ftype = 'sparse'\n    _concatenator = staticmethod(_concat._concat_sparse)\n\n    def __init__(self, values, placement, ndim=None):\n        # Ensure that we have the underlying SparseArray here...\n        if isinstance(values, ABCSeries):\n            values = values.values\n        assert isinstance(values, SparseArray)\n        super(SparseBlock, self).__init__(values, placement, ndim=ndim)\n\n    @property\n    def _holder(self):\n        return SparseArray\n\n    @property\n    def shape(self):\n        return (len(self.mgr_locs), self.sp_index.length)\n\n    @property\n    def fill_value(self):\n        # return np.nan\n        return self.values.fill_value\n\n    @fill_value.setter\n    def fill_value(self, v):\n        self.values.fill_value = v\n\n    def to_dense(self):\n        return self.values.to_dense().view()\n\n    @property\n    def sp_values(self):\n        return self.values.sp_values\n\n    @sp_values.setter\n    def sp_values(self, v):\n        # reset the sparse values\n        self.values = SparseArray(v, sparse_index=self.sp_index,\n                                  kind=self.kind, dtype=v.dtype,\n                                  fill_value=self.values.fill_value,\n                                  copy=False)\n\n    @property\n    def sp_index(self):\n        return self.values.sp_index\n\n    @property\n    def kind(self):\n        return self.values.kind\n\n    def _astype(self, dtype, copy=False, errors='raise', values=None,\n                klass=None, mgr=None, **kwargs):\n        if values is None:\n            values = self.values\n        values = values.astype(dtype, copy=copy)\n        return self.make_block_same_class(values=values,\n                                          placement=self.mgr_locs)\n\n    def __len__(self):\n        try:\n            return self.sp_index.length\n        except:\n            return 0\n\n    def copy(self, deep=True, mgr=None):\n        return self.make_block_same_class(values=self.values,\n                                          sparse_index=self.sp_index,\n                                          kind=self.kind, copy=deep,\n                                          placement=self.mgr_locs)\n\n    def make_block_same_class(self, values, placement, sparse_index=None,\n                              kind=None, dtype=None, fill_value=None,\n                              copy=False, ndim=None):\n        \"\"\" return a new block \"\"\"\n        if dtype is None:\n            dtype = values.dtype\n        if fill_value is None and not isinstance(values, SparseArray):\n            fill_value = self.values.fill_value\n\n        # if not isinstance(values, SparseArray) and values.ndim != self.ndim:\n        #     raise ValueError(\"ndim mismatch\")\n\n        if values.ndim == 2:\n            nitems = values.shape[0]\n\n            if nitems == 0:\n                # kludgy, but SparseBlocks cannot handle slices, where the\n                # output is 0-item, so let's convert it to a dense block: it\n                # won't take space since there's 0 items, plus it will preserve\n                # the dtype.\n                return self.make_block(np.empty(values.shape, dtype=dtype),\n                                       placement)\n            elif nitems > 1:\n                raise ValueError(\"Only 1-item 2d sparse blocks are supported\")\n            else:\n                values = values.reshape(values.shape[1])\n\n        new_values = SparseArray(values, sparse_index=sparse_index,\n                                 kind=kind or self.kind, dtype=dtype,\n                                 fill_value=fill_value, copy=copy)\n        return self.make_block(new_values,\n                               placement=placement)\n\n    def interpolate(self, method='pad', axis=0, inplace=False, limit=None,\n                    fill_value=None, **kwargs):\n\n        values = missing.interpolate_2d(self.values.to_dense(), method, axis,\n                                        limit, fill_value)\n        return self.make_block_same_class(values=values,\n                                          placement=self.mgr_locs)\n\n    def fillna(self, value, limit=None, inplace=False, downcast=None,\n               mgr=None):\n        # we may need to upcast our fill to match our dtype\n        if limit is not None:\n            raise NotImplementedError(\"specifying a limit for 'fillna' has \"\n                                      \"not been implemented yet\")\n        values = self.values if inplace else self.values.copy()\n        values = values.fillna(value, downcast=downcast)\n        return [self.make_block_same_class(values=values,\n                                           placement=self.mgr_locs)]\n\n    def shift(self, periods, axis=0, mgr=None):\n        \"\"\" shift the block by periods \"\"\"\n        N = len(self.values.T)\n        indexer = np.zeros(N, dtype=int)\n        if periods > 0:\n            indexer[periods:] = np.arange(N - periods)\n        else:\n            indexer[:periods] = np.arange(-periods, N)\n        new_values = self.values.to_dense().take(indexer)\n        # convert integer to float if necessary. need to do a lot more than\n        # that, handle boolean etc also\n        new_values, fill_value = maybe_upcast(new_values)\n        if periods > 0:\n            new_values[:periods] = fill_value\n        else:\n            new_values[periods:] = fill_value\n        return [self.make_block_same_class(new_values,\n                                           placement=self.mgr_locs)]\n\n    def sparse_reindex(self, new_index):\n        \"\"\" sparse reindex and return a new block\n            current reindex only works for float64 dtype! \"\"\"\n        values = self.values\n        values = values.sp_index.to_int_index().reindex(\n            values.sp_values.astype('float64'), values.fill_value, new_index)\n        return self.make_block_same_class(values, sparse_index=new_index,\n                                          placement=self.mgr_locs)\n\n\n# -----------------------------------------------------------------\n# Constructor Helpers\n\ndef get_block_type(values, dtype=None):\n    \"\"\"\n    Find the appropriate Block subclass to use for the given values and dtype.\n\n    Parameters\n    ----------\n    values : ndarray-like\n    dtype : numpy or pandas dtype\n\n    Returns\n    -------\n    cls : class, subclass of Block\n    \"\"\"\n    dtype = dtype or values.dtype\n    vtype = dtype.type\n\n    if is_sparse(values):\n        cls = SparseBlock\n    elif issubclass(vtype, np.floating):\n        cls = FloatBlock\n    elif issubclass(vtype, np.timedelta64):\n        assert issubclass(vtype, np.integer)\n        cls = TimeDeltaBlock\n    elif issubclass(vtype, np.complexfloating):\n        cls = ComplexBlock\n    elif is_categorical(values):\n        cls = CategoricalBlock\n    elif is_extension_array_dtype(values):\n        cls = ExtensionBlock\n    elif issubclass(vtype, np.datetime64):\n        assert not is_datetimetz(values)\n        cls = DatetimeBlock\n    elif is_datetimetz(values):\n        cls = DatetimeTZBlock\n    elif issubclass(vtype, np.integer):\n        cls = IntBlock\n    elif dtype == np.bool_:\n        cls = BoolBlock\n    else:\n        cls = ObjectBlock\n    return cls\n\n\ndef make_block(values, placement, klass=None, ndim=None, dtype=None,\n               fastpath=None):\n    if fastpath is not None:\n        # GH#19265 pyarrow is passing this\n        warnings.warn(\"fastpath argument is deprecated, will be removed \"\n                      \"in a future release.\", DeprecationWarning)\n    if klass is None:\n        dtype = dtype or values.dtype\n        klass = get_block_type(values, dtype)\n\n    elif klass is DatetimeTZBlock and not is_datetimetz(values):\n        return klass(values, ndim=ndim,\n                     placement=placement, dtype=dtype)\n\n    return klass(values, ndim=ndim, placement=placement)\n\n\n# -----------------------------------------------------------------\n\ndef _extend_blocks(result, blocks=None):\n    \"\"\" return a new extended blocks, givin the result \"\"\"\n    from pandas.core.internals import BlockManager\n    if blocks is None:\n        blocks = []\n    if isinstance(result, list):\n        for r in result:\n            if isinstance(r, list):\n                blocks.extend(r)\n            else:\n                blocks.append(r)\n    elif isinstance(result, BlockManager):\n        blocks.extend(result.blocks)\n    else:\n        blocks.append(result)\n    return blocks\n\n\ndef _block_shape(values, ndim=1, shape=None):\n    \"\"\" guarantee the shape of the values to be at least 1 d \"\"\"\n    if values.ndim < ndim:\n        if shape is None:\n            shape = values.shape\n        values = values.reshape(tuple((1, ) + shape))\n    return values\n\n\ndef _merge_blocks(blocks, dtype=None, _can_consolidate=True):\n\n    if len(blocks) == 1:\n        return blocks[0]\n\n    if _can_consolidate:\n\n        if dtype is None:\n            if len({b.dtype for b in blocks}) != 1:\n                raise AssertionError(\"_merge_blocks are invalid!\")\n            dtype = blocks[0].dtype\n\n        # FIXME: optimization potential in case all mgrs contain slices and\n        # combination of those slices is a slice, too.\n        new_mgr_locs = np.concatenate([b.mgr_locs.as_array for b in blocks])\n        new_values = _vstack([b.values for b in blocks], dtype)\n\n        argsort = np.argsort(new_mgr_locs)\n        new_values = new_values[argsort]\n        new_mgr_locs = new_mgr_locs[argsort]\n\n        return make_block(new_values, placement=new_mgr_locs)\n\n    # no merge\n    return blocks\n\n\ndef _vstack(to_stack, dtype):\n\n    # work around NumPy 1.6 bug\n    if dtype == _NS_DTYPE or dtype == _TD_DTYPE:\n        new_values = np.vstack([x.view('i8') for x in to_stack])\n        return new_values.view(dtype)\n\n    else:\n        return np.vstack(to_stack)\n\n\ndef _block2d_to_blocknd(values, placement, shape, labels, ref_items):\n    \"\"\" pivot to the labels shape \"\"\"\n    panel_shape = (len(placement),) + shape\n\n    # TODO: lexsort depth needs to be 2!!\n\n    # Create observation selection vector using major and minor\n    # labels, for converting to panel format.\n    selector = _factor_indexer(shape[1:], labels)\n    mask = np.zeros(np.prod(shape), dtype=bool)\n    mask.put(selector, True)\n\n    if mask.all():\n        pvalues = np.empty(panel_shape, dtype=values.dtype)\n    else:\n        dtype, fill_value = maybe_promote(values.dtype)\n        pvalues = np.empty(panel_shape, dtype=dtype)\n        pvalues.fill(fill_value)\n\n    for i in range(len(placement)):\n        pvalues[i].flat[mask] = values[:, i]\n\n    return make_block(pvalues, placement=placement)\n\n\ndef _safe_reshape(arr, new_shape):\n    \"\"\"\n    If possible, reshape `arr` to have shape `new_shape`,\n    with a couple of exceptions (see gh-13012):\n\n    1) If `arr` is a ExtensionArray or Index, `arr` will be\n       returned as is.\n    2) If `arr` is a Series, the `_values` attribute will\n       be reshaped and returned.\n\n    Parameters\n    ----------\n    arr : array-like, object to be reshaped\n    new_shape : int or tuple of ints, the new shape\n    \"\"\"\n    if isinstance(arr, ABCSeries):\n        arr = arr._values\n    if not isinstance(arr, ABCExtensionArray):\n        arr = arr.reshape(new_shape)\n    return arr\n\n\ndef _factor_indexer(shape, labels):\n    \"\"\"\n    given a tuple of shape and a list of Categorical labels, return the\n    expanded label indexer\n    \"\"\"\n    mult = np.array(shape)[::-1].cumprod()[::-1]\n    return ensure_platform_int(\n        np.sum(np.array(labels).T * np.append(mult, [1]), axis=1).T)\n\n\ndef _putmask_smart(v, m, n):\n    \"\"\"\n    Return a new ndarray, try to preserve dtype if possible.\n\n    Parameters\n    ----------\n    v : `values`, updated in-place (array like)\n    m : `mask`, applies to both sides (array like)\n    n : `new values` either scalar or an array like aligned with `values`\n\n    Returns\n    -------\n    values : ndarray with updated values\n        this *may* be a copy of the original\n\n    See Also\n    --------\n    ndarray.putmask\n    \"\"\"\n\n    # we cannot use np.asarray() here as we cannot have conversions\n    # that numpy does when numeric are mixed with strings\n\n    # n should be the length of the mask or a scalar here\n    if not is_list_like(n):\n        n = np.repeat(n, len(m))\n    elif isinstance(n, np.ndarray) and n.ndim == 0:  # numpy scalar\n        n = np.repeat(np.array(n, ndmin=1), len(m))\n\n    # see if we are only masking values that if putted\n    # will work in the current dtype\n    try:\n        nn = n[m]\n\n        # make sure that we have a nullable type\n        # if we have nulls\n        if not _isna_compat(v, nn[0]):\n            raise ValueError\n\n        # we ignore ComplexWarning here\n        with warnings.catch_warnings(record=True):\n            nn_at = nn.astype(v.dtype)\n\n        # avoid invalid dtype comparisons\n        # between numbers & strings\n\n        # only compare integers/floats\n        # don't compare integers to datetimelikes\n        if (not is_numeric_v_string_like(nn, nn_at) and\n            (is_float_dtype(nn.dtype) or\n             is_integer_dtype(nn.dtype) and\n             is_float_dtype(nn_at.dtype) or\n             is_integer_dtype(nn_at.dtype))):\n\n            comp = (nn == nn_at)\n            if is_list_like(comp) and comp.all():\n                nv = v.copy()\n                nv[m] = nn_at\n                return nv\n    except (ValueError, IndexError, TypeError):\n        pass\n\n    n = np.asarray(n)\n\n    def _putmask_preserve(nv, n):\n        try:\n            nv[m] = n[m]\n        except (IndexError, ValueError):\n            nv[m] = n\n        return nv\n\n    # preserves dtype if possible\n    if v.dtype.kind == n.dtype.kind:\n        return _putmask_preserve(v, n)\n\n    # change the dtype if needed\n    dtype, _ = maybe_promote(n.dtype)\n\n    if is_extension_type(v.dtype) and is_object_dtype(dtype):\n        v = v.get_values(dtype)\n    else:\n        v = v.astype(dtype)\n\n    return _putmask_preserve(v, n)\n",
      "file_patch": "@@ -0,0 +1,3417 @@\n+# -*- coding: utf-8 -*-\n+import warnings\n+import inspect\n+import re\n+from datetime import datetime, timedelta, date\n+\n+import numpy as np\n+\n+from pandas._libs import lib, tslib, tslibs, internals as libinternals\n+from pandas._libs.tslibs import conversion, Timedelta\n+\n+from pandas import compat\n+from pandas.compat import range, zip\n+\n+from pandas.util._validators import validate_bool_kwarg\n+\n+from pandas.core.dtypes.dtypes import (\n+    ExtensionDtype, DatetimeTZDtype,\n+    PandasExtensionDtype,\n+    CategoricalDtype)\n+from pandas.core.dtypes.common import (\n+    _TD_DTYPE, _NS_DTYPE,\n+    ensure_platform_int,\n+    is_integer,\n+    is_dtype_equal,\n+    is_timedelta64_dtype,\n+    is_datetime64_dtype, is_datetimetz, is_sparse,\n+    is_categorical, is_categorical_dtype,\n+    is_integer_dtype,\n+    is_datetime64tz_dtype,\n+    is_bool_dtype,\n+    is_object_dtype,\n+    is_float_dtype,\n+    is_numeric_v_string_like, is_extension_type,\n+    is_extension_array_dtype,\n+    is_list_like,\n+    is_re,\n+    is_re_compilable,\n+    pandas_dtype)\n+from pandas.core.dtypes.cast import (\n+    maybe_downcast_to_dtype,\n+    maybe_upcast,\n+    maybe_promote,\n+    infer_dtype_from,\n+    infer_dtype_from_scalar,\n+    soft_convert_objects,\n+    maybe_convert_objects,\n+    astype_nansafe,\n+    find_common_type,\n+    maybe_infer_dtype_type)\n+from pandas.core.dtypes.missing import (\n+    isna, notna, array_equivalent,\n+    _isna_compat,\n+    is_null_datelike_scalar)\n+import pandas.core.dtypes.concat as _concat\n+from pandas.core.dtypes.generic import (\n+    ABCSeries,\n+    ABCDatetimeIndex,\n+    ABCExtensionArray,\n+    ABCIndexClass)\n+\n+import pandas.core.common as com\n+import pandas.core.algorithms as algos\n+import pandas.core.missing as missing\n+from pandas.core.base import PandasObject\n+\n+from pandas.core.arrays import Categorical\n+from pandas.core.sparse.array import SparseArray\n+\n+from pandas.core.indexes.datetimes import DatetimeIndex\n+from pandas.core.indexes.timedeltas import TimedeltaIndex\n+from pandas.core.indexing import check_setitem_lengths\n+\n+from pandas.io.formats.printing import pprint_thing\n+\n+\n+class Block(PandasObject):\n+    \"\"\"\n+    Canonical n-dimensional unit of homogeneous dtype contained in a pandas\n+    data structure\n+\n+    Index-ignorant; let the container take care of that\n+    \"\"\"\n+    __slots__ = ['_mgr_locs', 'values', 'ndim']\n+    is_numeric = False\n+    is_float = False\n+    is_integer = False\n+    is_complex = False\n+    is_datetime = False\n+    is_datetimetz = False\n+    is_timedelta = False\n+    is_bool = False\n+    is_object = False\n+    is_categorical = False\n+    is_sparse = False\n+    is_extension = False\n+    _box_to_block_values = True\n+    _can_hold_na = False\n+    _can_consolidate = True\n+    _verify_integrity = True\n+    _validate_ndim = True\n+    _ftype = 'dense'\n+    _concatenator = staticmethod(np.concatenate)\n+\n+    def __init__(self, values, placement, ndim=None):\n+        self.ndim = self._check_ndim(values, ndim)\n+        self.mgr_locs = placement\n+        self.values = values\n+\n+        if (self._validate_ndim and self.ndim and\n+                len(self.mgr_locs) != len(self.values)):\n+            raise ValueError(\n+                'Wrong number of items passed {val}, placement implies '\n+                '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))\n+\n+    def _check_ndim(self, values, ndim):\n+        \"\"\"ndim inference and validation.\n+\n+        Infers ndim from 'values' if not provided to __init__.\n+        Validates that values.ndim and ndim are consistent if and only if\n+        the class variable '_validate_ndim' is True.\n+\n+        Parameters\n+        ----------\n+        values : array-like\n+        ndim : int or None\n+\n+        Returns\n+        -------\n+        ndim : int\n+\n+        Raises\n+        ------\n+        ValueError : the number of dimensions do not match\n+        \"\"\"\n+        if ndim is None:\n+            ndim = values.ndim\n+\n+        if self._validate_ndim and values.ndim != ndim:\n+            msg = (\"Wrong number of dimensions. values.ndim != ndim \"\n+                   \"[{} != {}]\")\n+            raise ValueError(msg.format(values.ndim, ndim))\n+\n+        return ndim\n+\n+    @property\n+    def _holder(self):\n+        \"\"\"The array-like that can hold the underlying values.\n+\n+        None for 'Block', overridden by subclasses that don't\n+        use an ndarray.\n+        \"\"\"\n+        return None\n+\n+    @property\n+    def _consolidate_key(self):\n+        return (self._can_consolidate, self.dtype.name)\n+\n+    @property\n+    def _is_single_block(self):\n+        return self.ndim == 1\n+\n+    @property\n+    def is_view(self):\n+        \"\"\" return a boolean if I am possibly a view \"\"\"\n+        return self.values.base is not None\n+\n+    @property\n+    def is_datelike(self):\n+        \"\"\" return True if I am a non-datelike \"\"\"\n+        return self.is_datetime or self.is_timedelta\n+\n+    def is_categorical_astype(self, dtype):\n+        \"\"\"\n+        validate that we have a astypeable to categorical,\n+        returns a boolean if we are a categorical\n+        \"\"\"\n+        if dtype is Categorical or dtype is CategoricalDtype:\n+            # this is a pd.Categorical, but is not\n+            # a valid type for astypeing\n+            raise TypeError(\"invalid type {0} for astype\".format(dtype))\n+\n+        elif is_categorical_dtype(dtype):\n+            return True\n+\n+        return False\n+\n+    def external_values(self, dtype=None):\n+        \"\"\" return an outside world format, currently just the ndarray \"\"\"\n+        return self.values\n+\n+    def internal_values(self, dtype=None):\n+        \"\"\" return an internal format, currently just the ndarray\n+        this should be the pure internal API format\n+        \"\"\"\n+        return self.values\n+\n+    def formatting_values(self):\n+        \"\"\"Return the internal values used by the DataFrame/SeriesFormatter\"\"\"\n+        return self.internal_values()\n+\n+    def get_values(self, dtype=None):\n+        \"\"\"\n+        return an internal format, currently just the ndarray\n+        this is often overridden to handle to_dense like operations\n+        \"\"\"\n+        if is_object_dtype(dtype):\n+            return self.values.astype(object)\n+        return self.values\n+\n+    def to_dense(self):\n+        return self.values.view()\n+\n+    @property\n+    def _na_value(self):\n+        return np.nan\n+\n+    @property\n+    def fill_value(self):\n+        return np.nan\n+\n+    @property\n+    def mgr_locs(self):\n+        return self._mgr_locs\n+\n+    @mgr_locs.setter\n+    def mgr_locs(self, new_mgr_locs):\n+        if not isinstance(new_mgr_locs, libinternals.BlockPlacement):\n+            new_mgr_locs = libinternals.BlockPlacement(new_mgr_locs)\n+\n+        self._mgr_locs = new_mgr_locs\n+\n+    @property\n+    def array_dtype(self):\n+        \"\"\" the dtype to return if I want to construct this block as an\n+        array\n+        \"\"\"\n+        return self.dtype\n+\n+    def make_block(self, values, placement=None, ndim=None):\n+        \"\"\"\n+        Create a new block, with type inference propagate any values that are\n+        not specified\n+        \"\"\"\n+        if placement is None:\n+            placement = self.mgr_locs\n+        if ndim is None:\n+            ndim = self.ndim\n+\n+        return make_block(values, placement=placement, ndim=ndim)\n+\n+    def make_block_scalar(self, values):\n+        \"\"\"\n+        Create a ScalarBlock\n+        \"\"\"\n+        return ScalarBlock(values)\n+\n+    def make_block_same_class(self, values, placement=None, ndim=None,\n+                              dtype=None):\n+        \"\"\" Wrap given values in a block of same type as self. \"\"\"\n+        if dtype is not None:\n+            # issue 19431 fastparquet is passing this\n+            warnings.warn(\"dtype argument is deprecated, will be removed \"\n+                          \"in a future release.\", DeprecationWarning)\n+        if placement is None:\n+            placement = self.mgr_locs\n+        return make_block(values, placement=placement, ndim=ndim,\n+                          klass=self.__class__, dtype=dtype)\n+\n+    def __unicode__(self):\n+\n+        # don't want to print out all of the items here\n+        name = pprint_thing(self.__class__.__name__)\n+        if self._is_single_block:\n+\n+            result = '{name}: {len} dtype: {dtype}'.format(\n+                name=name, len=len(self), dtype=self.dtype)\n+\n+        else:\n+\n+            shape = ' x '.join(pprint_thing(s) for s in self.shape)\n+            result = '{name}: {index}, {shape}, dtype: {dtype}'.format(\n+                name=name, index=pprint_thing(self.mgr_locs.indexer),\n+                shape=shape, dtype=self.dtype)\n+\n+        return result\n+\n+    def __len__(self):\n+        return len(self.values)\n+\n+    def __getstate__(self):\n+        return self.mgr_locs.indexer, self.values\n+\n+    def __setstate__(self, state):\n+        self.mgr_locs = libinternals.BlockPlacement(state[0])\n+        self.values = state[1]\n+        self.ndim = self.values.ndim\n+\n+    def _slice(self, slicer):\n+        \"\"\" return a slice of my values \"\"\"\n+        return self.values[slicer]\n+\n+    def reshape_nd(self, labels, shape, ref_items, mgr=None):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        labels : list of new axis labels\n+        shape : new shape\n+        ref_items : new ref_items\n+\n+        return a new block that is transformed to a nd block\n+        \"\"\"\n+        return _block2d_to_blocknd(values=self.get_values().T,\n+                                   placement=self.mgr_locs, shape=shape,\n+                                   labels=labels, ref_items=ref_items)\n+\n+    def getitem_block(self, slicer, new_mgr_locs=None):\n+        \"\"\"\n+        Perform __getitem__-like, return result as block.\n+\n+        As of now, only supports slices that preserve dimensionality.\n+        \"\"\"\n+        if new_mgr_locs is None:\n+            if isinstance(slicer, tuple):\n+                axis0_slicer = slicer[0]\n+            else:\n+                axis0_slicer = slicer\n+            new_mgr_locs = self.mgr_locs[axis0_slicer]\n+\n+        new_values = self._slice(slicer)\n+\n+        if self._validate_ndim and new_values.ndim != self.ndim:\n+            raise ValueError(\"Only same dim slicing is allowed\")\n+\n+        return self.make_block_same_class(new_values, new_mgr_locs)\n+\n+    @property\n+    def shape(self):\n+        return self.values.shape\n+\n+    @property\n+    def dtype(self):\n+        return self.values.dtype\n+\n+    @property\n+    def ftype(self):\n+        return \"{dtype}:{ftype}\".format(dtype=self.dtype, ftype=self._ftype)\n+\n+    def merge(self, other):\n+        return _merge_blocks([self, other])\n+\n+    def concat_same_type(self, to_concat, placement=None):\n+        \"\"\"\n+        Concatenate list of single blocks of the same type.\n+        \"\"\"\n+        values = self._concatenator([blk.values for blk in to_concat],\n+                                    axis=self.ndim - 1)\n+        return self.make_block_same_class(\n+            values, placement=placement or slice(0, len(values), 1))\n+\n+    def iget(self, i):\n+        return self.values[i]\n+\n+    def set(self, locs, values, check=False):\n+        \"\"\"\n+        Modify Block in-place with new item value\n+\n+        Returns\n+        -------\n+        None\n+        \"\"\"\n+        self.values[locs] = values\n+\n+    def delete(self, loc):\n+        \"\"\"\n+        Delete given loc(-s) from block in-place.\n+        \"\"\"\n+        self.values = np.delete(self.values, loc, 0)\n+        self.mgr_locs = self.mgr_locs.delete(loc)\n+\n+    def apply(self, func, mgr=None, **kwargs):\n+        \"\"\" apply the function to my values; return a block if we are not\n+        one\n+        \"\"\"\n+        with np.errstate(all='ignore'):\n+            result = func(self.values, **kwargs)\n+        if not isinstance(result, Block):\n+            result = self.make_block(values=_block_shape(result,\n+                                                         ndim=self.ndim))\n+\n+        return result\n+\n+    def fillna(self, value, limit=None, inplace=False, downcast=None,\n+               mgr=None):\n+        \"\"\" fillna on the block with the value. If we fail, then convert to\n+        ObjectBlock and try again\n+        \"\"\"\n+        inplace = validate_bool_kwarg(inplace, 'inplace')\n+\n+        if not self._can_hold_na:\n+            if inplace:\n+                return self\n+            else:\n+                return self.copy()\n+\n+        mask = isna(self.values)\n+        if limit is not None:\n+            if not is_integer(limit):\n+                raise ValueError('Limit must be an integer')\n+            if limit < 1:\n+                raise ValueError('Limit must be greater than 0')\n+            if self.ndim > 2:\n+                raise NotImplementedError(\"number of dimensions for 'fillna' \"\n+                                          \"is currently limited to 2\")\n+            mask[mask.cumsum(self.ndim - 1) > limit] = False\n+\n+        # fillna, but if we cannot coerce, then try again as an ObjectBlock\n+        try:\n+            values, _, _, _ = self._try_coerce_args(self.values, value)\n+            blocks = self.putmask(mask, value, inplace=inplace)\n+            blocks = [b.make_block(values=self._try_coerce_result(b.values))\n+                      for b in blocks]\n+            return self._maybe_downcast(blocks, downcast)\n+        except (TypeError, ValueError):\n+\n+            # we can't process the value, but nothing to do\n+            if not mask.any():\n+                return self if inplace else self.copy()\n+\n+            # operate column-by-column\n+            def f(m, v, i):\n+                block = self.coerce_to_target_dtype(value)\n+\n+                # slice out our block\n+                if i is not None:\n+                    block = block.getitem_block(slice(i, i + 1))\n+                return block.fillna(value,\n+                                    limit=limit,\n+                                    inplace=inplace,\n+                                    downcast=None)\n+\n+            return self.split_and_operate(mask, f, inplace)\n+\n+    def split_and_operate(self, mask, f, inplace):\n+        \"\"\"\n+        split the block per-column, and apply the callable f\n+        per-column, return a new block for each. Handle\n+        masking which will not change a block unless needed.\n+\n+        Parameters\n+        ----------\n+        mask : 2-d boolean mask\n+        f : callable accepting (1d-mask, 1d values, indexer)\n+        inplace : boolean\n+\n+        Returns\n+        -------\n+        list of blocks\n+        \"\"\"\n+\n+        if mask is None:\n+            mask = np.ones(self.shape, dtype=bool)\n+        new_values = self.values\n+\n+        def make_a_block(nv, ref_loc):\n+            if isinstance(nv, Block):\n+                block = nv\n+            elif isinstance(nv, list):\n+                block = nv[0]\n+            else:\n+                # Put back the dimension that was taken from it and make\n+                # a block out of the result.\n+                try:\n+                    nv = _block_shape(nv, ndim=self.ndim)\n+                except (AttributeError, NotImplementedError):\n+                    pass\n+                block = self.make_block(values=nv,\n+                                        placement=ref_loc)\n+            return block\n+\n+        # ndim == 1\n+        if self.ndim == 1:\n+            if mask.any():\n+                nv = f(mask, new_values, None)\n+            else:\n+                nv = new_values if inplace else new_values.copy()\n+            block = make_a_block(nv, self.mgr_locs)\n+            return [block]\n+\n+        # ndim > 1\n+        new_blocks = []\n+        for i, ref_loc in enumerate(self.mgr_locs):\n+            m = mask[i]\n+            v = new_values[i]\n+\n+            # need a new block\n+            if m.any():\n+                nv = f(m, v, i)\n+            else:\n+                nv = v if inplace else v.copy()\n+\n+            block = make_a_block(nv, [ref_loc])\n+            new_blocks.append(block)\n+\n+        return new_blocks\n+\n+    def _maybe_downcast(self, blocks, downcast=None):\n+\n+        # no need to downcast our float\n+        # unless indicated\n+        if downcast is None and self.is_float:\n+            return blocks\n+        elif downcast is None and (self.is_timedelta or self.is_datetime):\n+            return blocks\n+\n+        if not isinstance(blocks, list):\n+            blocks = [blocks]\n+        return _extend_blocks([b.downcast(downcast) for b in blocks])\n+\n+    def downcast(self, dtypes=None, mgr=None):\n+        \"\"\" try to downcast each item to the dict of dtypes if present \"\"\"\n+\n+        # turn it off completely\n+        if dtypes is False:\n+            return self\n+\n+        values = self.values\n+\n+        # single block handling\n+        if self._is_single_block:\n+\n+            # try to cast all non-floats here\n+            if dtypes is None:\n+                dtypes = 'infer'\n+\n+            nv = maybe_downcast_to_dtype(values, dtypes)\n+            return self.make_block(nv)\n+\n+        # ndim > 1\n+        if dtypes is None:\n+            return self\n+\n+        if not (dtypes == 'infer' or isinstance(dtypes, dict)):\n+            raise ValueError(\"downcast must have a dictionary or 'infer' as \"\n+                             \"its argument\")\n+\n+        # operate column-by-column\n+        # this is expensive as it splits the blocks items-by-item\n+        def f(m, v, i):\n+\n+            if dtypes == 'infer':\n+                dtype = 'infer'\n+            else:\n+                raise AssertionError(\"dtypes as dict is not supported yet\")\n+\n+            if dtype is not None:\n+                v = maybe_downcast_to_dtype(v, dtype)\n+            return v\n+\n+        return self.split_and_operate(None, f, False)\n+\n+    def astype(self, dtype, copy=False, errors='raise', values=None, **kwargs):\n+        return self._astype(dtype, copy=copy, errors=errors, values=values,\n+                            **kwargs)\n+\n+    def _astype(self, dtype, copy=False, errors='raise', values=None,\n+                klass=None, mgr=None, **kwargs):\n+        \"\"\"Coerce to the new type\n+\n+        Parameters\n+        ----------\n+        dtype : str, dtype convertible\n+        copy : boolean, default False\n+            copy if indicated\n+        errors : str, {'raise', 'ignore'}, default 'ignore'\n+            - ``raise`` : allow exceptions to be raised\n+            - ``ignore`` : suppress exceptions. On error return original object\n+\n+        Returns\n+        -------\n+        Block\n+        \"\"\"\n+        errors_legal_values = ('raise', 'ignore')\n+\n+        if errors not in errors_legal_values:\n+            invalid_arg = (\"Expected value of kwarg 'errors' to be one of {}. \"\n+                           \"Supplied value is '{}'\".format(\n+                               list(errors_legal_values), errors))\n+            raise ValueError(invalid_arg)\n+\n+        if (inspect.isclass(dtype) and\n+                issubclass(dtype, (PandasExtensionDtype, ExtensionDtype))):\n+            msg = (\"Expected an instance of {}, but got the class instead. \"\n+                   \"Try instantiating 'dtype'.\".format(dtype.__name__))\n+            raise TypeError(msg)\n+\n+        # may need to convert to categorical\n+        if self.is_categorical_astype(dtype):\n+\n+            # deprecated 17636\n+            if ('categories' in kwargs or 'ordered' in kwargs):\n+                if isinstance(dtype, CategoricalDtype):\n+                    raise TypeError(\n+                        \"Cannot specify a CategoricalDtype and also \"\n+                        \"`categories` or `ordered`. Use \"\n+                        \"`dtype=CategoricalDtype(categories, ordered)`\"\n+                        \" instead.\")\n+                warnings.warn(\"specifying 'categories' or 'ordered' in \"\n+                              \".astype() is deprecated; pass a \"\n+                              \"CategoricalDtype instead\",\n+                              FutureWarning, stacklevel=7)\n+\n+            categories = kwargs.get('categories', None)\n+            ordered = kwargs.get('ordered', None)\n+            if com._any_not_none(categories, ordered):\n+                dtype = CategoricalDtype(categories, ordered)\n+\n+            if is_categorical_dtype(self.values):\n+                # GH 10696/18593: update an existing categorical efficiently\n+                return self.make_block(self.values.astype(dtype, copy=copy))\n+\n+            return self.make_block(Categorical(self.values, dtype=dtype))\n+\n+        # convert dtypes if needed\n+        dtype = pandas_dtype(dtype)\n+\n+        # astype processing\n+        if is_dtype_equal(self.dtype, dtype):\n+            if copy:\n+                return self.copy()\n+            return self\n+\n+        if klass is None:\n+            if dtype == np.object_:\n+                klass = ObjectBlock\n+        try:\n+            # force the copy here\n+            if values is None:\n+\n+                if issubclass(dtype.type,\n+                              (compat.text_type, compat.string_types)):\n+\n+                    # use native type formatting for datetime/tz/timedelta\n+                    if self.is_datelike:\n+                        values = self.to_native_types()\n+\n+                    # astype formatting\n+                    else:\n+                        values = self.get_values()\n+\n+                else:\n+                    values = self.get_values(dtype=dtype)\n+\n+                # _astype_nansafe works fine with 1-d only\n+                values = astype_nansafe(values.ravel(), dtype, copy=True)\n+\n+                # TODO(extension)\n+                # should we make this attribute?\n+                try:\n+                    values = values.reshape(self.shape)\n+                except AttributeError:\n+                    pass\n+\n+            newb = make_block(values, placement=self.mgr_locs,\n+                              klass=klass)\n+        except:\n+            if errors == 'raise':\n+                raise\n+            newb = self.copy() if copy else self\n+\n+        if newb.is_numeric and self.is_numeric:\n+            if newb.shape != self.shape:\n+                raise TypeError(\n+                    \"cannot set astype for copy = [{copy}] for dtype \"\n+                    \"({dtype} [{itemsize}]) with smaller itemsize than \"\n+                    \"current ({newb_dtype} [{newb_size}])\".format(\n+                        copy=copy, dtype=self.dtype.name,\n+                        itemsize=self.itemsize, newb_dtype=newb.dtype.name,\n+                        newb_size=newb.itemsize))\n+        return newb\n+\n+    def convert(self, copy=True, **kwargs):\n+        \"\"\" attempt to coerce any object types to better types return a copy\n+        of the block (if copy = True) by definition we are not an ObjectBlock\n+        here!\n+        \"\"\"\n+\n+        return self.copy() if copy else self\n+\n+    def _can_hold_element(self, element):\n+        \"\"\" require the same dtype as ourselves \"\"\"\n+        dtype = self.values.dtype.type\n+        tipo = maybe_infer_dtype_type(element)\n+        if tipo is not None:\n+            return issubclass(tipo.type, dtype)\n+        return isinstance(element, dtype)\n+\n+    def _try_cast_result(self, result, dtype=None):\n+        \"\"\" try to cast the result to our original type, we may have\n+        roundtripped thru object in the mean-time\n+        \"\"\"\n+        if dtype is None:\n+            dtype = self.dtype\n+\n+        if self.is_integer or self.is_bool or self.is_datetime:\n+            pass\n+        elif self.is_float and result.dtype == self.dtype:\n+\n+            # protect against a bool/object showing up here\n+            if isinstance(dtype, compat.string_types) and dtype == 'infer':\n+                return result\n+            if not isinstance(dtype, type):\n+                dtype = dtype.type\n+            if issubclass(dtype, (np.bool_, np.object_)):\n+                if issubclass(dtype, np.bool_):\n+                    if isna(result).all():\n+                        return result.astype(np.bool_)\n+                    else:\n+                        result = result.astype(np.object_)\n+                        result[result == 1] = True\n+                        result[result == 0] = False\n+                        return result\n+                else:\n+                    return result.astype(np.object_)\n+\n+            return result\n+\n+        # may need to change the dtype here\n+        return maybe_downcast_to_dtype(result, dtype)\n+\n+    def _try_coerce_args(self, values, other):\n+        \"\"\" provide coercion to our input arguments \"\"\"\n+\n+        if np.any(notna(other)) and not self._can_hold_element(other):\n+            # coercion issues\n+            # let higher levels handle\n+            raise TypeError(\"cannot convert {} to an {}\".format(\n+                type(other).__name__,\n+                type(self).__name__.lower().replace('Block', '')))\n+\n+        return values, False, other, False\n+\n+    def _try_coerce_result(self, result):\n+        \"\"\" reverse of try_coerce_args \"\"\"\n+        return result\n+\n+    def _try_coerce_and_cast_result(self, result, dtype=None):\n+        result = self._try_coerce_result(result)\n+        result = self._try_cast_result(result, dtype=dtype)\n+        return result\n+\n+    def to_native_types(self, slicer=None, na_rep='nan', quoting=None,\n+                        **kwargs):\n+        \"\"\" convert to our native types format, slicing if desired \"\"\"\n+\n+        values = self.get_values()\n+\n+        if slicer is not None:\n+            values = values[:, slicer]\n+        mask = isna(values)\n+\n+        if not self.is_object and not quoting:\n+            values = values.astype(str)\n+        else:\n+            values = np.array(values, dtype='object')\n+\n+        values[mask] = na_rep\n+        return values\n+\n+    # block actions ####\n+    def copy(self, deep=True, mgr=None):\n+        \"\"\" copy constructor \"\"\"\n+        values = self.values\n+        if deep:\n+            values = values.copy()\n+        return self.make_block_same_class(values)\n+\n+    def replace(self, to_replace, value, inplace=False, filter=None,\n+                regex=False, convert=True, mgr=None):\n+        \"\"\" replace the to_replace value with value, possible to create new\n+        blocks here this is just a call to putmask. regex is not used here.\n+        It is used in ObjectBlocks.  It is here for API\n+        compatibility.\n+        \"\"\"\n+\n+        inplace = validate_bool_kwarg(inplace, 'inplace')\n+        original_to_replace = to_replace\n+\n+        # try to replace, if we raise an error, convert to ObjectBlock and\n+        # retry\n+        try:\n+            values, _, to_replace, _ = self._try_coerce_args(self.values,\n+                                                             to_replace)\n+            mask = missing.mask_missing(values, to_replace)\n+            if filter is not None:\n+                filtered_out = ~self.mgr_locs.isin(filter)\n+                mask[filtered_out.nonzero()[0]] = False\n+\n+            blocks = self.putmask(mask, value, inplace=inplace)\n+            if convert:\n+                blocks = [b.convert(by_item=True, numeric=False,\n+                                    copy=not inplace) for b in blocks]\n+            return blocks\n+        except (TypeError, ValueError):\n+\n+            # try again with a compatible block\n+            block = self.astype(object)\n+            return block.replace(\n+                to_replace=original_to_replace, value=value, inplace=inplace,\n+                filter=filter, regex=regex, convert=convert)\n+\n+    def _replace_single(self, *args, **kwargs):\n+        \"\"\" no-op on a non-ObjectBlock \"\"\"\n+        return self if kwargs['inplace'] else self.copy()\n+\n+    def setitem(self, indexer, value, mgr=None):\n+        \"\"\"Set the value inplace, returning a a maybe different typed block.\n+\n+        Parameters\n+        ----------\n+        indexer : tuple, list-like, array-like, slice\n+            The subset of self.values to set\n+        value : object\n+            The value being set\n+        mgr : BlockPlacement, optional\n+\n+        Returns\n+        -------\n+        Block\n+\n+        Notes\n+        -----\n+        `indexer` is a direct slice/positional indexer. `value` must\n+        be a compatible shape.\n+        \"\"\"\n+        # coerce None values, if appropriate\n+        if value is None:\n+            if self.is_numeric:\n+                value = np.nan\n+\n+        # coerce if block dtype can store value\n+        values = self.values\n+        try:\n+            values, _, value, _ = self._try_coerce_args(values, value)\n+            # can keep its own dtype\n+            if hasattr(value, 'dtype') and is_dtype_equal(values.dtype,\n+                                                          value.dtype):\n+                dtype = self.dtype\n+            else:\n+                dtype = 'infer'\n+\n+        except (TypeError, ValueError):\n+            # current dtype cannot store value, coerce to common dtype\n+            find_dtype = False\n+\n+            if hasattr(value, 'dtype'):\n+                dtype = value.dtype\n+                find_dtype = True\n+\n+            elif lib.is_scalar(value):\n+                if isna(value):\n+                    # NaN promotion is handled in latter path\n+                    dtype = False\n+                else:\n+                    dtype, _ = infer_dtype_from_scalar(value,\n+                                                       pandas_dtype=True)\n+                    find_dtype = True\n+            else:\n+                dtype = 'infer'\n+\n+            if find_dtype:\n+                dtype = find_common_type([values.dtype, dtype])\n+                if not is_dtype_equal(self.dtype, dtype):\n+                    b = self.astype(dtype)\n+                    return b.setitem(indexer, value, mgr=mgr)\n+\n+        # value must be storeable at this moment\n+        arr_value = np.array(value)\n+\n+        # cast the values to a type that can hold nan (if necessary)\n+        if not self._can_hold_element(value):\n+            dtype, _ = maybe_promote(arr_value.dtype)\n+            values = values.astype(dtype)\n+\n+        transf = (lambda x: x.T) if self.ndim == 2 else (lambda x: x)\n+        values = transf(values)\n+\n+        # length checking\n+        check_setitem_lengths(indexer, value, values)\n+\n+        def _is_scalar_indexer(indexer):\n+            # return True if we are all scalar indexers\n+\n+            if arr_value.ndim == 1:\n+                if not isinstance(indexer, tuple):\n+                    indexer = tuple([indexer])\n+                    return any(isinstance(idx, np.ndarray) and len(idx) == 0\n+                               for idx in indexer)\n+            return False\n+\n+        def _is_empty_indexer(indexer):\n+            # return a boolean if we have an empty indexer\n+\n+            if is_list_like(indexer) and not len(indexer):\n+                return True\n+            if arr_value.ndim == 1:\n+                if not isinstance(indexer, tuple):\n+                    indexer = tuple([indexer])\n+                return any(isinstance(idx, np.ndarray) and len(idx) == 0\n+                           for idx in indexer)\n+            return False\n+\n+        # empty indexers\n+        # 8669 (empty)\n+        if _is_empty_indexer(indexer):\n+            pass\n+\n+        # setting a single element for each dim and with a rhs that could\n+        # be say a list\n+        # GH 6043\n+        elif _is_scalar_indexer(indexer):\n+            values[indexer] = value\n+\n+        # if we are an exact match (ex-broadcasting),\n+        # then use the resultant dtype\n+        elif (len(arr_value.shape) and\n+              arr_value.shape[0] == values.shape[0] and\n+              np.prod(arr_value.shape) == np.prod(values.shape)):\n+            values[indexer] = value\n+            try:\n+                values = values.astype(arr_value.dtype)\n+            except ValueError:\n+                pass\n+\n+        # set\n+        else:\n+            values[indexer] = value\n+\n+        # coerce and try to infer the dtypes of the result\n+        values = self._try_coerce_and_cast_result(values, dtype)\n+        block = self.make_block(transf(values))\n+        return block\n+\n+    def putmask(self, mask, new, align=True, inplace=False, axis=0,\n+                transpose=False, mgr=None):\n+        \"\"\" putmask the data to the block; it is possible that we may create a\n+        new dtype of block\n+\n+        return the resulting block(s)\n+\n+        Parameters\n+        ----------\n+        mask  : the condition to respect\n+        new : a ndarray/object\n+        align : boolean, perform alignment on other/cond, default is True\n+        inplace : perform inplace modification, default is False\n+        axis : int\n+        transpose : boolean\n+            Set to True if self is stored with axes reversed\n+\n+        Returns\n+        -------\n+        a list of new blocks, the result of the putmask\n+        \"\"\"\n+\n+        new_values = self.values if inplace else self.values.copy()\n+\n+        new = getattr(new, 'values', new)\n+        mask = getattr(mask, 'values', mask)\n+\n+        # if we are passed a scalar None, convert it here\n+        if not is_list_like(new) and isna(new) and not self.is_object:\n+            new = self.fill_value\n+\n+        if self._can_hold_element(new):\n+            _, _, new, _ = self._try_coerce_args(new_values, new)\n+\n+            if transpose:\n+                new_values = new_values.T\n+\n+            # If the default repeat behavior in np.putmask would go in the\n+            # wrong direction, then explicitly repeat and reshape new instead\n+            if getattr(new, 'ndim', 0) >= 1:\n+                if self.ndim - 1 == new.ndim and axis == 1:\n+                    new = np.repeat(\n+                        new, new_values.shape[-1]).reshape(self.shape)\n+                new = new.astype(new_values.dtype)\n+\n+            # we require exact matches between the len of the\n+            # values we are setting (or is compat). np.putmask\n+            # doesn't check this and will simply truncate / pad\n+            # the output, but we want sane error messages\n+            #\n+            # TODO: this prob needs some better checking\n+            # for 2D cases\n+            if ((is_list_like(new) and\n+                 np.any(mask[mask]) and\n+                 getattr(new, 'ndim', 1) == 1)):\n+\n+                if not (mask.shape[-1] == len(new) or\n+                        mask[mask].shape[-1] == len(new) or\n+                        len(new) == 1):\n+                    raise ValueError(\"cannot assign mismatch \"\n+                                     \"length to masked array\")\n+\n+            np.putmask(new_values, mask, new)\n+\n+        # maybe upcast me\n+        elif mask.any():\n+            if transpose:\n+                mask = mask.T\n+                if isinstance(new, np.ndarray):\n+                    new = new.T\n+                axis = new_values.ndim - axis - 1\n+\n+            # Pseudo-broadcast\n+            if getattr(new, 'ndim', 0) >= 1:\n+                if self.ndim - 1 == new.ndim:\n+                    new_shape = list(new.shape)\n+                    new_shape.insert(axis, 1)\n+                    new = new.reshape(tuple(new_shape))\n+\n+            # operate column-by-column\n+            def f(m, v, i):\n+\n+                if i is None:\n+                    # ndim==1 case.\n+                    n = new\n+                else:\n+\n+                    if isinstance(new, np.ndarray):\n+                        n = np.squeeze(new[i % new.shape[0]])\n+                    else:\n+                        n = np.array(new)\n+\n+                    # type of the new block\n+                    dtype, _ = maybe_promote(n.dtype)\n+\n+                    # we need to explicitly astype here to make a copy\n+                    n = n.astype(dtype)\n+\n+                nv = _putmask_smart(v, m, n)\n+                return nv\n+\n+            new_blocks = self.split_and_operate(mask, f, inplace)\n+            return new_blocks\n+\n+        if inplace:\n+            return [self]\n+\n+        if transpose:\n+            new_values = new_values.T\n+\n+        return [self.make_block(new_values)]\n+\n+    def coerce_to_target_dtype(self, other):\n+        \"\"\"\n+        coerce the current block to a dtype compat for other\n+        we will return a block, possibly object, and not raise\n+\n+        we can also safely try to coerce to the same dtype\n+        and will receive the same block\n+        \"\"\"\n+\n+        # if we cannot then coerce to object\n+        dtype, _ = infer_dtype_from(other, pandas_dtype=True)\n+\n+        if is_dtype_equal(self.dtype, dtype):\n+            return self\n+\n+        if self.is_bool or is_object_dtype(dtype) or is_bool_dtype(dtype):\n+            # we don't upcast to bool\n+            return self.astype(object)\n+\n+        elif ((self.is_float or self.is_complex) and\n+              (is_integer_dtype(dtype) or is_float_dtype(dtype))):\n+            # don't coerce float/complex to int\n+            return self\n+\n+        elif (self.is_datetime or\n+              is_datetime64_dtype(dtype) or\n+              is_datetime64tz_dtype(dtype)):\n+\n+            # not a datetime\n+            if not ((is_datetime64_dtype(dtype) or\n+                     is_datetime64tz_dtype(dtype)) and self.is_datetime):\n+                return self.astype(object)\n+\n+            # don't upcast timezone with different timezone or no timezone\n+            mytz = getattr(self.dtype, 'tz', None)\n+            othertz = getattr(dtype, 'tz', None)\n+\n+            if str(mytz) != str(othertz):\n+                return self.astype(object)\n+\n+            raise AssertionError(\"possible recursion in \"\n+                                 \"coerce_to_target_dtype: {} {}\".format(\n+                                     self, other))\n+\n+        elif (self.is_timedelta or is_timedelta64_dtype(dtype)):\n+\n+            # not a timedelta\n+            if not (is_timedelta64_dtype(dtype) and self.is_timedelta):\n+                return self.astype(object)\n+\n+            raise AssertionError(\"possible recursion in \"\n+                                 \"coerce_to_target_dtype: {} {}\".format(\n+                                     self, other))\n+\n+        try:\n+            return self.astype(dtype)\n+        except (ValueError, TypeError):\n+            pass\n+\n+        return self.astype(object)\n+\n+    def interpolate(self, method='pad', axis=0, index=None, values=None,\n+                    inplace=False, limit=None, limit_direction='forward',\n+                    limit_area=None, fill_value=None, coerce=False,\n+                    downcast=None, mgr=None, **kwargs):\n+\n+        inplace = validate_bool_kwarg(inplace, 'inplace')\n+\n+        def check_int_bool(self, inplace):\n+            # Only FloatBlocks will contain NaNs.\n+            # timedelta subclasses IntBlock\n+            if (self.is_bool or self.is_integer) and not self.is_timedelta:\n+                if inplace:\n+                    return self\n+                else:\n+                    return self.copy()\n+\n+        # a fill na type method\n+        try:\n+            m = missing.clean_fill_method(method)\n+        except:\n+            m = None\n+\n+        if m is not None:\n+            r = check_int_bool(self, inplace)\n+            if r is not None:\n+                return r\n+            return self._interpolate_with_fill(method=m, axis=axis,\n+                                               inplace=inplace, limit=limit,\n+                                               fill_value=fill_value,\n+                                               coerce=coerce,\n+                                               downcast=downcast, mgr=mgr)\n+        # try an interp method\n+        try:\n+            m = missing.clean_interp_method(method, **kwargs)\n+        except:\n+            m = None\n+\n+        if m is not None:\n+            r = check_int_bool(self, inplace)\n+            if r is not None:\n+                return r\n+            return self._interpolate(method=m, index=index, values=values,\n+                                     axis=axis, limit=limit,\n+                                     limit_direction=limit_direction,\n+                                     limit_area=limit_area,\n+                                     fill_value=fill_value, inplace=inplace,\n+                                     downcast=downcast, mgr=mgr, **kwargs)\n+\n+        raise ValueError(\"invalid method '{0}' to interpolate.\".format(method))\n+\n+    def _interpolate_with_fill(self, method='pad', axis=0, inplace=False,\n+                               limit=None, fill_value=None, coerce=False,\n+                               downcast=None, mgr=None):\n+        \"\"\" fillna but using the interpolate machinery \"\"\"\n+\n+        inplace = validate_bool_kwarg(inplace, 'inplace')\n+\n+        # if we are coercing, then don't force the conversion\n+        # if the block can't hold the type\n+        if coerce:\n+            if not self._can_hold_na:\n+                if inplace:\n+                    return [self]\n+                else:\n+                    return [self.copy()]\n+\n+        values = self.values if inplace else self.values.copy()\n+        values, _, fill_value, _ = self._try_coerce_args(values, fill_value)\n+        values = missing.interpolate_2d(values, method=method, axis=axis,\n+                                        limit=limit, fill_value=fill_value,\n+                                        dtype=self.dtype)\n+        values = self._try_coerce_result(values)\n+\n+        blocks = [self.make_block_same_class(values, ndim=self.ndim)]\n+        return self._maybe_downcast(blocks, downcast)\n+\n+    def _interpolate(self, method=None, index=None, values=None,\n+                     fill_value=None, axis=0, limit=None,\n+                     limit_direction='forward', limit_area=None,\n+                     inplace=False, downcast=None, mgr=None, **kwargs):\n+        \"\"\" interpolate using scipy wrappers \"\"\"\n+\n+        inplace = validate_bool_kwarg(inplace, 'inplace')\n+        data = self.values if inplace else self.values.copy()\n+\n+        # only deal with floats\n+        if not self.is_float:\n+            if not self.is_integer:\n+                return self\n+            data = data.astype(np.float64)\n+\n+        if fill_value is None:\n+            fill_value = self.fill_value\n+\n+        if method in ('krogh', 'piecewise_polynomial', 'pchip'):\n+            if not index.is_monotonic:\n+                raise ValueError(\"{0} interpolation requires that the \"\n+                                 \"index be monotonic.\".format(method))\n+        # process 1-d slices in the axis direction\n+\n+        def func(x):\n+\n+            # process a 1-d slice, returning it\n+            # should the axis argument be handled below in apply_along_axis?\n+            # i.e. not an arg to missing.interpolate_1d\n+            return missing.interpolate_1d(index, x, method=method, limit=limit,\n+                                          limit_direction=limit_direction,\n+                                          limit_area=limit_area,\n+                                          fill_value=fill_value,\n+                                          bounds_error=False, **kwargs)\n+\n+        # interp each column independently\n+        interp_values = np.apply_along_axis(func, axis, data)\n+\n+        blocks = [self.make_block_same_class(interp_values)]\n+        return self._maybe_downcast(blocks, downcast)\n+\n+    def take_nd(self, indexer, axis, new_mgr_locs=None, fill_tuple=None):\n+        \"\"\"\n+        Take values according to indexer and return them as a block.bb\n+\n+        \"\"\"\n+\n+        # algos.take_nd dispatches for DatetimeTZBlock, CategoricalBlock\n+        # so need to preserve types\n+        # sparse is treated like an ndarray, but needs .get_values() shaping\n+\n+        values = self.values\n+        if self.is_sparse:\n+            values = self.get_values()\n+\n+        if fill_tuple is None:\n+            fill_value = self.fill_value\n+            new_values = algos.take_nd(values, indexer, axis=axis,\n+                                       allow_fill=False)\n+        else:\n+            fill_value = fill_tuple[0]\n+            new_values = algos.take_nd(values, indexer, axis=axis,\n+                                       allow_fill=True, fill_value=fill_value)\n+\n+        if new_mgr_locs is None:\n+            if axis == 0:\n+                slc = libinternals.indexer_as_slice(indexer)\n+                if slc is not None:\n+                    new_mgr_locs = self.mgr_locs[slc]\n+                else:\n+                    new_mgr_locs = self.mgr_locs[indexer]\n+            else:\n+                new_mgr_locs = self.mgr_locs\n+\n+        if not is_dtype_equal(new_values.dtype, self.dtype):\n+            return self.make_block(new_values, new_mgr_locs)\n+        else:\n+            return self.make_block_same_class(new_values, new_mgr_locs)\n+\n+    def diff(self, n, axis=1, mgr=None):\n+        \"\"\" return block for the diff of the values \"\"\"\n+        new_values = algos.diff(self.values, n, axis=axis)\n+        return [self.make_block(values=new_values)]\n+\n+    def shift(self, periods, axis=0, mgr=None):\n+        \"\"\" shift the block by periods, possibly upcast \"\"\"\n+\n+        # convert integer to float if necessary. need to do a lot more than\n+        # that, handle boolean etc also\n+        new_values, fill_value = maybe_upcast(self.values)\n+\n+        # make sure array sent to np.roll is c_contiguous\n+        f_ordered = new_values.flags.f_contiguous\n+        if f_ordered:\n+            new_values = new_values.T\n+            axis = new_values.ndim - axis - 1\n+\n+        if np.prod(new_values.shape):\n+            new_values = np.roll(new_values, ensure_platform_int(periods),\n+                                 axis=axis)\n+\n+        axis_indexer = [slice(None)] * self.ndim\n+        if periods > 0:\n+            axis_indexer[axis] = slice(None, periods)\n+        else:\n+            axis_indexer[axis] = slice(periods, None)\n+        new_values[tuple(axis_indexer)] = fill_value\n+\n+        # restore original order\n+        if f_ordered:\n+            new_values = new_values.T\n+\n+        return [self.make_block(new_values)]\n+\n+    def eval(self, func, other, errors='raise', try_cast=False, mgr=None):\n+        \"\"\"\n+        evaluate the block; return result block from the result\n+\n+        Parameters\n+        ----------\n+        func  : how to combine self, other\n+        other : a ndarray/object\n+        errors : str, {'raise', 'ignore'}, default 'raise'\n+            - ``raise`` : allow exceptions to be raised\n+            - ``ignore`` : suppress exceptions. On error return original object\n+\n+        try_cast : try casting the results to the input type\n+\n+        Returns\n+        -------\n+        a new block, the result of the func\n+        \"\"\"\n+        orig_other = other\n+        values = self.values\n+\n+        other = getattr(other, 'values', other)\n+\n+        # make sure that we can broadcast\n+        is_transposed = False\n+        if hasattr(other, 'ndim') and hasattr(values, 'ndim'):\n+            if values.ndim != other.ndim:\n+                is_transposed = True\n+            else:\n+                if values.shape == other.shape[::-1]:\n+                    is_transposed = True\n+                elif values.shape[0] == other.shape[-1]:\n+                    is_transposed = True\n+                else:\n+                    # this is a broadcast error heree\n+                    raise ValueError(\n+                        \"cannot broadcast shape [{t_shape}] with \"\n+                        \"block values [{oth_shape}]\".format(\n+                            t_shape=values.T.shape, oth_shape=other.shape))\n+\n+        transf = (lambda x: x.T) if is_transposed else (lambda x: x)\n+\n+        # coerce/transpose the args if needed\n+        try:\n+            values, values_mask, other, other_mask = self._try_coerce_args(\n+                transf(values), other)\n+        except TypeError:\n+            block = self.coerce_to_target_dtype(orig_other)\n+            return block.eval(func, orig_other,\n+                              errors=errors,\n+                              try_cast=try_cast, mgr=mgr)\n+\n+        # get the result, may need to transpose the other\n+        def get_result(other):\n+\n+            # avoid numpy warning of comparisons again None\n+            if other is None:\n+                result = not func.__name__ == 'eq'\n+\n+            # avoid numpy warning of elementwise comparisons to object\n+            elif is_numeric_v_string_like(values, other):\n+                result = False\n+\n+            # avoid numpy warning of elementwise comparisons\n+            elif func.__name__ == 'eq':\n+                if is_list_like(other) and not isinstance(other, np.ndarray):\n+                    other = np.asarray(other)\n+\n+                    # if we can broadcast, then ok\n+                    if values.shape[-1] != other.shape[-1]:\n+                        return False\n+                result = func(values, other)\n+            else:\n+                result = func(values, other)\n+\n+            # mask if needed\n+            if isinstance(values_mask, np.ndarray) and values_mask.any():\n+                result = result.astype('float64', copy=False)\n+                result[values_mask] = np.nan\n+            if other_mask is True:\n+                result = result.astype('float64', copy=False)\n+                result[:] = np.nan\n+            elif isinstance(other_mask, np.ndarray) and other_mask.any():\n+                result = result.astype('float64', copy=False)\n+                result[other_mask.ravel()] = np.nan\n+\n+            return result\n+\n+        # error handler if we have an issue operating with the function\n+        def handle_error():\n+\n+            if errors == 'raise':\n+                # The 'detail' variable is defined in outer scope.\n+                raise TypeError(\n+                    'Could not operate {other!r} with block values '\n+                    '{detail!s}'.format(other=other, detail=detail))  # noqa\n+            else:\n+                # return the values\n+                result = np.empty(values.shape, dtype='O')\n+                result.fill(np.nan)\n+                return result\n+\n+        # get the result\n+        try:\n+            with np.errstate(all='ignore'):\n+                result = get_result(other)\n+\n+        # if we have an invalid shape/broadcast error\n+        # GH4576, so raise instead of allowing to pass through\n+        except ValueError as detail:\n+            raise\n+        except Exception as detail:\n+            result = handle_error()\n+\n+        # technically a broadcast error in numpy can 'work' by returning a\n+        # boolean False\n+        if not isinstance(result, np.ndarray):\n+            if not isinstance(result, np.ndarray):\n+\n+                # differentiate between an invalid ndarray-ndarray comparison\n+                # and an invalid type comparison\n+                if isinstance(values, np.ndarray) and is_list_like(other):\n+                    raise ValueError(\n+                        'Invalid broadcasting comparison [{other!r}] with '\n+                        'block values'.format(other=other))\n+\n+                raise TypeError('Could not compare [{other!r}] '\n+                                'with block values'.format(other=other))\n+\n+        # transpose if needed\n+        result = transf(result)\n+\n+        # try to cast if requested\n+        if try_cast:\n+            result = self._try_cast_result(result)\n+\n+        result = _block_shape(result, ndim=self.ndim)\n+        return [self.make_block(result)]\n+\n+    def where(self, other, cond, align=True, errors='raise',\n+              try_cast=False, axis=0, transpose=False, mgr=None):\n+        \"\"\"\n+        evaluate the block; return result block(s) from the result\n+\n+        Parameters\n+        ----------\n+        other : a ndarray/object\n+        cond  : the condition to respect\n+        align : boolean, perform alignment on other/cond\n+        errors : str, {'raise', 'ignore'}, default 'raise'\n+            - ``raise`` : allow exceptions to be raised\n+            - ``ignore`` : suppress exceptions. On error return original object\n+\n+        axis : int\n+        transpose : boolean\n+            Set to True if self is stored with axes reversed\n+\n+        Returns\n+        -------\n+        a new block(s), the result of the func\n+        \"\"\"\n+        import pandas.core.computation.expressions as expressions\n+        assert errors in ['raise', 'ignore']\n+\n+        values = self.values\n+        orig_other = other\n+        if transpose:\n+            values = values.T\n+\n+        other = getattr(other, '_values', getattr(other, 'values', other))\n+        cond = getattr(cond, 'values', cond)\n+\n+        # If the default broadcasting would go in the wrong direction, then\n+        # explicitly reshape other instead\n+        if getattr(other, 'ndim', 0) >= 1:\n+            if values.ndim - 1 == other.ndim and axis == 1:\n+                other = other.reshape(tuple(other.shape + (1, )))\n+            elif transpose and values.ndim == self.ndim - 1:\n+                cond = cond.T\n+\n+        if not hasattr(cond, 'shape'):\n+            raise ValueError(\"where must have a condition that is ndarray \"\n+                             \"like\")\n+\n+        # our where function\n+        def func(cond, values, other):\n+            if cond.ravel().all():\n+                return values\n+\n+            values, values_mask, other, other_mask = self._try_coerce_args(\n+                values, other)\n+\n+            try:\n+                return self._try_coerce_result(expressions.where(\n+                    cond, values, other))\n+            except Exception as detail:\n+                if errors == 'raise':\n+                    raise TypeError(\n+                        'Could not operate [{other!r}] with block values '\n+                        '[{detail!s}]'.format(other=other, detail=detail))\n+                else:\n+                    # return the values\n+                    result = np.empty(values.shape, dtype='float64')\n+                    result.fill(np.nan)\n+                    return result\n+\n+        # see if we can operate on the entire block, or need item-by-item\n+        # or if we are a single block (ndim == 1)\n+        try:\n+            result = func(cond, values, other)\n+        except TypeError:\n+\n+            # we cannot coerce, return a compat dtype\n+            # we are explicitly ignoring errors\n+            block = self.coerce_to_target_dtype(other)\n+            blocks = block.where(orig_other, cond, align=align,\n+                                 errors=errors,\n+                                 try_cast=try_cast, axis=axis,\n+                                 transpose=transpose)\n+            return self._maybe_downcast(blocks, 'infer')\n+\n+        if self._can_hold_na or self.ndim == 1:\n+\n+            if transpose:\n+                result = result.T\n+\n+            # try to cast if requested\n+            if try_cast:\n+                result = self._try_cast_result(result)\n+\n+            return self.make_block(result)\n+\n+        # might need to separate out blocks\n+        axis = cond.ndim - 1\n+        cond = cond.swapaxes(axis, 0)\n+        mask = np.array([cond[i].all() for i in range(cond.shape[0])],\n+                        dtype=bool)\n+\n+        result_blocks = []\n+        for m in [mask, ~mask]:\n+            if m.any():\n+                r = self._try_cast_result(result.take(m.nonzero()[0],\n+                                                      axis=axis))\n+                result_blocks.append(\n+                    self.make_block(r.T, placement=self.mgr_locs[m]))\n+\n+        return result_blocks\n+\n+    def equals(self, other):\n+        if self.dtype != other.dtype or self.shape != other.shape:\n+            return False\n+        return array_equivalent(self.values, other.values)\n+\n+    def _unstack(self, unstacker_func, new_columns):\n+        \"\"\"Return a list of unstacked blocks of self\n+\n+        Parameters\n+        ----------\n+        unstacker_func : callable\n+            Partially applied unstacker.\n+        new_columns : Index\n+            All columns of the unstacked BlockManager.\n+\n+        Returns\n+        -------\n+        blocks : list of Block\n+            New blocks of unstacked values.\n+        mask : array_like of bool\n+            The mask of columns of `blocks` we should keep.\n+        \"\"\"\n+        unstacker = unstacker_func(self.values.T)\n+        new_items = unstacker.get_new_columns()\n+        new_placement = new_columns.get_indexer(new_items)\n+        new_values, mask = unstacker.get_new_values()\n+\n+        mask = mask.any(0)\n+        new_values = new_values.T[mask]\n+        new_placement = new_placement[mask]\n+\n+        blocks = [make_block(new_values, placement=new_placement)]\n+        return blocks, mask\n+\n+    def quantile(self, qs, interpolation='linear', axis=0, mgr=None):\n+        \"\"\"\n+        compute the quantiles of the\n+\n+        Parameters\n+        ----------\n+        qs: a scalar or list of the quantiles to be computed\n+        interpolation: type of interpolation, default 'linear'\n+        axis: axis to compute, default 0\n+\n+        Returns\n+        -------\n+        tuple of (axis, block)\n+\n+        \"\"\"\n+        kw = {'interpolation': interpolation}\n+        values = self.get_values()\n+        values, _, _, _ = self._try_coerce_args(values, values)\n+\n+        def _nanpercentile1D(values, mask, q, **kw):\n+            values = values[~mask]\n+\n+            if len(values) == 0:\n+                if lib.is_scalar(q):\n+                    return self._na_value\n+                else:\n+                    return np.array([self._na_value] * len(q),\n+                                    dtype=values.dtype)\n+\n+            return np.percentile(values, q, **kw)\n+\n+        def _nanpercentile(values, q, axis, **kw):\n+\n+            mask = isna(self.values)\n+            if not lib.is_scalar(mask) and mask.any():\n+                if self.ndim == 1:\n+                    return _nanpercentile1D(values, mask, q, **kw)\n+                else:\n+                    # for nonconsolidatable blocks mask is 1D, but values 2D\n+                    if mask.ndim < values.ndim:\n+                        mask = mask.reshape(values.shape)\n+                    if axis == 0:\n+                        values = values.T\n+                        mask = mask.T\n+                    result = [_nanpercentile1D(val, m, q, **kw) for (val, m)\n+                              in zip(list(values), list(mask))]\n+                    result = np.array(result, dtype=values.dtype, copy=False).T\n+                    return result\n+            else:\n+                return np.percentile(values, q, axis=axis, **kw)\n+\n+        from pandas import Float64Index\n+        is_empty = values.shape[axis] == 0\n+        if is_list_like(qs):\n+            ax = Float64Index(qs)\n+\n+            if is_empty:\n+                if self.ndim == 1:\n+                    result = self._na_value\n+                else:\n+                    # create the array of na_values\n+                    # 2d len(values) * len(qs)\n+                    result = np.repeat(np.array([self._na_value] * len(qs)),\n+                                       len(values)).reshape(len(values),\n+                                                            len(qs))\n+            else:\n+\n+                try:\n+                    result = _nanpercentile(values, np.array(qs) * 100,\n+                                            axis=axis, **kw)\n+                except ValueError:\n+\n+                    # older numpies don't handle an array for q\n+                    result = [_nanpercentile(values, q * 100,\n+                                             axis=axis, **kw) for q in qs]\n+\n+                result = np.array(result, copy=False)\n+                if self.ndim > 1:\n+                    result = result.T\n+\n+        else:\n+\n+            if self.ndim == 1:\n+                ax = Float64Index([qs])\n+            else:\n+                ax = mgr.axes[0]\n+\n+            if is_empty:\n+                if self.ndim == 1:\n+                    result = self._na_value\n+                else:\n+                    result = np.array([self._na_value] * len(self))\n+            else:\n+                result = _nanpercentile(values, qs * 100, axis=axis, **kw)\n+\n+        ndim = getattr(result, 'ndim', None) or 0\n+        result = self._try_coerce_result(result)\n+        if lib.is_scalar(result):\n+            return ax, self.make_block_scalar(result)\n+        return ax, make_block(result,\n+                              placement=np.arange(len(result)),\n+                              ndim=ndim)\n+\n+\n+class ScalarBlock(Block):\n+    \"\"\"\n+    a scalar compat Block\n+    \"\"\"\n+    __slots__ = ['_mgr_locs', 'values', 'ndim']\n+\n+    def __init__(self, values):\n+        self.ndim = 0\n+        self.mgr_locs = [0]\n+        self.values = values\n+\n+    @property\n+    def dtype(self):\n+        return type(self.values)\n+\n+    @property\n+    def shape(self):\n+        return tuple([0])\n+\n+    def __len__(self):\n+        return 0\n+\n+\n+class NonConsolidatableMixIn(object):\n+    \"\"\" hold methods for the nonconsolidatable blocks \"\"\"\n+    _can_consolidate = False\n+    _verify_integrity = False\n+    _validate_ndim = False\n+\n+    def __init__(self, values, placement, ndim=None):\n+        \"\"\"Initialize a non-consolidatable block.\n+\n+        'ndim' may be inferred from 'placement'.\n+\n+        This will call continue to call __init__ for the other base\n+        classes mixed in with this Mixin.\n+        \"\"\"\n+        # Placement must be converted to BlockPlacement so that we can check\n+        # its length\n+        if not isinstance(placement, libinternals.BlockPlacement):\n+            placement = libinternals.BlockPlacement(placement)\n+\n+        # Maybe infer ndim from placement\n+        if ndim is None:\n+            if len(placement) != 1:\n+                ndim = 1\n+            else:\n+                ndim = 2\n+        super(NonConsolidatableMixIn, self).__init__(values, placement,\n+                                                     ndim=ndim)\n+\n+    @property\n+    def shape(self):\n+        if self.ndim == 1:\n+            return (len(self.values)),\n+        return (len(self.mgr_locs), len(self.values))\n+\n+    def get_values(self, dtype=None):\n+        \"\"\" need to to_dense myself (and always return a ndim sized object) \"\"\"\n+        values = self.values.to_dense()\n+        if values.ndim == self.ndim - 1:\n+            values = values.reshape((1,) + values.shape)\n+        return values\n+\n+    def iget(self, col):\n+\n+        if self.ndim == 2 and isinstance(col, tuple):\n+            col, loc = col\n+            if not com.is_null_slice(col) and col != 0:\n+                raise IndexError(\"{0} only contains one item\".format(self))\n+            return self.values[loc]\n+        else:\n+            if col != 0:\n+                raise IndexError(\"{0} only contains one item\".format(self))\n+            return self.values\n+\n+    def should_store(self, value):\n+        return isinstance(value, self._holder)\n+\n+    def set(self, locs, values, check=False):\n+        assert locs.tolist() == [0]\n+        self.values = values\n+\n+    def putmask(self, mask, new, align=True, inplace=False, axis=0,\n+                transpose=False, mgr=None):\n+        \"\"\"\n+        putmask the data to the block; we must be a single block and not\n+        generate other blocks\n+\n+        return the resulting block\n+\n+        Parameters\n+        ----------\n+        mask  : the condition to respect\n+        new : a ndarray/object\n+        align : boolean, perform alignment on other/cond, default is True\n+        inplace : perform inplace modification, default is False\n+\n+        Returns\n+        -------\n+        a new block, the result of the putmask\n+        \"\"\"\n+        inplace = validate_bool_kwarg(inplace, 'inplace')\n+\n+        # use block's copy logic.\n+        # .values may be an Index which does shallow copy by default\n+        new_values = self.values if inplace else self.copy().values\n+        new_values, _, new, _ = self._try_coerce_args(new_values, new)\n+\n+        if isinstance(new, np.ndarray) and len(new) == len(mask):\n+            new = new[mask]\n+\n+        mask = _safe_reshape(mask, new_values.shape)\n+\n+        new_values[mask] = new\n+        new_values = self._try_coerce_result(new_values)\n+        return [self.make_block(values=new_values)]\n+\n+    def _slice(self, slicer):\n+        \"\"\" return a slice of my values (but densify first) \"\"\"\n+        return self.get_values()[slicer]\n+\n+    def _try_cast_result(self, result, dtype=None):\n+        return result\n+\n+    def _unstack(self, unstacker_func, new_columns):\n+        \"\"\"Return a list of unstacked blocks of self\n+\n+        Parameters\n+        ----------\n+        unstacker_func : callable\n+            Partially applied unstacker.\n+        new_columns : Index\n+            All columns of the unstacked BlockManager.\n+\n+        Returns\n+        -------\n+        blocks : list of Block\n+            New blocks of unstacked values.\n+        mask : array_like of bool\n+            The mask of columns of `blocks` we should keep.\n+        \"\"\"\n+        # NonConsolidatable blocks can have a single item only, so we return\n+        # one block per item\n+        unstacker = unstacker_func(self.values.T)\n+        new_items = unstacker.get_new_columns()\n+        new_placement = new_columns.get_indexer(new_items)\n+        new_values, mask = unstacker.get_new_values()\n+\n+        mask = mask.any(0)\n+        new_values = new_values.T[mask]\n+        new_placement = new_placement[mask]\n+\n+        blocks = [self.make_block_same_class(vals, [place])\n+                  for vals, place in zip(new_values, new_placement)]\n+        return blocks, mask\n+\n+\n+class ExtensionBlock(NonConsolidatableMixIn, Block):\n+    \"\"\"Block for holding extension types.\n+\n+    Notes\n+    -----\n+    This holds all 3rd-party extension array types. It's also the immediate\n+    parent class for our internal extension types' blocks, CategoricalBlock.\n+\n+    ExtensionArrays are limited to 1-D.\n+    \"\"\"\n+    is_extension = True\n+\n+    def __init__(self, values, placement, ndim=None):\n+        values = self._maybe_coerce_values(values)\n+        super(ExtensionBlock, self).__init__(values, placement, ndim)\n+\n+    def _maybe_coerce_values(self, values):\n+        \"\"\"Unbox to an extension array.\n+\n+        This will unbox an ExtensionArray stored in an Index or Series.\n+        ExtensionArrays pass through. No dtype coercion is done.\n+\n+        Parameters\n+        ----------\n+        values : Index, Series, ExtensionArray\n+\n+        Returns\n+        -------\n+        ExtensionArray\n+        \"\"\"\n+        if isinstance(values, (ABCIndexClass, ABCSeries)):\n+            values = values._values\n+        return values\n+\n+    @property\n+    def _holder(self):\n+        # For extension blocks, the holder is values-dependent.\n+        return type(self.values)\n+\n+    @property\n+    def fill_value(self):\n+        # Used in reindex_indexer\n+        return self.values.dtype.na_value\n+\n+    @property\n+    def _can_hold_na(self):\n+        # The default ExtensionArray._can_hold_na is True\n+        return self._holder._can_hold_na\n+\n+    @property\n+    def is_view(self):\n+        \"\"\"Extension arrays are never treated as views.\"\"\"\n+        return False\n+\n+    def setitem(self, indexer, value, mgr=None):\n+        \"\"\"Set the value inplace, returning a same-typed block.\n+\n+        This differs from Block.setitem by not allowing setitem to change\n+        the dtype of the Block.\n+\n+        Parameters\n+        ----------\n+        indexer : tuple, list-like, array-like, slice\n+            The subset of self.values to set\n+        value : object\n+            The value being set\n+        mgr : BlockPlacement, optional\n+\n+        Returns\n+        -------\n+        Block\n+\n+        Notes\n+        -----\n+        `indexer` is a direct slice/positional indexer. `value` must\n+        be a compatible shape.\n+        \"\"\"\n+        if isinstance(indexer, tuple):\n+            # we are always 1-D\n+            indexer = indexer[0]\n+\n+        check_setitem_lengths(indexer, value, self.values)\n+        self.values[indexer] = value\n+        return self\n+\n+    def get_values(self, dtype=None):\n+        # ExtensionArrays must be iterable, so this works.\n+        values = np.asarray(self.values)\n+        if values.ndim == self.ndim - 1:\n+            values = values.reshape((1,) + values.shape)\n+        return values\n+\n+    def to_dense(self):\n+        return np.asarray(self.values)\n+\n+    def take_nd(self, indexer, axis=0, new_mgr_locs=None, fill_tuple=None):\n+        \"\"\"\n+        Take values according to indexer and return them as a block.\n+        \"\"\"\n+        if fill_tuple is None:\n+            fill_value = None\n+        else:\n+            fill_value = fill_tuple[0]\n+\n+        # axis doesn't matter; we are really a single-dim object\n+        # but are passed the axis depending on the calling routing\n+        # if its REALLY axis 0, then this will be a reindex and not a take\n+        new_values = self.values.take(indexer, fill_value=fill_value,\n+                                      allow_fill=True)\n+\n+        # if we are a 1-dim object, then always place at 0\n+        if self.ndim == 1:\n+            new_mgr_locs = [0]\n+        else:\n+            if new_mgr_locs is None:\n+                new_mgr_locs = self.mgr_locs\n+\n+        return self.make_block_same_class(new_values, new_mgr_locs)\n+\n+    def _can_hold_element(self, element):\n+        # XXX: We may need to think about pushing this onto the array.\n+        # We're doing the same as CategoricalBlock here.\n+        return True\n+\n+    def _slice(self, slicer):\n+        \"\"\" return a slice of my values \"\"\"\n+\n+        # slice the category\n+        # return same dims as we currently have\n+\n+        if isinstance(slicer, tuple) and len(slicer) == 2:\n+            if not com.is_null_slice(slicer[0]):\n+                raise AssertionError(\"invalid slicing for a 1-ndim \"\n+                                     \"categorical\")\n+            slicer = slicer[1]\n+\n+        return self.values[slicer]\n+\n+    def formatting_values(self):\n+        return self.values._formatting_values()\n+\n+    def concat_same_type(self, to_concat, placement=None):\n+        \"\"\"\n+        Concatenate list of single blocks of the same type.\n+        \"\"\"\n+        values = self._holder._concat_same_type(\n+            [blk.values for blk in to_concat])\n+        placement = placement or slice(0, len(values), 1)\n+        return self.make_block_same_class(values, ndim=self.ndim,\n+                                          placement=placement)\n+\n+    def fillna(self, value, limit=None, inplace=False, downcast=None,\n+               mgr=None):\n+        values = self.values if inplace else self.values.copy()\n+        values = values.fillna(value=value, limit=limit)\n+        return [self.make_block_same_class(values=values,\n+                                           placement=self.mgr_locs,\n+                                           ndim=self.ndim)]\n+\n+    def interpolate(self, method='pad', axis=0, inplace=False, limit=None,\n+                    fill_value=None, **kwargs):\n+\n+        values = self.values if inplace else self.values.copy()\n+        return self.make_block_same_class(\n+            values=values.fillna(value=fill_value, method=method,\n+                                 limit=limit),\n+            placement=self.mgr_locs)\n+\n+\n+class NumericBlock(Block):\n+    __slots__ = ()\n+    is_numeric = True\n+    _can_hold_na = True\n+\n+\n+class FloatOrComplexBlock(NumericBlock):\n+    __slots__ = ()\n+\n+    def equals(self, other):\n+        if self.dtype != other.dtype or self.shape != other.shape:\n+            return False\n+        left, right = self.values, other.values\n+        return ((left == right) | (np.isnan(left) & np.isnan(right))).all()\n+\n+\n+class FloatBlock(FloatOrComplexBlock):\n+    __slots__ = ()\n+    is_float = True\n+\n+    def _can_hold_element(self, element):\n+        tipo = maybe_infer_dtype_type(element)\n+        if tipo is not None:\n+            return (issubclass(tipo.type, (np.floating, np.integer)) and\n+                    not issubclass(tipo.type, (np.datetime64, np.timedelta64)))\n+        return (\n+            isinstance(\n+                element, (float, int, np.floating, np.int_, compat.long))\n+            and not isinstance(element, (bool, np.bool_, datetime, timedelta,\n+                                         np.datetime64, np.timedelta64)))\n+\n+    def to_native_types(self, slicer=None, na_rep='', float_format=None,\n+                        decimal='.', quoting=None, **kwargs):\n+        \"\"\" convert to our native types format, slicing if desired \"\"\"\n+\n+        values = self.values\n+        if slicer is not None:\n+            values = values[:, slicer]\n+\n+        # see gh-13418: no special formatting is desired at the\n+        # output (important for appropriate 'quoting' behaviour),\n+        # so do not pass it through the FloatArrayFormatter\n+        if float_format is None and decimal == '.':\n+            mask = isna(values)\n+\n+            if not quoting:\n+                values = values.astype(str)\n+            else:\n+                values = np.array(values, dtype='object')\n+\n+            values[mask] = na_rep\n+            return values\n+\n+        from pandas.io.formats.format import FloatArrayFormatter\n+        formatter = FloatArrayFormatter(values, na_rep=na_rep,\n+                                        float_format=float_format,\n+                                        decimal=decimal, quoting=quoting,\n+                                        fixed_width=False)\n+        return formatter.get_result_as_array()\n+\n+    def should_store(self, value):\n+        # when inserting a column should not coerce integers to floats\n+        # unnecessarily\n+        return (issubclass(value.dtype.type, np.floating) and\n+                value.dtype == self.dtype)\n+\n+\n+class ComplexBlock(FloatOrComplexBlock):\n+    __slots__ = ()\n+    is_complex = True\n+\n+    def _can_hold_element(self, element):\n+        tipo = maybe_infer_dtype_type(element)\n+        if tipo is not None:\n+            return issubclass(tipo.type,\n+                              (np.floating, np.integer, np.complexfloating))\n+        return (\n+            isinstance(\n+                element,\n+                (float, int, complex, np.float_, np.int_, compat.long))\n+            and not isinstance(element, (bool, np.bool_)))\n+\n+    def should_store(self, value):\n+        return issubclass(value.dtype.type, np.complexfloating)\n+\n+\n+class IntBlock(NumericBlock):\n+    __slots__ = ()\n+    is_integer = True\n+    _can_hold_na = False\n+\n+    def _can_hold_element(self, element):\n+        tipo = maybe_infer_dtype_type(element)\n+        if tipo is not None:\n+            return (issubclass(tipo.type, np.integer) and\n+                    not issubclass(tipo.type, (np.datetime64,\n+                                               np.timedelta64)) and\n+                    self.dtype.itemsize >= tipo.itemsize)\n+        return is_integer(element)\n+\n+    def should_store(self, value):\n+        return is_integer_dtype(value) and value.dtype == self.dtype\n+\n+\n+class DatetimeLikeBlockMixin(object):\n+    \"\"\"Mixin class for DatetimeBlock and DatetimeTZBlock.\"\"\"\n+\n+    @property\n+    def _holder(self):\n+        return DatetimeIndex\n+\n+    @property\n+    def _na_value(self):\n+        return tslibs.NaT\n+\n+    @property\n+    def fill_value(self):\n+        return tslibs.iNaT\n+\n+    def get_values(self, dtype=None):\n+        \"\"\"\n+        return object dtype as boxed values, such as Timestamps/Timedelta\n+        \"\"\"\n+        if is_object_dtype(dtype):\n+            return lib.map_infer(self.values.ravel(),\n+                                 self._box_func).reshape(self.values.shape)\n+        return self.values\n+\n+\n+class TimeDeltaBlock(DatetimeLikeBlockMixin, IntBlock):\n+    __slots__ = ()\n+    is_timedelta = True\n+    _can_hold_na = True\n+    is_numeric = False\n+\n+    def __init__(self, values, placement, ndim=None):\n+        if values.dtype != _TD_DTYPE:\n+            values = conversion.ensure_timedelta64ns(values)\n+\n+        super(TimeDeltaBlock, self).__init__(values,\n+                                             placement=placement, ndim=ndim)\n+\n+    @property\n+    def _holder(self):\n+        return TimedeltaIndex\n+\n+    @property\n+    def _box_func(self):\n+        return lambda x: Timedelta(x, unit='ns')\n+\n+    def _can_hold_element(self, element):\n+        tipo = maybe_infer_dtype_type(element)\n+        if tipo is not None:\n+            return issubclass(tipo.type, np.timedelta64)\n+        return is_integer(element) or isinstance(\n+            element, (timedelta, np.timedelta64))\n+\n+    def fillna(self, value, **kwargs):\n+\n+        # allow filling with integers to be\n+        # interpreted as seconds\n+        if is_integer(value) and not isinstance(value, np.timedelta64):\n+            value = Timedelta(value, unit='s')\n+        return super(TimeDeltaBlock, self).fillna(value, **kwargs)\n+\n+    def _try_coerce_args(self, values, other):\n+        \"\"\"\n+        Coerce values and other to int64, with null values converted to\n+        iNaT. values is always ndarray-like, other may not be\n+\n+        Parameters\n+        ----------\n+        values : ndarray-like\n+        other : ndarray-like or scalar\n+\n+        Returns\n+        -------\n+        base-type values, values mask, base-type other, other mask\n+        \"\"\"\n+\n+        values_mask = isna(values)\n+        values = values.view('i8')\n+        other_mask = False\n+\n+        if isinstance(other, bool):\n+            raise TypeError\n+        elif is_null_datelike_scalar(other):\n+            other = tslibs.iNaT\n+            other_mask = True\n+        elif isinstance(other, Timedelta):\n+            other_mask = isna(other)\n+            other = other.value\n+        elif isinstance(other, timedelta):\n+            other = Timedelta(other).value\n+        elif isinstance(other, np.timedelta64):\n+            other_mask = isna(other)\n+            other = Timedelta(other).value\n+        elif hasattr(other, 'dtype') and is_timedelta64_dtype(other):\n+            other_mask = isna(other)\n+            other = other.astype('i8', copy=False).view('i8')\n+        else:\n+            # coercion issues\n+            # let higher levels handle\n+            raise TypeError\n+\n+        return values, values_mask, other, other_mask\n+\n+    def _try_coerce_result(self, result):\n+        \"\"\" reverse of try_coerce_args / try_operate \"\"\"\n+        if isinstance(result, np.ndarray):\n+            mask = isna(result)\n+            if result.dtype.kind in ['i', 'f', 'O']:\n+                result = result.astype('m8[ns]')\n+            result[mask] = tslibs.iNaT\n+        elif isinstance(result, (np.integer, np.float)):\n+            result = self._box_func(result)\n+        return result\n+\n+    def should_store(self, value):\n+        return issubclass(value.dtype.type, np.timedelta64)\n+\n+    def to_native_types(self, slicer=None, na_rep=None, quoting=None,\n+                        **kwargs):\n+        \"\"\" convert to our native types format, slicing if desired \"\"\"\n+\n+        values = self.values\n+        if slicer is not None:\n+            values = values[:, slicer]\n+        mask = isna(values)\n+\n+        rvalues = np.empty(values.shape, dtype=object)\n+        if na_rep is None:\n+            na_rep = 'NaT'\n+        rvalues[mask] = na_rep\n+        imask = (~mask).ravel()\n+\n+        # FIXME:\n+        # should use the formats.format.Timedelta64Formatter here\n+        # to figure what format to pass to the Timedelta\n+        # e.g. to not show the decimals say\n+        rvalues.flat[imask] = np.array([Timedelta(val)._repr_base(format='all')\n+                                        for val in values.ravel()[imask]],\n+                                       dtype=object)\n+        return rvalues\n+\n+\n+class BoolBlock(NumericBlock):\n+    __slots__ = ()\n+    is_bool = True\n+    _can_hold_na = False\n+\n+    def _can_hold_element(self, element):\n+        tipo = maybe_infer_dtype_type(element)\n+        if tipo is not None:\n+            return issubclass(tipo.type, np.bool_)\n+        return isinstance(element, (bool, np.bool_))\n+\n+    def should_store(self, value):\n+        return issubclass(value.dtype.type, np.bool_)\n+\n+    def replace(self, to_replace, value, inplace=False, filter=None,\n+                regex=False, convert=True, mgr=None):\n+        inplace = validate_bool_kwarg(inplace, 'inplace')\n+        to_replace_values = np.atleast_1d(to_replace)\n+        if not np.can_cast(to_replace_values, bool):\n+            return self\n+        return super(BoolBlock, self).replace(to_replace, value,\n+                                              inplace=inplace, filter=filter,\n+                                              regex=regex, convert=convert,\n+                                              mgr=mgr)\n+\n+\n+class ObjectBlock(Block):\n+    __slots__ = ()\n+    is_object = True\n+    _can_hold_na = True\n+\n+    def __init__(self, values, placement=None, ndim=2):\n+        if issubclass(values.dtype.type, compat.string_types):\n+            values = np.array(values, dtype=object)\n+\n+        super(ObjectBlock, self).__init__(values, ndim=ndim,\n+                                          placement=placement)\n+\n+    @property\n+    def is_bool(self):\n+        \"\"\" we can be a bool if we have only bool values but are of type\n+        object\n+        \"\"\"\n+        return lib.is_bool_array(self.values.ravel())\n+\n+    # TODO: Refactor when convert_objects is removed since there will be 1 path\n+    def convert(self, *args, **kwargs):\n+        \"\"\" attempt to coerce any object types to better types return a copy of\n+        the block (if copy = True) by definition we ARE an ObjectBlock!!!!!\n+\n+        can return multiple blocks!\n+        \"\"\"\n+\n+        if args:\n+            raise NotImplementedError\n+        by_item = True if 'by_item' not in kwargs else kwargs['by_item']\n+\n+        new_inputs = ['coerce', 'datetime', 'numeric', 'timedelta']\n+        new_style = False\n+        for kw in new_inputs:\n+            new_style |= kw in kwargs\n+\n+        if new_style:\n+            fn = soft_convert_objects\n+            fn_inputs = new_inputs\n+        else:\n+            fn = maybe_convert_objects\n+            fn_inputs = ['convert_dates', 'convert_numeric',\n+                         'convert_timedeltas']\n+        fn_inputs += ['copy']\n+\n+        fn_kwargs = {}\n+        for key in fn_inputs:\n+            if key in kwargs:\n+                fn_kwargs[key] = kwargs[key]\n+\n+        # operate column-by-column\n+        def f(m, v, i):\n+            shape = v.shape\n+            values = fn(v.ravel(), **fn_kwargs)\n+            try:\n+                values = values.reshape(shape)\n+                values = _block_shape(values, ndim=self.ndim)\n+            except (AttributeError, NotImplementedError):\n+                pass\n+\n+            return values\n+\n+        if by_item and not self._is_single_block:\n+            blocks = self.split_and_operate(None, f, False)\n+        else:\n+            values = f(None, self.values.ravel(), None)\n+            blocks = [make_block(values, ndim=self.ndim,\n+                                 placement=self.mgr_locs)]\n+\n+        return blocks\n+\n+    def set(self, locs, values, check=False):\n+        \"\"\"\n+        Modify Block in-place with new item value\n+\n+        Returns\n+        -------\n+        None\n+        \"\"\"\n+\n+        # GH6026\n+        if check:\n+            try:\n+                if (self.values[locs] == values).all():\n+                    return\n+            except:\n+                pass\n+        try:\n+            self.values[locs] = values\n+        except (ValueError):\n+\n+            # broadcasting error\n+            # see GH6171\n+            new_shape = list(values.shape)\n+            new_shape[0] = len(self.items)\n+            self.values = np.empty(tuple(new_shape), dtype=self.dtype)\n+            self.values.fill(np.nan)\n+            self.values[locs] = values\n+\n+    def _maybe_downcast(self, blocks, downcast=None):\n+\n+        if downcast is not None:\n+            return blocks\n+\n+        # split and convert the blocks\n+        return _extend_blocks([b.convert(datetime=True, numeric=False)\n+                               for b in blocks])\n+\n+    def _can_hold_element(self, element):\n+        return True\n+\n+    def _try_coerce_args(self, values, other):\n+        \"\"\" provide coercion to our input arguments \"\"\"\n+\n+        if isinstance(other, ABCDatetimeIndex):\n+            # to store DatetimeTZBlock as object\n+            other = other.astype(object).values\n+\n+        return values, False, other, False\n+\n+    def should_store(self, value):\n+        return not (issubclass(value.dtype.type,\n+                               (np.integer, np.floating, np.complexfloating,\n+                                np.datetime64, np.bool_)) or\n+                    # TODO(ExtensionArray): remove is_extension_type\n+                    # when all extension arrays have been ported.\n+                    is_extension_type(value) or\n+                    is_extension_array_dtype(value))\n+\n+    def replace(self, to_replace, value, inplace=False, filter=None,\n+                regex=False, convert=True, mgr=None):\n+        to_rep_is_list = is_list_like(to_replace)\n+        value_is_list = is_list_like(value)\n+        both_lists = to_rep_is_list and value_is_list\n+        either_list = to_rep_is_list or value_is_list\n+\n+        result_blocks = []\n+        blocks = [self]\n+\n+        if not either_list and is_re(to_replace):\n+            return self._replace_single(to_replace, value, inplace=inplace,\n+                                        filter=filter, regex=True,\n+                                        convert=convert, mgr=mgr)\n+        elif not (either_list or regex):\n+            return super(ObjectBlock, self).replace(to_replace, value,\n+                                                    inplace=inplace,\n+                                                    filter=filter, regex=regex,\n+                                                    convert=convert, mgr=mgr)\n+        elif both_lists:\n+            for to_rep, v in zip(to_replace, value):\n+                result_blocks = []\n+                for b in blocks:\n+                    result = b._replace_single(to_rep, v, inplace=inplace,\n+                                               filter=filter, regex=regex,\n+                                               convert=convert, mgr=mgr)\n+                    result_blocks = _extend_blocks(result, result_blocks)\n+                blocks = result_blocks\n+            return result_blocks\n+\n+        elif to_rep_is_list and regex:\n+            for to_rep in to_replace:\n+                result_blocks = []\n+                for b in blocks:\n+                    result = b._replace_single(to_rep, value, inplace=inplace,\n+                                               filter=filter, regex=regex,\n+                                               convert=convert, mgr=mgr)\n+                    result_blocks = _extend_blocks(result, result_blocks)\n+                blocks = result_blocks\n+            return result_blocks\n+\n+        return self._replace_single(to_replace, value, inplace=inplace,\n+                                    filter=filter, convert=convert,\n+                                    regex=regex, mgr=mgr)\n+\n+    def _replace_single(self, to_replace, value, inplace=False, filter=None,\n+                        regex=False, convert=True, mgr=None):\n+\n+        inplace = validate_bool_kwarg(inplace, 'inplace')\n+\n+        # to_replace is regex compilable\n+        to_rep_re = regex and is_re_compilable(to_replace)\n+\n+        # regex is regex compilable\n+        regex_re = is_re_compilable(regex)\n+\n+        # only one will survive\n+        if to_rep_re and regex_re:\n+            raise AssertionError('only one of to_replace and regex can be '\n+                                 'regex compilable')\n+\n+        # if regex was passed as something that can be a regex (rather than a\n+        # boolean)\n+        if regex_re:\n+            to_replace = regex\n+\n+        regex = regex_re or to_rep_re\n+\n+        # try to get the pattern attribute (compiled re) or it's a string\n+        try:\n+            pattern = to_replace.pattern\n+        except AttributeError:\n+            pattern = to_replace\n+\n+        # if the pattern is not empty and to_replace is either a string or a\n+        # regex\n+        if regex and pattern:\n+            rx = re.compile(to_replace)\n+        else:\n+            # if the thing to replace is not a string or compiled regex call\n+            # the superclass method -> to_replace is some kind of object\n+            return super(ObjectBlock, self).replace(to_replace, value,\n+                                                    inplace=inplace,\n+                                                    filter=filter, regex=regex,\n+                                                    mgr=mgr)\n+\n+        new_values = self.values if inplace else self.values.copy()\n+\n+        # deal with replacing values with objects (strings) that match but\n+        # whose replacement is not a string (numeric, nan, object)\n+        if isna(value) or not isinstance(value, compat.string_types):\n+\n+            def re_replacer(s):\n+                try:\n+                    return value if rx.search(s) is not None else s\n+                except TypeError:\n+                    return s\n+        else:\n+            # value is guaranteed to be a string here, s can be either a string\n+            # or null if it's null it gets returned\n+            def re_replacer(s):\n+                try:\n+                    return rx.sub(value, s)\n+                except TypeError:\n+                    return s\n+\n+        f = np.vectorize(re_replacer, otypes=[self.dtype])\n+\n+        if filter is None:\n+            filt = slice(None)\n+        else:\n+            filt = self.mgr_locs.isin(filter).nonzero()[0]\n+\n+        new_values[filt] = f(new_values[filt])\n+\n+        # convert\n+        block = self.make_block(new_values)\n+        if convert:\n+            block = block.convert(by_item=True, numeric=False)\n+\n+        return block\n+\n+\n+class CategoricalBlock(ExtensionBlock):\n+    __slots__ = ()\n+    is_categorical = True\n+    _verify_integrity = True\n+    _can_hold_na = True\n+    _concatenator = staticmethod(_concat._concat_categorical)\n+\n+    def __init__(self, values, placement, ndim=None):\n+        from pandas.core.arrays.categorical import _maybe_to_categorical\n+\n+        # coerce to categorical if we can\n+        super(CategoricalBlock, self).__init__(_maybe_to_categorical(values),\n+                                               placement=placement,\n+                                               ndim=ndim)\n+\n+    @property\n+    def _holder(self):\n+        return Categorical\n+\n+    @property\n+    def array_dtype(self):\n+        \"\"\" the dtype to return if I want to construct this block as an\n+        array\n+        \"\"\"\n+        return np.object_\n+\n+    def _try_coerce_result(self, result):\n+        \"\"\" reverse of try_coerce_args \"\"\"\n+\n+        # GH12564: CategoricalBlock is 1-dim only\n+        # while returned results could be any dim\n+        if ((not is_categorical_dtype(result)) and\n+                isinstance(result, np.ndarray)):\n+            result = _block_shape(result, ndim=self.ndim)\n+\n+        return result\n+\n+    def shift(self, periods, axis=0, mgr=None):\n+        return self.make_block_same_class(values=self.values.shift(periods),\n+                                          placement=self.mgr_locs)\n+\n+    def to_dense(self):\n+        # Categorical.get_values returns a DatetimeIndex for datetime\n+        # categories, so we can't simply use `np.asarray(self.values)` like\n+        # other types.\n+        return self.values.get_values()\n+\n+    def to_native_types(self, slicer=None, na_rep='', quoting=None, **kwargs):\n+        \"\"\" convert to our native types format, slicing if desired \"\"\"\n+\n+        values = self.values\n+        if slicer is not None:\n+            # Categorical is always one dimension\n+            values = values[slicer]\n+        mask = isna(values)\n+        values = np.array(values, dtype='object')\n+        values[mask] = na_rep\n+\n+        # we are expected to return a 2-d ndarray\n+        return values.reshape(1, len(values))\n+\n+    def concat_same_type(self, to_concat, placement=None):\n+        \"\"\"\n+        Concatenate list of single blocks of the same type.\n+\n+        Note that this CategoricalBlock._concat_same_type *may* not\n+        return a CategoricalBlock. When the categories in `to_concat`\n+        differ, this will return an object ndarray.\n+\n+        If / when we decide we don't like that behavior:\n+\n+        1. Change Categorical._concat_same_type to use union_categoricals\n+        2. Delete this method.\n+        \"\"\"\n+        values = self._concatenator([blk.values for blk in to_concat],\n+                                    axis=self.ndim - 1)\n+        # not using self.make_block_same_class as values can be object dtype\n+        return make_block(\n+            values, placement=placement or slice(0, len(values), 1),\n+            ndim=self.ndim)\n+\n+\n+class DatetimeBlock(DatetimeLikeBlockMixin, Block):\n+    __slots__ = ()\n+    is_datetime = True\n+    _can_hold_na = True\n+\n+    def __init__(self, values, placement, ndim=None):\n+        values = self._maybe_coerce_values(values)\n+        super(DatetimeBlock, self).__init__(values,\n+                                            placement=placement, ndim=ndim)\n+\n+    def _maybe_coerce_values(self, values):\n+        \"\"\"Input validation for values passed to __init__. Ensure that\n+        we have datetime64ns, coercing if necessary.\n+\n+        Parameters\n+        ----------\n+        values : array-like\n+            Must be convertible to datetime64\n+\n+        Returns\n+        -------\n+        values : ndarray[datetime64ns]\n+\n+        Overridden by DatetimeTZBlock.\n+        \"\"\"\n+        if values.dtype != _NS_DTYPE:\n+            values = conversion.ensure_datetime64ns(values)\n+        return values\n+\n+    def _astype(self, dtype, mgr=None, **kwargs):\n+        \"\"\"\n+        these automatically copy, so copy=True has no effect\n+        raise on an except if raise == True\n+        \"\"\"\n+\n+        # if we are passed a datetime64[ns, tz]\n+        if is_datetime64tz_dtype(dtype):\n+            dtype = DatetimeTZDtype(dtype)\n+\n+            values = self.values\n+            if getattr(values, 'tz', None) is None:\n+                values = DatetimeIndex(values).tz_localize('UTC')\n+            values = values.tz_convert(dtype.tz)\n+            return self.make_block(values)\n+\n+        # delegate\n+        return super(DatetimeBlock, self)._astype(dtype=dtype, **kwargs)\n+\n+    def _can_hold_element(self, element):\n+        tipo = maybe_infer_dtype_type(element)\n+        if tipo is not None:\n+            # TODO: this still uses asarray, instead of dtype.type\n+            element = np.array(element)\n+            return element.dtype == _NS_DTYPE or element.dtype == np.int64\n+        return (is_integer(element) or isinstance(element, datetime) or\n+                isna(element))\n+\n+    def _try_coerce_args(self, values, other):\n+        \"\"\"\n+        Coerce values and other to dtype 'i8'. NaN and NaT convert to\n+        the smallest i8, and will correctly round-trip to NaT if converted\n+        back in _try_coerce_result. values is always ndarray-like, other\n+        may not be\n+\n+        Parameters\n+        ----------\n+        values : ndarray-like\n+        other : ndarray-like or scalar\n+\n+        Returns\n+        -------\n+        base-type values, values mask, base-type other, other mask\n+        \"\"\"\n+\n+        values_mask = isna(values)\n+        values = values.view('i8')\n+        other_mask = False\n+\n+        if isinstance(other, bool):\n+            raise TypeError\n+        elif is_null_datelike_scalar(other):\n+            other = tslibs.iNaT\n+            other_mask = True\n+        elif isinstance(other, (datetime, np.datetime64, date)):\n+            other = self._box_func(other)\n+            if getattr(other, 'tz') is not None:\n+                raise TypeError(\"cannot coerce a Timestamp with a tz on a \"\n+                                \"naive Block\")\n+            other_mask = isna(other)\n+            other = other.asm8.view('i8')\n+        elif hasattr(other, 'dtype') and is_datetime64_dtype(other):\n+            other_mask = isna(other)\n+            other = other.astype('i8', copy=False).view('i8')\n+        else:\n+            # coercion issues\n+            # let higher levels handle\n+            raise TypeError\n+\n+        return values, values_mask, other, other_mask\n+\n+    def _try_coerce_result(self, result):\n+        \"\"\" reverse of try_coerce_args \"\"\"\n+        if isinstance(result, np.ndarray):\n+            if result.dtype.kind in ['i', 'f', 'O']:\n+                try:\n+                    result = result.astype('M8[ns]')\n+                except ValueError:\n+                    pass\n+        elif isinstance(result, (np.integer, np.float, np.datetime64)):\n+            result = self._box_func(result)\n+        return result\n+\n+    @property\n+    def _box_func(self):\n+        return tslibs.Timestamp\n+\n+    def to_native_types(self, slicer=None, na_rep=None, date_format=None,\n+                        quoting=None, **kwargs):\n+        \"\"\" convert to our native types format, slicing if desired \"\"\"\n+\n+        values = self.values\n+        if slicer is not None:\n+            values = values[..., slicer]\n+\n+        from pandas.io.formats.format import _get_format_datetime64_from_values\n+        format = _get_format_datetime64_from_values(values, date_format)\n+\n+        result = tslib.format_array_from_datetime(\n+            values.view('i8').ravel(), tz=getattr(self.values, 'tz', None),\n+            format=format, na_rep=na_rep).reshape(values.shape)\n+        return np.atleast_2d(result)\n+\n+    def should_store(self, value):\n+        return (issubclass(value.dtype.type, np.datetime64) and\n+                not is_datetimetz(value))\n+\n+    def set(self, locs, values, check=False):\n+        \"\"\"\n+        Modify Block in-place with new item value\n+\n+        Returns\n+        -------\n+        None\n+        \"\"\"\n+        if values.dtype != _NS_DTYPE:\n+            # Workaround for numpy 1.6 bug\n+            values = conversion.ensure_datetime64ns(values)\n+\n+        self.values[locs] = values\n+\n+\n+class DatetimeTZBlock(NonConsolidatableMixIn, DatetimeBlock):\n+    \"\"\" implement a datetime64 block with a tz attribute \"\"\"\n+    __slots__ = ()\n+    _concatenator = staticmethod(_concat._concat_datetime)\n+    is_datetimetz = True\n+\n+    def __init__(self, values, placement, ndim=2, dtype=None):\n+        # XXX: This will end up calling _maybe_coerce_values twice\n+        # when dtype is not None. It's relatively cheap (just an isinstance)\n+        # but it'd nice to avoid.\n+        #\n+        # If we can remove dtype from __init__, and push that conversion\n+        # push onto the callers, then we can remove this entire __init__\n+        # and just use DatetimeBlock's.\n+        if dtype is not None:\n+            values = self._maybe_coerce_values(values, dtype=dtype)\n+        super(DatetimeTZBlock, self).__init__(values, placement=placement,\n+                                              ndim=ndim)\n+\n+    def _maybe_coerce_values(self, values, dtype=None):\n+        \"\"\"Input validation for values passed to __init__. Ensure that\n+        we have datetime64TZ, coercing if necessary.\n+\n+        Parametetrs\n+        -----------\n+        values : array-like\n+            Must be convertible to datetime64\n+        dtype : string or DatetimeTZDtype, optional\n+            Does a shallow copy to this tz\n+\n+        Returns\n+        -------\n+        values : ndarray[datetime64ns]\n+        \"\"\"\n+        if not isinstance(values, self._holder):\n+            values = self._holder(values)\n+\n+        if dtype is not None:\n+            if isinstance(dtype, compat.string_types):\n+                dtype = DatetimeTZDtype.construct_from_string(dtype)\n+            values = values._shallow_copy(tz=dtype.tz)\n+\n+        if values.tz is None:\n+            raise ValueError(\"cannot create a DatetimeTZBlock without a tz\")\n+\n+        return values\n+\n+    @property\n+    def is_view(self):\n+        \"\"\" return a boolean if I am possibly a view \"\"\"\n+        # check the ndarray values of the DatetimeIndex values\n+        return self.values.values.base is not None\n+\n+    def copy(self, deep=True, mgr=None):\n+        \"\"\" copy constructor \"\"\"\n+        values = self.values\n+        if deep:\n+            values = values.copy(deep=True)\n+        return self.make_block_same_class(values)\n+\n+    def external_values(self):\n+        \"\"\" we internally represent the data as a DatetimeIndex, but for\n+        external compat with ndarray, export as a ndarray of Timestamps\n+        \"\"\"\n+        return self.values.astype('datetime64[ns]').values\n+\n+    def get_values(self, dtype=None):\n+        # return object dtype as Timestamps with the zones\n+        if is_object_dtype(dtype):\n+            return lib.map_infer(\n+                self.values.ravel(), self._box_func).reshape(self.values.shape)\n+        return self.values\n+\n+    def _slice(self, slicer):\n+        \"\"\" return a slice of my values \"\"\"\n+        if isinstance(slicer, tuple):\n+            col, loc = slicer\n+            if not com.is_null_slice(col) and col != 0:\n+                raise IndexError(\"{0} only contains one item\".format(self))\n+            return self.values[loc]\n+        return self.values[slicer]\n+\n+    def _try_coerce_args(self, values, other):\n+        \"\"\"\n+        localize and return i8 for the values\n+\n+        Parameters\n+        ----------\n+        values : ndarray-like\n+        other : ndarray-like or scalar\n+\n+        Returns\n+        -------\n+        base-type values, values mask, base-type other, other mask\n+        \"\"\"\n+        values_mask = _block_shape(isna(values), ndim=self.ndim)\n+        # asi8 is a view, needs copy\n+        values = _block_shape(values.asi8, ndim=self.ndim)\n+        other_mask = False\n+\n+        if isinstance(other, ABCSeries):\n+            other = self._holder(other)\n+            other_mask = isna(other)\n+\n+        if isinstance(other, bool):\n+            raise TypeError\n+        elif (is_null_datelike_scalar(other) or\n+              (lib.is_scalar(other) and isna(other))):\n+            other = tslibs.iNaT\n+            other_mask = True\n+        elif isinstance(other, self._holder):\n+            if other.tz != self.values.tz:\n+                raise ValueError(\"incompatible or non tz-aware value\")\n+            other_mask = _block_shape(isna(other), ndim=self.ndim)\n+            other = _block_shape(other.asi8, ndim=self.ndim)\n+        elif isinstance(other, (np.datetime64, datetime, date)):\n+            other = tslibs.Timestamp(other)\n+            tz = getattr(other, 'tz', None)\n+\n+            # test we can have an equal time zone\n+            if tz is None or str(tz) != str(self.values.tz):\n+                raise ValueError(\"incompatible or non tz-aware value\")\n+            other_mask = isna(other)\n+            other = other.value\n+        else:\n+            raise TypeError\n+\n+        return values, values_mask, other, other_mask\n+\n+    def _try_coerce_result(self, result):\n+        \"\"\" reverse of try_coerce_args \"\"\"\n+        if isinstance(result, np.ndarray):\n+            if result.dtype.kind in ['i', 'f', 'O']:\n+                result = result.astype('M8[ns]')\n+        elif isinstance(result, (np.integer, np.float, np.datetime64)):\n+            result = tslibs.Timestamp(result, tz=self.values.tz)\n+        if isinstance(result, np.ndarray):\n+            # allow passing of > 1dim if its trivial\n+            if result.ndim > 1:\n+                result = result.reshape(np.prod(result.shape))\n+            result = self.values._shallow_copy(result)\n+\n+        return result\n+\n+    @property\n+    def _box_func(self):\n+        return lambda x: tslibs.Timestamp(x, tz=self.dtype.tz)\n+\n+    def shift(self, periods, axis=0, mgr=None):\n+        \"\"\" shift the block by periods \"\"\"\n+\n+        # think about moving this to the DatetimeIndex. This is a non-freq\n+        # (number of periods) shift ###\n+\n+        N = len(self)\n+        indexer = np.zeros(N, dtype=int)\n+        if periods > 0:\n+            indexer[periods:] = np.arange(N - periods)\n+        else:\n+            indexer[:periods] = np.arange(-periods, N)\n+\n+        new_values = self.values.asi8.take(indexer)\n+\n+        if periods > 0:\n+            new_values[:periods] = tslibs.iNaT\n+        else:\n+            new_values[periods:] = tslibs.iNaT\n+\n+        new_values = self.values._shallow_copy(new_values)\n+        return [self.make_block_same_class(new_values,\n+                                           placement=self.mgr_locs)]\n+\n+    def diff(self, n, axis=0, mgr=None):\n+        \"\"\"1st discrete difference\n+\n+        Parameters\n+        ----------\n+        n : int, number of periods to diff\n+        axis : int, axis to diff upon. default 0\n+        mgr : default None\n+\n+        Return\n+        ------\n+        A list with a new TimeDeltaBlock.\n+\n+        Note\n+        ----\n+        The arguments here are mimicking shift so they are called correctly\n+        by apply.\n+        \"\"\"\n+        if axis == 0:\n+            # Cannot currently calculate diff across multiple blocks since this\n+            # function is invoked via apply\n+            raise NotImplementedError\n+        new_values = (self.values - self.shift(n, axis=axis)[0].values).asi8\n+\n+        # Reshape the new_values like how algos.diff does for timedelta data\n+        new_values = new_values.reshape(1, len(new_values))\n+        new_values = new_values.astype('timedelta64[ns]')\n+        return [TimeDeltaBlock(new_values, placement=self.mgr_locs.indexer)]\n+\n+    def concat_same_type(self, to_concat, placement=None):\n+        \"\"\"\n+        Concatenate list of single blocks of the same type.\n+        \"\"\"\n+        values = self._concatenator([blk.values for blk in to_concat],\n+                                    axis=self.ndim - 1)\n+        # not using self.make_block_same_class as values can be non-tz dtype\n+        return make_block(\n+            values, placement=placement or slice(0, len(values), 1))\n+\n+\n+class SparseBlock(NonConsolidatableMixIn, Block):\n+    \"\"\" implement as a list of sparse arrays of the same dtype \"\"\"\n+    __slots__ = ()\n+    is_sparse = True\n+    is_numeric = True\n+    _box_to_block_values = False\n+    _can_hold_na = True\n+    _ftype = 'sparse'\n+    _concatenator = staticmethod(_concat._concat_sparse)\n+\n+    def __init__(self, values, placement, ndim=None):\n+        # Ensure that we have the underlying SparseArray here...\n+        if isinstance(values, ABCSeries):\n+            values = values.values\n+        assert isinstance(values, SparseArray)\n+        super(SparseBlock, self).__init__(values, placement, ndim=ndim)\n+\n+    @property\n+    def _holder(self):\n+        return SparseArray\n+\n+    @property\n+    def shape(self):\n+        return (len(self.mgr_locs), self.sp_index.length)\n+\n+    @property\n+    def fill_value(self):\n+        # return np.nan\n+        return self.values.fill_value\n+\n+    @fill_value.setter\n+    def fill_value(self, v):\n+        self.values.fill_value = v\n+\n+    def to_dense(self):\n+        return self.values.to_dense().view()\n+\n+    @property\n+    def sp_values(self):\n+        return self.values.sp_values\n+\n+    @sp_values.setter\n+    def sp_values(self, v):\n+        # reset the sparse values\n+        self.values = SparseArray(v, sparse_index=self.sp_index,\n+                                  kind=self.kind, dtype=v.dtype,\n+                                  fill_value=self.values.fill_value,\n+                                  copy=False)\n+\n+    @property\n+    def sp_index(self):\n+        return self.values.sp_index\n+\n+    @property\n+    def kind(self):\n+        return self.values.kind\n+\n+    def _astype(self, dtype, copy=False, errors='raise', values=None,\n+                klass=None, mgr=None, **kwargs):\n+        if values is None:\n+            values = self.values\n+        values = values.astype(dtype, copy=copy)\n+        return self.make_block_same_class(values=values,\n+                                          placement=self.mgr_locs)\n+\n+    def __len__(self):\n+        try:\n+            return self.sp_index.length\n+        except:\n+            return 0\n+\n+    def copy(self, deep=True, mgr=None):\n+        return self.make_block_same_class(values=self.values,\n+                                          sparse_index=self.sp_index,\n+                                          kind=self.kind, copy=deep,\n+                                          placement=self.mgr_locs)\n+\n+    def make_block_same_class(self, values, placement, sparse_index=None,\n+                              kind=None, dtype=None, fill_value=None,\n+                              copy=False, ndim=None):\n+        \"\"\" return a new block \"\"\"\n+        if dtype is None:\n+            dtype = values.dtype\n+        if fill_value is None and not isinstance(values, SparseArray):\n+            fill_value = self.values.fill_value\n+\n+        # if not isinstance(values, SparseArray) and values.ndim != self.ndim:\n+        #     raise ValueError(\"ndim mismatch\")\n+\n+        if values.ndim == 2:\n+            nitems = values.shape[0]\n+\n+            if nitems == 0:\n+                # kludgy, but SparseBlocks cannot handle slices, where the\n+                # output is 0-item, so let's convert it to a dense block: it\n+                # won't take space since there's 0 items, plus it will preserve\n+                # the dtype.\n+                return self.make_block(np.empty(values.shape, dtype=dtype),\n+                                       placement)\n+            elif nitems > 1:\n+                raise ValueError(\"Only 1-item 2d sparse blocks are supported\")\n+            else:\n+                values = values.reshape(values.shape[1])\n+\n+        new_values = SparseArray(values, sparse_index=sparse_index,\n+                                 kind=kind or self.kind, dtype=dtype,\n+                                 fill_value=fill_value, copy=copy)\n+        return self.make_block(new_values,\n+                               placement=placement)\n+\n+    def interpolate(self, method='pad', axis=0, inplace=False, limit=None,\n+                    fill_value=None, **kwargs):\n+\n+        values = missing.interpolate_2d(self.values.to_dense(), method, axis,\n+                                        limit, fill_value)\n+        return self.make_block_same_class(values=values,\n+                                          placement=self.mgr_locs)\n+\n+    def fillna(self, value, limit=None, inplace=False, downcast=None,\n+               mgr=None):\n+        # we may need to upcast our fill to match our dtype\n+        if limit is not None:\n+            raise NotImplementedError(\"specifying a limit for 'fillna' has \"\n+                                      \"not been implemented yet\")\n+        values = self.values if inplace else self.values.copy()\n+        values = values.fillna(value, downcast=downcast)\n+        return [self.make_block_same_class(values=values,\n+                                           placement=self.mgr_locs)]\n+\n+    def shift(self, periods, axis=0, mgr=None):\n+        \"\"\" shift the block by periods \"\"\"\n+        N = len(self.values.T)\n+        indexer = np.zeros(N, dtype=int)\n+        if periods > 0:\n+            indexer[periods:] = np.arange(N - periods)\n+        else:\n+            indexer[:periods] = np.arange(-periods, N)\n+        new_values = self.values.to_dense().take(indexer)\n+        # convert integer to float if necessary. need to do a lot more than\n+        # that, handle boolean etc also\n+        new_values, fill_value = maybe_upcast(new_values)\n+        if periods > 0:\n+            new_values[:periods] = fill_value\n+        else:\n+            new_values[periods:] = fill_value\n+        return [self.make_block_same_class(new_values,\n+                                           placement=self.mgr_locs)]\n+\n+    def sparse_reindex(self, new_index):\n+        \"\"\" sparse reindex and return a new block\n+            current reindex only works for float64 dtype! \"\"\"\n+        values = self.values\n+        values = values.sp_index.to_int_index().reindex(\n+            values.sp_values.astype('float64'), values.fill_value, new_index)\n+        return self.make_block_same_class(values, sparse_index=new_index,\n+                                          placement=self.mgr_locs)\n+\n+\n+# -----------------------------------------------------------------\n+# Constructor Helpers\n+\n+def get_block_type(values, dtype=None):\n+    \"\"\"\n+    Find the appropriate Block subclass to use for the given values and dtype.\n+\n+    Parameters\n+    ----------\n+    values : ndarray-like\n+    dtype : numpy or pandas dtype\n+\n+    Returns\n+    -------\n+    cls : class, subclass of Block\n+    \"\"\"\n+    dtype = dtype or values.dtype\n+    vtype = dtype.type\n+\n+    if is_sparse(values):\n+        cls = SparseBlock\n+    elif issubclass(vtype, np.floating):\n+        cls = FloatBlock\n+    elif issubclass(vtype, np.timedelta64):\n+        assert issubclass(vtype, np.integer)\n+        cls = TimeDeltaBlock\n+    elif issubclass(vtype, np.complexfloating):\n+        cls = ComplexBlock\n+    elif is_categorical(values):\n+        cls = CategoricalBlock\n+    elif is_extension_array_dtype(values):\n+        cls = ExtensionBlock\n+    elif issubclass(vtype, np.datetime64):\n+        assert not is_datetimetz(values)\n+        cls = DatetimeBlock\n+    elif is_datetimetz(values):\n+        cls = DatetimeTZBlock\n+    elif issubclass(vtype, np.integer):\n+        cls = IntBlock\n+    elif dtype == np.bool_:\n+        cls = BoolBlock\n+    else:\n+        cls = ObjectBlock\n+    return cls\n+\n+\n+def make_block(values, placement, klass=None, ndim=None, dtype=None,\n+               fastpath=None):\n+    if fastpath is not None:\n+        # GH#19265 pyarrow is passing this\n+        warnings.warn(\"fastpath argument is deprecated, will be removed \"\n+                      \"in a future release.\", DeprecationWarning)\n+    if klass is None:\n+        dtype = dtype or values.dtype\n+        klass = get_block_type(values, dtype)\n+\n+    elif klass is DatetimeTZBlock and not is_datetimetz(values):\n+        return klass(values, ndim=ndim,\n+                     placement=placement, dtype=dtype)\n+\n+    return klass(values, ndim=ndim, placement=placement)\n+\n+\n+# -----------------------------------------------------------------\n+\n+def _extend_blocks(result, blocks=None):\n+    \"\"\" return a new extended blocks, givin the result \"\"\"\n+    from pandas.core.internals import BlockManager\n+    if blocks is None:\n+        blocks = []\n+    if isinstance(result, list):\n+        for r in result:\n+            if isinstance(r, list):\n+                blocks.extend(r)\n+            else:\n+                blocks.append(r)\n+    elif isinstance(result, BlockManager):\n+        blocks.extend(result.blocks)\n+    else:\n+        blocks.append(result)\n+    return blocks\n+\n+\n+def _block_shape(values, ndim=1, shape=None):\n+    \"\"\" guarantee the shape of the values to be at least 1 d \"\"\"\n+    if values.ndim < ndim:\n+        if shape is None:\n+            shape = values.shape\n+        values = values.reshape(tuple((1, ) + shape))\n+    return values\n+\n+\n+def _merge_blocks(blocks, dtype=None, _can_consolidate=True):\n+\n+    if len(blocks) == 1:\n+        return blocks[0]\n+\n+    if _can_consolidate:\n+\n+        if dtype is None:\n+            if len({b.dtype for b in blocks}) != 1:\n+                raise AssertionError(\"_merge_blocks are invalid!\")\n+            dtype = blocks[0].dtype\n+\n+        # FIXME: optimization potential in case all mgrs contain slices and\n+        # combination of those slices is a slice, too.\n+        new_mgr_locs = np.concatenate([b.mgr_locs.as_array for b in blocks])\n+        new_values = _vstack([b.values for b in blocks], dtype)\n+\n+        argsort = np.argsort(new_mgr_locs)\n+        new_values = new_values[argsort]\n+        new_mgr_locs = new_mgr_locs[argsort]\n+\n+        return make_block(new_values, placement=new_mgr_locs)\n+\n+    # no merge\n+    return blocks\n+\n+\n+def _vstack(to_stack, dtype):\n+\n+    # work around NumPy 1.6 bug\n+    if dtype == _NS_DTYPE or dtype == _TD_DTYPE:\n+        new_values = np.vstack([x.view('i8') for x in to_stack])\n+        return new_values.view(dtype)\n+\n+    else:\n+        return np.vstack(to_stack)\n+\n+\n+def _block2d_to_blocknd(values, placement, shape, labels, ref_items):\n+    \"\"\" pivot to the labels shape \"\"\"\n+    panel_shape = (len(placement),) + shape\n+\n+    # TODO: lexsort depth needs to be 2!!\n+\n+    # Create observation selection vector using major and minor\n+    # labels, for converting to panel format.\n+    selector = _factor_indexer(shape[1:], labels)\n+    mask = np.zeros(np.prod(shape), dtype=bool)\n+    mask.put(selector, True)\n+\n+    if mask.all():\n+        pvalues = np.empty(panel_shape, dtype=values.dtype)\n+    else:\n+        dtype, fill_value = maybe_promote(values.dtype)\n+        pvalues = np.empty(panel_shape, dtype=dtype)\n+        pvalues.fill(fill_value)\n+\n+    for i in range(len(placement)):\n+        pvalues[i].flat[mask] = values[:, i]\n+\n+    return make_block(pvalues, placement=placement)\n+\n+\n+def _safe_reshape(arr, new_shape):\n+    \"\"\"\n+    If possible, reshape `arr` to have shape `new_shape`,\n+    with a couple of exceptions (see gh-13012):\n+\n+    1) If `arr` is a ExtensionArray or Index, `arr` will be\n+       returned as is.\n+    2) If `arr` is a Series, the `_values` attribute will\n+       be reshaped and returned.\n+\n+    Parameters\n+    ----------\n+    arr : array-like, object to be reshaped\n+    new_shape : int or tuple of ints, the new shape\n+    \"\"\"\n+    if isinstance(arr, ABCSeries):\n+        arr = arr._values\n+    if not isinstance(arr, ABCExtensionArray):\n+        arr = arr.reshape(new_shape)\n+    return arr\n+\n+\n+def _factor_indexer(shape, labels):\n+    \"\"\"\n+    given a tuple of shape and a list of Categorical labels, return the\n+    expanded label indexer\n+    \"\"\"\n+    mult = np.array(shape)[::-1].cumprod()[::-1]\n+    return ensure_platform_int(\n+        np.sum(np.array(labels).T * np.append(mult, [1]), axis=1).T)\n+\n+\n+def _putmask_smart(v, m, n):\n+    \"\"\"\n+    Return a new ndarray, try to preserve dtype if possible.\n+\n+    Parameters\n+    ----------\n+    v : `values`, updated in-place (array like)\n+    m : `mask`, applies to both sides (array like)\n+    n : `new values` either scalar or an array like aligned with `values`\n+\n+    Returns\n+    -------\n+    values : ndarray with updated values\n+        this *may* be a copy of the original\n+\n+    See Also\n+    --------\n+    ndarray.putmask\n+    \"\"\"\n+\n+    # we cannot use np.asarray() here as we cannot have conversions\n+    # that numpy does when numeric are mixed with strings\n+\n+    # n should be the length of the mask or a scalar here\n+    if not is_list_like(n):\n+        n = np.repeat(n, len(m))\n+    elif isinstance(n, np.ndarray) and n.ndim == 0:  # numpy scalar\n+        n = np.repeat(np.array(n, ndmin=1), len(m))\n+\n+    # see if we are only masking values that if putted\n+    # will work in the current dtype\n+    try:\n+        nn = n[m]\n+\n+        # make sure that we have a nullable type\n+        # if we have nulls\n+        if not _isna_compat(v, nn[0]):\n+            raise ValueError\n+\n+        # we ignore ComplexWarning here\n+        with warnings.catch_warnings(record=True):\n+            nn_at = nn.astype(v.dtype)\n+\n+        # avoid invalid dtype comparisons\n+        # between numbers & strings\n+\n+        # only compare integers/floats\n+        # don't compare integers to datetimelikes\n+        if (not is_numeric_v_string_like(nn, nn_at) and\n+            (is_float_dtype(nn.dtype) or\n+             is_integer_dtype(nn.dtype) and\n+             is_float_dtype(nn_at.dtype) or\n+             is_integer_dtype(nn_at.dtype))):\n+\n+            comp = (nn == nn_at)\n+            if is_list_like(comp) and comp.all():\n+                nv = v.copy()\n+                nv[m] = nn_at\n+                return nv\n+    except (ValueError, IndexError, TypeError):\n+        pass\n+\n+    n = np.asarray(n)\n+\n+    def _putmask_preserve(nv, n):\n+        try:\n+            nv[m] = n[m]\n+        except (IndexError, ValueError):\n+            nv[m] = n\n+        return nv\n+\n+    # preserves dtype if possible\n+    if v.dtype.kind == n.dtype.kind:\n+        return _putmask_preserve(v, n)\n+\n+    # change the dtype if needed\n+    dtype, _ = maybe_promote(n.dtype)\n+\n+    if is_extension_type(v.dtype) and is_object_dtype(dtype):\n+        v = v.get_values(dtype)\n+    else:\n+        v = v.astype(dtype)\n+\n+    return _putmask_preserve(v, n)\n",
      "files_name_in_blame_commit": [
        "test_external_block.py",
        "__init__.py",
        "blocks.py"
      ]
    }
  },
  "commits_modify_file_before_fix": {
    "size": 854
  },
  "recursive_blame_commits": {}
}