{
  "id": "38",
  "blame_commit": {
    "commit": {
      "commit_id": "588b558cfa6b57c23e81202046b9f4add0e9e4f0",
      "commit_message": "REF: DatetimeLikeArray (#24024)",
      "commit_author": "Tom Augspurger",
      "commit_date": "2019-01-02 13:20:34",
      "commit_parent": "8088fe0f3d6ee964b28b0895660d33b988ee215d"
    },
    "function": {
      "function_name": "__new__",
      "function_code_before": "def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n    return cls._from_sequence(values, dtype=dtype, copy=copy, freq=freq)",
      "function_code_after": "",
      "function_before_start_line": 162,
      "function_before_end_line": 163,
      "function_after_start_line": "",
      "function_after_end_line": "",
      "function_before_token_count": 38,
      "function_after_token_count": 0,
      "functions_name_modified_file": [
        "_to_m8",
        "astype",
        "total_seconds",
        "_simple_new",
        "_generate_regular_range",
        "__rfloordiv__",
        "sequence_to_td64ns",
        "__mul__",
        "__floordiv__",
        "_from_sequence",
        "__neg__",
        "_addsub_offset_array",
        "__divmod__",
        "ints_to_td64ns",
        "to_pytimedelta",
        "_add_datetimelike_scalar",
        "__abs__",
        "_maybe_clear_freq",
        "__rmod__",
        "objects_to_td64ns",
        "extract_values_freq",
        "_add_delta",
        "__rtruediv__",
        "__mod__",
        "_is_convertible_to_td",
        "dtype",
        "_box_func",
        "__array__",
        "__rdivmod__",
        "_field_accessor",
        "_unbox_scalar",
        "_scalar_from_string",
        "_format_native_types",
        "_td_array_cmp",
        "_validate_fill_value",
        "_formatter",
        "__init__",
        "_generate_range",
        "_add_offset",
        "_add_datetime_arraylike",
        "_check_compatible_with",
        "components",
        "__truediv__"
      ],
      "functions_name_all_files": [
        "set_defaultencoding",
        "test_equality",
        "Object_endTypeContext",
        "walk",
        "test_td64arr_mod_int",
        "_maybe_convert_timedelta",
        "identical",
        "select",
        "test_getitem_fancy_1d",
        "test_frame_add_tz_mismatch_converts_to_utc",
        "ordered",
        "test_ix_setitem_slice_dataframe",
        "_sub_period",
        "_box_func",
        "Object_iterBegin",
        "Dict_iterBegin",
        "_string_data_error",
        "_validate_join_method",
        "test_xs",
        "is_object_dtype",
        "test_scalar_assignment",
        "unit",
        "timedelta_range",
        "drop_duplicates",
        "test_append_empty_frame_to_series_with_dateutil_tz",
        "test_convert_objects",
        "test_constructor",
        "makeUIntIndex",
        "test_concat_exclude_none",
        "_update_inplace",
        "test_numpy_informed",
        "is_",
        "test_columns_dtypes",
        "_delegate_method",
        "size",
        "_putmask_smart",
        "test_set_reset",
        "split_and_operate",
        "storage_obj_type",
        "makeObjectSeries",
        "is_datetime64_dtype",
        "assert_class_equal",
        "find_common_type",
        "assert_block_equal",
        "is_datetime_or_timedelta_dtype",
        "nunique",
        "test_setitem_single_column_mixed_datetime",
        "List_iterGetName",
        "test_subclass",
        "NpyDateTimeScalarToJSON",
        "maybe_promote",
        "inferred_type",
        "_reindex_columns",
        "ravel",
        "test_td64arr_add_sub_float",
        "test_append_different_columns_types",
        "_eadata",
        "mgr_locs",
        "update_dtype",
        "validate_ordered",
        "NpyTypeToJSONType",
        "value_counts",
        "test_value_counts_unique_nunique_null",
        "_get_level_values",
        "test_to_excel_xlsxwriter",
        "should_store",
        "test_panel_index",
        "test_slice_floats",
        "sequence_to_dt64ns",
        "test_get_axis_number",
        "test_fancy_index_int_labels_exceptions",
        "test_filter",
        "test_compound",
        "mgr",
        "_time_shift",
        "makeMixedDataFrame",
        "na_cmp",
        "test_setitem_scalars_no_index",
        "_left_indexer",
        "from_scalars",
        "List_iterNext",
        "test_reindex_level",
        "storable",
        "test_mixin",
        "test_missing_unicode_key",
        "_join_non_unique",
        "is_dtype",
        "test_sem",
        "__divmod__",
        "test_boolean_indexing_mixed",
        "data_orientation",
        "test_construction",
        "check_output",
        "internal_values",
        "argmin",
        "make_test_panel",
        "test_reindex_multi",
        "nblocks",
        "test_non_unique_invalid",
        "repeat",
        "test_numpy_round",
        "to_records",
        "test_validate_ndim",
        "test_multiindex_blocks",
        "ensure_categorical",
        "_get_nearest_indexer",
        "update",
        "test_ix_multi_take_multiindex",
        "tz",
        "read_axes",
        "view",
        "List_iterGetValue",
        "__fspath__",
        "test_concatlike_datetimetz",
        "set_kind",
        "test_abs",
        "test_get_attr",
        "to_pytimedelta",
        "_get_unique_index",
        "to_feather",
        "test_set_value_resize",
        "default_index",
        "test_boolean_index_empty_corner",
        "test_unstack",
        "makeCategoricalIndex",
        "test_boolean_indexing",
        "test_frame_values_with_tz",
        "setitem",
        "__truediv__",
        "NpyDatetime64ToJSON",
        "_verify_integrity",
        "write_index",
        "test_td64arr_floordiv_int",
        "__instancecheck__",
        "test_concat_bug_3602",
        "empty",
        "test_construction_not_supported",
        "test_concat_categorical",
        "test_concat_inner_join_empty",
        "_join_multi",
        "_compare_other",
        "test_td64arr_add_td64_array",
        "__rmod__",
        "_resolution",
        "_add_delta",
        "_create_storer",
        "test_incorrect_dtype_raises",
        "merge",
        "NpyArr_freeItemValue",
        "test_append_different_columns",
        "_timezone",
        "test_copy",
        "test_setitem_fancy_mixed_2d",
        "test_concat_multiindex_with_none_in_index_names",
        "_add_offset",
        "maybe_cast_to_integer_array",
        "test_timedelta_ops_with_missing_values",
        "_is_convertible_to_index",
        "test_mean",
        "test_setitem_ndarray",
        "test_numpy_array",
        "read_index",
        "notnull",
        "flush",
        "test_to_panel_na_handling",
        "test_ctor_orderedDict",
        "test_repeat_preserves_tz",
        "test_constructor_resize",
        "ensure_clean_dir",
        "test_td64arr_sub_pi",
        "assert_almost_equal",
        "reset_testing_mode",
        "tz_localize",
        "test_td64arr_floordiv_tdscalar",
        "construct_from_string",
        "_ensure_encoding",
        "test_axis_dummies",
        "array_dtype",
        "is_categorical",
        "test_get_plane_axes",
        "Object_releaseObject",
        "_try_cast_result",
        "get_attr",
        "test_value_counts_bins",
        "is_interval",
        "month_name",
        "test_set",
        "test_hash",
        "_concat_categorical",
        "sortlevel",
        "raise_assert_detail",
        "dot",
        "_new_PeriodIndex",
        "test_select",
        "is_sorted",
        "test_tdi_sub_dt64_array",
        "test_set_change_dtype",
        "_from_sequence",
        "_addsub_offset_array",
        "is_timedelta64_dtype",
        "_add_numeric_methods",
        "to_dense",
        "test_zero_step_raises",
        "_maybe_clear_freq",
        "test_neg",
        "makePeriodSeries",
        "isiterable",
        "_check_view",
        "set_atom_datetime64",
        "Index_iterGetValue",
        "_coerce_scalar_to_index",
        "get_ftypes",
        "test_keys",
        "test_concat_series_axis1",
        "_evaluate_with_timedelta_like",
        "test_getitem_boolean_list",
        "end_time",
        "read_coordinates",
        "round_trip_pickle",
        "test_combine_add",
        "NpyArr_iterNextItem",
        "is_datelike_mixed_type",
        "dropna",
        "needs_filling",
        "astype_nansafe",
        "maybe_upcast",
        "test_setitem_invalidates_datetime_index_freq",
        "groups",
        "_setitem_array",
        "_get_converter",
        "test_fillna_preserves_tz",
        "test_get_none",
        "period_range",
        "swaplevel",
        "set_table",
        "test_transpose_copy",
        "test_iteritems",
        "test_td64arr_mul_numeric_scalar",
        "test_categorical_concat_gh7864",
        "generate",
        "nbytes",
        "test_is_bool_dtype",
        "__rtruediv__",
        "tolist",
        "test_getitem_empty_frame_with_boolean",
        "set_atom_data",
        "create_block",
        "test_categorical_concat_append",
        "_is_metadata_of",
        "melt",
        "test_concat_ignore_index",
        "test_concat_sorts_index",
        "__init__",
        "test_td64arr_div_td64_ndarray",
        "test_combine_series",
        "CDouble",
        "contains",
        "Iter_iterEnd",
        "tz_convert",
        "asfreq",
        "test_ix_align",
        "form_blocks",
        "test_add_series_with_extension_array",
        "sequence_to_td64ns",
        "set_names",
        "get_indexer_for",
        "test_setitem_callable",
        "_validate_index_level",
        "test_concat_datetime_timezone",
        "set_metadata",
        "test_td64arr_mul_int",
        "makeTimeSeries",
        "box_expected",
        "sort_with_none",
        "dt64arr_to_periodarr",
        "__sizeof__",
        "_check_expected_dtype",
        "make_data",
        "_box_item_values",
        "test_iterable_map",
        "maybe_infer_dtype_type",
        "df_full",
        "test_filter_row_groups",
        "coerce_to_target_dtype",
        "convert_rows_list_to_csv_str",
        "test_registry",
        "_summary",
        "test_cmp_dt64_arraylike_tznaive",
        "test_concat_no_unnecessary_upcast",
        "not_hashable",
        "test_constructor_empty_panel",
        "to_numpy",
        "test_concat_empty_series_timelike",
        "sort_index",
        "test_getitem_sparse_column",
        "PyFloatToDOUBLE",
        "set_atom_string",
        "_selection_list",
        "Series_iterBegin",
        "test_tdarr_div_length_mismatch",
        "assign",
        "data_for_grouping",
        "to_period",
        "from_array",
        "set_atom_datetime64tz",
        "_can_reindex",
        "_check_compatible_with",
        "test_fancy_setitem_int_labels",
        "max",
        "test_parser",
        "register",
        "test_alias_to_unit_bad_alias_raises",
        "test_none_comparison",
        "test_td64arr_with_offset_series",
        "from_records",
        "_replace_single",
        "test_frame_join_tzaware",
        "test_duplicated_drop_duplicates_index",
        "_finalize",
        "test_memory_usage",
        "PyTimeToJSON",
        "flags",
        "_set_names",
        "_filter_indexer_tolerance",
        "test_frame_from_records_utc",
        "_from_factorized",
        "col",
        "__copy__",
        "_concat_same_dtype",
        "test_set_minor_major",
        "test_update_from_dict",
        "total_seconds",
        "test_concat_series_partial_columns_names",
        "test_infer_from_tdi",
        "test_tdi_add_timestamp_nat_masking",
        "test_handle_empty_objects",
        "get_object",
        "freqstr",
        "create_index",
        "test_tricky_container",
        "ints_to_td64ns",
        "test_concat_mixed_objs",
        "test_set_dataframe_column_ns_dtype",
        "test_equals",
        "to_native_types",
        "test_constructor_error_msgs",
        "test_astype_no_copy",
        "add_nans",
        "_from_nested_dict",
        "_sanitize_column",
        "test_setitem_fancy_2d",
        "test_panel_concat_buglet",
        "test_astype",
        "write_data",
        "test_get",
        "test_td64arr_add_offset_index",
        "test_where_none",
        "notna",
        "_engine",
        "_make_skipna_wrapper",
        "_interpolate_with_fill",
        "maybe_convert_objects",
        "_generate_range",
        "test_append_dtype_coerce",
        "test_setitem_single_column_mixed",
        "_is_memory_usage_qualified",
        "_maybe_update_attributes",
        "__setstate__",
        "_sparse_blockify",
        "test_td64arr_mul_int_series",
        "test_concat_aligned_sort_does_not_raise",
        "_outer_indexer",
        "has_duplicates",
        "__rsub__",
        "test_setitem_boolean_mask",
        "test_getitem_fancy_labels",
        "_reindex_multi",
        "offset",
        "test_same_categories_different_order",
        "rename_axis",
        "_formatter_func",
        "validate",
        "_convert_can_do_setop",
        "write",
        "hasnans",
        "test_frame_align_aware",
        "test_identity",
        "nlevels",
        "init_ndarray",
        "is_open",
        "_parsed_string_to_bounds",
        "is_datetimelike_v_object",
        "test_delitem_corner",
        "to_stata",
        "test_concat_series_name_npscalar_tuple",
        "PdBlock_iterGetName_Transpose",
        "is_old_version",
        "_preprocess_slice_or_indexer",
        "test_update_raise_bad_parameter",
        "test_update_nooverwrite",
        "makeDateIndex",
        "_assert_take_fillable",
        "getitem_block",
        "test_td64arr_div_tdlike_scalar_with_nat",
        "_ixs",
        "groupby",
        "_get_counts",
        "test_from_sequence_dtype",
        "validate_and_set",
        "_maybe_utc_convert",
        "read",
        "write_array_empty",
        "_raise_on_incompatible",
        "test_iloc_row",
        "test_getitem_callable",
        "style",
        "maybe_downcast_to_dtype",
        "test_arith_series_with_array",
        "test_update",
        "test_frame_no_datetime64_dtype",
        "_reset_identity",
        "is_integer",
        "debug",
        "test_getattr",
        "__eq__",
        "_list_of_series_to_arrays",
        "randu_array",
        "_assert_can_do_setop",
        "get_dtype_counts",
        "__matmul__",
        "test_timedelta64_operations_with_timedeltas",
        "write_data_chunk",
        "test_write_index",
        "PdBlock_iterEnd",
        "_unpickle_matrix_compat",
        "_maybe_normalize_endpoints",
        "test_partition_on_supported",
        "reindex",
        "reduction",
        "test_concat_categorical_coercion_nan",
        "test_concat_aligned_sort",
        "makeFloatSeries",
        "test_categorical_concat_dtypes",
        "_join_compat",
        "test_construction_from_string",
        "test_median",
        "test_concat_NaT_dataframes",
        "test_construction_base_constructor",
        "get_duplicates",
        "test_iterable",
        "create_single_mgr",
        "query",
        "from_items",
        "test_write_column_multiindex",
        "test_pickle",
        "transpose",
        "replace",
        "test_td64arr_add_sub_tdi",
        "test_categorical_concat_preserve",
        "test_td64arr_sub_td64_array",
        "_left_indexer_unique",
        "test_unbounded_slice_raises",
        "network",
        "_validate_names",
        "reorder_arrays",
        "test_setitem_datetimelike_with_inference",
        "test_xs_duplicates",
        "assert_frame_equal",
        "union_categoricals",
        "floor",
        "test_dups_index",
        "test_concat_categorical_ordered",
        "test_to_panel_duplicates",
        "test_td64arr_add_timestamp",
        "test_constructor_iso",
        "map",
        "test_iat",
        "concatenate_join_units",
        "test_panel_dups",
        "validate_multiindex",
        "test_construction_generic",
        "is_floating",
        "test_copy_names",
        "test_getitem",
        "_constructor_sliced",
        "_convert_string_array",
        "stack",
        "eval",
        "Dir_iterBegin",
        "_validate_dt64_dtype",
        "test_factorize_repeated",
        "set_trace",
        "is_full",
        "unique",
        "test_concat_empty_series",
        "test_td64arr_floordiv_tdlike_scalar",
        "Index_iterNext",
        "test_reindex_axis_style",
        "test_as_array_datetime",
        "Dir_iterNext",
        "is_extension_array_dtype",
        "test_contains",
        "engine",
        "maybe_infer_freq",
        "take_nd",
        "Iter_iterGetValue",
        "set_object_info",
        "pandas_dtype",
        "test_timedelta64_ops_nat",
        "__bytes__",
        "_map_values",
        "to_html",
        "objects_to_td64ns",
        "ea_passthrough",
        "Iter_iterGetName",
        "get_indexer",
        "test_attrs",
        "check_error_on_write",
        "validate_endpoints",
        "test_addition_ops",
        "_get_level_number",
        "test_reindex_index",
        "test_constructor_dict_mixed",
        "_ensure_localized",
        "test_concat_multiindex_dfs_with_deepcopy",
        "test_blockplacement_add_int",
        "get_numeric_mat",
        "test_numpy_array_all_dtypes",
        "makeTimedeltaIndex",
        "test_is_extension_array_dtype",
        "_block2d_to_blocknd",
        "Dict_iterGetValue",
        "time",
        "_extend_blocks",
        "_get_dtype",
        "test_getitem_fancy_slice_integers_step",
        "test_concat_NaT_dataframes_all_NaT_axis_1",
        "test_options_auto",
        "timeit",
        "combine_concat_plans",
        "test_unsupported",
        "_get_reconciled_name_object",
        "test_categorical_categories",
        "_maybe_cast_slice_bound",
        "is_float_dtype",
        "_compare_or_regex_match",
        "iterrows",
        "write_multi_index",
        "is_datetimelike",
        "duplicated",
        "get_ftype_counts",
        "test_empty",
        "test_concatlike_datetimetz_to_object",
        "_is_monotonic_increasing",
        "PandasDateTimeStructToJSON",
        "_getitem_bool_array",
        "test_min_max",
        "_valid_locales",
        "to_panel",
        "test_concat_categoricalindex",
        "test_get_axis_name",
        "test_categorical_concat",
        "_is_strictly_monotonic_decreasing",
        "NpyArr_iterGetValue",
        "__neg__",
        "test_std",
        "_period_array_cmp",
        "test_loc_uint64",
        "test_is_dtype",
        "_time_to_micros",
        "test_interleave",
        "test_nested_exception",
        "_hash_categories",
        "PdBlock_iterGetName",
        "objects_to_datetime64ns",
        "get_result",
        "_get_dtype_type",
        "test_concat_order",
        "_field_accessor",
        "droplevel",
        "test_float64_ns_rounded",
        "append_to_multiple",
        "test_min",
        "randu",
        "check_round_trip",
        "to_frame",
        "makeRangeIndex",
        "symmetric_difference",
        "test_setitem_with_unaligned_tz_aware_datetime_column",
        "test_construction_errors",
        "test_compare_timedelta_series",
        "_convert_object_array",
        "_reindex_index",
        "itertuples",
        "test_categorical_equality",
        "cast_scalar_to_array",
        "create_block_manager_from_blocks",
        "_get_names",
        "read_metadata",
        "PyStringToUTF8",
        "Series_iterGetName",
        "__getattr__",
        "test_multiindex_xs",
        "round_trip_pathlib",
        "makeMissingDataframe",
        "Index_iterBegin",
        "test_concat_categorical_3elem_coercion",
        "_concat_sparse",
        "_consolidate",
        "_consolidate_check",
        "fp_lt_014",
        "infer_dtype_from_array",
        "test_options_fp",
        "_delegate_class",
        "_simple_blockify",
        "infer",
        "__getitem__",
        "getCols",
        "reset_cache",
        "test_duplicate_columns",
        "test_get_set_value_no_partial_indexing",
        "_holder",
        "maybe_convert_platform",
        "to_array",
        "read_multi_index",
        "Iter_iterNext",
        "test_setitem_always_copy",
        "test_setitem_frame",
        "data_missing_for_sorting",
        "get_attrs",
        "test_concat_series",
        "set_timezone",
        "_range_from_fields",
        "_filters",
        "_interleaved_dtype",
        "_is_unique",
        "_getitem_frame",
        "decompress_file",
        "as_array",
        "__str__",
        "test_where_bug_mixed",
        "getPeriodData",
        "Dict_iterGetName",
        "Object_getDoubleValue",
        "create_pandas_abc_type",
        "test_concat_NaT_series_dataframe_all_NaT",
        "_read_group",
        "test_reindex_frame_add_nat",
        "test_xs_corner",
        "test_non_array_raises",
        "_list_of_dict_to_arrays",
        "_get_loc_only_exact_matches",
        "init_dict",
        "NpyFloatToDOUBLE",
        "pandas_type",
        "get_atom_coltype",
        "test_get_slice",
        "idxmin",
        "test_non_monotonic_reindex_methods",
        "test_setitem_frame_align",
        "test_blockplacement_add",
        "test_frame_tz_localize",
        "is_categorical_dtype",
        "write_sparse_intindex",
        "__setattr__",
        "Series_iterNext",
        "strides",
        "test_concat_keys_and_levels",
        "test_concat_NaT_series",
        "_sub_datetimelike_scalar",
        "items_overlap_with_suffix",
        "test_tdi_cmp_str_invalid",
        "test_mask_callable",
        "test_update_deprecation",
        "test_append_many",
        "_slice",
        "_blknos",
        "test_concat_different_extension_dtypes_upcasts",
        "test_invalid_delegation",
        "test_concatlike_datetimetz_short",
        "__iter__",
        "List_iterBegin",
        "test_slice_to_array_conversion",
        "extract_values_freq",
        "test_ix_frame_align",
        "_repr_fits_vertical_",
        "test_frame_setitem_timestamp",
        "maybe_upcast_putmask",
        "_default_locale_getter",
        "_convert_listlike_indexer",
        "test_to_frame",
        "test_truncate_fillna_bug",
        "test_all_any_unhandled",
        "test_td64arr_mul_td64arr_raises",
        "test_hash_vs_equality",
        "test_tdi_add_dt64_array",
        "_can_hold_na",
        "test_where_bug_transposition",
        "test_to_frame_multi_major_minor",
        "assert_sp_series_equal",
        "test_append_different_columns_types_raises",
        "get_upcast_box",
        "__or__",
        "set_info",
        "select_as_multiple",
        "is_normalized",
        "_unconvert_index",
        "_add_logical_methods_disabled",
        "index_cols",
        "test_td64arr_pow_invalid",
        "test_setitem_ambig",
        "makeStringSeries",
        "_set_item",
        "PyDateTimeToJSON",
        "test_get_axis",
        "all_timeseries_index_generator",
        "is_lexsorted_for_tuple",
        "_convert_slice_indexer",
        "Tuple_iterBegin",
        "set_attrs",
        "makePeriodPanel",
        "test_update_dtype",
        "test_mask_inplace",
        "cdate_range",
        "test_invalid_raises",
        "test_td64arr_div_numeric_array",
        "_evaluate_compare",
        "dtype",
        "construction_error",
        "searchsorted",
        "test_take",
        "test_nan_invalid",
        "is_datetimetz",
        "_int64index",
        "test_merge",
        "set_atom_categorical",
        "test_concat_invalid_first_argument",
        "_sub_datetime_arraylike",
        "makeCustomIndex",
        "test_repr",
        "test_td64arr_add_offset_array",
        "assert_is_valid_plot_return_object",
        "assert_extension_array_equal",
        "open",
        "_box_values",
        "test_td64arr_rfloordiv_tdscalar_explicit",
        "_is_boolean",
        "_na_value",
        "test_setitem_with_unaligned_sparse_value",
        "take",
        "_is_strictly_monotonic_increasing",
        "assert_timedelta_array_equal",
        "assert_raises_regex",
        "df_compat",
        "createTypeContext",
        "test_concat_series_axis1_same_names_ignore_index",
        "axes",
        "get_slice",
        "_ensure_valid_index",
        "union",
        "_get_index_factory",
        "__invert__",
        "test_get_numeric_data",
        "is_categorical_astype",
        "get_numeric_data",
        "consolidate",
        "assert_index_equal",
        "test_categorical_index_preserver",
        "_try_coerce_result",
        "test_ix_multi_take_nonint_index",
        "Index_iterEnd",
        "corrwith",
        "_from_categorical_dtype",
        "test_concat_period_other_series",
        "test_to_sparse",
        "_safe_reshape",
        "test_alias_to_unit_raises",
        "is_bool_dtype",
        "test_td64arr_div_tdlike_scalar",
        "is_interval_dtype",
        "test_panel_np_all",
        "can_connect",
        "test_construction_from_string_errors",
        "all",
        "_mpl_repr",
        "make_empty",
        "ensure_int64_or_float64",
        "_to_m8",
        "test_truncate",
        "_gotitem",
        "set",
        "soft_convert_objects",
        "set_atom",
        "take_data",
        "test_transpose_non_default_axes",
        "lookup",
        "indexer_at_time",
        "remove",
        "argmax",
        "_check_isinstance",
        "_is_monotonic_decreasing",
        "_unpickle_frame_compat",
        "__and__",
        "test_loc_iterable",
        "is_unique",
        "test_append_preserve_index_name",
        "test_sparse_mixed",
        "test_equal_but_different",
        "test_to_frame_mixed",
        "_sub_datelike",
        "_shallow_copy_with_infer",
        "test_getitem_boolean",
        "get_value",
        "test_categorical",
        "test_getitem_boolean_casting",
        "validate_dtype_freq",
        "_aggregate_multiple_funcs",
        "test_verify_integrity_deprecated",
        "test_tz_setter_raises",
        "get_locales",
        "test_invalid_engine",
        "_is_empty_array",
        "is_object",
        "test_append_same_columns_type",
        "is_datetime64tz_dtype",
        "_allow_na_ops",
        "construct_1d_arraylike_from_scalar",
        "index_subclass_makers_generator",
        "test_concat_bug_2972",
        "test_value_counts_preserves_tz",
        "test_getitem_ix_boolean_duplicates_multiple",
        "test_value_counts_inferred",
        "to_flat_index",
        "_homogenize",
        "DataFrame_iterGetValue",
        "test_dtypes",
        "Dir_iterEnd",
        "test_searchsorted",
        "test_holder",
        "test_consolidate",
        "is_dtype_equal",
        "test_repr_empty",
        "_reindex_non_unique",
        "test_append_sorts",
        "test_arith",
        "_maybe_coerce_values",
        "makeStringIndex",
        "test_concat_tz_series_tzlocal",
        "_round",
        "getTimeSeriesData",
        "_td_array_cmp",
        "test_raise_when_not_implemented",
        "is_consolidated",
        "test_setitem_fancy_scalar",
        "is_integer_dtype",
        "_consolidate_inplace",
        "ftype",
        "isin",
        "NpyArr_freeLabels",
        "_aggregate",
        "test_getitem_setitem_ix_bool_keyerror",
        "test_td64arr_mul_too_short_raises",
        "maybe_cast_item",
        "timetz",
        "trim_join_unit",
        "is_period_arraylike",
        "test_td64arr_add_timedeltalike",
        "test_where_array_like",
        "_make_field_arrays",
        "test_setitem_datetime_coercion",
        "to_julian_date",
        "test_get_bool_data",
        "__mod__",
        "asobject",
        "test_from_frame_level1_unsorted",
        "set_testing_mode",
        "test_to_numpy_dtype",
        "makeBoolIndex",
        "__reduce__",
        "_add_nat",
        "exception_matches",
        "_from_datetime64",
        "test_concat_multiindex_rangeindex",
        "_concat_index_same_dtype",
        "write_array",
        "Object_invokeDefaultHandler",
        "test_where_datetime",
        "__isub__",
        "test_panel_concat_other_axes",
        "test_slicing_maintains_type",
        "test_getitem_setitem_fancy_exceptions",
        "cov",
        "__mul__",
        "combine_first",
        "test_getitem_ix_mixed_integer",
        "unstack",
        "_convert_tolerance",
        "test_apply_no_or_zero_ndim",
        "_selected_obj",
        "_is_cython_func",
        "validate_col",
        "asi8",
        "Object_getLongValue",
        "__abs__",
        "is_unsigned_integer_dtype",
        "mode",
        "test_other_type_raises",
        "_combine_match_index",
        "_check_timedeltalike_freq_compat",
        "test_binop_other",
        "_values_for_argsort",
        "test_conform",
        "_formatter",
        "difference",
        "test_set_value",
        "_set_foo",
        "test_block_shape",
        "makePeriodFrame",
        "applymap",
        "test_union_categorical_same_categories_different_order",
        "is_string_dtype",
        "test_td64arr_add_datetime64_nat",
        "_concatenate_2d",
        "select_dtypes",
        "_format_data",
        "test_concatlike_dtypes_coercion",
        "test_consolidate_ordering_issues",
        "validate_inferred_freq",
        "is_int64_dtype",
        "test_getitem_fancy_xs",
        "test_order_hashes_different",
        "_concat_datetime",
        "_reduce",
        "create_description",
        "assert_dict_equal",
        "iget",
        "_validate_frequency",
        "_setitem_slice",
        "validate_names",
        "test_td64_df_add_int_frame",
        "test_assignment",
        "test_arith_series_with_scalar",
        "_list_to_arrays",
        "_combine_match_columns",
        "use_numexpr",
        "test_basic",
        "test_to_string",
        "join",
        "test_as_array_int_bool",
        "test_multiindex_with_columns",
        "test_getitem_fancy_boolean",
        "test_crossed_dtypes_weird_corner",
        "write_metadata",
        "_convert_arr_indexer",
        "is_exists",
        "test_numpy_transpose",
        "format",
        "test_duplicate_ref_loc_failure",
        "_get_value",
        "df_cross_compat",
        "register_extension_dtype",
        "pivot_table",
        "validate_tz_from_dtype",
        "test_getitem_ix_float_duplicates",
        "test_str_vs_repr",
        "_repr_html_",
        "get_loc",
        "test_tz_dtype_mismatch_raises",
        "Dir_iterGetValue",
        "test_ndarray_compat_properties",
        "_block",
        "_delegate_property_set",
        "values_cols",
        "test_compression",
        "objToJSONFile",
        "test_to_numpy_copy",
        "_apply_meta",
        "process_axes",
        "to_timestamp",
        "test_make_block_same_class",
        "shape",
        "test_name_repr",
        "components",
        "test_concatlike_common_period_mixed_dt_to_object",
        "get_long_attr",
        "write_block_index",
        "test_concat_tz_frame",
        "read_sparse_intindex",
        "test_error_on_using_partition_cols_and_partition_on",
        "test_concat_keys_with_none",
        "test_array_multiindex_raises",
        "test_constructor_fails_with_not_3d_input",
        "construct_array_type",
        "indexer_between_time",
        "__floordiv__",
        "ensure_clean",
        "test_td64arr_mod_tdscalar",
        "test_concat_copy",
        "test_validate_bool_args",
        "Object_iterEnd",
        "test_reindex_methods_nearest_special",
        "test_from_pandas_array",
        "test_cumsum",
        "validate_attr",
        "test_concat_NaT_dataframes_all_NaT_axis_0",
        "test_frame_tz_convert",
        "_check_stat_op",
        "test_all_any",
        "objToJSON",
        "_join_monotonic",
        "pa",
        "test_ix_multi_take",
        "test_constructor_observe_dtype",
        "test_update_filtered",
        "__getstate__",
        "test_partition_cols_supported",
        "test_setitem_other_callable",
        "_invalid_indexer",
        "reset_index",
        "PyIntToINT64",
        "__nonzero__",
        "_check_ndim",
        "assert_datetime_array_equal",
        "test_concat_rename_index",
        "_repr_fits_horizontal_",
        "is_period",
        "_concat_index_asobject",
        "CLong",
        "_complevel",
        "_can_fast_union",
        "maybe_unwrap_index",
        "inferred_freq",
        "test_sort_values",
        "test_timedelta64_conversions",
        "is_datetime_arraylike",
        "needs_i8_conversion",
        "sanitize_array",
        "test_binary_ops_docs",
        "test_concat_sorts_columns",
        "_unstack",
        "test_to_excel",
        "__array__",
        "make_block",
        "_try_get_item",
        "_from_fastpath",
        "test_parallel",
        "test_iter_box",
        "ceil",
        "test_td64arr_sub_NaT",
        "NpyArr_iterGetName",
        "test_float64_unit_conversion",
        "test_iterable_items",
        "test_apply_slabs",
        "_box_values_as_index",
        "test_concat_bug_1719",
        "test_options_py",
        "test_mask",
        "_unconvert_index_legacy",
        "test_from_categorical_dtype_identity",
        "test_where_axis",
        "coerce_indexer_dtype",
        "test_sum",
        "test_concat_empty_and_non_empty_series_regression",
        "_add_datetimelike_scalar",
        "test_set_axis",
        "test_dt64tz_setitem_does_not_mutate_dti",
        "put",
        "_reindex_axis",
        "test_factorize",
        "test_reindex_cast",
        "get_attr_length",
        "NpyArr_iterEnd",
        "slice_locs",
        "queryables",
        "test_setitem_dtype",
        "test_where",
        "ndim",
        "delete",
        "test_ffill_bfill",
        "test_tdi_rmul_arraylike",
        "_is_unorderable_exception",
        "_stack_arrays",
        "set_atom_complex",
        "DataFrame_iterGetName",
        "_can_hold_element",
        "info",
        "_add_delta_tdi",
        "getMixedTypeDict",
        "equalContents",
        "assert_numpy_array_equal",
        "cvalues",
        "_constructor_expanddim",
        "test_getitem_setitem_boolean_misaligned",
        "initObjToJSON",
        "Object_iterNext",
        "_sub_period_array",
        "is_timedelta64_ns_dtype",
        "is_boolean",
        "array",
        "_attributes",
        "test_where_bug",
        "_add_numeric_methods_disabled",
        "test_getitem_list_duplicates",
        "set_index",
        "test_var",
        "get_item",
        "_get_metadata_path",
        "get_atom_string",
        "test_bool_indexing",
        "get_bool_data",
        "keys",
        "test_direct_arith_with_series_returns_not_implemented",
        "add_nans_panel4d",
        "test_convert",
        "get_indexer_non_unique",
        "check_mutable_error",
        "test_setitem_empty",
        "check_ops_properties",
        "_values",
        "check_result",
        "attrs",
        "test_frame_reset_index",
        "test_where_complex",
        "PdBlockPassThru_iterBegin",
        "test_ufunc_coercions",
        "test_invert",
        "_convert_index",
        "NpyArr_iterNext",
        "test_td64arr_add_sub_numeric_scalar_invalid",
        "makeMissingCustomDataframe",
        "_maybe_localize_point",
        "_try_aggregate_string_function",
        "test_caching",
        "assert_copy",
        "test_setitem_clears_freq",
        "type",
        "fp",
        "Tuple_iterGetName",
        "test_timedelta",
        "_test_op",
        "test_construct_from_string_raises",
        "test_options_get_engine",
        "test_getitem_setitem_float_labels",
        "_concat_indexes",
        "_create_comparison_method",
        "test_where_dataframe_col_match",
        "reset_display_options",
        "is_all_dates",
        "assert_categorical_equal",
        "test_at_time_between_time_datetimeindex",
        "_wrap_setop_result",
        "test_tdi_mul_int_array_zerodim",
        "slice_indexer",
        "Tuple_iterEnd",
        "test_constructor_cast",
        "test_value_counts_datetime64",
        "_generate_regular_range",
        "maybe_set_size",
        "test_where_empty_df_and_empty_cond_having_non_bool_dtypes",
        "wrap_arithmetic_op",
        "test_dti_tdi_numeric_ops",
        "test_concat_series_axis1_names_applied",
        "read_block_index",
        "test_concat_keys_specific_levels",
        "read_hdf",
        "_convert_index_indexer",
        "__radd__",
        "_factor_indexer",
        "_concat_datetimetz",
        "_interleave",
        "test_constructor_name",
        "test_td64arr_sub_period",
        "item",
        "concatenate_block_managers",
        "__repr__",
        "test_equality_invalid",
        "is_type_compatible",
        "test_drop_duplicates_series_vs_dataframe",
        "__iadd__",
        "test_tdi_mul_float_series",
        "_maybe_box_as_values",
        "NpyArrPassThru_iterBegin",
        "test_is_mixed_dtype",
        "__setitem__",
        "_make_comparison_op",
        "to_perioddelta",
        "test_iloc_duplicates",
        "test_is_not_extension_array_dtype",
        "test_mgr_locs",
        "test_setitem_cast",
        "get_slice_bound",
        "_ensure_datetimelike_to_i8",
        "ncols",
        "set_value",
        "test_getitem_fancy_slice",
        "test_set_value_with_index_dtype_change",
        "_infer_tz_from_endpoints",
        "PdBlock_iterNextItem",
        "Iter_iterBegin",
        "is_leap_year",
        "assert_attr_equal",
        "close",
        "_try_cast",
        "PdBlock_iterNext",
        "select_column",
        "get",
        "set_atom_timedelta64",
        "test_dst",
        "summary",
        "test_tdi_mul_int_array",
        "values",
        "_consolidate_key",
        "test_non_unique_pickle",
        "_local_timestamps",
        "_get_fill_indexer_searchsorted",
        "_selection_name",
        "test_td64arr_addsub_anchored_offset_arraylike",
        "reindex_indexer",
        "makeMultiIndex",
        "is_offsetlike",
        "validate_periods",
        "_has_complex_internals",
        "resolution",
        "test_error",
        "test_read_columns",
        "test_concat_will_upcast",
        "__new__",
        "test_setitem_boolean",
        "test_append_missing_column_proper_upcast",
        "test_getitem_fancy_scalar",
        "test_reindex_methods",
        "_transform_index",
        "test_setitem_list",
        "_delegate_property_get",
        "get_names_from_index",
        "is_numeric",
        "downcast",
        "_hasnans",
        "test_index_namedtuple",
        "test_getitem_setitem_integer_slice_keyerrors",
        "test_not_string",
        "test_td64arr_sub_offset_array",
        "test_setitem_clear_caches",
        "table_type_short",
        "test_xs_view",
        "select_as_coordinates",
        "test_interval_index",
        "asof_locs",
        "test_td64arr_add_int_series_invalid",
        "set_data",
        "test_setitem_None",
        "PyUnicodeToUTF8",
        "test_categorial_datetimelike",
        "test_rename",
        "_get_tz",
        "test_where_callable",
        "get_reindexed_values",
        "validate_read",
        "__len__",
        "test_deprecated_fastpath",
        "factorize",
        "is_simple_frame",
        "transform",
        "astype",
        "masked_rec_array_to_mgr",
        "to_hdf",
        "test_shift",
        "_getitem_multilevel",
        "test_value_counts_unique_nunique",
        "concat",
        "apply",
        "test_swapaxes",
        "isna",
        "validate_metadata",
        "test_string_methods_dont_fail",
        "_slice_take_blocks_ax0",
        "where",
        "to_gbq",
        "__unicode__",
        "strftime",
        "_setitem_frame",
        "test_infer_from_tdi_mismatch",
        "test_major_xs",
        "_block_shape",
        "indexables",
        "test_concat_tz_series_with_datetimelike",
        "test_constructor_invalid",
        "test_td64arr_div_td64nat",
        "_set_tz",
        "test_td64arr_mul_tdlike_scalar_raises",
        "_add_logical_methods",
        "_fast_union",
        "DataFrame_iterBegin",
        "_series",
        "_reindex_axes",
        "corr",
        "read_column",
        "validate_version",
        "test_iloc_col",
        "test_default_index",
        "test_tuple_categories",
        "test_td64arr_add_sub_numeric_arr_invalid",
        "test_fancy_getitem_slice_mixed",
        "List_iterEnd",
        "read_array",
        "makeDataFrame",
        "test_as_array_float",
        "_combine_frame",
        "test_name_repr_generic",
        "test_drop",
        "test_concat_multiindex_with_tz",
        "_ensure_term",
        "_make_wrapped_arith_op",
        "update_info",
        "_class_to_alias",
        "test_td64arr_rfloordiv_tdscalar",
        "test_try_coerce_arg",
        "_is_convertible_to_td",
        "_partial_date_slice",
        "test_prod",
        "test_tdi_mul_int_series",
        "test_to_numpy",
        "test_concat_timedelta64_block",
        "test_operators_timedelta64_with_timedelta",
        "test_columns_dtypes_invalid",
        "optional_args",
        "_validate_date_like_dtype",
        "_handle",
        "test_concat_keys_levels_no_overlap",
        "test_head_tail",
        "test_concat_categorical_coercion",
        "NpyArr_getLabel",
        "_scalar_data_error",
        "test_concat_period_series",
        "_is_single_block",
        "get_sub_attr",
        "test_comparisons_coverage",
        "test_cross_engine_fp_pa",
        "is_datetimelike_v_numeric",
        "categories",
        "start_time",
        "_maybe_downcast",
        "is_view",
        "test_getitem_boolean_iadd",
        "_cleanup",
        "test_constructor_dtypes",
        "test_td64arr_div_int",
        "tzinfo",
        "to_dict",
        "test_xs_keep_level",
        "is_multi_index",
        "test_update_raise_on_overlap",
        "test_setitem_different_tz_raises",
        "test_timedelta64_operations_with_DateOffset",
        "test_delitem_and_pop",
        "nsmallest",
        "_validate_format",
        "_count_level",
        "test_where_align",
        "test_rank",
        "test_concatlike_same_dtypes",
        "test_iloc_sparse_propegate_fill_value",
        "is_transposed",
        "test_concat_multiindex_with_keys",
        "itemsize",
        "test_setitem_mulit_index",
        "shift",
        "test_dropna",
        "is_period_dtype",
        "_add_numeric_methods_add_sub_disabled",
        "test_ops_scalar",
        "prep_ndarray",
        "NpyArr_encodeLabels",
        "_freeze",
        "__delitem__",
        "test_combine_scalar",
        "test_setattr_column",
        "_maybe_mask_results",
        "_astype",
        "_try_convert_to_int_index",
        "count",
        "test_datetime_tz",
        "_add_numeric_methods_binary",
        "_info_repr",
        "test_concat_datetime64_block",
        "test_insert",
        "test_setitem_tuple",
        "period_array",
        "test_array_to_slice_conversion",
        "rands",
        "test_registry_find",
        "is_monotonic",
        "_assert_can_do_op",
        "_put_str",
        "insert",
        "test_td64arr_add_intlike",
        "test_concatlike_common_period",
        "replace_list",
        "test_single_mgr_ctor",
        "test_td64arr_rmul_numeric_array",
        "test_is_boolean",
        "pathname",
        "test_td64arr_add_sub_td64_nat",
        "test_setitem_boolean_column",
        "test_apply",
        "Dir_iterGetName",
        "_get_attributes_dict",
        "maybe_cast_to_datetime",
        "test_where_invalid_input_single",
        "_try_coerce_and_cast_result",
        "test_getitem_listlike",
        "test_setitem_mixed_datetime",
        "is_numeric_v_string_like",
        "test_reindex_items",
        "test_concat_categorical_empty",
        "test_setitem_corner2",
        "find",
        "_ensure_str",
        "test_getitem_setitem_ix_negative_integers",
        "root",
        "_coerce_to_ndarray",
        "is_monotonic_increasing",
        "_get_string_slice",
        "test_not_slice_like_arrays",
        "nlargest",
        "construct_1d_object_array_from_listlike",
        "test_no_mutable_funcs",
        "data",
        "fill_value",
        "from_dict",
        "create_axes",
        "PdBlock_iterBegin",
        "__array_wrap__",
        "__rdivmod__",
        "test_concatlike_common_coerce_to_pandas_object",
        "test_setitem_list_not_dataframe",
        "_unbox_scalar",
        "_combine_const",
        "NpyArr_iterNextNone",
        "get_values",
        "PyLongToINT64",
        "coerce_to_dtypes",
        "makeFloatIndex",
        "__ne__",
        "__exit__",
        "sort",
        "Object_iterGetValue",
        "_from_arrays",
        "validate_data_columns",
        "test_getitem_setitem_non_ix_labels",
        "Tuple_iterNext",
        "get_dtype_kinds",
        "date_range",
        "freq",
        "_get_info",
        "_is_homogeneous_type",
        "date",
        "test_min_max_empty",
        "test_basic_dtype",
        "_addsub_int_array",
        "test_operators",
        "test_join",
        "test_iterable_object_and_category",
        "_can_hold_identifiers_and_holds_name",
        "getSeriesData",
        "_format_native_types",
        "test_dtype_coerceion",
        "_add_datetime_arraylike",
        "is_nested_object",
        "test_td64arr_add_sub_timestamp",
        "test_tdi_add_overflow",
        "_simple_new",
        "assert_sp_frame_equal",
        "diff",
        "get_block_type",
        "test_categories",
        "test_where_ndframe_align",
        "data_missing",
        "_get_foo",
        "_trim_front",
        "argsort",
        "_new_Index",
        "_scalar_type",
        "__contains__",
        "test_where_invalid_input_multiple",
        "test_concat_dataframe_keys_bug",
        "drop",
        "test_get_dummies",
        "test_empty_dtype_coerce",
        "_join_level",
        "_make_arithmetic_op",
        "_ftype",
        "from_csv",
        "test_operators_timedelta64",
        "formatting_values",
        "__xor__",
        "read_index_legacy",
        "test_comparisons_nat",
        "is_extension_type",
        "test_setitem_empty_frame_with_boolean",
        "arrays_to_mgr",
        "get_atom_datetime64",
        "Series_iterEnd",
        "test_categorical_block_pickle",
        "test_subtraction_ops_with_tz",
        "extract_index",
        "makeIntIndex",
        "combine",
        "filename",
        "day_name",
        "test_comparisons",
        "test_concat_iterables",
        "is_datelike",
        "set_name",
        "create_table_index",
        "all_index_generator",
        "test_round",
        "__deepcopy__",
        "test_from_dict_mixed_orient",
        "_validate_for_numeric_unaryop",
        "pivot",
        "_add_timedeltalike_scalar",
        "read_index_node",
        "assert_series_equal",
        "get_storer",
        "test_boolean_compare_transpose_tzindex_with_dst",
        "test_to_frame_multi_major",
        "to_sparse",
        "test_s3_roundtrip",
        "is_uniform_join_units",
        "test_append_records",
        "_blklocs",
        "infer_dtype_from",
        "test_int64_nocopy",
        "test_getitem_setitem_boolean_multi",
        "rands_array",
        "_make_na_block",
        "test_tshift",
        "_get_frame_result_type",
        "snap",
        "test_bool_with_none",
        "reindex_axis",
        "_scalar_from_string",
        "_constructor",
        "maybe_convert_dtype",
        "_maybe_promote",
        "_get_agg_axis",
        "makePeriodIndex",
        "_maybe_convert",
        "to_series",
        "test_skew",
        "_get_dtype_from_object",
        "PdBlockPassThru_iterEnd",
        "_parse_dtype_strict",
        "maybe_castable",
        "_is_dates_only",
        "sort_values",
        "test_astype_to_same",
        "sanitize_index",
        "any_extension_types",
        "test_values_consistent",
        "is_numeric_mixed_type",
        "test_iter",
        "_is_builtin_func",
        "test_comp_nat",
        "test_basic_subset_columns",
        "test_mixed",
        "write_to_compressed",
        "test_slice_iter",
        "__sub__",
        "format_type",
        "test_fancy_getitem_int_labels",
        "to_string",
        "_complib",
        "test_astype_int",
        "Index_iterGetName",
        "is_na",
        "makeIntervalIndex",
        "_validate_indexer",
        "test_concat_categorical_multi_coercion",
        "test_sort_index",
        "get_dtypes",
        "base",
        "test_tz_dtype_matches",
        "_ndarray_values",
        "NpyArr_iterBegin",
        "is_uniform_reindex",
        "test_concat_mixed_dtypes",
        "_get_fill_indexer",
        "test_setitem_corner",
        "Object_beginTypeContext",
        "_get_time_micros",
        "is_indexed",
        "test_count",
        "test_concatlike_common_period_diff_freq_to_object",
        "_add_numeric_methods_unary",
        "test_td64arr_sub_timedeltalike",
        "test_sparse",
        "test_write_multiindex",
        "test_pct_change",
        "_box_col_values",
        "test_constructor_corner",
        "_evaluate_with_datetime_like",
        "test_td64arr_rmod_tdscalar",
        "_unconvert_string_array",
        "any",
        "aggregate",
        "test_arith_flex_panel",
        "NpyArrPassThru_iterEnd",
        "makePanel",
        "_alias_to_class",
        "_format_with_header",
        "_partial_td_slice",
        "normalize",
        "__hash__",
        "test_from_categorical_dtype_ordered",
        "is_datetime64_any_dtype",
        "idxmax",
        "__add__",
        "dtype_str",
        "test_setitem_datetimeindex_tz",
        "fillna",
        "_fast_count_smallints",
        "test_slice_len",
        "create_block_manager_from_arrays",
        "isnull",
        "_concat",
        "reshape_nd",
        "get_node",
        "test_sort",
        "test_concat_inner_sort",
        "_join_i8_wrapper",
        "is_numeric_dtype",
        "test_concat_dict",
        "bar",
        "test_transpose",
        "_format_attrs",
        "Dict_iterEnd",
        "_check_if_open",
        "intersection",
        "_convert_list_indexer",
        "test_td64arr_rfloordiv_tdlike_scalar",
        "test_neg_freq",
        "make_block_same_class",
        "is_sparse",
        "_validate_for_numeric_binop",
        "getArangeMat",
        "assert_sp_array_equal",
        "test_append",
        "is_scipy_sparse",
        "__rmatmul__",
        "xs",
        "to_parquet",
        "test_td64arr_sub_timestamp_raises",
        "create_mgr",
        "DataFrame_iterEnd",
        "convert",
        "_sort_levels_monotonic",
        "test_td64arr_div_numeric_scalar",
        "_sub_nat",
        "test_interleave_non_unique_cols",
        "memory_usage",
        "is_monotonic_decreasing",
        "test_unicode_repr_doesnt_raise",
        "_add_comparison_methods",
        "create",
        "is_bool",
        "nrows_expected",
        "setup_method",
        "test_equals_block_order_different_dtypes",
        "test_type_error_multiindex",
        "_concat_rangeindex_same_dtype",
        "is_mixed",
        "Dict_iterNext",
        "_add_datetimelike_methods",
        "can_set_locale",
        "fast_xs",
        "_get_grouper_for_level",
        "to_arrays",
        "data_for_sorting",
        "test_minor_xs_mixed",
        "test_getitem_fancy_xs_check_view",
        "assert_produces_warning",
        "ensure_index",
        "test_lookup",
        "test_cross_engine_pa_fp",
        "table",
        "is_any_int_dtype",
        "__rfloordiv__",
        "_convert_for_op",
        "is_string_like_dtype",
        "pudebug",
        "get_value_maybe_box",
        "test_ctor_dict",
        "test_set_change_dtype_slice",
        "test_td64arr_sub_offset_index",
        "test_order_matters",
        "test_unordered_same",
        "test_where_tz_values",
        "test_max",
        "construct_1d_ndarray_preserving_na",
        "test_ops_differently_indexed",
        "set_version",
        "assert_period_array_equal",
        "get_atom_data",
        "randbool",
        "_interpolate",
        "test_delete",
        "test_not_slice_like_slices",
        "align",
        "set_locale",
        "ensure_float",
        "append",
        "interpolate",
        "test_getitem_fancy_2d",
        "invalidate_string_dtypes",
        "is_signed_integer_dtype",
        "test_float_series_rdiv_td64arr",
        "assert_contains_all",
        "test_setitem_fancy_boolean",
        "__enter__",
        "validate_min_itemsize",
        "assert_interval_array_equal",
        "test_major_xs_mixed",
        "_write_to_group",
        "_need_convert",
        "test_ndarray_values",
        "test_concat_invalid",
        "_maybe_cast_indexer",
        "get_empty_dtype_and_na",
        "test_with_mixed_tuples",
        "test_reindex_indexer",
        "_get_series_result_type",
        "makeTimeDataFrame",
        "_fletcher32",
        "test_concat_empty_and_non_empty_frame_regression",
        "maybe_infer_to_datetimelike",
        "test_setitem_with_sparse_value",
        "Object_getStringValue",
        "_post_setstate",
        "assert_panel_equal",
        "Tuple_iterGetValue",
        "_try_coerce_args",
        "test_is_dtype_no_warning",
        "test_from_categorical_dtype_categories",
        "_convert_datetimelike_to_object",
        "test_write_ignoring_index",
        "to_pydatetime",
        "equals",
        "test_from_categorical_dtype_both",
        "rename",
        "_convert_scalar_indexer",
        "_to_safe_for_reshape",
        "Object_iterGetName",
        "is_dtype_union_equal",
        "_concat_same_type",
        "set_pos",
        "index",
        "_ensure_has_len",
        "test_reindex",
        "_get_ordinal_range",
        "test_concat",
        "with_csv_dialect",
        "test_combinePanel",
        "_get_unstack_items",
        "test_setitem_list_of_tuples",
        "test_subtraction_ops",
        "DataFrame_iterNext",
        "test_concat_with_group_keys",
        "_has_same_tz",
        "test_assigning_ops",
        "test_combineFrame",
        "test_reindex_axis",
        "test_concat_tz_series",
        "quantile",
        "is_complex_dtype",
        "_format_space",
        "_wrap_joined_index",
        "_set_value",
        "makeCustomDataframe",
        "Object_getIntValue",
        "test_td64arr_mul_tdscalar_invalid",
        "get_mgr_concatenation_plan",
        "validate_categories",
        "create_for_block",
        "description",
        "_reset_cache",
        "union_many",
        "test_freq_infer_raises",
        "_get_axes",
        "test_setitem_fancy_1d",
        "test_get_value",
        "infer_dtype_from_scalar",
        "test_array",
        "get_atom_timedelta64",
        "test_array_interface",
        "test_concat_categorical_tz",
        "_isnan",
        "ensure_safe_environment_variables",
        "external_values",
        "assert_equal",
        "test_getitem_setitem_ix_duplicates",
        "test_minor_xs",
        "_searchsorted_monotonic",
        "select_coords",
        "test_getitem_dupe_cols",
        "test_compat",
        "test_dt64_data_invalid",
        "iteritems",
        "test_construction_from_string_error_subtype",
        "test_range_kwargs_deprecated",
        "test_functions_no_warnings",
        "test_getitem_fancy_ints",
        "reorder_levels",
        "test_value_counts",
        "test_ix_dup",
        "test_update_dtype_string",
        "holds_integer",
        "_concat_compat",
        "_obj_with_exclusions",
        "_merge_blocks",
        "_multi_blockify",
        "_tables",
        "test_td64arr_add_str_invalid",
        "_shallow_copy",
        "_nan_idxs",
        "test_mask_edge_case_1xN_frame",
        "_values_for_factorize",
        "is_datetime64_ns_dtype",
        "is_mixed_type",
        "name",
        "makeUnicodeIndex",
        "asof",
        "_inner_indexer",
        "test_categorical_equality_strings",
        "test_multiindex_get",
        "test_reindex_like",
        "round_trip_localpath",
        "test_mismatched_timezone_raises",
        "PyIntToINT32",
        "set_axis",
        "_rebuild_blknos_and_blklocs",
        "test_update_dtype_errors",
        "test_constructor_coverage",
        "_ensure_decoded",
        "make_block_scalar",
        "_validate_fill_value",
        "concat_same_type",
        "test_setitem",
        "test_loc_duplicates",
        "test_concat_period_multiple_freq_series",
        "putmask",
        "_replace_coerce",
        "_new_DatetimeIndex",
        "test_fillna",
        "copy",
        "test_append_length0_frame",
        "items",
        "Series_iterGetValue",
        "bdate_range",
        "nrows",
        "set_attr",
        "test_equality_generic",
        "maybe_infer_tz",
        "infer_axes",
        "test_logical_with_nas",
        "ensure_index_from_sequences",
        "test_concat_single_with_key",
        "test_single_element_ix_dont_upcast",
        "_dt_array_cmp",
        "test_to_frame_multi_drop_level",
        "get_nat",
        "na_value",
        "round",
        "_create_missing_idx",
        "test_as_array_datetime_tz",
        "test_td64arr_div_nat_invalid",
        "min",
        "_assert_tzawareness_compat"
      ],
      "functions_name_co_evolved_modified_file": [
        "__init__",
        "extract_values_freq",
        "_simple_new"
      ],
      "functions_name_co_evolved_all_files": [
        "test_fillna_preserves_tz",
        "date_range",
        "is_view",
        "array",
        "test_error",
        "_maybe_coerce_values",
        "dtype",
        "test_unstack",
        "__init__",
        "test_direct_arith_with_series_returns_not_implemented",
        "test_make_block_same_class",
        "data_for_sorting",
        "_holder",
        "test_freq_infer_raises",
        "test_frame_values_with_tz",
        "__setstate__",
        "setitem",
        "test_array_interface",
        "_simple_new",
        "test_add_series_with_extension_array",
        "construct_array_type",
        "test_append_empty_frame_to_series_with_dateutil_tz",
        "_values",
        "external_values",
        "data_missing_for_sorting",
        "shift",
        "data_missing",
        "pandas_dtype",
        "_compare_other",
        "_box_values",
        "test_concat_mixed_dtypes",
        "test_incorrect_dtype_raises",
        "test_to_numpy_dtype",
        "test_copy",
        "as_array",
        "test_value_counts",
        "reset_index",
        "get_reindexed_values",
        "_ensure_localized",
        "_wrap_setop_result",
        "test_non_array_raises",
        "write_array",
        "_eadata",
        "_shallow_copy",
        "astype",
        "_try_coerce_result",
        "test_from_sequence_dtype",
        "test_repeat_preserves_tz",
        "combine_first",
        "test_pandas_registry",
        "asi8",
        "test_value_counts_unique_nunique",
        "test_mismatched_timezone_raises",
        "test_arith_series_with_array",
        "to_numpy",
        "sanitize_array",
        "_concat_datetimetz",
        "test_other_type_raises",
        "sequence_to_dt64ns",
        "__array__",
        "_validate_fill_value",
        "concat_same_type",
        "data_for_grouping",
        "test_setitem",
        "fillna",
        "_data",
        "_time_shift",
        "_new_DatetimeIndex",
        "copy",
        "assert_series_equal",
        "_make_comparison_op",
        "_box_values_as_index",
        "na_cmp",
        "maybe_infer_to_datetimelike",
        "test_is_not_extension_array_dtype",
        "_join_i8_wrapper",
        "_try_coerce_args",
        "_addsub_offset_array",
        "test_int64_nocopy",
        "to_dense",
        "_dt_array_cmp",
        "extract_values_freq",
        "test_dt64tz_setitem_does_not_mutate_dti",
        "na_value",
        "data",
        "test_arith_series_with_scalar",
        "test_pandas_registry_find",
        "get_values",
        "maybe_convert_dtype",
        "test_tdi_rmul_arraylike",
        "tz",
        "test_combine_add",
        "test_concat",
        "_concat_same_dtype",
        "test_setitem_invalidates_datetime_index_freq",
        "view"
      ]
    },
    "file": {
      "file_name": "timedeltas.py",
      "file_nloc": 583,
      "file_complexity": 185,
      "file_token_count": 4369,
      "file_before": "# -*- coding: utf-8 -*-\nfrom __future__ import division\n\nfrom datetime import timedelta\nimport warnings\n\nimport numpy as np\n\nfrom pandas._libs import lib, tslibs\nfrom pandas._libs.tslibs import NaT, Timedelta, Timestamp, iNaT\nfrom pandas._libs.tslibs.fields import get_timedelta_field\nfrom pandas._libs.tslibs.timedeltas import (\n    array_to_timedelta64, parse_timedelta_unit)\nimport pandas.compat as compat\nfrom pandas.util._decorators import Appender\n\nfrom pandas.core.dtypes.common import (\n    _NS_DTYPE, _TD_DTYPE, ensure_int64, is_datetime64_dtype, is_float_dtype,\n    is_int64_dtype, is_integer_dtype, is_list_like, is_object_dtype, is_scalar,\n    is_string_dtype, is_timedelta64_dtype, is_timedelta64_ns_dtype,\n    pandas_dtype)\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.generic import (\n    ABCDataFrame, ABCIndexClass, ABCSeries, ABCTimedeltaIndex)\nfrom pandas.core.dtypes.missing import isna\n\nfrom pandas.core import ops\nfrom pandas.core.algorithms import checked_add_with_arr\nimport pandas.core.common as com\n\nfrom pandas.tseries.frequencies import to_offset\nfrom pandas.tseries.offsets import Tick\n\nfrom . import datetimelike as dtl\n\n\ndef _to_m8(key):\n    \"\"\"\n    Timedelta-like => dt64\n    \"\"\"\n    if not isinstance(key, Timedelta):\n        # this also converts strings\n        key = Timedelta(key)\n\n    # return an type that can be compared\n    return np.int64(key.value).view(_TD_DTYPE)\n\n\ndef _is_convertible_to_td(key):\n    return isinstance(key, (Tick, timedelta,\n                            np.timedelta64, compat.string_types))\n\n\ndef _field_accessor(name, alias, docstring=None):\n    def f(self):\n        values = self.asi8\n        result = get_timedelta_field(values, alias)\n        if self._hasnans:\n            result = self._maybe_mask_results(result, fill_value=None,\n                                              convert='float64')\n\n        return result\n\n    f.__name__ = name\n    f.__doc__ = \"\\n{}\\n\".format(docstring)\n    return property(f)\n\n\ndef _td_array_cmp(cls, op):\n    \"\"\"\n    Wrap comparison operations to convert timedelta-like to timedelta64\n    \"\"\"\n    opname = '__{name}__'.format(name=op.__name__)\n    nat_result = True if opname == '__ne__' else False\n\n    meth = getattr(dtl.DatetimeLikeArrayMixin, opname)\n\n    def wrapper(self, other):\n        if _is_convertible_to_td(other) or other is NaT:\n            try:\n                other = _to_m8(other)\n            except ValueError:\n                # failed to parse as timedelta\n                return ops.invalid_comparison(self, other, op)\n\n            result = meth(self, other)\n            if isna(other):\n                result.fill(nat_result)\n\n        elif not is_list_like(other):\n            return ops.invalid_comparison(self, other, op)\n\n        elif len(other) != len(self):\n            raise ValueError(\"Lengths must match\")\n\n        else:\n            try:\n                other = type(self)._from_sequence(other)._data\n            except (ValueError, TypeError):\n                return ops.invalid_comparison(self, other, op)\n\n            result = meth(self, other)\n            result = com.values_from_object(result)\n\n            o_mask = np.array(isna(other))\n            if o_mask.any():\n                result[o_mask] = nat_result\n\n        if self._hasnans:\n            result[self._isnan] = nat_result\n\n        return result\n\n    return compat.set_function_name(wrapper, opname, cls)\n\n\nclass TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps):\n    _typ = \"timedeltaarray\"\n    _scalar_type = Timedelta\n    __array_priority__ = 1000\n    # define my properties & methods for delegation\n    _other_ops = []\n    _bool_ops = []\n    _object_ops = ['freq']\n    _field_ops = ['days', 'seconds', 'microseconds', 'nanoseconds']\n    _datetimelike_ops = _field_ops + _object_ops + _bool_ops\n    _datetimelike_methods = [\"to_pytimedelta\", \"total_seconds\",\n                             \"round\", \"floor\", \"ceil\"]\n\n    # Needed so that NaT.__richcmp__(DateTimeArray) operates pointwise\n    ndim = 1\n\n    @property\n    def _box_func(self):\n        return lambda x: Timedelta(x, unit='ns')\n\n    @property\n    def dtype(self):\n        return _TD_DTYPE\n\n    # ----------------------------------------------------------------\n    # Constructors\n    _attributes = [\"freq\"]\n\n    @classmethod\n    def _simple_new(cls, values, freq=None, dtype=_TD_DTYPE):\n        # `dtype` is passed by _shallow_copy in corner cases, should always\n        #  be timedelta64[ns] if present\n        assert dtype == _TD_DTYPE\n        assert isinstance(values, np.ndarray), type(values)\n\n        if values.dtype == 'i8':\n            values = values.view('m8[ns]')\n\n        assert values.dtype == 'm8[ns]'\n\n        result = object.__new__(cls)\n        result._data = values\n        result._freq = freq\n        return result\n\n    def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n        return cls._from_sequence(values, dtype=dtype, copy=copy, freq=freq)\n\n    @classmethod\n    def _from_sequence(cls, data, dtype=_TD_DTYPE, copy=False,\n                       freq=None, unit=None):\n        if dtype != _TD_DTYPE:\n            raise ValueError(\"Only timedelta64[ns] dtype is valid.\")\n\n        freq, freq_infer = dtl.maybe_infer_freq(freq)\n\n        data, inferred_freq = sequence_to_td64ns(data, copy=copy, unit=unit)\n        freq, freq_infer = dtl.validate_inferred_freq(freq, inferred_freq,\n                                                      freq_infer)\n\n        result = cls._simple_new(data, freq=freq)\n\n        if inferred_freq is None and freq is not None:\n            # this condition precludes `freq_infer`\n            cls._validate_frequency(result, freq)\n\n        elif freq_infer:\n            result.freq = to_offset(result.inferred_freq)\n\n        return result\n\n    @classmethod\n    def _generate_range(cls, start, end, periods, freq, closed=None):\n\n        periods = dtl.validate_periods(periods)\n        if freq is None and any(x is None for x in [periods, start, end]):\n            raise ValueError('Must provide freq argument if no data is '\n                             'supplied')\n\n        if com.count_not_none(start, end, periods, freq) != 3:\n            raise ValueError('Of the four parameters: start, end, periods, '\n                             'and freq, exactly three must be specified')\n\n        if start is not None:\n            start = Timedelta(start)\n\n        if end is not None:\n            end = Timedelta(end)\n\n        if start is None and end is None:\n            if closed is not None:\n                raise ValueError(\"Closed has to be None if not both of start\"\n                                 \"and end are defined\")\n\n        left_closed, right_closed = dtl.validate_endpoints(closed)\n\n        if freq is not None:\n            index = _generate_regular_range(start, end, periods, freq)\n        else:\n            index = np.linspace(start.value, end.value, periods).astype('i8')\n\n        if not left_closed:\n            index = index[1:]\n        if not right_closed:\n            index = index[:-1]\n\n        return cls._simple_new(index, freq=freq)\n\n    # ----------------------------------------------------------------\n    # DatetimeLike Interface\n\n    def _unbox_scalar(self, value):\n        if not isinstance(value, self._scalar_type) and value is not NaT:\n            raise ValueError(\"'value' should be a Timedelta.\")\n        self._check_compatible_with(value)\n        return value.value\n\n    def _scalar_from_string(self, value):\n        return Timedelta(value)\n\n    def _check_compatible_with(self, other):\n        # we don't have anything to validate.\n        pass\n\n    def _maybe_clear_freq(self):\n        self._freq = None\n\n    # ----------------------------------------------------------------\n    # Array-Like / EA-Interface Methods\n\n    def __array__(self, dtype=None):\n        # TODO(https://github.com/pandas-dev/pandas/pull/23593)\n        # Maybe push to parent once datetimetz __array__ is figured out.\n        if is_object_dtype(dtype):\n            return np.array(list(self), dtype=object)\n        elif is_int64_dtype(dtype):\n            return self.asi8\n\n        return self._data\n\n    @Appender(dtl.DatetimeLikeArrayMixin._validate_fill_value.__doc__)\n    def _validate_fill_value(self, fill_value):\n        if isna(fill_value):\n            fill_value = iNaT\n        elif isinstance(fill_value, (timedelta, np.timedelta64, Tick)):\n            fill_value = Timedelta(fill_value).value\n        else:\n            raise ValueError(\"'fill_value' should be a Timedelta. \"\n                             \"Got '{got}'.\".format(got=fill_value))\n        return fill_value\n\n    def astype(self, dtype, copy=True):\n        # We handle\n        #   --> timedelta64[ns]\n        #   --> timedelta64\n        # DatetimeLikeArrayMixin super call handles other cases\n        dtype = pandas_dtype(dtype)\n\n        if is_timedelta64_dtype(dtype) and not is_timedelta64_ns_dtype(dtype):\n            # by pandas convention, converting to non-nano timedelta64\n            #  returns an int64-dtyped array with ints representing multiples\n            #  of the desired timedelta unit.  This is essentially division\n            if self._hasnans:\n                # avoid double-copying\n                result = self._data.astype(dtype, copy=False)\n                values = self._maybe_mask_results(result,\n                                                  fill_value=None,\n                                                  convert='float64')\n                return values\n            result = self._data.astype(dtype, copy=copy)\n            return result.astype('i8')\n        elif is_timedelta64_ns_dtype(dtype):\n            if copy:\n                return self.copy()\n            return self\n        return dtl.DatetimeLikeArrayMixin.astype(self, dtype, copy=copy)\n\n    # ----------------------------------------------------------------\n    # Rendering Methods\n\n    def _formatter(self, boxed=False):\n        from pandas.io.formats.format import _get_format_timedelta64\n        return _get_format_timedelta64(self, box=True)\n\n    def _format_native_types(self, na_rep='NaT', date_format=None):\n        from pandas.io.formats.format import _get_format_timedelta64\n\n        formatter = _get_format_timedelta64(self._data, na_rep)\n        return np.array([formatter(x) for x in self._data])\n\n    # ----------------------------------------------------------------\n    # Arithmetic Methods\n\n    _create_comparison_method = classmethod(_td_array_cmp)\n\n    def _add_offset(self, other):\n        assert not isinstance(other, Tick)\n        raise TypeError(\"cannot add the type {typ} to a {cls}\"\n                        .format(typ=type(other).__name__,\n                                cls=type(self).__name__))\n\n    def _add_delta(self, delta):\n        \"\"\"\n        Add a timedelta-like, Tick, or TimedeltaIndex-like object\n        to self, yielding a new TimedeltaArray.\n\n        Parameters\n        ----------\n        other : {timedelta, np.timedelta64, Tick,\n                 TimedeltaIndex, ndarray[timedelta64]}\n\n        Returns\n        -------\n        result : TimedeltaArray\n        \"\"\"\n        new_values = super(TimedeltaArrayMixin, self)._add_delta(delta)\n        return type(self)._from_sequence(new_values, freq='infer')\n\n    def _add_datetime_arraylike(self, other):\n        \"\"\"\n        Add DatetimeArray/Index or ndarray[datetime64] to TimedeltaArray.\n        \"\"\"\n        if isinstance(other, np.ndarray):\n            # At this point we have already checked that dtype is datetime64\n            from pandas.core.arrays import DatetimeArrayMixin\n            other = DatetimeArrayMixin(other)\n\n        # defer to implementation in DatetimeArray\n        return other + self\n\n    def _add_datetimelike_scalar(self, other):\n        # adding a timedeltaindex to a datetimelike\n        from pandas.core.arrays import DatetimeArrayMixin\n\n        assert other is not NaT\n        other = Timestamp(other)\n        if other is NaT:\n            # In this case we specifically interpret NaT as a datetime, not\n            # the timedelta interpretation we would get by returning self + NaT\n            result = self.asi8.view('m8[ms]') + NaT.to_datetime64()\n            return DatetimeArrayMixin(result)\n\n        i8 = self.asi8\n        result = checked_add_with_arr(i8, other.value,\n                                      arr_mask=self._isnan)\n        result = self._maybe_mask_results(result)\n        dtype = DatetimeTZDtype(tz=other.tz) if other.tz else _NS_DTYPE\n        return DatetimeArrayMixin(result, dtype=dtype, freq=self.freq)\n\n    def _addsub_offset_array(self, other, op):\n        # Add or subtract Array-like of DateOffset objects\n        try:\n            # TimedeltaIndex can only operate with a subset of DateOffset\n            # subclasses.  Incompatible classes will raise AttributeError,\n            # which we re-raise as TypeError\n            return super(TimedeltaArrayMixin, self)._addsub_offset_array(\n                other, op\n            )\n        except AttributeError:\n            raise TypeError(\"Cannot add/subtract non-tick DateOffset to {cls}\"\n                            .format(cls=type(self).__name__))\n\n    def __mul__(self, other):\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCDataFrame, ABCSeries, ABCIndexClass)):\n            return NotImplemented\n\n        if is_scalar(other):\n            # numpy will accept float and int, raise TypeError for others\n            result = self._data * other\n            freq = None\n            if self.freq is not None and not isna(other):\n                freq = self.freq * other\n            return type(self)(result, freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self) and not is_timedelta64_dtype(other):\n            # Exclude timedelta64 here so we correctly raise TypeError\n            #  for that instead of ValueError\n            raise ValueError(\"Cannot multiply with unequal lengths\")\n\n        if is_object_dtype(other):\n            # this multiplication will succeed only if all elements of other\n            #  are int or float scalars, so we will end up with\n            #  timedelta64[ns]-dtyped result\n            result = [self[n] * other[n] for n in range(len(self))]\n            result = np.array(result)\n            return type(self)(result)\n\n        # numpy will accept float or int dtype, raise TypeError for others\n        result = self._data * other\n        return type(self)(result)\n\n    __rmul__ = __mul__\n\n    def __truediv__(self, other):\n        # timedelta / X is well-defined for timedelta-like or numeric X\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n            if other is NaT:\n                # specifically timedelta64-NaT\n                result = np.empty(self.shape, dtype=np.float64)\n                result.fill(np.nan)\n                return result\n\n            # otherwise, dispatch to Timedelta implementation\n            return self._data / other\n\n        elif lib.is_scalar(other):\n            # assume it is numeric\n            result = self._data / other\n            freq = None\n            if self.freq is not None:\n                # Tick division is not implemented, so operate on Timedelta\n                freq = self.freq.delta / other\n            return type(self)(result, freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # e.g. list, tuple\n            other = np.array(other)\n\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide vectors with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            # let numpy handle it\n            return self._data / other\n\n        elif is_object_dtype(other):\n            # Note: we do not do type inference on the result, so either\n            #  an object array or numeric-dtyped (if numpy does inference)\n            #  will be returned.  GH#23829\n            result = [self[n] / other[n] for n in range(len(self))]\n            result = np.array(result)\n            return result\n\n        else:\n            result = self._data / other\n            return type(self)(result)\n\n    def __rtruediv__(self, other):\n        # X / timedelta is defined only for timedelta-like X\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n            if other is NaT:\n                # specifically timedelta64-NaT\n                result = np.empty(self.shape, dtype=np.float64)\n                result.fill(np.nan)\n                return result\n\n            # otherwise, dispatch to Timedelta implementation\n            return other / self._data\n\n        elif lib.is_scalar(other):\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=type(other).__name__,\n                                    cls=type(self).__name__))\n\n        if not hasattr(other, \"dtype\"):\n            # e.g. list, tuple\n            other = np.array(other)\n\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide vectors with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            # let numpy handle it\n            return other / self._data\n\n        elif is_object_dtype(other):\n            # Note: unlike in __truediv__, we do not _need_ to do type#\n            #  inference on the result.  It does not raise, a numeric array\n            #  is returned.  GH#23829\n            result = [other[n] / self[n] for n in range(len(self))]\n            return np.array(result)\n\n        else:\n            raise TypeError(\"Cannot divide {dtype} data by {cls}\"\n                            .format(dtype=other.dtype,\n                                    cls=type(self).__name__))\n\n    if compat.PY2:\n        __div__ = __truediv__\n        __rdiv__ = __rtruediv__\n\n    def __floordiv__(self, other):\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if is_scalar(other):\n            if isinstance(other, (timedelta, np.timedelta64, Tick)):\n                other = Timedelta(other)\n                if other is NaT:\n                    # treat this specifically as timedelta-NaT\n                    result = np.empty(self.shape, dtype=np.float64)\n                    result.fill(np.nan)\n                    return result\n\n                # dispatch to Timedelta implementation\n                result = other.__rfloordiv__(self._data)\n                return result\n\n            # at this point we should only have numeric scalars; anything\n            #  else will raise\n            result = self.asi8 // other\n            result[self._isnan] = iNaT\n            freq = None\n            if self.freq is not None:\n                # Note: freq gets division, not floor-division\n                freq = self.freq / other\n            return type(self)(result.view('m8[ns]'), freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            other = type(self)(other)\n\n            # numpy timedelta64 does not natively support floordiv, so operate\n            #  on the i8 values\n            result = self.asi8 // other.asi8\n            mask = self._isnan | other._isnan\n            if mask.any():\n                result = result.astype(np.int64)\n                result[mask] = np.nan\n            return result\n\n        elif is_object_dtype(other):\n            result = [self[n] // other[n] for n in range(len(self))]\n            result = np.array(result)\n            if lib.infer_dtype(result) == 'timedelta':\n                result, _ = sequence_to_td64ns(result)\n                return type(self)(result)\n            return result\n\n        elif is_integer_dtype(other) or is_float_dtype(other):\n            result = self._data // other\n            return type(self)(result)\n\n        else:\n            dtype = getattr(other, \"dtype\", type(other).__name__)\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=dtype, cls=type(self).__name__))\n\n    def __rfloordiv__(self, other):\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if is_scalar(other):\n            if isinstance(other, (timedelta, np.timedelta64, Tick)):\n                other = Timedelta(other)\n                if other is NaT:\n                    # treat this specifically as timedelta-NaT\n                    result = np.empty(self.shape, dtype=np.float64)\n                    result.fill(np.nan)\n                    return result\n\n                # dispatch to Timedelta implementation\n                result = other.__floordiv__(self._data)\n                return result\n\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=type(other).__name__,\n                                    cls=type(self).__name__))\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            other = type(self)(other)\n\n            # numpy timedelta64 does not natively support floordiv, so operate\n            #  on the i8 values\n            result = other.asi8 // self.asi8\n            mask = self._isnan | other._isnan\n            if mask.any():\n                result = result.astype(np.int64)\n                result[mask] = np.nan\n            return result\n\n        elif is_object_dtype(other):\n            result = [other[n] // self[n] for n in range(len(self))]\n            result = np.array(result)\n            return result\n\n        else:\n            dtype = getattr(other, \"dtype\", type(other).__name__)\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=dtype, cls=type(self).__name__))\n\n    def __mod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n        return self - (self // other) * other\n\n    def __rmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n        return other - (other // self) * self\n\n    def __divmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n\n        res1 = self // other\n        res2 = self - res1 * other\n        return res1, res2\n\n    def __rdivmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n\n        res1 = other // self\n        res2 = other - res1 * self\n        return res1, res2\n\n    # Note: TimedeltaIndex overrides this in call to cls._add_numeric_methods\n    def __neg__(self):\n        if self.freq is not None:\n            return type(self)(-self._data, freq=-self.freq)\n        return type(self)(-self._data)\n\n    def __abs__(self):\n        # Note: freq is not preserved\n        return type(self)(np.abs(self._data))\n\n    # ----------------------------------------------------------------\n    # Conversion Methods - Vectorized analogues of Timedelta methods\n\n    def total_seconds(self):\n        \"\"\"\n        Return total duration of each element expressed in seconds.\n\n        This method is available directly on TimedeltaArray, TimedeltaIndex\n        and on Series containing timedelta values under the ``.dt`` namespace.\n\n        Returns\n        -------\n        seconds : [ndarray, Float64Index, Series]\n            When the calling object is a TimedeltaArray, the return type\n            is ndarray.  When the calling object is a TimedeltaIndex,\n            the return type is a Float64Index. When the calling object\n            is a Series, the return type is Series of type `float64` whose\n            index is the same as the original.\n\n        See Also\n        --------\n        datetime.timedelta.total_seconds : Standard library version\n            of this method.\n        TimedeltaIndex.components : Return a DataFrame with components of\n            each Timedelta.\n\n        Examples\n        --------\n        **Series**\n\n        >>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='d'))\n        >>> s\n        0   0 days\n        1   1 days\n        2   2 days\n        3   3 days\n        4   4 days\n        dtype: timedelta64[ns]\n\n        >>> s.dt.total_seconds()\n        0         0.0\n        1     86400.0\n        2    172800.0\n        3    259200.0\n        4    345600.0\n        dtype: float64\n\n        **TimedeltaIndex**\n\n        >>> idx = pd.to_timedelta(np.arange(5), unit='d')\n        >>> idx\n        TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],\n                       dtype='timedelta64[ns]', freq=None)\n\n        >>> idx.total_seconds()\n        Float64Index([0.0, 86400.0, 172800.0, 259200.00000000003, 345600.0],\n                     dtype='float64')\n        \"\"\"\n        return self._maybe_mask_results(1e-9 * self.asi8, fill_value=None)\n\n    def to_pytimedelta(self):\n        \"\"\"\n        Return Timedelta Array/Index as object ndarray of datetime.timedelta\n        objects.\n\n        Returns\n        -------\n        datetimes : ndarray\n        \"\"\"\n        return tslibs.ints_to_pytimedelta(self.asi8)\n\n    days = _field_accessor(\"days\", \"days\",\n                           \"Number of days for each element.\")\n    seconds = _field_accessor(\"seconds\", \"seconds\",\n                              \"Number of seconds (>= 0 and less than 1 day) \"\n                              \"for each element.\")\n    microseconds = _field_accessor(\"microseconds\", \"microseconds\",\n                                   \"Number of microseconds (>= 0 and less \"\n                                   \"than 1 second) for each element.\")\n    nanoseconds = _field_accessor(\"nanoseconds\", \"nanoseconds\",\n                                  \"Number of nanoseconds (>= 0 and less \"\n                                  \"than 1 microsecond) for each element.\")\n\n    @property\n    def components(self):\n        \"\"\"\n        Return a dataframe of the components (days, hours, minutes,\n        seconds, milliseconds, microseconds, nanoseconds) of the Timedeltas.\n\n        Returns\n        -------\n        a DataFrame\n        \"\"\"\n        from pandas import DataFrame\n\n        columns = ['days', 'hours', 'minutes', 'seconds',\n                   'milliseconds', 'microseconds', 'nanoseconds']\n        hasnans = self._hasnans\n        if hasnans:\n            def f(x):\n                if isna(x):\n                    return [np.nan] * len(columns)\n                return x.components\n        else:\n            def f(x):\n                return x.components\n\n        result = DataFrame([f(x) for x in self], columns=columns)\n        if not hasnans:\n            result = result.astype('int64')\n        return result\n\n\nTimedeltaArrayMixin._add_comparison_ops()\n\n\n# ---------------------------------------------------------------------\n# Constructor Helpers\n\ndef sequence_to_td64ns(data, copy=False, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Parameters\n    ----------\n    array : list-like\n    copy : bool, default False\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    converted : numpy.ndarray\n        The sequence converted to a numpy array with dtype ``timedelta64[ns]``.\n    inferred_freq : Tick or None\n        The inferred frequency of the sequence.\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting ``errors=ignore`` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    inferred_freq = None\n    unit = parse_timedelta_unit(unit)\n\n    # Unwrap whatever we have into a np.ndarray\n    if not hasattr(data, 'dtype'):\n        # e.g. list, tuple\n        if np.ndim(data) == 0:\n            # i.e. generator\n            data = list(data)\n        data = np.array(data, copy=False)\n    elif isinstance(data, ABCSeries):\n        data = data._values\n    elif isinstance(data, (ABCTimedeltaIndex, TimedeltaArrayMixin)):\n        inferred_freq = data.freq\n        data = data._data\n\n    # Convert whatever we have into timedelta64[ns] dtype\n    if is_object_dtype(data) or is_string_dtype(data):\n        # no need to make a copy, need to convert if string-dtyped\n        data = objects_to_td64ns(data, unit=unit, errors=errors)\n        copy = False\n\n    elif is_integer_dtype(data):\n        # treat as multiples of the given unit\n        data, copy_made = ints_to_td64ns(data, unit=unit)\n        copy = copy and not copy_made\n\n    elif is_float_dtype(data):\n        # treat as multiples of the given unit.  If after converting to nanos,\n        #  there are fractional components left, these are truncated\n        #  (i.e. NOT rounded)\n        mask = np.isnan(data)\n        coeff = np.timedelta64(1, unit) / np.timedelta64(1, 'ns')\n        data = (coeff * data).astype(np.int64).view('timedelta64[ns]')\n        data[mask] = iNaT\n        copy = False\n\n    elif is_timedelta64_dtype(data):\n        if data.dtype != _TD_DTYPE:\n            # non-nano unit\n            # TODO: watch out for overflows\n            data = data.astype(_TD_DTYPE)\n            copy = False\n\n    elif is_datetime64_dtype(data):\n        # GH#23539\n        warnings.warn(\"Passing datetime64-dtype data to TimedeltaIndex is \"\n                      \"deprecated, will raise a TypeError in a future \"\n                      \"version\",\n                      FutureWarning, stacklevel=4)\n        data = ensure_int64(data).view(_TD_DTYPE)\n\n    else:\n        raise TypeError(\"dtype {dtype} cannot be converted to timedelta64[ns]\"\n                        .format(dtype=data.dtype))\n\n    data = np.array(data, copy=copy)\n    assert data.dtype == 'm8[ns]', data\n    return data, inferred_freq\n\n\ndef ints_to_td64ns(data, unit=\"ns\"):\n    \"\"\"\n    Convert an ndarray with integer-dtype to timedelta64[ns] dtype, treating\n    the integers as multiples of the given timedelta unit.\n\n    Parameters\n    ----------\n    data : numpy.ndarray with integer-dtype\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n    bool : whether a copy was made\n    \"\"\"\n    copy_made = False\n    unit = unit if unit is not None else \"ns\"\n\n    if data.dtype != np.int64:\n        # converting to int64 makes a copy, so we can avoid\n        # re-copying later\n        data = data.astype(np.int64)\n        copy_made = True\n\n    if unit != \"ns\":\n        dtype_str = \"timedelta64[{unit}]\".format(unit=unit)\n        data = data.view(dtype_str)\n\n        # TODO: watch out for overflows when converting from lower-resolution\n        data = data.astype(\"timedelta64[ns]\")\n        # the astype conversion makes a copy, so we can avoid re-copying later\n        copy_made = True\n\n    else:\n        data = data.view(\"timedelta64[ns]\")\n\n    return data, copy_made\n\n\ndef objects_to_td64ns(data, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Convert a object-dtyped or string-dtyped array into an\n    timedelta64[ns]-dtyped array.\n\n    Parameters\n    ----------\n    data : ndarray or Index\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting `errors=ignore` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    # coerce Index to np.ndarray, converting string-dtype if necessary\n    values = np.array(data, dtype=np.object_, copy=False)\n\n    result = array_to_timedelta64(values,\n                                  unit=unit, errors=errors)\n    return result.view('timedelta64[ns]')\n\n\ndef _generate_regular_range(start, end, periods, offset):\n    stride = offset.nanos\n    if periods is None:\n        b = Timedelta(start).value\n        e = Timedelta(end).value\n        e += stride - e % stride\n    elif start is not None:\n        b = Timedelta(start).value\n        e = b + periods * stride\n    elif end is not None:\n        e = Timedelta(end).value + stride\n        b = e - periods * stride\n    else:\n        raise ValueError(\"at least 'start' or 'end' should be specified \"\n                         \"if a 'period' is given.\")\n\n    data = np.arange(b, e, stride, dtype=np.int64)\n    return data\n",
      "file_after": "# -*- coding: utf-8 -*-\nfrom __future__ import division\n\nfrom datetime import timedelta\nimport warnings\n\nimport numpy as np\n\nfrom pandas._libs import lib, tslibs\nfrom pandas._libs.tslibs import NaT, Timedelta, Timestamp, iNaT\nfrom pandas._libs.tslibs.fields import get_timedelta_field\nfrom pandas._libs.tslibs.timedeltas import (\n    array_to_timedelta64, parse_timedelta_unit)\nimport pandas.compat as compat\nfrom pandas.util._decorators import Appender\n\nfrom pandas.core.dtypes.common import (\n    _NS_DTYPE, _TD_DTYPE, ensure_int64, is_datetime64_dtype, is_float_dtype,\n    is_int64_dtype, is_integer_dtype, is_list_like, is_object_dtype, is_scalar,\n    is_string_dtype, is_timedelta64_dtype, is_timedelta64_ns_dtype,\n    pandas_dtype)\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.generic import (\n    ABCDataFrame, ABCIndexClass, ABCSeries, ABCTimedeltaIndex)\nfrom pandas.core.dtypes.missing import isna\n\nfrom pandas.core import ops\nfrom pandas.core.algorithms import checked_add_with_arr\nimport pandas.core.common as com\n\nfrom pandas.tseries.frequencies import to_offset\nfrom pandas.tseries.offsets import Tick\n\nfrom . import datetimelike as dtl\n\n_BAD_DTYPE = \"dtype {dtype} cannot be converted to timedelta64[ns]\"\n\n\ndef _to_m8(key):\n    \"\"\"\n    Timedelta-like => dt64\n    \"\"\"\n    if not isinstance(key, Timedelta):\n        # this also converts strings\n        key = Timedelta(key)\n\n    # return an type that can be compared\n    return np.int64(key.value).view(_TD_DTYPE)\n\n\ndef _is_convertible_to_td(key):\n    return isinstance(key, (Tick, timedelta,\n                            np.timedelta64, compat.string_types))\n\n\ndef _field_accessor(name, alias, docstring=None):\n    def f(self):\n        values = self.asi8\n        result = get_timedelta_field(values, alias)\n        if self._hasnans:\n            result = self._maybe_mask_results(result, fill_value=None,\n                                              convert='float64')\n\n        return result\n\n    f.__name__ = name\n    f.__doc__ = \"\\n{}\\n\".format(docstring)\n    return property(f)\n\n\ndef _td_array_cmp(cls, op):\n    \"\"\"\n    Wrap comparison operations to convert timedelta-like to timedelta64\n    \"\"\"\n    opname = '__{name}__'.format(name=op.__name__)\n    nat_result = True if opname == '__ne__' else False\n\n    meth = getattr(dtl.DatetimeLikeArrayMixin, opname)\n\n    def wrapper(self, other):\n        if _is_convertible_to_td(other) or other is NaT:\n            try:\n                other = _to_m8(other)\n            except ValueError:\n                # failed to parse as timedelta\n                return ops.invalid_comparison(self, other, op)\n\n            result = meth(self, other)\n            if isna(other):\n                result.fill(nat_result)\n\n        elif not is_list_like(other):\n            return ops.invalid_comparison(self, other, op)\n\n        elif len(other) != len(self):\n            raise ValueError(\"Lengths must match\")\n\n        else:\n            try:\n                other = type(self)._from_sequence(other)._data\n            except (ValueError, TypeError):\n                return ops.invalid_comparison(self, other, op)\n\n            result = meth(self, other)\n            result = com.values_from_object(result)\n\n            o_mask = np.array(isna(other))\n            if o_mask.any():\n                result[o_mask] = nat_result\n\n        if self._hasnans:\n            result[self._isnan] = nat_result\n\n        return result\n\n    return compat.set_function_name(wrapper, opname, cls)\n\n\nclass TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps):\n    _typ = \"timedeltaarray\"\n    _scalar_type = Timedelta\n    __array_priority__ = 1000\n    # define my properties & methods for delegation\n    _other_ops = []\n    _bool_ops = []\n    _object_ops = ['freq']\n    _field_ops = ['days', 'seconds', 'microseconds', 'nanoseconds']\n    _datetimelike_ops = _field_ops + _object_ops + _bool_ops\n    _datetimelike_methods = [\"to_pytimedelta\", \"total_seconds\",\n                             \"round\", \"floor\", \"ceil\"]\n\n    # Needed so that NaT.__richcmp__(DateTimeArray) operates pointwise\n    ndim = 1\n\n    @property\n    def _box_func(self):\n        return lambda x: Timedelta(x, unit='ns')\n\n    @property\n    def dtype(self):\n        return _TD_DTYPE\n\n    # ----------------------------------------------------------------\n    # Constructors\n    _attributes = [\"freq\"]\n\n    def __init__(self, values, dtype=_TD_DTYPE, freq=None, copy=False):\n        if isinstance(values, (ABCSeries, ABCIndexClass)):\n            values = values._values\n\n        if isinstance(values, type(self)):\n            values, freq, freq_infer = extract_values_freq(values, freq)\n\n        if not isinstance(values, np.ndarray):\n            msg = (\n                \"Unexpected type '{}'. 'values' must be a TimedeltaArray \"\n                \"ndarray, or Series or Index containing one of those.\"\n            )\n            raise ValueError(msg.format(type(values).__name__))\n\n        if values.dtype == 'i8':\n            # for compat with datetime/timedelta/period shared methods,\n            #  we can sometimes get here with int64 values.  These represent\n            #  nanosecond UTC (or tz-naive) unix timestamps\n            values = values.view(_TD_DTYPE)\n\n        if values.dtype != _TD_DTYPE:\n            raise TypeError(_BAD_DTYPE.format(dtype=values.dtype))\n\n        try:\n            dtype_mismatch = dtype != _TD_DTYPE\n        except TypeError:\n            raise TypeError(_BAD_DTYPE.format(dtype=dtype))\n        else:\n            if dtype_mismatch:\n                raise TypeError(_BAD_DTYPE.format(dtype=dtype))\n\n        if freq == \"infer\":\n            msg = (\n                \"Frequency inference not allowed in TimedeltaArray.__init__. \"\n                \"Use 'pd.array()' instead.\"\n            )\n            raise ValueError(msg)\n\n        if copy:\n            values = values.copy()\n        if freq:\n            freq = to_offset(freq)\n\n        self._data = values\n        self._dtype = dtype\n        self._freq = freq\n\n    @classmethod\n    def _simple_new(cls, values, freq=None, dtype=_TD_DTYPE):\n        return cls(values, dtype=dtype, freq=freq)\n\n    @classmethod\n    def _from_sequence(cls, data, dtype=_TD_DTYPE, copy=False,\n                       freq=None, unit=None):\n        if dtype != _TD_DTYPE:\n            raise ValueError(\"Only timedelta64[ns] dtype is valid.\")\n\n        freq, freq_infer = dtl.maybe_infer_freq(freq)\n\n        data, inferred_freq = sequence_to_td64ns(data, copy=copy, unit=unit)\n        freq, freq_infer = dtl.validate_inferred_freq(freq, inferred_freq,\n                                                      freq_infer)\n\n        result = cls._simple_new(data, freq=freq)\n\n        if inferred_freq is None and freq is not None:\n            # this condition precludes `freq_infer`\n            cls._validate_frequency(result, freq)\n\n        elif freq_infer:\n            result.freq = to_offset(result.inferred_freq)\n\n        return result\n\n    @classmethod\n    def _generate_range(cls, start, end, periods, freq, closed=None):\n\n        periods = dtl.validate_periods(periods)\n        if freq is None and any(x is None for x in [periods, start, end]):\n            raise ValueError('Must provide freq argument if no data is '\n                             'supplied')\n\n        if com.count_not_none(start, end, periods, freq) != 3:\n            raise ValueError('Of the four parameters: start, end, periods, '\n                             'and freq, exactly three must be specified')\n\n        if start is not None:\n            start = Timedelta(start)\n\n        if end is not None:\n            end = Timedelta(end)\n\n        if start is None and end is None:\n            if closed is not None:\n                raise ValueError(\"Closed has to be None if not both of start\"\n                                 \"and end are defined\")\n\n        left_closed, right_closed = dtl.validate_endpoints(closed)\n\n        if freq is not None:\n            index = _generate_regular_range(start, end, periods, freq)\n        else:\n            index = np.linspace(start.value, end.value, periods).astype('i8')\n\n        if not left_closed:\n            index = index[1:]\n        if not right_closed:\n            index = index[:-1]\n\n        return cls._simple_new(index, freq=freq)\n\n    # ----------------------------------------------------------------\n    # DatetimeLike Interface\n\n    def _unbox_scalar(self, value):\n        if not isinstance(value, self._scalar_type) and value is not NaT:\n            raise ValueError(\"'value' should be a Timedelta.\")\n        self._check_compatible_with(value)\n        return value.value\n\n    def _scalar_from_string(self, value):\n        return Timedelta(value)\n\n    def _check_compatible_with(self, other):\n        # we don't have anything to validate.\n        pass\n\n    def _maybe_clear_freq(self):\n        self._freq = None\n\n    # ----------------------------------------------------------------\n    # Array-Like / EA-Interface Methods\n\n    def __array__(self, dtype=None):\n        # TODO(https://github.com/pandas-dev/pandas/pull/23593)\n        # Maybe push to parent once datetimetz __array__ is figured out.\n        if is_object_dtype(dtype):\n            return np.array(list(self), dtype=object)\n        elif is_int64_dtype(dtype):\n            return self.asi8\n\n        return self._data\n\n    @Appender(dtl.DatetimeLikeArrayMixin._validate_fill_value.__doc__)\n    def _validate_fill_value(self, fill_value):\n        if isna(fill_value):\n            fill_value = iNaT\n        elif isinstance(fill_value, (timedelta, np.timedelta64, Tick)):\n            fill_value = Timedelta(fill_value).value\n        else:\n            raise ValueError(\"'fill_value' should be a Timedelta. \"\n                             \"Got '{got}'.\".format(got=fill_value))\n        return fill_value\n\n    def astype(self, dtype, copy=True):\n        # We handle\n        #   --> timedelta64[ns]\n        #   --> timedelta64\n        # DatetimeLikeArrayMixin super call handles other cases\n        dtype = pandas_dtype(dtype)\n\n        if is_timedelta64_dtype(dtype) and not is_timedelta64_ns_dtype(dtype):\n            # by pandas convention, converting to non-nano timedelta64\n            #  returns an int64-dtyped array with ints representing multiples\n            #  of the desired timedelta unit.  This is essentially division\n            if self._hasnans:\n                # avoid double-copying\n                result = self._data.astype(dtype, copy=False)\n                values = self._maybe_mask_results(result,\n                                                  fill_value=None,\n                                                  convert='float64')\n                return values\n            result = self._data.astype(dtype, copy=copy)\n            return result.astype('i8')\n        elif is_timedelta64_ns_dtype(dtype):\n            if copy:\n                return self.copy()\n            return self\n        return dtl.DatetimeLikeArrayMixin.astype(self, dtype, copy=copy)\n\n    # ----------------------------------------------------------------\n    # Rendering Methods\n\n    def _formatter(self, boxed=False):\n        from pandas.io.formats.format import _get_format_timedelta64\n        return _get_format_timedelta64(self, box=True)\n\n    def _format_native_types(self, na_rep='NaT', date_format=None):\n        from pandas.io.formats.format import _get_format_timedelta64\n\n        formatter = _get_format_timedelta64(self._data, na_rep)\n        return np.array([formatter(x) for x in self._data])\n\n    # ----------------------------------------------------------------\n    # Arithmetic Methods\n\n    _create_comparison_method = classmethod(_td_array_cmp)\n\n    def _add_offset(self, other):\n        assert not isinstance(other, Tick)\n        raise TypeError(\"cannot add the type {typ} to a {cls}\"\n                        .format(typ=type(other).__name__,\n                                cls=type(self).__name__))\n\n    def _add_delta(self, delta):\n        \"\"\"\n        Add a timedelta-like, Tick, or TimedeltaIndex-like object\n        to self, yielding a new TimedeltaArray.\n\n        Parameters\n        ----------\n        other : {timedelta, np.timedelta64, Tick,\n                 TimedeltaIndex, ndarray[timedelta64]}\n\n        Returns\n        -------\n        result : TimedeltaArray\n        \"\"\"\n        new_values = super(TimedeltaArrayMixin, self)._add_delta(delta)\n        return type(self)._from_sequence(new_values, freq='infer')\n\n    def _add_datetime_arraylike(self, other):\n        \"\"\"\n        Add DatetimeArray/Index or ndarray[datetime64] to TimedeltaArray.\n        \"\"\"\n        if isinstance(other, np.ndarray):\n            # At this point we have already checked that dtype is datetime64\n            from pandas.core.arrays import DatetimeArrayMixin\n            other = DatetimeArrayMixin(other)\n\n        # defer to implementation in DatetimeArray\n        return other + self\n\n    def _add_datetimelike_scalar(self, other):\n        # adding a timedeltaindex to a datetimelike\n        from pandas.core.arrays import DatetimeArrayMixin\n\n        assert other is not NaT\n        other = Timestamp(other)\n        if other is NaT:\n            # In this case we specifically interpret NaT as a datetime, not\n            # the timedelta interpretation we would get by returning self + NaT\n            result = self.asi8.view('m8[ms]') + NaT.to_datetime64()\n            return DatetimeArrayMixin(result)\n\n        i8 = self.asi8\n        result = checked_add_with_arr(i8, other.value,\n                                      arr_mask=self._isnan)\n        result = self._maybe_mask_results(result)\n        dtype = DatetimeTZDtype(tz=other.tz) if other.tz else _NS_DTYPE\n        return DatetimeArrayMixin(result, dtype=dtype, freq=self.freq)\n\n    def _addsub_offset_array(self, other, op):\n        # Add or subtract Array-like of DateOffset objects\n        try:\n            # TimedeltaIndex can only operate with a subset of DateOffset\n            # subclasses.  Incompatible classes will raise AttributeError,\n            # which we re-raise as TypeError\n            return super(TimedeltaArrayMixin, self)._addsub_offset_array(\n                other, op\n            )\n        except AttributeError:\n            raise TypeError(\"Cannot add/subtract non-tick DateOffset to {cls}\"\n                            .format(cls=type(self).__name__))\n\n    def __mul__(self, other):\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCDataFrame, ABCSeries, ABCIndexClass)):\n            return NotImplemented\n\n        if is_scalar(other):\n            # numpy will accept float and int, raise TypeError for others\n            result = self._data * other\n            freq = None\n            if self.freq is not None and not isna(other):\n                freq = self.freq * other\n            return type(self)(result, freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self) and not is_timedelta64_dtype(other):\n            # Exclude timedelta64 here so we correctly raise TypeError\n            #  for that instead of ValueError\n            raise ValueError(\"Cannot multiply with unequal lengths\")\n\n        if is_object_dtype(other):\n            # this multiplication will succeed only if all elements of other\n            #  are int or float scalars, so we will end up with\n            #  timedelta64[ns]-dtyped result\n            result = [self[n] * other[n] for n in range(len(self))]\n            result = np.array(result)\n            return type(self)(result)\n\n        # numpy will accept float or int dtype, raise TypeError for others\n        result = self._data * other\n        return type(self)(result)\n\n    __rmul__ = __mul__\n\n    def __truediv__(self, other):\n        # timedelta / X is well-defined for timedelta-like or numeric X\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n            if other is NaT:\n                # specifically timedelta64-NaT\n                result = np.empty(self.shape, dtype=np.float64)\n                result.fill(np.nan)\n                return result\n\n            # otherwise, dispatch to Timedelta implementation\n            return self._data / other\n\n        elif lib.is_scalar(other):\n            # assume it is numeric\n            result = self._data / other\n            freq = None\n            if self.freq is not None:\n                # Tick division is not implemented, so operate on Timedelta\n                freq = self.freq.delta / other\n            return type(self)(result, freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # e.g. list, tuple\n            other = np.array(other)\n\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide vectors with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            # let numpy handle it\n            return self._data / other\n\n        elif is_object_dtype(other):\n            # Note: we do not do type inference on the result, so either\n            #  an object array or numeric-dtyped (if numpy does inference)\n            #  will be returned.  GH#23829\n            result = [self[n] / other[n] for n in range(len(self))]\n            result = np.array(result)\n            return result\n\n        else:\n            result = self._data / other\n            return type(self)(result)\n\n    def __rtruediv__(self, other):\n        # X / timedelta is defined only for timedelta-like X\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n            if other is NaT:\n                # specifically timedelta64-NaT\n                result = np.empty(self.shape, dtype=np.float64)\n                result.fill(np.nan)\n                return result\n\n            # otherwise, dispatch to Timedelta implementation\n            return other / self._data\n\n        elif lib.is_scalar(other):\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=type(other).__name__,\n                                    cls=type(self).__name__))\n\n        if not hasattr(other, \"dtype\"):\n            # e.g. list, tuple\n            other = np.array(other)\n\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide vectors with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            # let numpy handle it\n            return other / self._data\n\n        elif is_object_dtype(other):\n            # Note: unlike in __truediv__, we do not _need_ to do type#\n            #  inference on the result.  It does not raise, a numeric array\n            #  is returned.  GH#23829\n            result = [other[n] / self[n] for n in range(len(self))]\n            return np.array(result)\n\n        else:\n            raise TypeError(\"Cannot divide {dtype} data by {cls}\"\n                            .format(dtype=other.dtype,\n                                    cls=type(self).__name__))\n\n    if compat.PY2:\n        __div__ = __truediv__\n        __rdiv__ = __rtruediv__\n\n    def __floordiv__(self, other):\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if is_scalar(other):\n            if isinstance(other, (timedelta, np.timedelta64, Tick)):\n                other = Timedelta(other)\n                if other is NaT:\n                    # treat this specifically as timedelta-NaT\n                    result = np.empty(self.shape, dtype=np.float64)\n                    result.fill(np.nan)\n                    return result\n\n                # dispatch to Timedelta implementation\n                result = other.__rfloordiv__(self._data)\n                return result\n\n            # at this point we should only have numeric scalars; anything\n            #  else will raise\n            result = self.asi8 // other\n            result[self._isnan] = iNaT\n            freq = None\n            if self.freq is not None:\n                # Note: freq gets division, not floor-division\n                freq = self.freq / other\n            return type(self)(result.view('m8[ns]'), freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            other = type(self)(other)\n\n            # numpy timedelta64 does not natively support floordiv, so operate\n            #  on the i8 values\n            result = self.asi8 // other.asi8\n            mask = self._isnan | other._isnan\n            if mask.any():\n                result = result.astype(np.int64)\n                result[mask] = np.nan\n            return result\n\n        elif is_object_dtype(other):\n            result = [self[n] // other[n] for n in range(len(self))]\n            result = np.array(result)\n            if lib.infer_dtype(result) == 'timedelta':\n                result, _ = sequence_to_td64ns(result)\n                return type(self)(result)\n            return result\n\n        elif is_integer_dtype(other) or is_float_dtype(other):\n            result = self._data // other\n            return type(self)(result)\n\n        else:\n            dtype = getattr(other, \"dtype\", type(other).__name__)\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=dtype, cls=type(self).__name__))\n\n    def __rfloordiv__(self, other):\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if is_scalar(other):\n            if isinstance(other, (timedelta, np.timedelta64, Tick)):\n                other = Timedelta(other)\n                if other is NaT:\n                    # treat this specifically as timedelta-NaT\n                    result = np.empty(self.shape, dtype=np.float64)\n                    result.fill(np.nan)\n                    return result\n\n                # dispatch to Timedelta implementation\n                result = other.__floordiv__(self._data)\n                return result\n\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=type(other).__name__,\n                                    cls=type(self).__name__))\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            other = type(self)(other)\n\n            # numpy timedelta64 does not natively support floordiv, so operate\n            #  on the i8 values\n            result = other.asi8 // self.asi8\n            mask = self._isnan | other._isnan\n            if mask.any():\n                result = result.astype(np.int64)\n                result[mask] = np.nan\n            return result\n\n        elif is_object_dtype(other):\n            result = [other[n] // self[n] for n in range(len(self))]\n            result = np.array(result)\n            return result\n\n        else:\n            dtype = getattr(other, \"dtype\", type(other).__name__)\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=dtype, cls=type(self).__name__))\n\n    def __mod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n        return self - (self // other) * other\n\n    def __rmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n        return other - (other // self) * self\n\n    def __divmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n\n        res1 = self // other\n        res2 = self - res1 * other\n        return res1, res2\n\n    def __rdivmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n\n        res1 = other // self\n        res2 = other - res1 * self\n        return res1, res2\n\n    # Note: TimedeltaIndex overrides this in call to cls._add_numeric_methods\n    def __neg__(self):\n        if self.freq is not None:\n            return type(self)(-self._data, freq=-self.freq)\n        return type(self)(-self._data)\n\n    def __abs__(self):\n        # Note: freq is not preserved\n        return type(self)(np.abs(self._data))\n\n    # ----------------------------------------------------------------\n    # Conversion Methods - Vectorized analogues of Timedelta methods\n\n    def total_seconds(self):\n        \"\"\"\n        Return total duration of each element expressed in seconds.\n\n        This method is available directly on TimedeltaArray, TimedeltaIndex\n        and on Series containing timedelta values under the ``.dt`` namespace.\n\n        Returns\n        -------\n        seconds : [ndarray, Float64Index, Series]\n            When the calling object is a TimedeltaArray, the return type\n            is ndarray.  When the calling object is a TimedeltaIndex,\n            the return type is a Float64Index. When the calling object\n            is a Series, the return type is Series of type `float64` whose\n            index is the same as the original.\n\n        See Also\n        --------\n        datetime.timedelta.total_seconds : Standard library version\n            of this method.\n        TimedeltaIndex.components : Return a DataFrame with components of\n            each Timedelta.\n\n        Examples\n        --------\n        **Series**\n\n        >>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='d'))\n        >>> s\n        0   0 days\n        1   1 days\n        2   2 days\n        3   3 days\n        4   4 days\n        dtype: timedelta64[ns]\n\n        >>> s.dt.total_seconds()\n        0         0.0\n        1     86400.0\n        2    172800.0\n        3    259200.0\n        4    345600.0\n        dtype: float64\n\n        **TimedeltaIndex**\n\n        >>> idx = pd.to_timedelta(np.arange(5), unit='d')\n        >>> idx\n        TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],\n                       dtype='timedelta64[ns]', freq=None)\n\n        >>> idx.total_seconds()\n        Float64Index([0.0, 86400.0, 172800.0, 259200.00000000003, 345600.0],\n                     dtype='float64')\n        \"\"\"\n        return self._maybe_mask_results(1e-9 * self.asi8, fill_value=None)\n\n    def to_pytimedelta(self):\n        \"\"\"\n        Return Timedelta Array/Index as object ndarray of datetime.timedelta\n        objects.\n\n        Returns\n        -------\n        datetimes : ndarray\n        \"\"\"\n        return tslibs.ints_to_pytimedelta(self.asi8)\n\n    days = _field_accessor(\"days\", \"days\",\n                           \"Number of days for each element.\")\n    seconds = _field_accessor(\"seconds\", \"seconds\",\n                              \"Number of seconds (>= 0 and less than 1 day) \"\n                              \"for each element.\")\n    microseconds = _field_accessor(\"microseconds\", \"microseconds\",\n                                   \"Number of microseconds (>= 0 and less \"\n                                   \"than 1 second) for each element.\")\n    nanoseconds = _field_accessor(\"nanoseconds\", \"nanoseconds\",\n                                  \"Number of nanoseconds (>= 0 and less \"\n                                  \"than 1 microsecond) for each element.\")\n\n    @property\n    def components(self):\n        \"\"\"\n        Return a dataframe of the components (days, hours, minutes,\n        seconds, milliseconds, microseconds, nanoseconds) of the Timedeltas.\n\n        Returns\n        -------\n        a DataFrame\n        \"\"\"\n        from pandas import DataFrame\n\n        columns = ['days', 'hours', 'minutes', 'seconds',\n                   'milliseconds', 'microseconds', 'nanoseconds']\n        hasnans = self._hasnans\n        if hasnans:\n            def f(x):\n                if isna(x):\n                    return [np.nan] * len(columns)\n                return x.components\n        else:\n            def f(x):\n                return x.components\n\n        result = DataFrame([f(x) for x in self], columns=columns)\n        if not hasnans:\n            result = result.astype('int64')\n        return result\n\n\nTimedeltaArrayMixin._add_comparison_ops()\n\n\n# ---------------------------------------------------------------------\n# Constructor Helpers\n\ndef sequence_to_td64ns(data, copy=False, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Parameters\n    ----------\n    array : list-like\n    copy : bool, default False\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    converted : numpy.ndarray\n        The sequence converted to a numpy array with dtype ``timedelta64[ns]``.\n    inferred_freq : Tick or None\n        The inferred frequency of the sequence.\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting ``errors=ignore`` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    inferred_freq = None\n    unit = parse_timedelta_unit(unit)\n\n    # Unwrap whatever we have into a np.ndarray\n    if not hasattr(data, 'dtype'):\n        # e.g. list, tuple\n        if np.ndim(data) == 0:\n            # i.e. generator\n            data = list(data)\n        data = np.array(data, copy=False)\n    elif isinstance(data, ABCSeries):\n        data = data._values\n    elif isinstance(data, (ABCTimedeltaIndex, TimedeltaArrayMixin)):\n        inferred_freq = data.freq\n        data = data._data\n\n    # Convert whatever we have into timedelta64[ns] dtype\n    if is_object_dtype(data) or is_string_dtype(data):\n        # no need to make a copy, need to convert if string-dtyped\n        data = objects_to_td64ns(data, unit=unit, errors=errors)\n        copy = False\n\n    elif is_integer_dtype(data):\n        # treat as multiples of the given unit\n        data, copy_made = ints_to_td64ns(data, unit=unit)\n        copy = copy and not copy_made\n\n    elif is_float_dtype(data):\n        # treat as multiples of the given unit.  If after converting to nanos,\n        #  there are fractional components left, these are truncated\n        #  (i.e. NOT rounded)\n        mask = np.isnan(data)\n        coeff = np.timedelta64(1, unit) / np.timedelta64(1, 'ns')\n        data = (coeff * data).astype(np.int64).view('timedelta64[ns]')\n        data[mask] = iNaT\n        copy = False\n\n    elif is_timedelta64_dtype(data):\n        if data.dtype != _TD_DTYPE:\n            # non-nano unit\n            # TODO: watch out for overflows\n            data = data.astype(_TD_DTYPE)\n            copy = False\n\n    elif is_datetime64_dtype(data):\n        # GH#23539\n        warnings.warn(\"Passing datetime64-dtype data to TimedeltaIndex is \"\n                      \"deprecated, will raise a TypeError in a future \"\n                      \"version\",\n                      FutureWarning, stacklevel=4)\n        data = ensure_int64(data).view(_TD_DTYPE)\n\n    else:\n        raise TypeError(\"dtype {dtype} cannot be converted to timedelta64[ns]\"\n                        .format(dtype=data.dtype))\n\n    data = np.array(data, copy=copy)\n    assert data.dtype == 'm8[ns]', data\n    return data, inferred_freq\n\n\ndef ints_to_td64ns(data, unit=\"ns\"):\n    \"\"\"\n    Convert an ndarray with integer-dtype to timedelta64[ns] dtype, treating\n    the integers as multiples of the given timedelta unit.\n\n    Parameters\n    ----------\n    data : numpy.ndarray with integer-dtype\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n    bool : whether a copy was made\n    \"\"\"\n    copy_made = False\n    unit = unit if unit is not None else \"ns\"\n\n    if data.dtype != np.int64:\n        # converting to int64 makes a copy, so we can avoid\n        # re-copying later\n        data = data.astype(np.int64)\n        copy_made = True\n\n    if unit != \"ns\":\n        dtype_str = \"timedelta64[{unit}]\".format(unit=unit)\n        data = data.view(dtype_str)\n\n        # TODO: watch out for overflows when converting from lower-resolution\n        data = data.astype(\"timedelta64[ns]\")\n        # the astype conversion makes a copy, so we can avoid re-copying later\n        copy_made = True\n\n    else:\n        data = data.view(\"timedelta64[ns]\")\n\n    return data, copy_made\n\n\ndef objects_to_td64ns(data, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Convert a object-dtyped or string-dtyped array into an\n    timedelta64[ns]-dtyped array.\n\n    Parameters\n    ----------\n    data : ndarray or Index\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting `errors=ignore` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    # coerce Index to np.ndarray, converting string-dtype if necessary\n    values = np.array(data, dtype=np.object_, copy=False)\n\n    result = array_to_timedelta64(values,\n                                  unit=unit, errors=errors)\n    return result.view('timedelta64[ns]')\n\n\ndef _generate_regular_range(start, end, periods, offset):\n    stride = offset.nanos\n    if periods is None:\n        b = Timedelta(start).value\n        e = Timedelta(end).value\n        e += stride - e % stride\n    elif start is not None:\n        b = Timedelta(start).value\n        e = b + periods * stride\n    elif end is not None:\n        e = Timedelta(end).value + stride\n        b = e - periods * stride\n    else:\n        raise ValueError(\"at least 'start' or 'end' should be specified \"\n                         \"if a 'period' is given.\")\n\n    data = np.arange(b, e, stride, dtype=np.int64)\n    return data\n\n\ndef extract_values_freq(arr, freq):\n    # type: (TimedeltaArray, Offset) -> Tuple[ndarray, Offset, bool]\n    freq_infer = False\n    if freq is None:\n        freq = arr.freq\n    elif freq and arr.freq:\n        freq = to_offset(freq)\n        freq, freq_infer = dtl.validate_inferred_freq(\n            freq, arr.freq,\n            freq_infer=False\n        )\n    values = arr._data\n    return values, freq, freq_infer\n",
      "file_patch": "@@ -33,6 +33,8 @@ from pandas.tseries.offsets import Tick\n \n from . import datetimelike as dtl\n \n+_BAD_DTYPE = \"dtype {dtype} cannot be converted to timedelta64[ns]\"\n+\n \n def _to_m8(key):\n     \"\"\"\n@@ -142,25 +144,56 @@ class TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps):\n     # Constructors\n     _attributes = [\"freq\"]\n \n-    @classmethod\n-    def _simple_new(cls, values, freq=None, dtype=_TD_DTYPE):\n-        # `dtype` is passed by _shallow_copy in corner cases, should always\n-        #  be timedelta64[ns] if present\n-        assert dtype == _TD_DTYPE\n-        assert isinstance(values, np.ndarray), type(values)\n+    def __init__(self, values, dtype=_TD_DTYPE, freq=None, copy=False):\n+        if isinstance(values, (ABCSeries, ABCIndexClass)):\n+            values = values._values\n+\n+        if isinstance(values, type(self)):\n+            values, freq, freq_infer = extract_values_freq(values, freq)\n+\n+        if not isinstance(values, np.ndarray):\n+            msg = (\n+                \"Unexpected type '{}'. 'values' must be a TimedeltaArray \"\n+                \"ndarray, or Series or Index containing one of those.\"\n+            )\n+            raise ValueError(msg.format(type(values).__name__))\n \n         if values.dtype == 'i8':\n-            values = values.view('m8[ns]')\n+            # for compat with datetime/timedelta/period shared methods,\n+            #  we can sometimes get here with int64 values.  These represent\n+            #  nanosecond UTC (or tz-naive) unix timestamps\n+            values = values.view(_TD_DTYPE)\n \n-        assert values.dtype == 'm8[ns]'\n+        if values.dtype != _TD_DTYPE:\n+            raise TypeError(_BAD_DTYPE.format(dtype=values.dtype))\n \n-        result = object.__new__(cls)\n-        result._data = values\n-        result._freq = freq\n-        return result\n+        try:\n+            dtype_mismatch = dtype != _TD_DTYPE\n+        except TypeError:\n+            raise TypeError(_BAD_DTYPE.format(dtype=dtype))\n+        else:\n+            if dtype_mismatch:\n+                raise TypeError(_BAD_DTYPE.format(dtype=dtype))\n \n-    def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n-        return cls._from_sequence(values, dtype=dtype, copy=copy, freq=freq)\n+        if freq == \"infer\":\n+            msg = (\n+                \"Frequency inference not allowed in TimedeltaArray.__init__. \"\n+                \"Use 'pd.array()' instead.\"\n+            )\n+            raise ValueError(msg)\n+\n+        if copy:\n+            values = values.copy()\n+        if freq:\n+            freq = to_offset(freq)\n+\n+        self._data = values\n+        self._dtype = dtype\n+        self._freq = freq\n+\n+    @classmethod\n+    def _simple_new(cls, values, freq=None, dtype=_TD_DTYPE):\n+        return cls(values, dtype=dtype, freq=freq)\n \n     @classmethod\n     def _from_sequence(cls, data, dtype=_TD_DTYPE, copy=False,\n@@ -984,3 +1017,18 @@ def _generate_regular_range(start, end, periods, offset):\n \n     data = np.arange(b, e, stride, dtype=np.int64)\n     return data\n+\n+\n+def extract_values_freq(arr, freq):\n+    # type: (TimedeltaArray, Offset) -> Tuple[ndarray, Offset, bool]\n+    freq_infer = False\n+    if freq is None:\n+        freq = arr.freq\n+    elif freq and arr.freq:\n+        freq = to_offset(freq)\n+        freq, freq_infer = dtl.validate_inferred_freq(\n+            freq, arr.freq,\n+            freq_infer=False\n+        )\n+    values = arr._data\n+    return values, freq, freq_infer\n",
      "files_name_in_blame_commit": [
        "period.py",
        "managers.py",
        "test_timedeltas.py",
        "test_datetime.py",
        "generic.py",
        "test_block_internals.py",
        "cast.py",
        "pytables.py",
        "frame.py",
        "common.py",
        "base.py",
        "datetimes.py",
        "test_datetimes.py",
        "test_common.py",
        "test_concat.py",
        "test_indexing.py",
        "array.py",
        "test_internals.py",
        "construction.py",
        "test_panel.py",
        "testing.py",
        "test_base.py",
        "test_timedelta64.py",
        "test_parquet.py",
        "bool.py",
        "blocks.py",
        "datetimelike.py",
        "test_dtypes.py",
        "test_construction.py",
        "timedeltas.py",
        "concat.py",
        "dtypes.py",
        "test_timezones.py"
      ]
    }
  },
  "commits_modify_file_before_fix": {
    "size": 234
  },
  "recursive_blame_commits": {
    "recursive_blame_function_lines": {
      "162": {
        "commit_id": "b1ee2dff81ca65fcf0e57fa673cb6bf1e47c18d4",
        "line_code": "    def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):",
        "commit_date": "2018-11-29 00:33:32",
        "valid": 1
      },
      "163": {
        "commit_id": "4ae63aac0b6063b5a8c40cfe088b222d808153c0",
        "line_code": "        return cls._from_sequence(values, dtype=dtype, copy=copy, freq=freq)",
        "commit_date": "2018-12-05 17:44:50",
        "valid": 1
      }
    },
    "commits": {
      "4ae63aac0b6063b5a8c40cfe088b222d808153c0": {
        "commit": {
          "commit_id": "4ae63aac0b6063b5a8c40cfe088b222d808153c0",
          "commit_message": "Implement DatetimeArray._from_sequence (#24074)",
          "commit_author": "jbrockmendel",
          "commit_date": "2018-12-05 17:44:50",
          "commit_parent": "2643721fdd66f11fd91dc245ef200ba792836c56"
        },
        "function": {
          "function_name": "__new__",
          "function_code_before": "def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n    return cls._from_sequence(values, freq=freq, dtype=dtype, copy=copy)",
          "function_code_after": "def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n    return cls._from_sequence(values, dtype=dtype, copy=copy, freq=freq)",
          "function_before_start_line": 148,
          "function_before_end_line": 149,
          "function_after_start_line": 148,
          "function_after_end_line": 149,
          "function_before_token_count": 38,
          "function_after_token_count": 38,
          "functions_name_modified_file": [
            "_to_m8",
            "total_seconds",
            "_simple_new",
            "_generate_regular_range",
            "__rfloordiv__",
            "sequence_to_td64ns",
            "__mul__",
            "__floordiv__",
            "_from_sequence",
            "__neg__",
            "_addsub_offset_array",
            "__divmod__",
            "_is_monotonic_decreasing",
            "ints_to_td64ns",
            "to_pytimedelta",
            "_add_datetimelike_scalar",
            "__abs__",
            "__rmod__",
            "objects_to_td64ns",
            "_add_delta",
            "__rtruediv__",
            "_is_unique",
            "__mod__",
            "_is_convertible_to_td",
            "dtype",
            "__new__",
            "_box_func",
            "__rdivmod__",
            "_field_accessor",
            "_td_array_cmp",
            "_validate_fill_value",
            "_generate_range",
            "_add_offset",
            "_add_datetime_arraylike",
            "_is_monotonic_increasing",
            "components",
            "__truediv__"
          ],
          "functions_name_all_files": [
            "_local_timestamps",
            "_add_delta_tdi",
            "_generate_range_overflow_safe",
            "total_seconds",
            "start_time",
            "date_range",
            "freq",
            "period_range",
            "_is_dates_only",
            "_sub_nat",
            "_has_same_tz",
            "is_normalized",
            "freqstr",
            "validate_tz_from_dtype",
            "_sub_period_array",
            "ints_to_td64ns",
            "to_pytimedelta",
            "get_loc",
            "validate_periods",
            "_maybe_convert_timedelta",
            "nbytes",
            "_attributes",
            "_wrap_joined_index",
            "resolution",
            "_get_unique_index",
            "__rtruediv__",
            "date",
            "tzinfo",
            "cdate_range",
            "_addsub_int_array",
            "_sub_period",
            "_evaluate_compare",
            "dtype",
            "__new__",
            "_box_func",
            "searchsorted",
            "is_full",
            "_round",
            "_add_datetimelike_methods",
            "_engine",
            "_format_native_types",
            "unique",
            "_td_array_cmp",
            "_int64index",
            "__getitem__",
            "__init__",
            "_generate_range",
            "__sub__",
            "_apply_meta",
            "to_timestamp",
            "_add_datetime_arraylike",
            "union_many",
            "shape",
            "_maybe_update_attributes",
            "__setstate__",
            "timetz",
            "components",
            "__truediv__",
            "__rsub__",
            "_sub_datetime_arraylike",
            "tz_convert",
            "asfreq",
            "_simple_new",
            "_isnan",
            "__rfloordiv__",
            "sequence_to_td64ns",
            "_values",
            "offset",
            "indexer_between_time",
            "__floordiv__",
            "_convert_for_op",
            "maybe_infer_freq",
            "shift",
            "_make_field_arrays",
            "size",
            "_formatter_func",
            "hasnans",
            "_range_from_fields",
            "_box_values",
            "get_value_maybe_box",
            "_maybe_localize_point",
            "base",
            "_ndarray_values",
            "__rmod__",
            "to_julian_date",
            "objects_to_td64ns",
            "_resolution",
            "_add_delta",
            "__contains__",
            "get_indexer",
            "_is_unique",
            "__mod__",
            "asof_locs",
            "take",
            "_parsed_string_to_bounds",
            "_timezone",
            "_get_time_micros",
            "validate_endpoints",
            "_create_comparison_method",
            "_maybe_mask_results",
            "__reduce__",
            "_add_nat",
            "dt64arr_to_periodarr",
            "union",
            "_from_datetime64",
            "_add_offset",
            "is_all_dates",
            "inferred_type",
            "__len__",
            "_wrap_setop_result",
            "slice_indexer",
            "_shallow_copy",
            "_values_for_factorize",
            "astype",
            "__isub__",
            "_generate_regular_range",
            "period_array",
            "view",
            "_maybe_utc_convert",
            "time",
            "__mul__",
            "_can_fast_union",
            "inferred_freq",
            "tz_localize",
            "_convert_tolerance",
            "insert",
            "value_counts",
            "asi8",
            "normalize",
            "__abs__",
            "isna",
            "__radd__",
            "day_name",
            "sequence_to_dt64ns",
            "_check_timedeltalike_freq_compat",
            "_maybe_cast_slice_bound",
            "__array__",
            "__add__",
            "strftime",
            "_sub_datetimelike_scalar",
            "item",
            "_values_for_argsort",
            "_validate_fill_value",
            "_formatter",
            "_get_attributes_dict",
            "month_name",
            "to_period",
            "fillna",
            "_assert_can_do_setop",
            "_time_shift",
            "_new_DatetimeIndex",
            "ceil",
            "is_type_compatible",
            "__iadd__",
            "copy",
            "_is_monotonic_increasing",
            "_maybe_box_as_values",
            "_new_PeriodIndex",
            "_mpl_repr",
            "_add_timedeltalike_scalar",
            "__setitem__",
            "_make_comparison_op",
            "to_perioddelta",
            "bdate_range",
            "_fast_union",
            "_to_m8",
            "_join_i8_wrapper",
            "maybe_infer_tz",
            "_maybe_normalize_endpoints",
            "_from_sequence",
            "__neg__",
            "validate_inferred_freq",
            "_ensure_datetimelike_to_i8",
            "_addsub_offset_array",
            "indexer_at_time",
            "_period_array_cmp",
            "__divmod__",
            "to_pydatetime",
            "_time_to_micros",
            "_is_monotonic_decreasing",
            "_validate_frequency",
            "_add_datetimelike_scalar",
            "_infer_tz_from_endpoints",
            "_get_string_slice",
            "__iter__",
            "is_leap_year",
            "_dt_array_cmp",
            "intersection",
            "snap",
            "_is_convertible_to_td",
            "round",
            "objects_to_datetime64ns",
            "_partial_date_slice",
            "data",
            "_sub_datelike",
            "_concat_same_type",
            "_shallow_copy_with_infer",
            "_coerce_scalar_to_index",
            "__array_wrap__",
            "repeat",
            "flags",
            "__rdivmod__",
            "_field_accessor",
            "get_value",
            "validate_dtype_freq",
            "maybe_convert_dtype",
            "delete",
            "_get_ordinal_range",
            "_from_factorized",
            "_maybe_promote",
            "values",
            "end_time",
            "tz",
            "to_series",
            "floor",
            "join",
            "_assert_tzawareness_compat"
          ],
          "functions_name_co_evolved_modified_file": [
            "_from_sequence"
          ],
          "functions_name_co_evolved_all_files": [
            "__init__",
            "validate_tz_from_dtype",
            "_new_DatetimeIndex",
            "maybe_infer_tz",
            "_from_sequence",
            "validate_dtype_freq",
            "validate_inferred_freq",
            "maybe_convert_dtype",
            "sequence_to_dt64ns"
          ]
        },
        "file": {
          "file_name": "timedeltas.py",
          "file_nloc": 500,
          "file_complexity": 155,
          "file_token_count": 3828,
          "file_before": "# -*- coding: utf-8 -*-\nfrom __future__ import division\n\nfrom datetime import timedelta\nimport warnings\n\nimport numpy as np\n\nfrom pandas._libs import algos, lib, tslibs\nfrom pandas._libs.tslibs import NaT, Timedelta, Timestamp, iNaT\nfrom pandas._libs.tslibs.fields import get_timedelta_field\nfrom pandas._libs.tslibs.timedeltas import (\n    array_to_timedelta64, parse_timedelta_unit)\nimport pandas.compat as compat\nfrom pandas.util._decorators import Appender\n\nfrom pandas.core.dtypes.common import (\n    _TD_DTYPE, ensure_int64, is_datetime64_dtype, is_float_dtype,\n    is_integer_dtype, is_list_like, is_object_dtype, is_scalar,\n    is_string_dtype, is_timedelta64_dtype)\nfrom pandas.core.dtypes.generic import (\n    ABCDataFrame, ABCIndexClass, ABCSeries, ABCTimedeltaIndex)\nfrom pandas.core.dtypes.missing import isna\n\nfrom pandas.core import ops\nfrom pandas.core.algorithms import checked_add_with_arr, unique1d\nimport pandas.core.common as com\n\nfrom pandas.tseries.frequencies import to_offset\nfrom pandas.tseries.offsets import Tick\n\nfrom . import datetimelike as dtl\n\n\ndef _to_m8(key):\n    \"\"\"\n    Timedelta-like => dt64\n    \"\"\"\n    if not isinstance(key, Timedelta):\n        # this also converts strings\n        key = Timedelta(key)\n\n    # return an type that can be compared\n    return np.int64(key.value).view(_TD_DTYPE)\n\n\ndef _is_convertible_to_td(key):\n    return isinstance(key, (Tick, timedelta,\n                            np.timedelta64, compat.string_types))\n\n\ndef _field_accessor(name, alias, docstring=None):\n    def f(self):\n        values = self.asi8\n        result = get_timedelta_field(values, alias)\n        if self.hasnans:\n            result = self._maybe_mask_results(result, fill_value=None,\n                                              convert='float64')\n\n        return result\n\n    f.__name__ = name\n    f.__doc__ = \"\\n{}\\n\".format(docstring)\n    return property(f)\n\n\ndef _td_array_cmp(cls, op):\n    \"\"\"\n    Wrap comparison operations to convert timedelta-like to timedelta64\n    \"\"\"\n    opname = '__{name}__'.format(name=op.__name__)\n    nat_result = True if opname == '__ne__' else False\n\n    meth = getattr(dtl.DatetimeLikeArrayMixin, opname)\n\n    def wrapper(self, other):\n        if _is_convertible_to_td(other) or other is NaT:\n            try:\n                other = _to_m8(other)\n            except ValueError:\n                # failed to parse as timedelta\n                return ops.invalid_comparison(self, other, op)\n\n            result = meth(self, other)\n            if isna(other):\n                result.fill(nat_result)\n\n        elif not is_list_like(other):\n            return ops.invalid_comparison(self, other, op)\n\n        else:\n            try:\n                other = type(self)(other)._data\n            except (ValueError, TypeError):\n                return ops.invalid_comparison(self, other, op)\n\n            result = meth(self, other)\n            result = com.values_from_object(result)\n\n            o_mask = np.array(isna(other))\n            if o_mask.any():\n                result[o_mask] = nat_result\n\n        if self.hasnans:\n            result[self._isnan] = nat_result\n\n        return result\n\n    return compat.set_function_name(wrapper, opname, cls)\n\n\nclass TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps):\n    _typ = \"timedeltaarray\"\n    __array_priority__ = 1000\n\n    # Needed so that NaT.__richcmp__(DateTimeArray) operates pointwise\n    ndim = 1\n\n    @property\n    def _box_func(self):\n        return lambda x: Timedelta(x, unit='ns')\n\n    @property\n    def dtype(self):\n        return _TD_DTYPE\n\n    # ----------------------------------------------------------------\n    # Constructors\n    _attributes = [\"freq\"]\n\n    @classmethod\n    def _simple_new(cls, values, freq=None, dtype=_TD_DTYPE):\n        # `dtype` is passed by _shallow_copy in corner cases, should always\n        #  be timedelta64[ns] if present\n        assert dtype == _TD_DTYPE\n        assert isinstance(values, np.ndarray), type(values)\n\n        if values.dtype == 'i8':\n            values = values.view('m8[ns]')\n\n        assert values.dtype == 'm8[ns]'\n\n        result = object.__new__(cls)\n        result._data = values\n        result._freq = freq\n        return result\n\n    def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n        return cls._from_sequence(values, freq=freq, dtype=dtype, copy=copy)\n\n    @classmethod\n    def _from_sequence(cls, data, freq=None, unit=None,\n                       dtype=_TD_DTYPE, copy=False):\n        if dtype != _TD_DTYPE:\n            raise ValueError(\"Only timedelta64[ns] dtype is valid.\")\n\n        freq, freq_infer = dtl.maybe_infer_freq(freq)\n\n        data, inferred_freq = sequence_to_td64ns(data, copy=copy, unit=unit)\n        if inferred_freq is not None:\n            if freq is not None and freq != inferred_freq:\n                raise ValueError('Inferred frequency {inferred} from passed '\n                                 'values does not conform to passed frequency '\n                                 '{passed}'\n                                 .format(inferred=inferred_freq,\n                                         passed=freq.freqstr))\n            elif freq is None:\n                freq = inferred_freq\n            freq_infer = False\n\n        result = cls._simple_new(data, freq=freq)\n\n        if inferred_freq is None and freq is not None:\n            # this condition precludes `freq_infer`\n            cls._validate_frequency(result, freq)\n\n        elif freq_infer:\n            result.freq = to_offset(result.inferred_freq)\n\n        return result\n\n    @classmethod\n    def _generate_range(cls, start, end, periods, freq, closed=None):\n\n        periods = dtl.validate_periods(periods)\n        if freq is None and any(x is None for x in [periods, start, end]):\n            raise ValueError('Must provide freq argument if no data is '\n                             'supplied')\n\n        if com.count_not_none(start, end, periods, freq) != 3:\n            raise ValueError('Of the four parameters: start, end, periods, '\n                             'and freq, exactly three must be specified')\n\n        if start is not None:\n            start = Timedelta(start)\n\n        if end is not None:\n            end = Timedelta(end)\n\n        if start is None and end is None:\n            if closed is not None:\n                raise ValueError(\"Closed has to be None if not both of start\"\n                                 \"and end are defined\")\n\n        left_closed, right_closed = dtl.validate_endpoints(closed)\n\n        if freq is not None:\n            index = _generate_regular_range(start, end, periods, freq)\n        else:\n            index = np.linspace(start.value, end.value, periods).astype('i8')\n\n        if not left_closed:\n            index = index[1:]\n        if not right_closed:\n            index = index[:-1]\n\n        return cls._simple_new(index, freq=freq)\n\n    # ----------------------------------------------------------------\n    # Array-Like / EA-Interface Methods\n\n    @Appender(dtl.DatetimeLikeArrayMixin._validate_fill_value.__doc__)\n    def _validate_fill_value(self, fill_value):\n        if isna(fill_value):\n            fill_value = iNaT\n        elif isinstance(fill_value, (timedelta, np.timedelta64, Tick)):\n            fill_value = Timedelta(fill_value).value\n        else:\n            raise ValueError(\"'fill_value' should be a Timedelta. \"\n                             \"Got '{got}'.\".format(got=fill_value))\n        return fill_value\n\n    # monotonicity/uniqueness properties are called via frequencies.infer_freq,\n    #  see GH#23789\n\n    @property\n    def _is_monotonic_increasing(self):\n        return algos.is_monotonic(self.asi8, timelike=True)[0]\n\n    @property\n    def _is_monotonic_decreasing(self):\n        return algos.is_monotonic(self.asi8, timelike=True)[1]\n\n    @property\n    def _is_unique(self):\n        return len(unique1d(self.asi8)) == len(self)\n\n    # ----------------------------------------------------------------\n    # Arithmetic Methods\n\n    _create_comparison_method = classmethod(_td_array_cmp)\n\n    def _add_offset(self, other):\n        assert not isinstance(other, Tick)\n        raise TypeError(\"cannot add the type {typ} to a {cls}\"\n                        .format(typ=type(other).__name__,\n                                cls=type(self).__name__))\n\n    def _add_delta(self, delta):\n        \"\"\"\n        Add a timedelta-like, Tick, or TimedeltaIndex-like object\n        to self, yielding a new TimedeltaArray.\n\n        Parameters\n        ----------\n        other : {timedelta, np.timedelta64, Tick,\n                 TimedeltaIndex, ndarray[timedelta64]}\n\n        Returns\n        -------\n        result : TimedeltaArray\n        \"\"\"\n        new_values = dtl.DatetimeLikeArrayMixin._add_delta(self, delta)\n        return type(self)(new_values, freq='infer')\n\n    def _add_datetime_arraylike(self, other):\n        \"\"\"\n        Add DatetimeArray/Index or ndarray[datetime64] to TimedeltaArray.\n        \"\"\"\n        if isinstance(other, np.ndarray):\n            # At this point we have already checked that dtype is datetime64\n            from pandas.core.arrays import DatetimeArrayMixin\n            other = DatetimeArrayMixin(other)\n\n        # defer to implementation in DatetimeArray\n        return other + self\n\n    def _add_datetimelike_scalar(self, other):\n        # adding a timedeltaindex to a datetimelike\n        from pandas.core.arrays import DatetimeArrayMixin\n\n        assert other is not NaT\n        other = Timestamp(other)\n        if other is NaT:\n            # In this case we specifically interpret NaT as a datetime, not\n            # the timedelta interpretation we would get by returning self + NaT\n            result = self.asi8.view('m8[ms]') + NaT.to_datetime64()\n            return DatetimeArrayMixin(result)\n\n        i8 = self.asi8\n        result = checked_add_with_arr(i8, other.value,\n                                      arr_mask=self._isnan)\n        result = self._maybe_mask_results(result)\n        return DatetimeArrayMixin(result, tz=other.tz, freq=self.freq)\n\n    def _addsub_offset_array(self, other, op):\n        # Add or subtract Array-like of DateOffset objects\n        try:\n            # TimedeltaIndex can only operate with a subset of DateOffset\n            # subclasses.  Incompatible classes will raise AttributeError,\n            # which we re-raise as TypeError\n            return dtl.DatetimeLikeArrayMixin._addsub_offset_array(self, other,\n                                                                   op)\n        except AttributeError:\n            raise TypeError(\"Cannot add/subtract non-tick DateOffset to {cls}\"\n                            .format(cls=type(self).__name__))\n\n    def __mul__(self, other):\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCDataFrame, ABCSeries, ABCIndexClass)):\n            return NotImplemented\n\n        if is_scalar(other):\n            # numpy will accept float and int, raise TypeError for others\n            result = self._data * other\n            freq = None\n            if self.freq is not None and not isna(other):\n                freq = self.freq * other\n            return type(self)(result, freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self) and not is_timedelta64_dtype(other):\n            # Exclude timedelta64 here so we correctly raise TypeError\n            #  for that instead of ValueError\n            raise ValueError(\"Cannot multiply with unequal lengths\")\n\n        if is_object_dtype(other):\n            # this multiplication will succeed only if all elements of other\n            #  are int or float scalars, so we will end up with\n            #  timedelta64[ns]-dtyped result\n            result = [self[n] * other[n] for n in range(len(self))]\n            result = np.array(result)\n            return type(self)(result)\n\n        # numpy will accept float or int dtype, raise TypeError for others\n        result = self._data * other\n        return type(self)(result)\n\n    __rmul__ = __mul__\n\n    def __truediv__(self, other):\n        # timedelta / X is well-defined for timedelta-like or numeric X\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n            if other is NaT:\n                # specifically timedelta64-NaT\n                result = np.empty(self.shape, dtype=np.float64)\n                result.fill(np.nan)\n                return result\n\n            # otherwise, dispatch to Timedelta implementation\n            return self._data / other\n\n        elif lib.is_scalar(other):\n            # assume it is numeric\n            result = self._data / other\n            freq = None\n            if self.freq is not None:\n                # Tick division is not implemented, so operate on Timedelta\n                freq = self.freq.delta / other\n            return type(self)(result, freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # e.g. list, tuple\n            other = np.array(other)\n\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide vectors with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            # let numpy handle it\n            return self._data / other\n\n        elif is_object_dtype(other):\n            # Note: we do not do type inference on the result, so either\n            #  an object array or numeric-dtyped (if numpy does inference)\n            #  will be returned.  GH#23829\n            result = [self[n] / other[n] for n in range(len(self))]\n            result = np.array(result)\n            return result\n\n        else:\n            result = self._data / other\n            return type(self)(result)\n\n    def __rtruediv__(self, other):\n        # X / timedelta is defined only for timedelta-like X\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n            if other is NaT:\n                # specifically timedelta64-NaT\n                result = np.empty(self.shape, dtype=np.float64)\n                result.fill(np.nan)\n                return result\n\n            # otherwise, dispatch to Timedelta implementation\n            return other / self._data\n\n        elif lib.is_scalar(other):\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=type(other).__name__,\n                                    cls=type(self).__name__))\n\n        if not hasattr(other, \"dtype\"):\n            # e.g. list, tuple\n            other = np.array(other)\n\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide vectors with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            # let numpy handle it\n            return other / self._data\n\n        elif is_object_dtype(other):\n            # Note: unlike in __truediv__, we do not _need_ to do type#\n            #  inference on the result.  It does not raise, a numeric array\n            #  is returned.  GH#23829\n            result = [other[n] / self[n] for n in range(len(self))]\n            return np.array(result)\n\n        else:\n            raise TypeError(\"Cannot divide {dtype} data by {cls}\"\n                            .format(dtype=other.dtype,\n                                    cls=type(self).__name__))\n\n    if compat.PY2:\n        __div__ = __truediv__\n        __rdiv__ = __rtruediv__\n\n    def __floordiv__(self, other):\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if is_scalar(other):\n            if isinstance(other, (timedelta, np.timedelta64, Tick)):\n                other = Timedelta(other)\n                if other is NaT:\n                    # treat this specifically as timedelta-NaT\n                    result = np.empty(self.shape, dtype=np.float64)\n                    result.fill(np.nan)\n                    return result\n\n                # dispatch to Timedelta implementation\n                result = other.__rfloordiv__(self._data)\n                return result\n\n            # at this point we should only have numeric scalars; anything\n            #  else will raise\n            result = self.asi8 // other\n            result[self._isnan] = iNaT\n            freq = None\n            if self.freq is not None:\n                # Note: freq gets division, not floor-division\n                freq = self.freq / other\n            return type(self)(result.view('m8[ns]'), freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            other = type(self)(other)\n\n            # numpy timedelta64 does not natively support floordiv, so operate\n            #  on the i8 values\n            result = self.asi8 // other.asi8\n            mask = self._isnan | other._isnan\n            if mask.any():\n                result = result.astype(np.int64)\n                result[mask] = np.nan\n            return result\n\n        elif is_object_dtype(other):\n            result = [self[n] // other[n] for n in range(len(self))]\n            result = np.array(result)\n            if lib.infer_dtype(result) == 'timedelta':\n                result, _ = sequence_to_td64ns(result)\n                return type(self)(result)\n            return result\n\n        elif is_integer_dtype(other) or is_float_dtype(other):\n            result = self._data // other\n            return type(self)(result)\n\n        else:\n            dtype = getattr(other, \"dtype\", type(other).__name__)\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=dtype, cls=type(self).__name__))\n\n    def __rfloordiv__(self, other):\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if is_scalar(other):\n            if isinstance(other, (timedelta, np.timedelta64, Tick)):\n                other = Timedelta(other)\n                if other is NaT:\n                    # treat this specifically as timedelta-NaT\n                    result = np.empty(self.shape, dtype=np.float64)\n                    result.fill(np.nan)\n                    return result\n\n                # dispatch to Timedelta implementation\n                result = other.__floordiv__(self._data)\n                return result\n\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=type(other).__name__,\n                                    cls=type(self).__name__))\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            other = type(self)(other)\n\n            # numpy timedelta64 does not natively support floordiv, so operate\n            #  on the i8 values\n            result = other.asi8 // self.asi8\n            mask = self._isnan | other._isnan\n            if mask.any():\n                result = result.astype(np.int64)\n                result[mask] = np.nan\n            return result\n\n        elif is_object_dtype(other):\n            result = [other[n] // self[n] for n in range(len(self))]\n            result = np.array(result)\n            return result\n\n        else:\n            dtype = getattr(other, \"dtype\", type(other).__name__)\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=dtype, cls=type(self).__name__))\n\n    def __mod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n        return self - (self // other) * other\n\n    def __rmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n        return other - (other // self) * self\n\n    def __divmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n\n        res1 = self // other\n        res2 = self - res1 * other\n        return res1, res2\n\n    def __rdivmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n\n        res1 = other // self\n        res2 = other - res1 * self\n        return res1, res2\n\n    # Note: TimedeltaIndex overrides this in call to cls._add_numeric_methods\n    def __neg__(self):\n        if self.freq is not None:\n            return type(self)(-self._data, freq=-self.freq)\n        return type(self)(-self._data)\n\n    def __abs__(self):\n        # Note: freq is not preserved\n        return type(self)(np.abs(self._data))\n\n    # ----------------------------------------------------------------\n    # Conversion Methods - Vectorized analogues of Timedelta methods\n\n    def total_seconds(self):\n        \"\"\"\n        Return total duration of each element expressed in seconds.\n\n        This method is available directly on TimedeltaArray, TimedeltaIndex\n        and on Series containing timedelta values under the ``.dt`` namespace.\n\n        Returns\n        -------\n        seconds : [ndarray, Float64Index, Series]\n            When the calling object is a TimedeltaArray, the return type\n            is ndarray.  When the calling object is a TimedeltaIndex,\n            the return type is a Float64Index. When the calling object\n            is a Series, the return type is Series of type `float64` whose\n            index is the same as the original.\n\n        See Also\n        --------\n        datetime.timedelta.total_seconds : Standard library version\n            of this method.\n        TimedeltaIndex.components : Return a DataFrame with components of\n            each Timedelta.\n\n        Examples\n        --------\n        **Series**\n\n        >>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='d'))\n        >>> s\n        0   0 days\n        1   1 days\n        2   2 days\n        3   3 days\n        4   4 days\n        dtype: timedelta64[ns]\n\n        >>> s.dt.total_seconds()\n        0         0.0\n        1     86400.0\n        2    172800.0\n        3    259200.0\n        4    345600.0\n        dtype: float64\n\n        **TimedeltaIndex**\n\n        >>> idx = pd.to_timedelta(np.arange(5), unit='d')\n        >>> idx\n        TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],\n                       dtype='timedelta64[ns]', freq=None)\n\n        >>> idx.total_seconds()\n        Float64Index([0.0, 86400.0, 172800.0, 259200.00000000003, 345600.0],\n                     dtype='float64')\n        \"\"\"\n        return self._maybe_mask_results(1e-9 * self.asi8, fill_value=None)\n\n    def to_pytimedelta(self):\n        \"\"\"\n        Return Timedelta Array/Index as object ndarray of datetime.timedelta\n        objects.\n\n        Returns\n        -------\n        datetimes : ndarray\n        \"\"\"\n        return tslibs.ints_to_pytimedelta(self.asi8)\n\n    days = _field_accessor(\"days\", \"days\",\n                           \"Number of days for each element.\")\n    seconds = _field_accessor(\"seconds\", \"seconds\",\n                              \"Number of seconds (>= 0 and less than 1 day) \"\n                              \"for each element.\")\n    microseconds = _field_accessor(\"microseconds\", \"microseconds\",\n                                   \"Number of microseconds (>= 0 and less \"\n                                   \"than 1 second) for each element.\")\n    nanoseconds = _field_accessor(\"nanoseconds\", \"nanoseconds\",\n                                  \"Number of nanoseconds (>= 0 and less \"\n                                  \"than 1 microsecond) for each element.\")\n\n    @property\n    def components(self):\n        \"\"\"\n        Return a dataframe of the components (days, hours, minutes,\n        seconds, milliseconds, microseconds, nanoseconds) of the Timedeltas.\n\n        Returns\n        -------\n        a DataFrame\n        \"\"\"\n        from pandas import DataFrame\n\n        columns = ['days', 'hours', 'minutes', 'seconds',\n                   'milliseconds', 'microseconds', 'nanoseconds']\n        hasnans = self.hasnans\n        if hasnans:\n            def f(x):\n                if isna(x):\n                    return [np.nan] * len(columns)\n                return x.components\n        else:\n            def f(x):\n                return x.components\n\n        result = DataFrame([f(x) for x in self], columns=columns)\n        if not hasnans:\n            result = result.astype('int64')\n        return result\n\n\nTimedeltaArrayMixin._add_comparison_ops()\n\n\n# ---------------------------------------------------------------------\n# Constructor Helpers\n\ndef sequence_to_td64ns(data, copy=False, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Parameters\n    ----------\n    array : list-like\n    copy : bool, default False\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    converted : numpy.ndarray\n        The sequence converted to a numpy array with dtype ``timedelta64[ns]``.\n    inferred_freq : Tick or None\n        The inferred frequency of the sequence.\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting ``errors=ignore`` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    inferred_freq = None\n    unit = parse_timedelta_unit(unit)\n\n    # Unwrap whatever we have into a np.ndarray\n    if not hasattr(data, 'dtype'):\n        # e.g. list, tuple\n        if np.ndim(data) == 0:\n            # i.e. generator\n            data = list(data)\n        data = np.array(data, copy=False)\n    elif isinstance(data, ABCSeries):\n        data = data._values\n    elif isinstance(data, (ABCTimedeltaIndex, TimedeltaArrayMixin)):\n        inferred_freq = data.freq\n        data = data._data\n\n    # Convert whatever we have into timedelta64[ns] dtype\n    if is_object_dtype(data) or is_string_dtype(data):\n        # no need to make a copy, need to convert if string-dtyped\n        data = objects_to_td64ns(data, unit=unit, errors=errors)\n        copy = False\n\n    elif is_integer_dtype(data):\n        # treat as multiples of the given unit\n        data, copy_made = ints_to_td64ns(data, unit=unit)\n        copy = copy and not copy_made\n\n    elif is_float_dtype(data):\n        # treat as multiples of the given unit.  If after converting to nanos,\n        #  there are fractional components left, these are truncated\n        #  (i.e. NOT rounded)\n        mask = np.isnan(data)\n        coeff = np.timedelta64(1, unit) / np.timedelta64(1, 'ns')\n        data = (coeff * data).astype(np.int64).view('timedelta64[ns]')\n        data[mask] = iNaT\n        copy = False\n\n    elif is_timedelta64_dtype(data):\n        if data.dtype != _TD_DTYPE:\n            # non-nano unit\n            # TODO: watch out for overflows\n            data = data.astype(_TD_DTYPE)\n            copy = False\n\n    elif is_datetime64_dtype(data):\n        # GH#23539\n        warnings.warn(\"Passing datetime64-dtype data to TimedeltaIndex is \"\n                      \"deprecated, will raise a TypeError in a future \"\n                      \"version\",\n                      FutureWarning, stacklevel=4)\n        data = ensure_int64(data).view(_TD_DTYPE)\n\n    else:\n        raise TypeError(\"dtype {dtype} cannot be converted to timedelta64[ns]\"\n                        .format(dtype=data.dtype))\n\n    data = np.array(data, copy=copy)\n    assert data.dtype == 'm8[ns]', data\n    return data, inferred_freq\n\n\ndef ints_to_td64ns(data, unit=\"ns\"):\n    \"\"\"\n    Convert an ndarray with integer-dtype to timedelta64[ns] dtype, treating\n    the integers as multiples of the given timedelta unit.\n\n    Parameters\n    ----------\n    data : numpy.ndarray with integer-dtype\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n    bool : whether a copy was made\n    \"\"\"\n    copy_made = False\n    unit = unit if unit is not None else \"ns\"\n\n    if data.dtype != np.int64:\n        # converting to int64 makes a copy, so we can avoid\n        # re-copying later\n        data = data.astype(np.int64)\n        copy_made = True\n\n    if unit != \"ns\":\n        dtype_str = \"timedelta64[{unit}]\".format(unit=unit)\n        data = data.view(dtype_str)\n\n        # TODO: watch out for overflows when converting from lower-resolution\n        data = data.astype(\"timedelta64[ns]\")\n        # the astype conversion makes a copy, so we can avoid re-copying later\n        copy_made = True\n\n    else:\n        data = data.view(\"timedelta64[ns]\")\n\n    return data, copy_made\n\n\ndef objects_to_td64ns(data, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Convert a object-dtyped or string-dtyped array into an\n    timedelta64[ns]-dtyped array.\n\n    Parameters\n    ----------\n    data : ndarray or Index\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting `errors=ignore` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    # coerce Index to np.ndarray, converting string-dtype if necessary\n    values = np.array(data, dtype=np.object_, copy=False)\n\n    result = array_to_timedelta64(values,\n                                  unit=unit, errors=errors)\n    return result.view('timedelta64[ns]')\n\n\ndef _generate_regular_range(start, end, periods, offset):\n    stride = offset.nanos\n    if periods is None:\n        b = Timedelta(start).value\n        e = Timedelta(end).value\n        e += stride - e % stride\n    elif start is not None:\n        b = Timedelta(start).value\n        e = b + periods * stride\n    elif end is not None:\n        e = Timedelta(end).value + stride\n        b = e - periods * stride\n    else:\n        raise ValueError(\"at least 'start' or 'end' should be specified \"\n                         \"if a 'period' is given.\")\n\n    data = np.arange(b, e, stride, dtype=np.int64)\n    return data\n",
          "file_after": "# -*- coding: utf-8 -*-\nfrom __future__ import division\n\nfrom datetime import timedelta\nimport warnings\n\nimport numpy as np\n\nfrom pandas._libs import algos, lib, tslibs\nfrom pandas._libs.tslibs import NaT, Timedelta, Timestamp, iNaT\nfrom pandas._libs.tslibs.fields import get_timedelta_field\nfrom pandas._libs.tslibs.timedeltas import (\n    array_to_timedelta64, parse_timedelta_unit)\nimport pandas.compat as compat\nfrom pandas.util._decorators import Appender\n\nfrom pandas.core.dtypes.common import (\n    _TD_DTYPE, ensure_int64, is_datetime64_dtype, is_float_dtype,\n    is_integer_dtype, is_list_like, is_object_dtype, is_scalar,\n    is_string_dtype, is_timedelta64_dtype)\nfrom pandas.core.dtypes.generic import (\n    ABCDataFrame, ABCIndexClass, ABCSeries, ABCTimedeltaIndex)\nfrom pandas.core.dtypes.missing import isna\n\nfrom pandas.core import ops\nfrom pandas.core.algorithms import checked_add_with_arr, unique1d\nimport pandas.core.common as com\n\nfrom pandas.tseries.frequencies import to_offset\nfrom pandas.tseries.offsets import Tick\n\nfrom . import datetimelike as dtl\n\n\ndef _to_m8(key):\n    \"\"\"\n    Timedelta-like => dt64\n    \"\"\"\n    if not isinstance(key, Timedelta):\n        # this also converts strings\n        key = Timedelta(key)\n\n    # return an type that can be compared\n    return np.int64(key.value).view(_TD_DTYPE)\n\n\ndef _is_convertible_to_td(key):\n    return isinstance(key, (Tick, timedelta,\n                            np.timedelta64, compat.string_types))\n\n\ndef _field_accessor(name, alias, docstring=None):\n    def f(self):\n        values = self.asi8\n        result = get_timedelta_field(values, alias)\n        if self.hasnans:\n            result = self._maybe_mask_results(result, fill_value=None,\n                                              convert='float64')\n\n        return result\n\n    f.__name__ = name\n    f.__doc__ = \"\\n{}\\n\".format(docstring)\n    return property(f)\n\n\ndef _td_array_cmp(cls, op):\n    \"\"\"\n    Wrap comparison operations to convert timedelta-like to timedelta64\n    \"\"\"\n    opname = '__{name}__'.format(name=op.__name__)\n    nat_result = True if opname == '__ne__' else False\n\n    meth = getattr(dtl.DatetimeLikeArrayMixin, opname)\n\n    def wrapper(self, other):\n        if _is_convertible_to_td(other) or other is NaT:\n            try:\n                other = _to_m8(other)\n            except ValueError:\n                # failed to parse as timedelta\n                return ops.invalid_comparison(self, other, op)\n\n            result = meth(self, other)\n            if isna(other):\n                result.fill(nat_result)\n\n        elif not is_list_like(other):\n            return ops.invalid_comparison(self, other, op)\n\n        else:\n            try:\n                other = type(self)(other)._data\n            except (ValueError, TypeError):\n                return ops.invalid_comparison(self, other, op)\n\n            result = meth(self, other)\n            result = com.values_from_object(result)\n\n            o_mask = np.array(isna(other))\n            if o_mask.any():\n                result[o_mask] = nat_result\n\n        if self.hasnans:\n            result[self._isnan] = nat_result\n\n        return result\n\n    return compat.set_function_name(wrapper, opname, cls)\n\n\nclass TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps):\n    _typ = \"timedeltaarray\"\n    __array_priority__ = 1000\n\n    # Needed so that NaT.__richcmp__(DateTimeArray) operates pointwise\n    ndim = 1\n\n    @property\n    def _box_func(self):\n        return lambda x: Timedelta(x, unit='ns')\n\n    @property\n    def dtype(self):\n        return _TD_DTYPE\n\n    # ----------------------------------------------------------------\n    # Constructors\n    _attributes = [\"freq\"]\n\n    @classmethod\n    def _simple_new(cls, values, freq=None, dtype=_TD_DTYPE):\n        # `dtype` is passed by _shallow_copy in corner cases, should always\n        #  be timedelta64[ns] if present\n        assert dtype == _TD_DTYPE\n        assert isinstance(values, np.ndarray), type(values)\n\n        if values.dtype == 'i8':\n            values = values.view('m8[ns]')\n\n        assert values.dtype == 'm8[ns]'\n\n        result = object.__new__(cls)\n        result._data = values\n        result._freq = freq\n        return result\n\n    def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n        return cls._from_sequence(values, dtype=dtype, copy=copy, freq=freq)\n\n    @classmethod\n    def _from_sequence(cls, data, dtype=_TD_DTYPE, copy=False,\n                       freq=None, unit=None):\n        if dtype != _TD_DTYPE:\n            raise ValueError(\"Only timedelta64[ns] dtype is valid.\")\n\n        freq, freq_infer = dtl.maybe_infer_freq(freq)\n\n        data, inferred_freq = sequence_to_td64ns(data, copy=copy, unit=unit)\n        freq, freq_infer = dtl.validate_inferred_freq(freq, inferred_freq,\n                                                      freq_infer)\n\n        result = cls._simple_new(data, freq=freq)\n\n        if inferred_freq is None and freq is not None:\n            # this condition precludes `freq_infer`\n            cls._validate_frequency(result, freq)\n\n        elif freq_infer:\n            result.freq = to_offset(result.inferred_freq)\n\n        return result\n\n    @classmethod\n    def _generate_range(cls, start, end, periods, freq, closed=None):\n\n        periods = dtl.validate_periods(periods)\n        if freq is None and any(x is None for x in [periods, start, end]):\n            raise ValueError('Must provide freq argument if no data is '\n                             'supplied')\n\n        if com.count_not_none(start, end, periods, freq) != 3:\n            raise ValueError('Of the four parameters: start, end, periods, '\n                             'and freq, exactly three must be specified')\n\n        if start is not None:\n            start = Timedelta(start)\n\n        if end is not None:\n            end = Timedelta(end)\n\n        if start is None and end is None:\n            if closed is not None:\n                raise ValueError(\"Closed has to be None if not both of start\"\n                                 \"and end are defined\")\n\n        left_closed, right_closed = dtl.validate_endpoints(closed)\n\n        if freq is not None:\n            index = _generate_regular_range(start, end, periods, freq)\n        else:\n            index = np.linspace(start.value, end.value, periods).astype('i8')\n\n        if not left_closed:\n            index = index[1:]\n        if not right_closed:\n            index = index[:-1]\n\n        return cls._simple_new(index, freq=freq)\n\n    # ----------------------------------------------------------------\n    # Array-Like / EA-Interface Methods\n\n    @Appender(dtl.DatetimeLikeArrayMixin._validate_fill_value.__doc__)\n    def _validate_fill_value(self, fill_value):\n        if isna(fill_value):\n            fill_value = iNaT\n        elif isinstance(fill_value, (timedelta, np.timedelta64, Tick)):\n            fill_value = Timedelta(fill_value).value\n        else:\n            raise ValueError(\"'fill_value' should be a Timedelta. \"\n                             \"Got '{got}'.\".format(got=fill_value))\n        return fill_value\n\n    # monotonicity/uniqueness properties are called via frequencies.infer_freq,\n    #  see GH#23789\n\n    @property\n    def _is_monotonic_increasing(self):\n        return algos.is_monotonic(self.asi8, timelike=True)[0]\n\n    @property\n    def _is_monotonic_decreasing(self):\n        return algos.is_monotonic(self.asi8, timelike=True)[1]\n\n    @property\n    def _is_unique(self):\n        return len(unique1d(self.asi8)) == len(self)\n\n    # ----------------------------------------------------------------\n    # Arithmetic Methods\n\n    _create_comparison_method = classmethod(_td_array_cmp)\n\n    def _add_offset(self, other):\n        assert not isinstance(other, Tick)\n        raise TypeError(\"cannot add the type {typ} to a {cls}\"\n                        .format(typ=type(other).__name__,\n                                cls=type(self).__name__))\n\n    def _add_delta(self, delta):\n        \"\"\"\n        Add a timedelta-like, Tick, or TimedeltaIndex-like object\n        to self, yielding a new TimedeltaArray.\n\n        Parameters\n        ----------\n        other : {timedelta, np.timedelta64, Tick,\n                 TimedeltaIndex, ndarray[timedelta64]}\n\n        Returns\n        -------\n        result : TimedeltaArray\n        \"\"\"\n        new_values = dtl.DatetimeLikeArrayMixin._add_delta(self, delta)\n        return type(self)(new_values, freq='infer')\n\n    def _add_datetime_arraylike(self, other):\n        \"\"\"\n        Add DatetimeArray/Index or ndarray[datetime64] to TimedeltaArray.\n        \"\"\"\n        if isinstance(other, np.ndarray):\n            # At this point we have already checked that dtype is datetime64\n            from pandas.core.arrays import DatetimeArrayMixin\n            other = DatetimeArrayMixin(other)\n\n        # defer to implementation in DatetimeArray\n        return other + self\n\n    def _add_datetimelike_scalar(self, other):\n        # adding a timedeltaindex to a datetimelike\n        from pandas.core.arrays import DatetimeArrayMixin\n\n        assert other is not NaT\n        other = Timestamp(other)\n        if other is NaT:\n            # In this case we specifically interpret NaT as a datetime, not\n            # the timedelta interpretation we would get by returning self + NaT\n            result = self.asi8.view('m8[ms]') + NaT.to_datetime64()\n            return DatetimeArrayMixin(result)\n\n        i8 = self.asi8\n        result = checked_add_with_arr(i8, other.value,\n                                      arr_mask=self._isnan)\n        result = self._maybe_mask_results(result)\n        return DatetimeArrayMixin(result, tz=other.tz, freq=self.freq)\n\n    def _addsub_offset_array(self, other, op):\n        # Add or subtract Array-like of DateOffset objects\n        try:\n            # TimedeltaIndex can only operate with a subset of DateOffset\n            # subclasses.  Incompatible classes will raise AttributeError,\n            # which we re-raise as TypeError\n            return dtl.DatetimeLikeArrayMixin._addsub_offset_array(self, other,\n                                                                   op)\n        except AttributeError:\n            raise TypeError(\"Cannot add/subtract non-tick DateOffset to {cls}\"\n                            .format(cls=type(self).__name__))\n\n    def __mul__(self, other):\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCDataFrame, ABCSeries, ABCIndexClass)):\n            return NotImplemented\n\n        if is_scalar(other):\n            # numpy will accept float and int, raise TypeError for others\n            result = self._data * other\n            freq = None\n            if self.freq is not None and not isna(other):\n                freq = self.freq * other\n            return type(self)(result, freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self) and not is_timedelta64_dtype(other):\n            # Exclude timedelta64 here so we correctly raise TypeError\n            #  for that instead of ValueError\n            raise ValueError(\"Cannot multiply with unequal lengths\")\n\n        if is_object_dtype(other):\n            # this multiplication will succeed only if all elements of other\n            #  are int or float scalars, so we will end up with\n            #  timedelta64[ns]-dtyped result\n            result = [self[n] * other[n] for n in range(len(self))]\n            result = np.array(result)\n            return type(self)(result)\n\n        # numpy will accept float or int dtype, raise TypeError for others\n        result = self._data * other\n        return type(self)(result)\n\n    __rmul__ = __mul__\n\n    def __truediv__(self, other):\n        # timedelta / X is well-defined for timedelta-like or numeric X\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n            if other is NaT:\n                # specifically timedelta64-NaT\n                result = np.empty(self.shape, dtype=np.float64)\n                result.fill(np.nan)\n                return result\n\n            # otherwise, dispatch to Timedelta implementation\n            return self._data / other\n\n        elif lib.is_scalar(other):\n            # assume it is numeric\n            result = self._data / other\n            freq = None\n            if self.freq is not None:\n                # Tick division is not implemented, so operate on Timedelta\n                freq = self.freq.delta / other\n            return type(self)(result, freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # e.g. list, tuple\n            other = np.array(other)\n\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide vectors with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            # let numpy handle it\n            return self._data / other\n\n        elif is_object_dtype(other):\n            # Note: we do not do type inference on the result, so either\n            #  an object array or numeric-dtyped (if numpy does inference)\n            #  will be returned.  GH#23829\n            result = [self[n] / other[n] for n in range(len(self))]\n            result = np.array(result)\n            return result\n\n        else:\n            result = self._data / other\n            return type(self)(result)\n\n    def __rtruediv__(self, other):\n        # X / timedelta is defined only for timedelta-like X\n        other = lib.item_from_zerodim(other)\n\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n            if other is NaT:\n                # specifically timedelta64-NaT\n                result = np.empty(self.shape, dtype=np.float64)\n                result.fill(np.nan)\n                return result\n\n            # otherwise, dispatch to Timedelta implementation\n            return other / self._data\n\n        elif lib.is_scalar(other):\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=type(other).__name__,\n                                    cls=type(self).__name__))\n\n        if not hasattr(other, \"dtype\"):\n            # e.g. list, tuple\n            other = np.array(other)\n\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide vectors with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            # let numpy handle it\n            return other / self._data\n\n        elif is_object_dtype(other):\n            # Note: unlike in __truediv__, we do not _need_ to do type#\n            #  inference on the result.  It does not raise, a numeric array\n            #  is returned.  GH#23829\n            result = [other[n] / self[n] for n in range(len(self))]\n            return np.array(result)\n\n        else:\n            raise TypeError(\"Cannot divide {dtype} data by {cls}\"\n                            .format(dtype=other.dtype,\n                                    cls=type(self).__name__))\n\n    if compat.PY2:\n        __div__ = __truediv__\n        __rdiv__ = __rtruediv__\n\n    def __floordiv__(self, other):\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if is_scalar(other):\n            if isinstance(other, (timedelta, np.timedelta64, Tick)):\n                other = Timedelta(other)\n                if other is NaT:\n                    # treat this specifically as timedelta-NaT\n                    result = np.empty(self.shape, dtype=np.float64)\n                    result.fill(np.nan)\n                    return result\n\n                # dispatch to Timedelta implementation\n                result = other.__rfloordiv__(self._data)\n                return result\n\n            # at this point we should only have numeric scalars; anything\n            #  else will raise\n            result = self.asi8 // other\n            result[self._isnan] = iNaT\n            freq = None\n            if self.freq is not None:\n                # Note: freq gets division, not floor-division\n                freq = self.freq / other\n            return type(self)(result.view('m8[ns]'), freq=freq)\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            other = type(self)(other)\n\n            # numpy timedelta64 does not natively support floordiv, so operate\n            #  on the i8 values\n            result = self.asi8 // other.asi8\n            mask = self._isnan | other._isnan\n            if mask.any():\n                result = result.astype(np.int64)\n                result[mask] = np.nan\n            return result\n\n        elif is_object_dtype(other):\n            result = [self[n] // other[n] for n in range(len(self))]\n            result = np.array(result)\n            if lib.infer_dtype(result) == 'timedelta':\n                result, _ = sequence_to_td64ns(result)\n                return type(self)(result)\n            return result\n\n        elif is_integer_dtype(other) or is_float_dtype(other):\n            result = self._data // other\n            return type(self)(result)\n\n        else:\n            dtype = getattr(other, \"dtype\", type(other).__name__)\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=dtype, cls=type(self).__name__))\n\n    def __rfloordiv__(self, other):\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if is_scalar(other):\n            if isinstance(other, (timedelta, np.timedelta64, Tick)):\n                other = Timedelta(other)\n                if other is NaT:\n                    # treat this specifically as timedelta-NaT\n                    result = np.empty(self.shape, dtype=np.float64)\n                    result.fill(np.nan)\n                    return result\n\n                # dispatch to Timedelta implementation\n                result = other.__floordiv__(self._data)\n                return result\n\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=type(other).__name__,\n                                    cls=type(self).__name__))\n\n        if not hasattr(other, \"dtype\"):\n            # list, tuple\n            other = np.array(other)\n        if len(other) != len(self):\n            raise ValueError(\"Cannot divide with unequal lengths\")\n\n        elif is_timedelta64_dtype(other):\n            other = type(self)(other)\n\n            # numpy timedelta64 does not natively support floordiv, so operate\n            #  on the i8 values\n            result = other.asi8 // self.asi8\n            mask = self._isnan | other._isnan\n            if mask.any():\n                result = result.astype(np.int64)\n                result[mask] = np.nan\n            return result\n\n        elif is_object_dtype(other):\n            result = [other[n] // self[n] for n in range(len(self))]\n            result = np.array(result)\n            return result\n\n        else:\n            dtype = getattr(other, \"dtype\", type(other).__name__)\n            raise TypeError(\"Cannot divide {typ} by {cls}\"\n                            .format(typ=dtype, cls=type(self).__name__))\n\n    def __mod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n        return self - (self // other) * other\n\n    def __rmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n        return other - (other // self) * self\n\n    def __divmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n\n        res1 = self // other\n        res2 = self - res1 * other\n        return res1, res2\n\n    def __rdivmod__(self, other):\n        # Note: This is a naive implementation, can likely be optimized\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        other = lib.item_from_zerodim(other)\n        if isinstance(other, (timedelta, np.timedelta64, Tick)):\n            other = Timedelta(other)\n\n        res1 = other // self\n        res2 = other - res1 * self\n        return res1, res2\n\n    # Note: TimedeltaIndex overrides this in call to cls._add_numeric_methods\n    def __neg__(self):\n        if self.freq is not None:\n            return type(self)(-self._data, freq=-self.freq)\n        return type(self)(-self._data)\n\n    def __abs__(self):\n        # Note: freq is not preserved\n        return type(self)(np.abs(self._data))\n\n    # ----------------------------------------------------------------\n    # Conversion Methods - Vectorized analogues of Timedelta methods\n\n    def total_seconds(self):\n        \"\"\"\n        Return total duration of each element expressed in seconds.\n\n        This method is available directly on TimedeltaArray, TimedeltaIndex\n        and on Series containing timedelta values under the ``.dt`` namespace.\n\n        Returns\n        -------\n        seconds : [ndarray, Float64Index, Series]\n            When the calling object is a TimedeltaArray, the return type\n            is ndarray.  When the calling object is a TimedeltaIndex,\n            the return type is a Float64Index. When the calling object\n            is a Series, the return type is Series of type `float64` whose\n            index is the same as the original.\n\n        See Also\n        --------\n        datetime.timedelta.total_seconds : Standard library version\n            of this method.\n        TimedeltaIndex.components : Return a DataFrame with components of\n            each Timedelta.\n\n        Examples\n        --------\n        **Series**\n\n        >>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='d'))\n        >>> s\n        0   0 days\n        1   1 days\n        2   2 days\n        3   3 days\n        4   4 days\n        dtype: timedelta64[ns]\n\n        >>> s.dt.total_seconds()\n        0         0.0\n        1     86400.0\n        2    172800.0\n        3    259200.0\n        4    345600.0\n        dtype: float64\n\n        **TimedeltaIndex**\n\n        >>> idx = pd.to_timedelta(np.arange(5), unit='d')\n        >>> idx\n        TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],\n                       dtype='timedelta64[ns]', freq=None)\n\n        >>> idx.total_seconds()\n        Float64Index([0.0, 86400.0, 172800.0, 259200.00000000003, 345600.0],\n                     dtype='float64')\n        \"\"\"\n        return self._maybe_mask_results(1e-9 * self.asi8, fill_value=None)\n\n    def to_pytimedelta(self):\n        \"\"\"\n        Return Timedelta Array/Index as object ndarray of datetime.timedelta\n        objects.\n\n        Returns\n        -------\n        datetimes : ndarray\n        \"\"\"\n        return tslibs.ints_to_pytimedelta(self.asi8)\n\n    days = _field_accessor(\"days\", \"days\",\n                           \"Number of days for each element.\")\n    seconds = _field_accessor(\"seconds\", \"seconds\",\n                              \"Number of seconds (>= 0 and less than 1 day) \"\n                              \"for each element.\")\n    microseconds = _field_accessor(\"microseconds\", \"microseconds\",\n                                   \"Number of microseconds (>= 0 and less \"\n                                   \"than 1 second) for each element.\")\n    nanoseconds = _field_accessor(\"nanoseconds\", \"nanoseconds\",\n                                  \"Number of nanoseconds (>= 0 and less \"\n                                  \"than 1 microsecond) for each element.\")\n\n    @property\n    def components(self):\n        \"\"\"\n        Return a dataframe of the components (days, hours, minutes,\n        seconds, milliseconds, microseconds, nanoseconds) of the Timedeltas.\n\n        Returns\n        -------\n        a DataFrame\n        \"\"\"\n        from pandas import DataFrame\n\n        columns = ['days', 'hours', 'minutes', 'seconds',\n                   'milliseconds', 'microseconds', 'nanoseconds']\n        hasnans = self.hasnans\n        if hasnans:\n            def f(x):\n                if isna(x):\n                    return [np.nan] * len(columns)\n                return x.components\n        else:\n            def f(x):\n                return x.components\n\n        result = DataFrame([f(x) for x in self], columns=columns)\n        if not hasnans:\n            result = result.astype('int64')\n        return result\n\n\nTimedeltaArrayMixin._add_comparison_ops()\n\n\n# ---------------------------------------------------------------------\n# Constructor Helpers\n\ndef sequence_to_td64ns(data, copy=False, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Parameters\n    ----------\n    array : list-like\n    copy : bool, default False\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    converted : numpy.ndarray\n        The sequence converted to a numpy array with dtype ``timedelta64[ns]``.\n    inferred_freq : Tick or None\n        The inferred frequency of the sequence.\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting ``errors=ignore`` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    inferred_freq = None\n    unit = parse_timedelta_unit(unit)\n\n    # Unwrap whatever we have into a np.ndarray\n    if not hasattr(data, 'dtype'):\n        # e.g. list, tuple\n        if np.ndim(data) == 0:\n            # i.e. generator\n            data = list(data)\n        data = np.array(data, copy=False)\n    elif isinstance(data, ABCSeries):\n        data = data._values\n    elif isinstance(data, (ABCTimedeltaIndex, TimedeltaArrayMixin)):\n        inferred_freq = data.freq\n        data = data._data\n\n    # Convert whatever we have into timedelta64[ns] dtype\n    if is_object_dtype(data) or is_string_dtype(data):\n        # no need to make a copy, need to convert if string-dtyped\n        data = objects_to_td64ns(data, unit=unit, errors=errors)\n        copy = False\n\n    elif is_integer_dtype(data):\n        # treat as multiples of the given unit\n        data, copy_made = ints_to_td64ns(data, unit=unit)\n        copy = copy and not copy_made\n\n    elif is_float_dtype(data):\n        # treat as multiples of the given unit.  If after converting to nanos,\n        #  there are fractional components left, these are truncated\n        #  (i.e. NOT rounded)\n        mask = np.isnan(data)\n        coeff = np.timedelta64(1, unit) / np.timedelta64(1, 'ns')\n        data = (coeff * data).astype(np.int64).view('timedelta64[ns]')\n        data[mask] = iNaT\n        copy = False\n\n    elif is_timedelta64_dtype(data):\n        if data.dtype != _TD_DTYPE:\n            # non-nano unit\n            # TODO: watch out for overflows\n            data = data.astype(_TD_DTYPE)\n            copy = False\n\n    elif is_datetime64_dtype(data):\n        # GH#23539\n        warnings.warn(\"Passing datetime64-dtype data to TimedeltaIndex is \"\n                      \"deprecated, will raise a TypeError in a future \"\n                      \"version\",\n                      FutureWarning, stacklevel=4)\n        data = ensure_int64(data).view(_TD_DTYPE)\n\n    else:\n        raise TypeError(\"dtype {dtype} cannot be converted to timedelta64[ns]\"\n                        .format(dtype=data.dtype))\n\n    data = np.array(data, copy=copy)\n    assert data.dtype == 'm8[ns]', data\n    return data, inferred_freq\n\n\ndef ints_to_td64ns(data, unit=\"ns\"):\n    \"\"\"\n    Convert an ndarray with integer-dtype to timedelta64[ns] dtype, treating\n    the integers as multiples of the given timedelta unit.\n\n    Parameters\n    ----------\n    data : numpy.ndarray with integer-dtype\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n    bool : whether a copy was made\n    \"\"\"\n    copy_made = False\n    unit = unit if unit is not None else \"ns\"\n\n    if data.dtype != np.int64:\n        # converting to int64 makes a copy, so we can avoid\n        # re-copying later\n        data = data.astype(np.int64)\n        copy_made = True\n\n    if unit != \"ns\":\n        dtype_str = \"timedelta64[{unit}]\".format(unit=unit)\n        data = data.view(dtype_str)\n\n        # TODO: watch out for overflows when converting from lower-resolution\n        data = data.astype(\"timedelta64[ns]\")\n        # the astype conversion makes a copy, so we can avoid re-copying later\n        copy_made = True\n\n    else:\n        data = data.view(\"timedelta64[ns]\")\n\n    return data, copy_made\n\n\ndef objects_to_td64ns(data, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Convert a object-dtyped or string-dtyped array into an\n    timedelta64[ns]-dtyped array.\n\n    Parameters\n    ----------\n    data : ndarray or Index\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting `errors=ignore` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    # coerce Index to np.ndarray, converting string-dtype if necessary\n    values = np.array(data, dtype=np.object_, copy=False)\n\n    result = array_to_timedelta64(values,\n                                  unit=unit, errors=errors)\n    return result.view('timedelta64[ns]')\n\n\ndef _generate_regular_range(start, end, periods, offset):\n    stride = offset.nanos\n    if periods is None:\n        b = Timedelta(start).value\n        e = Timedelta(end).value\n        e += stride - e % stride\n    elif start is not None:\n        b = Timedelta(start).value\n        e = b + periods * stride\n    elif end is not None:\n        e = Timedelta(end).value + stride\n        b = e - periods * stride\n    else:\n        raise ValueError(\"at least 'start' or 'end' should be specified \"\n                         \"if a 'period' is given.\")\n\n    data = np.arange(b, e, stride, dtype=np.int64)\n    return data\n",
          "file_patch": "@@ -146,27 +146,19 @@ class TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps):\n         return result\n \n     def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n-        return cls._from_sequence(values, freq=freq, dtype=dtype, copy=copy)\n+        return cls._from_sequence(values, dtype=dtype, copy=copy, freq=freq)\n \n     @classmethod\n-    def _from_sequence(cls, data, freq=None, unit=None,\n-                       dtype=_TD_DTYPE, copy=False):\n+    def _from_sequence(cls, data, dtype=_TD_DTYPE, copy=False,\n+                       freq=None, unit=None):\n         if dtype != _TD_DTYPE:\n             raise ValueError(\"Only timedelta64[ns] dtype is valid.\")\n \n         freq, freq_infer = dtl.maybe_infer_freq(freq)\n \n         data, inferred_freq = sequence_to_td64ns(data, copy=copy, unit=unit)\n-        if inferred_freq is not None:\n-            if freq is not None and freq != inferred_freq:\n-                raise ValueError('Inferred frequency {inferred} from passed '\n-                                 'values does not conform to passed frequency '\n-                                 '{passed}'\n-                                 .format(inferred=inferred_freq,\n-                                         passed=freq.freqstr))\n-            elif freq is None:\n-                freq = inferred_freq\n-            freq_infer = False\n+        freq, freq_infer = dtl.validate_inferred_freq(freq, inferred_freq,\n+                                                      freq_infer)\n \n         result = cls._simple_new(data, freq=freq)\n \n",
          "files_name_in_blame_commit": [
            "datetimes.py",
            "timedeltas.py",
            "datetimelike.py",
            "period.py"
          ]
        }
      },
      "b1ee2dff81ca65fcf0e57fa673cb6bf1e47c18d4": {
        "commit": {
          "commit_id": "b1ee2dff81ca65fcf0e57fa673cb6bf1e47c18d4",
          "commit_message": "REF/TST: Fix remaining DatetimeArray with DateOffset arithmetic ops (#23789)",
          "commit_author": "jbrockmendel",
          "commit_date": "2018-11-29 00:33:32",
          "commit_parent": "580a0941475d856a0cde2df4ef3472404706cbba"
        },
        "function": {
          "function_name": "__new__",
          "function_code_before": "def __new__(cls, values, freq=None, dtype=_TD_DTYPE):\n    (freq, freq_infer) = dtl.maybe_infer_freq(freq)\n    values = np.array(values, copy=False)\n    if values.dtype == np.object_:\n        values = array_to_timedelta64(values)\n    result = cls._simple_new(values, freq=freq)\n    if freq_infer:\n        result.freq = to_offset(result.inferred_freq)\n    return result",
          "function_code_after": "def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n    (freq, freq_infer) = dtl.maybe_infer_freq(freq)\n    (values, inferred_freq) = sequence_to_td64ns(values, copy=copy, unit=None)\n    if inferred_freq is not None:\n        if freq is not None and freq != inferred_freq:\n            raise ValueError('Inferred frequency {inferred} from passed values does not conform to passed frequency {passed}'.format(inferred=inferred_freq, passed=freq.freqstr))\n        elif freq is None:\n            freq = inferred_freq\n            freq_infer = False\n    result = cls._simple_new(values, freq=freq)\n    if inferred_freq is None and len(result) > 0:\n        if freq is not None and (not freq_infer):\n            cls._validate_frequency(result, freq)\n    if freq_infer:\n        result.freq = to_offset(result.inferred_freq)\n    return result",
          "function_before_start_line": 165,
          "function_before_end_line": 177,
          "function_after_start_line": 165,
          "function_after_end_line": 191,
          "function_before_token_count": 79,
          "function_after_token_count": 148,
          "functions_name_modified_file": [
            "_to_m8",
            "total_seconds",
            "_simple_new",
            "_generate_regular_range",
            "sequence_to_td64ns",
            "__neg__",
            "_addsub_offset_array",
            "_is_monotonic_decreasing",
            "ints_to_td64ns",
            "to_pytimedelta",
            "_add_datetimelike_scalar",
            "__abs__",
            "objects_to_td64ns",
            "_add_delta",
            "_is_unique",
            "_is_convertible_to_td",
            "dtype",
            "__new__",
            "_box_func",
            "_field_accessor",
            "_evaluate_with_timedelta_like",
            "_td_array_cmp",
            "_validate_fill_value",
            "_generate_range",
            "_add_offset",
            "_add_datetime_arraylike",
            "_is_monotonic_increasing",
            "_wrap_tdi_op",
            "components"
          ],
          "functions_name_all_files": [
            "test_td64arr_add_timestamp",
            "test_constructor_iso",
            "date_range",
            "test_dti_iadd_int",
            "test_datetimeindex_sub_datetimeindex_overflow",
            "test_nat_comparison_tzawareness",
            "_onOffset",
            "get_loc",
            "test_dt64_mul_div_numeric_invalid",
            "day_deltas",
            "_box_func",
            "_format_native_types",
            "unique",
            "_get_monthly_rule",
            "test_dt64arr_add_sub_DateOffsets",
            "test_dti_ne_null_scalar",
            "test_td64arr_floordiv_tdlike_scalar",
            "_add_datetime_arraylike",
            "test_dt64arr_add_sub_td64ndarray",
            "test_dti_add_int",
            "shape",
            "test_td64arr_add_sub_timestamp",
            "_wrap_tdi_op",
            "components",
            "test_tdi_add_overflow",
            "timedelta_range",
            "_simple_new",
            "test_constructor",
            "indexer_between_time",
            "size",
            "test_dt64arr_add_sub_period_scalar",
            "test_timedelta64_ops_nat",
            "test_scalar_comparison_tzawareness",
            "objects_to_td64ns",
            "cbday_roll",
            "_prev_opening_time",
            "test_datetimeindex_sub_timestamp_overflow",
            "_get_suffix_prefix",
            "test_operators_timedelta64",
            "test_dt64arr_add_timestamp_raises",
            "test_dti_sub_offset_index",
            "test_comparisons_nat",
            "test_dti_isub_tdi",
            "deltas",
            "inferred_type",
            "test_dt64arr_sub_NaT",
            "_get_offset_day",
            "test_sub_dti_dti",
            "test_td64arr_add_sub_float",
            "test_dti_add_intarray_non_tick",
            "test_dti_cmp_null_scalar_inequality",
            "_can_fast_union",
            "_get_daytime_flag",
            "test_dt64ser_cmp_date_invalid",
            "test_timedelta64_conversions",
            "_apply_index_days",
            "_maybe_cast_slice_bound",
            "test_dti_isub_int",
            "test_timedelta64_equal_timedelta_supported_ops",
            "_get_business_hours_by_sec",
            "test_td64arr_sub_NaT",
            "test_float64_unit_conversion",
            "_is_monotonic_increasing",
            "test_dt64arr_add_timedeltalike_scalar",
            "test_dti_cmp_str",
            "test_dti_cmp_scalar_invalid",
            "__neg__",
            "test_int64_nocopy",
            "_time_to_micros",
            "test_operators_datetimelike_with_timezones",
            "_add_datetimelike_scalar",
            "test_dt64arr_add_sub_relativedelta_offsets",
            "snap",
            "test_dti_with_offset_series",
            "_field_accessor",
            "hour_deltas",
            "next_bday",
            "delete",
            "test_tdi_rmul_arraylike",
            "_maybe_promote",
            "test_float64_ns_rounded",
            "tz",
            "to_series",
            "year_has_extra_week",
            "test_compare_timedelta_series",
            "mdiffs",
            "_is_dates_only",
            "to_pytimedelta",
            "test_comp_nat",
            "test_dt64arr_iadd_timedeltalike_scalar",
            "test_operators_datetimelike_invalid",
            "test_dt64_series_add_intlike",
            "test_td64arr_floordiv_int",
            "_values",
            "infer_freq",
            "test_ufunc_coercions",
            "test_dti_eq_null_scalar",
            "test_td64arr_add_sub_numeric_scalar_invalid",
            "test_td64arr_add_td64_array",
            "get_offset",
            "test_dt64ser_sub_datetime_dtype",
            "_add_delta",
            "_is_unique",
            "test_tdi_div_tdlike_scalar",
            "_get_time_micros",
            "test_dti_sub_tdi",
            "m_offset",
            "_tick_comp",
            "deltas_asi8",
            "test_td64arr_sub_timedeltalike",
            "_add_offset",
            "test_dti_add_tick_tzaware",
            "is_all_dates",
            "test_dti_cmp_list",
            "test_dt64arr_sub_dtscalar",
            "_is_convertible_to_index",
            "_wrap_setop_result",
            "get_freq",
            "test_tdi_mul_int_array_zerodim",
            "slice_indexer",
            "onOffset",
            "test_dt64arr_naive_sub_dt64ndarray",
            "test_shift_months",
            "apply_index",
            "_generate_regular_range",
            "test_td64arr_sub_pi",
            "test_td64arr_floordiv_tdscalar",
            "test_ops_nat_mixed_datetime64_timedelta64",
            "_partial_td_slice",
            "__hash__",
            "test_dt64_series_add_mixed_tick_DateOffset",
            "rollforward",
            "test_constructor_name",
            "__add__",
            "test_td64arr_sub_period",
            "test_tdi_cmp_str_invalid",
            "test_series_comparison_scalars",
            "test_dti_add_tdi",
            "test_dt64arr_add_dt64ndarray_raises",
            "is_type_compatible",
            "test_tdi_mul_float_series",
            "month_position_check",
            "nanos",
            "_parse_suffix",
            "_repr_attrs",
            "test_tdi_sub_dt64_array",
            "_join_i8_wrapper",
            "_addsub_offset_array",
            "_get_roll",
            "test_datetime64_ops_nat",
            "intersection",
            "rep_stamp",
            "test_td64arr_rfloordiv_tdlike_scalar",
            "_evaluate_with_timedelta_like",
            "test_tdi_mul_int_array",
            "_rollback_to_year",
            "test_dti_sub_int",
            "test_td64arr_mul_td64arr_raises",
            "test_tdi_add_dt64_array",
            "test_td64arr_sub_timestamp_raises",
            "get_upcast_box",
            "test_td64arr_div_numeric_scalar",
            "test_td64arr_addsub_anchored_offset_arraylike",
            "month_roll",
            "test_nat_comparisons_scalar",
            "as_timestamp",
            "test_td64arr_pow_invalid",
            "test_td64arr_mul_numeric_scalar",
            "test_dt64arr_sub_datetime64_not_ns",
            "test_dt64arr_sub_timestamp",
            "nbytes",
            "test_dt64arr_add_sub_parr",
            "delta",
            "_maybe_add_count",
            "cdate_range",
            "test_sub_single_tz",
            "test_td64arr_div_numeric_array",
            "dtype",
            "__new__",
            "searchsorted",
            "dti_cmp_non_datetime",
            "rule_code",
            "get_period_alias",
            "__init__",
            "test_dti_add_series",
            "test_dt64_ser_cmp_date_warning",
            "test_td64arr_add_offset_array",
            "sequence_to_td64ns",
            "_convert_for_op",
            "test_td64arr_sub_offset_array",
            "test_add_datetimelike_and_dti",
            "test_td64arr_mul_int",
            "test_tdi_div_tdlike_scalar_with_nat",
            "get_value_maybe_box",
            "test_td64arr_rfloordiv_tdscalar_explicit",
            "test_td64arr_sub_offset_index",
            "is_unique_asi8",
            "get_year_end",
            "test_dti_cmp_tdi_tzawareness",
            "test_td64arr_add_int_series_invalid",
            "_infer_daily_rule",
            "union",
            "astype",
            "apply_wraps",
            "test_dt64arr_timestamp_equality",
            "test_dt64arr_add_mixed_offset_array",
            "_offset",
            "test_float_series_rdiv_td64arr",
            "apply",
            "test_tz_aware_scalar_comparison",
            "test_infer_from_tdi_mismatch",
            "_mpl_repr",
            "generate_range",
            "test_dt64arr_aware_sub_dt64ndarray_raises",
            "test_td64arr_mul_tdlike_scalar_raises",
            "_fast_union",
            "_to_m8",
            "test_td64arr_add_sub_numeric_arr_invalid",
            "test_dti_add_intarray_tick",
            "test_td64arr_with_offset_series",
            "indexer_at_time",
            "_is_monotonic_decreasing",
            "_delta_to_tick",
            "is_unique",
            "test_dt64arr_add_sub_float",
            "test_dti_cmp_nat_behaves_like_float_cmp_nan",
            "test_td64arr_rfloordiv_tdscalar",
            "_is_convertible_to_td",
            "_partial_date_slice",
            "_get_quarterly_rule",
            "test_dt64arr_add_sub_offset_ndarray",
            "test_tdi_mul_int_series",
            "get_value",
            "test_operators_timedelta64_with_timedelta",
            "isAnchored",
            "test_dti_iadd_tdi",
            "_get_annual_rule",
            "get_rule_code_suffix",
            "test_comparisons_coverage",
            "test_dt64arr_add_sub_DateOffset",
            "total_seconds",
            "test_infer_from_tdi",
            "test_tdi_add_timestamp_nat_masking",
            "test_dt64arr_add_sub_tick_DateOffset_smoke",
            "freqstr",
            "test_dt64_nat_comparison",
            "ints_to_td64ns",
            "_offset_str",
            "test_dt64arr_add_sub_td64_nat",
            "_wrap_joined_index",
            "test_td64arr_div_int",
            "test_td64arr_mul_tdscalar_invalid",
            "test_timedelta64_operations_with_DateOffset",
            "test_td64arr_add_offset_index",
            "_td_array_cmp",
            "_generate_range",
            "union_many",
            "_maybe_update_attributes",
            "test_dti_cmp_nat",
            "__setstate__",
            "test_td64arr_mul_too_short_raises",
            "_is_multiple",
            "test_dti_cmp_object_dtype",
            "test_td64arr_mul_int_series",
            "fields",
            "_end_apply_index",
            "offset",
            "_apply",
            "test_td64arr_add_timedeltalike",
            "_from_name",
            "_formatter_func",
            "test_comparison_invalid",
            "test_dt64arr_sub_timedeltalike_scalar",
            "test_dt64arr_series_sub_tick_DateOffset",
            "_next_opening_time",
            "test_dt64tz_series_sub_dtitz",
            "get_weeks",
            "_is_business_daily",
            "test_dt64_data_invalid",
            "test_dti_cmp_datetimelike",
            "_parsed_string_to_bounds",
            "test_timestamp_compare_series",
            "to_offset",
            "__reduce__",
            "test_dt64_series_arith_overflow",
            "test_td64arr_add_str_invalid",
            "_prefix",
            "name",
            "_maybe_utc_convert",
            "ydiffs",
            "rollback",
            "insert",
            "test_td64arr_add_intlike",
            "test_dt64arr_series_add_tick_DateOffset",
            "__abs__",
            "test_dti_add_intarray_no_freq",
            "test_td64arr_rmul_numeric_array",
            "test_td64arr_add_sub_td64_nat",
            "test_constructor_coverage",
            "_validate_fill_value",
            "__eq__",
            "test_sub_datetime_compat",
            "_new_DatetimeIndex",
            "test_timedelta64_operations_with_timedeltas",
            "bdate_range",
            "test_td64arr_add_datetime64_nat",
            "_get_wom_rule",
            "test_dt64arr_isub_timedeltalike_scalar",
            "test_construction_base_constructor",
            "_get_string_slice",
            "test_dti_add_offset_index",
            "test_dt64arr_add_td64_scalar",
            "test_comparison_tzawareness_compat",
            "test_td64arr_add_sub_tdi",
            "test_td64arr_sub_td64_array",
            "test_td64arr_div_nat_invalid",
            "join",
            "__ne__"
          ],
          "functions_name_co_evolved_modified_file": [
            "_add_datetimelike_scalar",
            "_is_unique",
            "_is_monotonic_increasing",
            "_is_monotonic_decreasing"
          ],
          "functions_name_co_evolved_all_files": [
            "test_dt64_with_DateOffsets_relativedelta",
            "_end_apply_index",
            "apply_index",
            "test_dt64arr_add_mixed_offset_array",
            "test_dt64_with_DateOffsets",
            "test_dti_sub_offset_array",
            "_is_monotonic_decreasing",
            "test_datetime64_with_DateOffset",
            "_add_datetimelike_scalar",
            "test_dt64arr_add_sub_relativedelta_offsets",
            "_is_unique",
            "test_dt64arr_add_sub_offset_ndarray",
            "test_infer_from_tdi_mismatch",
            "test_dt64_with_offset_array",
            "test_tdi_rmul_arraylike",
            "test_dt64arr_add_sub_DateOffsets",
            "__init__",
            "test_dti_add_offset_array",
            "_is_monotonic_increasing",
            "test_td64arr_add_sub_timestamp",
            "get_freq",
            "test_dt64arr_add_sub_DateOffset"
          ]
        },
        "file": {
          "file_name": "timedeltas.py",
          "file_nloc": 349,
          "file_complexity": 101,
          "file_token_count": 2529,
          "file_before": "# -*- coding: utf-8 -*-\nfrom __future__ import division\n\nfrom datetime import timedelta\nimport operator\nimport warnings\n\nimport numpy as np\n\nfrom pandas._libs import tslibs\nfrom pandas._libs.tslibs import NaT, Timedelta, Timestamp, iNaT\nfrom pandas._libs.tslibs.fields import get_timedelta_field\nfrom pandas._libs.tslibs.timedeltas import (\n    array_to_timedelta64, parse_timedelta_unit)\nimport pandas.compat as compat\nfrom pandas.util._decorators import Appender\n\nfrom pandas.core.dtypes.common import (\n    _TD_DTYPE, ensure_int64, is_datetime64_dtype, is_float_dtype,\n    is_integer_dtype, is_list_like, is_object_dtype, is_string_dtype,\n    is_timedelta64_dtype)\nfrom pandas.core.dtypes.generic import (\n    ABCDataFrame, ABCIndexClass, ABCSeries, ABCTimedeltaIndex)\nfrom pandas.core.dtypes.missing import isna\n\nfrom pandas.core import ops\nfrom pandas.core.algorithms import checked_add_with_arr\nimport pandas.core.common as com\n\nfrom pandas.tseries.frequencies import to_offset\nfrom pandas.tseries.offsets import Tick\n\nfrom . import datetimelike as dtl\n\n\ndef _to_m8(key):\n    \"\"\"\n    Timedelta-like => dt64\n    \"\"\"\n    if not isinstance(key, Timedelta):\n        # this also converts strings\n        key = Timedelta(key)\n\n    # return an type that can be compared\n    return np.int64(key.value).view(_TD_DTYPE)\n\n\ndef _is_convertible_to_td(key):\n    return isinstance(key, (Tick, timedelta,\n                            np.timedelta64, compat.string_types))\n\n\ndef _field_accessor(name, alias, docstring=None):\n    def f(self):\n        values = self.asi8\n        result = get_timedelta_field(values, alias)\n        if self.hasnans:\n            result = self._maybe_mask_results(result, fill_value=None,\n                                              convert='float64')\n\n        return result\n\n    f.__name__ = name\n    f.__doc__ = docstring\n    return property(f)\n\n\ndef _td_array_cmp(cls, op):\n    \"\"\"\n    Wrap comparison operations to convert timedelta-like to timedelta64\n    \"\"\"\n    opname = '__{name}__'.format(name=op.__name__)\n    nat_result = True if opname == '__ne__' else False\n\n    def wrapper(self, other):\n        msg = \"cannot compare a {cls} with type {typ}\"\n        meth = getattr(dtl.DatetimeLikeArrayMixin, opname)\n        if _is_convertible_to_td(other) or other is NaT:\n            try:\n                other = _to_m8(other)\n            except ValueError:\n                # failed to parse as timedelta\n                raise TypeError(msg.format(cls=type(self).__name__,\n                                           typ=type(other).__name__))\n            result = meth(self, other)\n            if isna(other):\n                result.fill(nat_result)\n\n        elif not is_list_like(other):\n            raise TypeError(msg.format(cls=type(self).__name__,\n                                       typ=type(other).__name__))\n        else:\n            other = type(self)(other)._data\n            result = meth(self, other)\n            result = com.values_from_object(result)\n\n            o_mask = np.array(isna(other))\n            if o_mask.any():\n                result[o_mask] = nat_result\n\n        if self.hasnans:\n            result[self._isnan] = nat_result\n\n        return result\n\n    return compat.set_function_name(wrapper, opname, cls)\n\n\ndef _wrap_tdi_op(op):\n    \"\"\"\n    Instead of re-implementing multiplication/division etc operations\n    in the Array class, for now we dispatch to the TimedeltaIndex\n    implementations.\n    \"\"\"\n    # TODO: implement directly here and wrap in TimedeltaIndex, instead of\n    #  the other way around\n    def method(self, other):\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        from pandas import TimedeltaIndex\n        obj = TimedeltaIndex(self)\n        result = op(obj, other)\n        if is_timedelta64_dtype(result):\n            return type(self)(result)\n        return np.array(result)\n\n    method.__name__ = '__{name}__'.format(name=op.__name__)\n    return method\n\n\nclass TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin):\n    _typ = \"timedeltaarray\"\n    __array_priority__ = 1000\n\n    @property\n    def _box_func(self):\n        return lambda x: Timedelta(x, unit='ns')\n\n    @property\n    def dtype(self):\n        return _TD_DTYPE\n\n    # ----------------------------------------------------------------\n    # Constructors\n    _attributes = [\"freq\"]\n\n    @classmethod\n    def _simple_new(cls, values, freq=None, dtype=_TD_DTYPE):\n        # `dtype` is passed by _shallow_copy in corner cases, should always\n        #  be timedelta64[ns] if present\n        assert dtype == _TD_DTYPE\n        assert isinstance(values, np.ndarray), type(values)\n\n        if values.dtype == 'i8':\n            values = values.view('m8[ns]')\n\n        assert values.dtype == 'm8[ns]'\n\n        result = object.__new__(cls)\n        result._data = values\n        result._freq = freq\n        return result\n\n    def __new__(cls, values, freq=None, dtype=_TD_DTYPE):\n\n        freq, freq_infer = dtl.maybe_infer_freq(freq)\n\n        values = np.array(values, copy=False)\n        if values.dtype == np.object_:\n            values = array_to_timedelta64(values)\n\n        result = cls._simple_new(values, freq=freq)\n        if freq_infer:\n            result.freq = to_offset(result.inferred_freq)\n\n        return result\n\n    @classmethod\n    def _generate_range(cls, start, end, periods, freq, closed=None):\n\n        periods = dtl.validate_periods(periods)\n        if freq is None and any(x is None for x in [periods, start, end]):\n            raise ValueError('Must provide freq argument if no data is '\n                             'supplied')\n\n        if com.count_not_none(start, end, periods, freq) != 3:\n            raise ValueError('Of the four parameters: start, end, periods, '\n                             'and freq, exactly three must be specified')\n\n        if start is not None:\n            start = Timedelta(start)\n\n        if end is not None:\n            end = Timedelta(end)\n\n        if start is None and end is None:\n            if closed is not None:\n                raise ValueError(\"Closed has to be None if not both of start\"\n                                 \"and end are defined\")\n\n        left_closed, right_closed = dtl.validate_endpoints(closed)\n\n        if freq is not None:\n            index = _generate_regular_range(start, end, periods, freq)\n        else:\n            index = np.linspace(start.value, end.value, periods).astype('i8')\n\n        if not left_closed:\n            index = index[1:]\n        if not right_closed:\n            index = index[:-1]\n\n        return cls._simple_new(index, freq=freq)\n\n    # ----------------------------------------------------------------\n    # Array-Like / EA-Interface Methods\n\n    @Appender(dtl.DatetimeLikeArrayMixin._validate_fill_value.__doc__)\n    def _validate_fill_value(self, fill_value):\n        if isna(fill_value):\n            fill_value = iNaT\n        elif isinstance(fill_value, (timedelta, np.timedelta64, Tick)):\n            fill_value = Timedelta(fill_value).value\n        else:\n            raise ValueError(\"'fill_value' should be a Timedelta. \"\n                             \"Got '{got}'.\".format(got=fill_value))\n        return fill_value\n\n    # ----------------------------------------------------------------\n    # Arithmetic Methods\n\n    _create_comparison_method = classmethod(_td_array_cmp)\n\n    def _add_offset(self, other):\n        assert not isinstance(other, Tick)\n        raise TypeError(\"cannot add the type {typ} to a {cls}\"\n                        .format(typ=type(other).__name__,\n                                cls=type(self).__name__))\n\n    def _add_delta(self, delta):\n        \"\"\"\n        Add a timedelta-like, Tick, or TimedeltaIndex-like object\n        to self, yielding a new TimedeltaArray.\n\n        Parameters\n        ----------\n        other : {timedelta, np.timedelta64, Tick,\n                 TimedeltaIndex, ndarray[timedelta64]}\n\n        Returns\n        -------\n        result : TimedeltaArray\n        \"\"\"\n        new_values = dtl.DatetimeLikeArrayMixin._add_delta(self, delta)\n        return type(self)(new_values, freq='infer')\n\n    def _add_datetime_arraylike(self, other):\n        \"\"\"\n        Add DatetimeArray/Index or ndarray[datetime64] to TimedeltaArray.\n        \"\"\"\n        if isinstance(other, np.ndarray):\n            # At this point we have already checked that dtype is datetime64\n            from pandas.core.arrays import DatetimeArrayMixin\n            other = DatetimeArrayMixin(other)\n\n        # defer to implementation in DatetimeArray\n        return other + self\n\n    def _add_datetimelike_scalar(self, other):\n        # adding a timedeltaindex to a datetimelike\n        from pandas.core.arrays import DatetimeArrayMixin\n\n        assert other is not NaT\n        other = Timestamp(other)\n        if other is NaT:\n            # In this case we specifically interpret NaT as a datetime, not\n            # the timedelta interpretation we would get by returning self + NaT\n            result = self.asi8.view('m8[ms]') + NaT.to_datetime64()\n            return DatetimeArrayMixin(result)\n\n        i8 = self.asi8\n        result = checked_add_with_arr(i8, other.value,\n                                      arr_mask=self._isnan)\n        result = self._maybe_mask_results(result)\n        return DatetimeArrayMixin(result, tz=other.tz)\n\n    def _addsub_offset_array(self, other, op):\n        # Add or subtract Array-like of DateOffset objects\n        try:\n            # TimedeltaIndex can only operate with a subset of DateOffset\n            # subclasses.  Incompatible classes will raise AttributeError,\n            # which we re-raise as TypeError\n            return dtl.DatetimeLikeArrayMixin._addsub_offset_array(self, other,\n                                                                   op)\n        except AttributeError:\n            raise TypeError(\"Cannot add/subtract non-tick DateOffset to {cls}\"\n                            .format(cls=type(self).__name__))\n\n    def _evaluate_with_timedelta_like(self, other, op):\n        if isinstance(other, ABCSeries):\n            # GH#19042\n            return NotImplemented\n\n        opstr = '__{opname}__'.format(opname=op.__name__).replace('__r', '__')\n        # allow division by a timedelta\n        if opstr in ['__div__', '__truediv__', '__floordiv__']:\n            if _is_convertible_to_td(other):\n                other = Timedelta(other)\n                if isna(other):\n                    raise NotImplementedError(\n                        \"division by pd.NaT not implemented\")\n\n                i8 = self.asi8\n                left, right = i8, other.value\n\n                if opstr in ['__floordiv__']:\n                    result = op(left, right)\n                else:\n                    result = op(left, np.float64(right))\n                result = self._maybe_mask_results(result, fill_value=None,\n                                                  convert='float64')\n                return result\n\n        return NotImplemented\n\n    __mul__ = _wrap_tdi_op(operator.mul)\n    __rmul__ = __mul__\n    __truediv__ = _wrap_tdi_op(operator.truediv)\n    __floordiv__ = _wrap_tdi_op(operator.floordiv)\n    __rfloordiv__ = _wrap_tdi_op(ops.rfloordiv)\n\n    if compat.PY2:\n        __div__ = __truediv__\n\n    # Note: TimedeltaIndex overrides this in call to cls._add_numeric_methods\n    def __neg__(self):\n        if self.freq is not None:\n            return type(self)(-self._data, freq=-self.freq)\n        return type(self)(-self._data)\n\n    def __abs__(self):\n        # Note: freq is not preserved\n        return type(self)(np.abs(self._data))\n\n    # ----------------------------------------------------------------\n    # Conversion Methods - Vectorized analogues of Timedelta methods\n\n    def total_seconds(self):\n        \"\"\"\n        Return total duration of each element expressed in seconds.\n\n        This method is available directly on TimedeltaArray, TimedeltaIndex\n        and on Series containing timedelta values under the ``.dt`` namespace.\n\n        Returns\n        -------\n        seconds : [ndarray, Float64Index, Series]\n            When the calling object is a TimedeltaArray, the return type\n            is ndarray.  When the calling object is a TimedeltaIndex,\n            the return type is a Float64Index. When the calling object\n            is a Series, the return type is Series of type `float64` whose\n            index is the same as the original.\n\n        See Also\n        --------\n        datetime.timedelta.total_seconds : Standard library version\n            of this method.\n        TimedeltaIndex.components : Return a DataFrame with components of\n            each Timedelta.\n\n        Examples\n        --------\n        **Series**\n\n        >>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='d'))\n        >>> s\n        0   0 days\n        1   1 days\n        2   2 days\n        3   3 days\n        4   4 days\n        dtype: timedelta64[ns]\n\n        >>> s.dt.total_seconds()\n        0         0.0\n        1     86400.0\n        2    172800.0\n        3    259200.0\n        4    345600.0\n        dtype: float64\n\n        **TimedeltaIndex**\n\n        >>> idx = pd.to_timedelta(np.arange(5), unit='d')\n        >>> idx\n        TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],\n                       dtype='timedelta64[ns]', freq=None)\n\n        >>> idx.total_seconds()\n        Float64Index([0.0, 86400.0, 172800.0, 259200.00000000003, 345600.0],\n                     dtype='float64')\n        \"\"\"\n        return self._maybe_mask_results(1e-9 * self.asi8, fill_value=None)\n\n    def to_pytimedelta(self):\n        \"\"\"\n        Return Timedelta Array/Index as object ndarray of datetime.timedelta\n        objects.\n\n        Returns\n        -------\n        datetimes : ndarray\n        \"\"\"\n        return tslibs.ints_to_pytimedelta(self.asi8)\n\n    days = _field_accessor(\"days\", \"days\",\n                           \" Number of days for each element. \")\n    seconds = _field_accessor(\"seconds\", \"seconds\",\n                              \" Number of seconds (>= 0 and less than 1 day) \"\n                              \"for each element. \")\n    microseconds = _field_accessor(\"microseconds\", \"microseconds\",\n                                   \"\\nNumber of microseconds (>= 0 and less \"\n                                   \"than 1 second) for each\\nelement. \")\n    nanoseconds = _field_accessor(\"nanoseconds\", \"nanoseconds\",\n                                  \"\\nNumber of nanoseconds (>= 0 and less \"\n                                  \"than 1 microsecond) for each\\nelement.\\n\")\n\n    @property\n    def components(self):\n        \"\"\"\n        Return a dataframe of the components (days, hours, minutes,\n        seconds, milliseconds, microseconds, nanoseconds) of the Timedeltas.\n\n        Returns\n        -------\n        a DataFrame\n        \"\"\"\n        from pandas import DataFrame\n\n        columns = ['days', 'hours', 'minutes', 'seconds',\n                   'milliseconds', 'microseconds', 'nanoseconds']\n        hasnans = self.hasnans\n        if hasnans:\n            def f(x):\n                if isna(x):\n                    return [np.nan] * len(columns)\n                return x.components\n        else:\n            def f(x):\n                return x.components\n\n        result = DataFrame([f(x) for x in self], columns=columns)\n        if not hasnans:\n            result = result.astype('int64')\n        return result\n\n\nTimedeltaArrayMixin._add_comparison_ops()\nTimedeltaArrayMixin._add_datetimelike_methods()\n\n\n# ---------------------------------------------------------------------\n# Constructor Helpers\n\ndef sequence_to_td64ns(data, copy=False, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Parameters\n    ----------\n    array : list-like\n    copy : bool, default False\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    converted : numpy.ndarray\n        The sequence converted to a numpy array with dtype ``timedelta64[ns]``.\n    inferred_freq : Tick or None\n        The inferred frequency of the sequence.\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting ``errors=ignore`` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    inferred_freq = None\n    unit = parse_timedelta_unit(unit)\n\n    # Unwrap whatever we have into a np.ndarray\n    if not hasattr(data, 'dtype'):\n        # e.g. list, tuple\n        if np.ndim(data) == 0:\n            # i.e. generator\n            data = list(data)\n        data = np.array(data, copy=False)\n    elif isinstance(data, ABCSeries):\n        data = data._values\n    elif isinstance(data, (ABCTimedeltaIndex, TimedeltaArrayMixin)):\n        inferred_freq = data.freq\n        data = data._data\n\n    # Convert whatever we have into timedelta64[ns] dtype\n    if is_object_dtype(data) or is_string_dtype(data):\n        # no need to make a copy, need to convert if string-dtyped\n        data = objects_to_td64ns(data, unit=unit, errors=errors)\n        copy = False\n\n    elif is_integer_dtype(data):\n        # treat as multiples of the given unit\n        data, copy_made = ints_to_td64ns(data, unit=unit)\n        copy = copy and not copy_made\n\n    elif is_float_dtype(data):\n        # treat as multiples of the given unit.  If after converting to nanos,\n        #  there are fractional components left, these are truncated\n        #  (i.e. NOT rounded)\n        mask = np.isnan(data)\n        coeff = np.timedelta64(1, unit) / np.timedelta64(1, 'ns')\n        data = (coeff * data).astype(np.int64).view('timedelta64[ns]')\n        data[mask] = iNaT\n        copy = False\n\n    elif is_timedelta64_dtype(data):\n        if data.dtype != _TD_DTYPE:\n            # non-nano unit\n            # TODO: watch out for overflows\n            data = data.astype(_TD_DTYPE)\n            copy = False\n\n    elif is_datetime64_dtype(data):\n        # GH#23539\n        warnings.warn(\"Passing datetime64-dtype data to TimedeltaIndex is \"\n                      \"deprecated, will raise a TypeError in a future \"\n                      \"version\",\n                      FutureWarning, stacklevel=3)\n        data = ensure_int64(data).view(_TD_DTYPE)\n\n    else:\n        raise TypeError(\"dtype {dtype} cannot be converted to timedelta64[ns]\"\n                        .format(dtype=data.dtype))\n\n    data = np.array(data, copy=copy)\n    assert data.dtype == 'm8[ns]', data\n    return data, inferred_freq\n\n\ndef ints_to_td64ns(data, unit=\"ns\"):\n    \"\"\"\n    Convert an ndarray with integer-dtype to timedelta64[ns] dtype, treating\n    the integers as multiples of the given timedelta unit.\n\n    Parameters\n    ----------\n    data : numpy.ndarray with integer-dtype\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n    bool : whether a copy was made\n    \"\"\"\n    copy_made = False\n    unit = unit if unit is not None else \"ns\"\n\n    if data.dtype != np.int64:\n        # converting to int64 makes a copy, so we can avoid\n        # re-copying later\n        data = data.astype(np.int64)\n        copy_made = True\n\n    if unit != \"ns\":\n        dtype_str = \"timedelta64[{unit}]\".format(unit=unit)\n        data = data.view(dtype_str)\n\n        # TODO: watch out for overflows when converting from lower-resolution\n        data = data.astype(\"timedelta64[ns]\")\n        # the astype conversion makes a copy, so we can avoid re-copying later\n        copy_made = True\n\n    else:\n        data = data.view(\"timedelta64[ns]\")\n\n    return data, copy_made\n\n\ndef objects_to_td64ns(data, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Convert a object-dtyped or string-dtyped array into an\n    timedelta64[ns]-dtyped array.\n\n    Parameters\n    ----------\n    data : ndarray or Index\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting `errors=ignore` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    # coerce Index to np.ndarray, converting string-dtype if necessary\n    values = np.array(data, dtype=np.object_, copy=False)\n\n    result = array_to_timedelta64(values,\n                                  unit=unit, errors=errors)\n    return result.view('timedelta64[ns]')\n\n\ndef _generate_regular_range(start, end, periods, offset):\n    stride = offset.nanos\n    if periods is None:\n        b = Timedelta(start).value\n        e = Timedelta(end).value\n        e += stride - e % stride\n    elif start is not None:\n        b = Timedelta(start).value\n        e = b + periods * stride\n    elif end is not None:\n        e = Timedelta(end).value + stride\n        b = e - periods * stride\n    else:\n        raise ValueError(\"at least 'start' or 'end' should be specified \"\n                         \"if a 'period' is given.\")\n\n    data = np.arange(b, e, stride, dtype=np.int64)\n    return data\n",
          "file_after": "# -*- coding: utf-8 -*-\nfrom __future__ import division\n\nfrom datetime import timedelta\nimport operator\nimport warnings\n\nimport numpy as np\n\nfrom pandas._libs import algos, tslibs\nfrom pandas._libs.tslibs import NaT, Timedelta, Timestamp, iNaT\nfrom pandas._libs.tslibs.fields import get_timedelta_field\nfrom pandas._libs.tslibs.timedeltas import (\n    array_to_timedelta64, parse_timedelta_unit)\nimport pandas.compat as compat\nfrom pandas.util._decorators import Appender\n\nfrom pandas.core.dtypes.common import (\n    _TD_DTYPE, ensure_int64, is_datetime64_dtype, is_float_dtype,\n    is_integer_dtype, is_list_like, is_object_dtype, is_string_dtype,\n    is_timedelta64_dtype)\nfrom pandas.core.dtypes.generic import (\n    ABCDataFrame, ABCIndexClass, ABCSeries, ABCTimedeltaIndex)\nfrom pandas.core.dtypes.missing import isna\n\nfrom pandas.core import ops\nfrom pandas.core.algorithms import checked_add_with_arr, unique1d\nimport pandas.core.common as com\n\nfrom pandas.tseries.frequencies import to_offset\nfrom pandas.tseries.offsets import Tick\n\nfrom . import datetimelike as dtl\n\n\ndef _to_m8(key):\n    \"\"\"\n    Timedelta-like => dt64\n    \"\"\"\n    if not isinstance(key, Timedelta):\n        # this also converts strings\n        key = Timedelta(key)\n\n    # return an type that can be compared\n    return np.int64(key.value).view(_TD_DTYPE)\n\n\ndef _is_convertible_to_td(key):\n    return isinstance(key, (Tick, timedelta,\n                            np.timedelta64, compat.string_types))\n\n\ndef _field_accessor(name, alias, docstring=None):\n    def f(self):\n        values = self.asi8\n        result = get_timedelta_field(values, alias)\n        if self.hasnans:\n            result = self._maybe_mask_results(result, fill_value=None,\n                                              convert='float64')\n\n        return result\n\n    f.__name__ = name\n    f.__doc__ = docstring\n    return property(f)\n\n\ndef _td_array_cmp(cls, op):\n    \"\"\"\n    Wrap comparison operations to convert timedelta-like to timedelta64\n    \"\"\"\n    opname = '__{name}__'.format(name=op.__name__)\n    nat_result = True if opname == '__ne__' else False\n\n    def wrapper(self, other):\n        msg = \"cannot compare a {cls} with type {typ}\"\n        meth = getattr(dtl.DatetimeLikeArrayMixin, opname)\n        if _is_convertible_to_td(other) or other is NaT:\n            try:\n                other = _to_m8(other)\n            except ValueError:\n                # failed to parse as timedelta\n                raise TypeError(msg.format(cls=type(self).__name__,\n                                           typ=type(other).__name__))\n            result = meth(self, other)\n            if isna(other):\n                result.fill(nat_result)\n\n        elif not is_list_like(other):\n            raise TypeError(msg.format(cls=type(self).__name__,\n                                       typ=type(other).__name__))\n        else:\n            other = type(self)(other)._data\n            result = meth(self, other)\n            result = com.values_from_object(result)\n\n            o_mask = np.array(isna(other))\n            if o_mask.any():\n                result[o_mask] = nat_result\n\n        if self.hasnans:\n            result[self._isnan] = nat_result\n\n        return result\n\n    return compat.set_function_name(wrapper, opname, cls)\n\n\ndef _wrap_tdi_op(op):\n    \"\"\"\n    Instead of re-implementing multiplication/division etc operations\n    in the Array class, for now we dispatch to the TimedeltaIndex\n    implementations.\n    \"\"\"\n    # TODO: implement directly here and wrap in TimedeltaIndex, instead of\n    #  the other way around\n    def method(self, other):\n        if isinstance(other, (ABCSeries, ABCDataFrame, ABCIndexClass)):\n            return NotImplemented\n\n        from pandas import TimedeltaIndex\n        obj = TimedeltaIndex(self)\n        result = op(obj, other)\n        if is_timedelta64_dtype(result):\n            return type(self)(result)\n        return np.array(result)\n\n    method.__name__ = '__{name}__'.format(name=op.__name__)\n    return method\n\n\nclass TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin):\n    _typ = \"timedeltaarray\"\n    __array_priority__ = 1000\n\n    @property\n    def _box_func(self):\n        return lambda x: Timedelta(x, unit='ns')\n\n    @property\n    def dtype(self):\n        return _TD_DTYPE\n\n    # ----------------------------------------------------------------\n    # Constructors\n    _attributes = [\"freq\"]\n\n    @classmethod\n    def _simple_new(cls, values, freq=None, dtype=_TD_DTYPE):\n        # `dtype` is passed by _shallow_copy in corner cases, should always\n        #  be timedelta64[ns] if present\n        assert dtype == _TD_DTYPE\n        assert isinstance(values, np.ndarray), type(values)\n\n        if values.dtype == 'i8':\n            values = values.view('m8[ns]')\n\n        assert values.dtype == 'm8[ns]'\n\n        result = object.__new__(cls)\n        result._data = values\n        result._freq = freq\n        return result\n\n    def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n\n        freq, freq_infer = dtl.maybe_infer_freq(freq)\n\n        values, inferred_freq = sequence_to_td64ns(\n            values, copy=copy, unit=None)\n        if inferred_freq is not None:\n            if freq is not None and freq != inferred_freq:\n                raise ValueError('Inferred frequency {inferred} from passed '\n                                 'values does not conform to passed frequency '\n                                 '{passed}'\n                                 .format(inferred=inferred_freq,\n                                         passed=freq.freqstr))\n            elif freq is None:\n                freq = inferred_freq\n                freq_infer = False\n\n        result = cls._simple_new(values, freq=freq)\n        # check that we are matching freqs\n        if inferred_freq is None and len(result) > 0:\n            if freq is not None and not freq_infer:\n                cls._validate_frequency(result, freq)\n\n        if freq_infer:\n            result.freq = to_offset(result.inferred_freq)\n\n        return result\n\n    @classmethod\n    def _generate_range(cls, start, end, periods, freq, closed=None):\n\n        periods = dtl.validate_periods(periods)\n        if freq is None and any(x is None for x in [periods, start, end]):\n            raise ValueError('Must provide freq argument if no data is '\n                             'supplied')\n\n        if com.count_not_none(start, end, periods, freq) != 3:\n            raise ValueError('Of the four parameters: start, end, periods, '\n                             'and freq, exactly three must be specified')\n\n        if start is not None:\n            start = Timedelta(start)\n\n        if end is not None:\n            end = Timedelta(end)\n\n        if start is None and end is None:\n            if closed is not None:\n                raise ValueError(\"Closed has to be None if not both of start\"\n                                 \"and end are defined\")\n\n        left_closed, right_closed = dtl.validate_endpoints(closed)\n\n        if freq is not None:\n            index = _generate_regular_range(start, end, periods, freq)\n        else:\n            index = np.linspace(start.value, end.value, periods).astype('i8')\n\n        if not left_closed:\n            index = index[1:]\n        if not right_closed:\n            index = index[:-1]\n\n        return cls._simple_new(index, freq=freq)\n\n    # ----------------------------------------------------------------\n    # Array-Like / EA-Interface Methods\n\n    @Appender(dtl.DatetimeLikeArrayMixin._validate_fill_value.__doc__)\n    def _validate_fill_value(self, fill_value):\n        if isna(fill_value):\n            fill_value = iNaT\n        elif isinstance(fill_value, (timedelta, np.timedelta64, Tick)):\n            fill_value = Timedelta(fill_value).value\n        else:\n            raise ValueError(\"'fill_value' should be a Timedelta. \"\n                             \"Got '{got}'.\".format(got=fill_value))\n        return fill_value\n\n    # monotonicity/uniqueness properties are called via frequencies.infer_freq,\n    #  see GH#23789\n\n    @property\n    def _is_monotonic_increasing(self):\n        return algos.is_monotonic(self.asi8, timelike=True)[0]\n\n    @property\n    def _is_monotonic_decreasing(self):\n        return algos.is_monotonic(self.asi8, timelike=True)[1]\n\n    @property\n    def _is_unique(self):\n        return len(unique1d(self.asi8)) == len(self)\n\n    # ----------------------------------------------------------------\n    # Arithmetic Methods\n\n    _create_comparison_method = classmethod(_td_array_cmp)\n\n    def _add_offset(self, other):\n        assert not isinstance(other, Tick)\n        raise TypeError(\"cannot add the type {typ} to a {cls}\"\n                        .format(typ=type(other).__name__,\n                                cls=type(self).__name__))\n\n    def _add_delta(self, delta):\n        \"\"\"\n        Add a timedelta-like, Tick, or TimedeltaIndex-like object\n        to self, yielding a new TimedeltaArray.\n\n        Parameters\n        ----------\n        other : {timedelta, np.timedelta64, Tick,\n                 TimedeltaIndex, ndarray[timedelta64]}\n\n        Returns\n        -------\n        result : TimedeltaArray\n        \"\"\"\n        new_values = dtl.DatetimeLikeArrayMixin._add_delta(self, delta)\n        return type(self)(new_values, freq='infer')\n\n    def _add_datetime_arraylike(self, other):\n        \"\"\"\n        Add DatetimeArray/Index or ndarray[datetime64] to TimedeltaArray.\n        \"\"\"\n        if isinstance(other, np.ndarray):\n            # At this point we have already checked that dtype is datetime64\n            from pandas.core.arrays import DatetimeArrayMixin\n            other = DatetimeArrayMixin(other)\n\n        # defer to implementation in DatetimeArray\n        return other + self\n\n    def _add_datetimelike_scalar(self, other):\n        # adding a timedeltaindex to a datetimelike\n        from pandas.core.arrays import DatetimeArrayMixin\n\n        assert other is not NaT\n        other = Timestamp(other)\n        if other is NaT:\n            # In this case we specifically interpret NaT as a datetime, not\n            # the timedelta interpretation we would get by returning self + NaT\n            result = self.asi8.view('m8[ms]') + NaT.to_datetime64()\n            return DatetimeArrayMixin(result)\n\n        i8 = self.asi8\n        result = checked_add_with_arr(i8, other.value,\n                                      arr_mask=self._isnan)\n        result = self._maybe_mask_results(result)\n        return DatetimeArrayMixin(result, tz=other.tz, freq=self.freq)\n\n    def _addsub_offset_array(self, other, op):\n        # Add or subtract Array-like of DateOffset objects\n        try:\n            # TimedeltaIndex can only operate with a subset of DateOffset\n            # subclasses.  Incompatible classes will raise AttributeError,\n            # which we re-raise as TypeError\n            return dtl.DatetimeLikeArrayMixin._addsub_offset_array(self, other,\n                                                                   op)\n        except AttributeError:\n            raise TypeError(\"Cannot add/subtract non-tick DateOffset to {cls}\"\n                            .format(cls=type(self).__name__))\n\n    def _evaluate_with_timedelta_like(self, other, op):\n        if isinstance(other, ABCSeries):\n            # GH#19042\n            return NotImplemented\n\n        opstr = '__{opname}__'.format(opname=op.__name__).replace('__r', '__')\n        # allow division by a timedelta\n        if opstr in ['__div__', '__truediv__', '__floordiv__']:\n            if _is_convertible_to_td(other):\n                other = Timedelta(other)\n                if isna(other):\n                    raise NotImplementedError(\n                        \"division by pd.NaT not implemented\")\n\n                i8 = self.asi8\n                left, right = i8, other.value\n\n                if opstr in ['__floordiv__']:\n                    result = op(left, right)\n                else:\n                    result = op(left, np.float64(right))\n                result = self._maybe_mask_results(result, fill_value=None,\n                                                  convert='float64')\n                return result\n\n        return NotImplemented\n\n    __mul__ = _wrap_tdi_op(operator.mul)\n    __rmul__ = __mul__\n    __truediv__ = _wrap_tdi_op(operator.truediv)\n    __floordiv__ = _wrap_tdi_op(operator.floordiv)\n    __rfloordiv__ = _wrap_tdi_op(ops.rfloordiv)\n\n    if compat.PY2:\n        __div__ = __truediv__\n\n    # Note: TimedeltaIndex overrides this in call to cls._add_numeric_methods\n    def __neg__(self):\n        if self.freq is not None:\n            return type(self)(-self._data, freq=-self.freq)\n        return type(self)(-self._data)\n\n    def __abs__(self):\n        # Note: freq is not preserved\n        return type(self)(np.abs(self._data))\n\n    # ----------------------------------------------------------------\n    # Conversion Methods - Vectorized analogues of Timedelta methods\n\n    def total_seconds(self):\n        \"\"\"\n        Return total duration of each element expressed in seconds.\n\n        This method is available directly on TimedeltaArray, TimedeltaIndex\n        and on Series containing timedelta values under the ``.dt`` namespace.\n\n        Returns\n        -------\n        seconds : [ndarray, Float64Index, Series]\n            When the calling object is a TimedeltaArray, the return type\n            is ndarray.  When the calling object is a TimedeltaIndex,\n            the return type is a Float64Index. When the calling object\n            is a Series, the return type is Series of type `float64` whose\n            index is the same as the original.\n\n        See Also\n        --------\n        datetime.timedelta.total_seconds : Standard library version\n            of this method.\n        TimedeltaIndex.components : Return a DataFrame with components of\n            each Timedelta.\n\n        Examples\n        --------\n        **Series**\n\n        >>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='d'))\n        >>> s\n        0   0 days\n        1   1 days\n        2   2 days\n        3   3 days\n        4   4 days\n        dtype: timedelta64[ns]\n\n        >>> s.dt.total_seconds()\n        0         0.0\n        1     86400.0\n        2    172800.0\n        3    259200.0\n        4    345600.0\n        dtype: float64\n\n        **TimedeltaIndex**\n\n        >>> idx = pd.to_timedelta(np.arange(5), unit='d')\n        >>> idx\n        TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],\n                       dtype='timedelta64[ns]', freq=None)\n\n        >>> idx.total_seconds()\n        Float64Index([0.0, 86400.0, 172800.0, 259200.00000000003, 345600.0],\n                     dtype='float64')\n        \"\"\"\n        return self._maybe_mask_results(1e-9 * self.asi8, fill_value=None)\n\n    def to_pytimedelta(self):\n        \"\"\"\n        Return Timedelta Array/Index as object ndarray of datetime.timedelta\n        objects.\n\n        Returns\n        -------\n        datetimes : ndarray\n        \"\"\"\n        return tslibs.ints_to_pytimedelta(self.asi8)\n\n    days = _field_accessor(\"days\", \"days\",\n                           \" Number of days for each element. \")\n    seconds = _field_accessor(\"seconds\", \"seconds\",\n                              \" Number of seconds (>= 0 and less than 1 day) \"\n                              \"for each element. \")\n    microseconds = _field_accessor(\"microseconds\", \"microseconds\",\n                                   \"\\nNumber of microseconds (>= 0 and less \"\n                                   \"than 1 second) for each\\nelement. \")\n    nanoseconds = _field_accessor(\"nanoseconds\", \"nanoseconds\",\n                                  \"\\nNumber of nanoseconds (>= 0 and less \"\n                                  \"than 1 microsecond) for each\\nelement.\\n\")\n\n    @property\n    def components(self):\n        \"\"\"\n        Return a dataframe of the components (days, hours, minutes,\n        seconds, milliseconds, microseconds, nanoseconds) of the Timedeltas.\n\n        Returns\n        -------\n        a DataFrame\n        \"\"\"\n        from pandas import DataFrame\n\n        columns = ['days', 'hours', 'minutes', 'seconds',\n                   'milliseconds', 'microseconds', 'nanoseconds']\n        hasnans = self.hasnans\n        if hasnans:\n            def f(x):\n                if isna(x):\n                    return [np.nan] * len(columns)\n                return x.components\n        else:\n            def f(x):\n                return x.components\n\n        result = DataFrame([f(x) for x in self], columns=columns)\n        if not hasnans:\n            result = result.astype('int64')\n        return result\n\n\nTimedeltaArrayMixin._add_comparison_ops()\nTimedeltaArrayMixin._add_datetimelike_methods()\n\n\n# ---------------------------------------------------------------------\n# Constructor Helpers\n\ndef sequence_to_td64ns(data, copy=False, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Parameters\n    ----------\n    array : list-like\n    copy : bool, default False\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    converted : numpy.ndarray\n        The sequence converted to a numpy array with dtype ``timedelta64[ns]``.\n    inferred_freq : Tick or None\n        The inferred frequency of the sequence.\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting ``errors=ignore`` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    inferred_freq = None\n    unit = parse_timedelta_unit(unit)\n\n    # Unwrap whatever we have into a np.ndarray\n    if not hasattr(data, 'dtype'):\n        # e.g. list, tuple\n        if np.ndim(data) == 0:\n            # i.e. generator\n            data = list(data)\n        data = np.array(data, copy=False)\n    elif isinstance(data, ABCSeries):\n        data = data._values\n    elif isinstance(data, (ABCTimedeltaIndex, TimedeltaArrayMixin)):\n        inferred_freq = data.freq\n        data = data._data\n\n    # Convert whatever we have into timedelta64[ns] dtype\n    if is_object_dtype(data) or is_string_dtype(data):\n        # no need to make a copy, need to convert if string-dtyped\n        data = objects_to_td64ns(data, unit=unit, errors=errors)\n        copy = False\n\n    elif is_integer_dtype(data):\n        # treat as multiples of the given unit\n        data, copy_made = ints_to_td64ns(data, unit=unit)\n        copy = copy and not copy_made\n\n    elif is_float_dtype(data):\n        # treat as multiples of the given unit.  If after converting to nanos,\n        #  there are fractional components left, these are truncated\n        #  (i.e. NOT rounded)\n        mask = np.isnan(data)\n        coeff = np.timedelta64(1, unit) / np.timedelta64(1, 'ns')\n        data = (coeff * data).astype(np.int64).view('timedelta64[ns]')\n        data[mask] = iNaT\n        copy = False\n\n    elif is_timedelta64_dtype(data):\n        if data.dtype != _TD_DTYPE:\n            # non-nano unit\n            # TODO: watch out for overflows\n            data = data.astype(_TD_DTYPE)\n            copy = False\n\n    elif is_datetime64_dtype(data):\n        # GH#23539\n        warnings.warn(\"Passing datetime64-dtype data to TimedeltaIndex is \"\n                      \"deprecated, will raise a TypeError in a future \"\n                      \"version\",\n                      FutureWarning, stacklevel=3)\n        data = ensure_int64(data).view(_TD_DTYPE)\n\n    else:\n        raise TypeError(\"dtype {dtype} cannot be converted to timedelta64[ns]\"\n                        .format(dtype=data.dtype))\n\n    data = np.array(data, copy=copy)\n    assert data.dtype == 'm8[ns]', data\n    return data, inferred_freq\n\n\ndef ints_to_td64ns(data, unit=\"ns\"):\n    \"\"\"\n    Convert an ndarray with integer-dtype to timedelta64[ns] dtype, treating\n    the integers as multiples of the given timedelta unit.\n\n    Parameters\n    ----------\n    data : numpy.ndarray with integer-dtype\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n    bool : whether a copy was made\n    \"\"\"\n    copy_made = False\n    unit = unit if unit is not None else \"ns\"\n\n    if data.dtype != np.int64:\n        # converting to int64 makes a copy, so we can avoid\n        # re-copying later\n        data = data.astype(np.int64)\n        copy_made = True\n\n    if unit != \"ns\":\n        dtype_str = \"timedelta64[{unit}]\".format(unit=unit)\n        data = data.view(dtype_str)\n\n        # TODO: watch out for overflows when converting from lower-resolution\n        data = data.astype(\"timedelta64[ns]\")\n        # the astype conversion makes a copy, so we can avoid re-copying later\n        copy_made = True\n\n    else:\n        data = data.view(\"timedelta64[ns]\")\n\n    return data, copy_made\n\n\ndef objects_to_td64ns(data, unit=\"ns\", errors=\"raise\"):\n    \"\"\"\n    Convert a object-dtyped or string-dtyped array into an\n    timedelta64[ns]-dtyped array.\n\n    Parameters\n    ----------\n    data : ndarray or Index\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n    errors : {\"raise\", \"coerce\", \"ignore\"}, default \"raise\"\n        How to handle elements that cannot be converted to timedelta64[ns].\n        See ``pandas.to_timedelta`` for details.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n\n    Raises\n    ------\n    ValueError : Data cannot be converted to timedelta64[ns].\n\n    Notes\n    -----\n    Unlike `pandas.to_timedelta`, if setting `errors=ignore` will not cause\n    errors to be ignored; they are caught and subsequently ignored at a\n    higher level.\n    \"\"\"\n    # coerce Index to np.ndarray, converting string-dtype if necessary\n    values = np.array(data, dtype=np.object_, copy=False)\n\n    result = array_to_timedelta64(values,\n                                  unit=unit, errors=errors)\n    return result.view('timedelta64[ns]')\n\n\ndef _generate_regular_range(start, end, periods, offset):\n    stride = offset.nanos\n    if periods is None:\n        b = Timedelta(start).value\n        e = Timedelta(end).value\n        e += stride - e % stride\n    elif start is not None:\n        b = Timedelta(start).value\n        e = b + periods * stride\n    elif end is not None:\n        e = Timedelta(end).value + stride\n        b = e - periods * stride\n    else:\n        raise ValueError(\"at least 'start' or 'end' should be specified \"\n                         \"if a 'period' is given.\")\n\n    data = np.arange(b, e, stride, dtype=np.int64)\n    return data\n",
          "file_patch": "@@ -7,7 +7,7 @@ import warnings\n \n import numpy as np\n \n-from pandas._libs import tslibs\n+from pandas._libs import algos, tslibs\n from pandas._libs.tslibs import NaT, Timedelta, Timestamp, iNaT\n from pandas._libs.tslibs.fields import get_timedelta_field\n from pandas._libs.tslibs.timedeltas import (\n@@ -24,7 +24,7 @@ from pandas.core.dtypes.generic import (\n from pandas.core.dtypes.missing import isna\n \n from pandas.core import ops\n-from pandas.core.algorithms import checked_add_with_arr\n+from pandas.core.algorithms import checked_add_with_arr, unique1d\n import pandas.core.common as com\n \n from pandas.tseries.frequencies import to_offset\n@@ -162,15 +162,29 @@ class TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin):\n         result._freq = freq\n         return result\n \n-    def __new__(cls, values, freq=None, dtype=_TD_DTYPE):\n+    def __new__(cls, values, freq=None, dtype=_TD_DTYPE, copy=False):\n \n         freq, freq_infer = dtl.maybe_infer_freq(freq)\n \n-        values = np.array(values, copy=False)\n-        if values.dtype == np.object_:\n-            values = array_to_timedelta64(values)\n+        values, inferred_freq = sequence_to_td64ns(\n+            values, copy=copy, unit=None)\n+        if inferred_freq is not None:\n+            if freq is not None and freq != inferred_freq:\n+                raise ValueError('Inferred frequency {inferred} from passed '\n+                                 'values does not conform to passed frequency '\n+                                 '{passed}'\n+                                 .format(inferred=inferred_freq,\n+                                         passed=freq.freqstr))\n+            elif freq is None:\n+                freq = inferred_freq\n+                freq_infer = False\n \n         result = cls._simple_new(values, freq=freq)\n+        # check that we are matching freqs\n+        if inferred_freq is None and len(result) > 0:\n+            if freq is not None and not freq_infer:\n+                cls._validate_frequency(result, freq)\n+\n         if freq_infer:\n             result.freq = to_offset(result.inferred_freq)\n \n@@ -227,6 +241,21 @@ class TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin):\n                              \"Got '{got}'.\".format(got=fill_value))\n         return fill_value\n \n+    # monotonicity/uniqueness properties are called via frequencies.infer_freq,\n+    #  see GH#23789\n+\n+    @property\n+    def _is_monotonic_increasing(self):\n+        return algos.is_monotonic(self.asi8, timelike=True)[0]\n+\n+    @property\n+    def _is_monotonic_decreasing(self):\n+        return algos.is_monotonic(self.asi8, timelike=True)[1]\n+\n+    @property\n+    def _is_unique(self):\n+        return len(unique1d(self.asi8)) == len(self)\n+\n     # ----------------------------------------------------------------\n     # Arithmetic Methods\n \n@@ -283,7 +312,7 @@ class TimedeltaArrayMixin(dtl.DatetimeLikeArrayMixin):\n         result = checked_add_with_arr(i8, other.value,\n                                       arr_mask=self._isnan)\n         result = self._maybe_mask_results(result)\n-        return DatetimeArrayMixin(result, tz=other.tz)\n+        return DatetimeArrayMixin(result, tz=other.tz, freq=self.freq)\n \n     def _addsub_offset_array(self, other, op):\n         # Add or subtract Array-like of DateOffset objects\n",
          "files_name_in_blame_commit": [
            "frequencies.py",
            "test_datetime64.py",
            "datetimes.py",
            "test_construction.py",
            "offsets.py",
            "timedeltas.py",
            "test_timedelta64.py",
            "timestamps.pyx"
          ]
        }
      }
    }
  }
}