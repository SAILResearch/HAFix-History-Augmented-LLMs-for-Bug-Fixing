{
  "id": "57",
  "blame_commit": {
    "commit": {
      "commit_id": "9120a7251d3ac13048d212b424cb92841ffd7cd4",
      "commit_message": "Further style fixes.",
      "commit_author": "Francois Chollet",
      "commit_date": "2017-01-11 14:32:35",
      "commit_parent": "a5ec992b1fb7e52b12c9cfa220defaa9a5b0628e"
    },
    "function": {
      "function_name": "predict",
      "function_code_before": "def predict(self, X, **kwargs):\n    \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n    kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n    return np.squeeze(self.model.predict(X, **kwargs))",
      "function_code_after": "def predict(self, x, **kwargs):\n    \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n    kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n    return np.squeeze(self.model.predict(x, **kwargs))",
      "function_before_start_line": 261,
      "function_before_end_line": 275,
      "function_after_start_line": 274,
      "function_after_end_line": 288,
      "function_before_token_count": 40,
      "function_after_token_count": 0,
      "functions_name_modified_file": [
        "__init__",
        "set_params",
        "get_params",
        "check_params",
        "predict",
        "filter_sk_params",
        "predict_proba",
        "fit",
        "score"
      ],
      "functions_name_all_files": [
        "__init__",
        "build",
        "call",
        "set_params",
        "get_params",
        "check_params",
        "predict",
        "filter_sk_params",
        "predict_proba",
        "fit",
        "score",
        "get_config"
      ],
      "functions_name_co_evolved_modified_file": [
        "set_params",
        "get_params",
        "check_params",
        "filter_sk_params",
        "predict_proba",
        "fit",
        "score"
      ],
      "functions_name_co_evolved_all_files": [
        "set_params",
        "get_params",
        "check_params",
        "filter_sk_params",
        "predict_proba",
        "fit",
        "score"
      ]
    },
    "file": {
      "file_name": "scikit_learn.py",
      "file_nloc": 143,
      "file_complexity": 34,
      "file_token_count": 851,
      "file_before": "from __future__ import absolute_import\n\nimport copy\nimport inspect\nimport types\n\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\nfrom ..models import Sequential\n\n\nclass BaseWrapper(object):\n    \"\"\"Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly.\n    Use descendant classes instead.\n\n    # Arguments\n        build_fn: callable function or class instance\n        sk_params: model parameters & fitting parameters\n\n    The build_fn should construct, compile and return a Keras model, which\n    will then be used to fit/predict. One of the following\n    three values could be passed to build_fn:\n    1. A function\n    2. An instance of a class that implements the __call__ method\n    3. None. This means you implement a class that inherits from either\n    `KerasClassifier` or `KerasRegressor`. The __call__ method of the\n    present class will then be treated as the default build_fn.\n\n    `sk_params` takes both model parameters and fitting parameters. Legal model\n    parameters are the arguments of `build_fn`. Note that like all other\n    estimators in scikit-learn, 'build_fn' should provide default values for\n    its arguments, so that you could create the estimator without passing any\n    values to `sk_params`.\n\n    `sk_params` could also accept parameters for calling `fit`, `predict`,\n    `predict_proba`, and `score` methods (e.g., `nb_epoch`, `batch_size`).\n    fitting (predicting) parameters are selected in the following order:\n\n    1. Values passed to the dictionary arguments of\n    `fit`, `predict`, `predict_proba`, and `score` methods\n    2. Values passed to `sk_params`\n    3. The default values of the `keras.models.Sequential`\n    `fit`, `predict`, `predict_proba` and `score` methods\n\n    When using scikit-learn's `grid_search` API, legal tunable parameters are\n    those you could pass to `sk_params`, including fitting parameters.\n    In other words, you could use `grid_search` to search for the best\n    `batch_size` or `nb_epoch` as well as the model parameters.\n    \"\"\"\n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n        self.check_params(sk_params)\n\n    def check_params(self, params):\n        \"\"\"Check for user typos in \"params\" keys to avoid\n        unwanted usage of default values\n\n        # Arguments\n            params: dictionary\n                The parameters to be checked\n        \"\"\"\n        legal_params_fns = [Sequential.fit, Sequential.predict,\n                            Sequential.predict_classes, Sequential.evaluate]\n        if self.build_fn is None:\n            legal_params_fns.append(self.__call__)\n        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n            legal_params_fns.append(self.build_fn.__call__)\n        else:\n            legal_params_fns.append(self.build_fn)\n\n        legal_params = []\n        for fn in legal_params_fns:\n            legal_params += inspect.getargspec(fn)[0]\n        legal_params = set(legal_params)\n\n        for params_name in params:\n            if params_name not in legal_params:\n                raise ValueError('{} is not a legal parameter'.format(params_name))\n\n    def get_params(self, deep=True):\n        \"\"\"Get parameters for this estimator.\n\n        # Arguments\n            deep: boolean, optional\n                If True, will return the parameters for this estimator and\n                contained sub-objects that are estimators.\n\n        # Returns\n            params : dict\n                Dictionary of parameter names mapped to their values.\n        \"\"\"\n        res = copy.deepcopy(self.sk_params)\n        res.update({'build_fn': self.build_fn})\n        return res\n\n    def set_params(self, **params):\n        \"\"\"Set the parameters of this estimator.\n\n        # Arguments\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        # Returns\n            self\n        \"\"\"\n        self.check_params(params)\n        self.sk_params.update(params)\n        return self\n\n    def fit(self, X, y, **kwargs):\n        \"\"\"Construct a new model with build_fn and fit the model according\n        to the given training data.\n\n        # Arguments\n            X : array-like, shape `(n_samples, n_features)`\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        \"\"\"\n\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(X, y, **fit_args)\n\n        return history\n\n    def filter_sk_params(self, fn, override={}):\n        \"\"\"Filter sk_params and return those in fn's arguments\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to override sk_params\n\n        # Returns\n            res : dictionary dictionary containing variables\n                in both sk_params and fn's arguments.\n        \"\"\"\n        res = {}\n        fn_args = inspect.getargspec(fn)[0]\n        for name, value in self.sk_params.items():\n            if name in fn_args:\n                res.update({name: value})\n        res.update(override)\n        return res\n\n\nclass KerasClassifier(BaseWrapper):\n    \"\"\"Implementation of the scikit-learn classifier API for Keras.\n    \"\"\"\n\n    def predict(self, X, **kwargs):\n        \"\"\"Returns the class predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Class predictions.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n        return self.model.predict_classes(X, **kwargs)\n\n    def predict_proba(self, X, **kwargs):\n        \"\"\"Returns class probability estimates for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            proba: array-like, shape `(n_samples, n_outputs)`\n                Class probability estimates.\n                In the case of binary classification,\n                tp match the scikit-learn API,\n                will return an array of shape '(n_samples, 2)'\n                (instead of `(n_sample, 1)` as in Keras).\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        probs = self.model.predict_proba(X, **kwargs)\n\n        # check if binary classification\n        if probs.shape[1] == 1:\n            # first column is probability of class 0 and second is of class 1\n            probs = np.hstack([1 - probs, probs])\n        return probs\n\n    def score(self, X, y, **kwargs):\n        \"\"\"Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        outputs = self.model.evaluate(X, y, **kwargs)\n        if not isinstance(outputs, list):\n            outputs = [outputs]\n        for name, output in zip(self.model.metrics_names, outputs):\n            if name == 'acc':\n                return output\n        raise ValueError('The model is not configured to compute accuracy. '\n                         'You should pass `metrics=[\"accuracy\"]` to '\n                         'the `model.compile()` method.')\n\n\nclass KerasRegressor(BaseWrapper):\n    \"\"\"Implementation of the scikit-learn regressor API for Keras.\n    \"\"\"\n\n    def predict(self, X, **kwargs):\n        \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return np.squeeze(self.model.predict(X, **kwargs))\n\n    def score(self, X, y, **kwargs):\n        \"\"\"Returns the mean loss on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        loss = self.model.evaluate(X, y, **kwargs)\n        if isinstance(loss, list):\n            return loss[0]\n        return loss\n",
      "file_after": "from __future__ import absolute_import\n\nimport copy\nimport inspect\nimport types\n\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\nfrom ..models import Sequential\n\n\nclass BaseWrapper(object):\n    \"\"\"Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly.\n    Use descendant classes instead.\n\n    # Arguments\n        build_fn: callable function or class instance\n        **sk_params: model parameters & fitting parameters\n\n    The build_fn should construct, compile and return a Keras model, which\n    will then be used to fit/predict. One of the following\n    three values could be passed to build_fn:\n    1. A function\n    2. An instance of a class that implements the __call__ method\n    3. None. This means you implement a class that inherits from either\n    `KerasClassifier` or `KerasRegressor`. The __call__ method of the\n    present class will then be treated as the default build_fn.\n\n    `sk_params` takes both model parameters and fitting parameters. Legal model\n    parameters are the arguments of `build_fn`. Note that like all other\n    estimators in scikit-learn, 'build_fn' should provide default values for\n    its arguments, so that you could create the estimator without passing any\n    values to `sk_params`.\n\n    `sk_params` could also accept parameters for calling `fit`, `predict`,\n    `predict_proba`, and `score` methods (e.g., `nb_epoch`, `batch_size`).\n    fitting (predicting) parameters are selected in the following order:\n\n    1. Values passed to the dictionary arguments of\n    `fit`, `predict`, `predict_proba`, and `score` methods\n    2. Values passed to `sk_params`\n    3. The default values of the `keras.models.Sequential`\n    `fit`, `predict`, `predict_proba` and `score` methods\n\n    When using scikit-learn's `grid_search` API, legal tunable parameters are\n    those you could pass to `sk_params`, including fitting parameters.\n    In other words, you could use `grid_search` to search for the best\n    `batch_size` or `nb_epoch` as well as the model parameters.\n    \"\"\"\n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n        self.check_params(sk_params)\n\n    def check_params(self, params):\n        \"\"\"Checks for user typos in \"params\" keys to avoid\n        unwanted usage of default values\n\n        # Arguments\n            params: dictionary\n                The parameters to be checked\n\n        # Raises\n            ValueError: if any member of `params` is not a valid\n                argument.\n        \"\"\"\n        legal_params_fns = [Sequential.fit, Sequential.predict,\n                            Sequential.predict_classes, Sequential.evaluate]\n        if self.build_fn is None:\n            legal_params_fns.append(self.__call__)\n        elif (not isinstance(self.build_fn, types.FunctionType) and\n              not isinstance(self.build_fn, types.MethodType)):\n            legal_params_fns.append(self.build_fn.__call__)\n        else:\n            legal_params_fns.append(self.build_fn)\n\n        legal_params = []\n        for fn in legal_params_fns:\n            legal_params += inspect.getargspec(fn)[0]\n        legal_params = set(legal_params)\n\n        for params_name in params:\n            if params_name not in legal_params:\n                raise ValueError('{} is not a legal parameter'.format(params_name))\n\n    def get_params(self, deep=True):\n        \"\"\"Gets parameters for this estimator.\n\n        # Arguments\n            deep: boolean, optional\n                If True, will return the parameters for this estimator and\n                contained sub-objects that are estimators.\n\n        # Returns\n            params : dict\n                Dictionary of parameter names mapped to their values.\n        \"\"\"\n        res = copy.deepcopy(self.sk_params)\n        res.update({'build_fn': self.build_fn})\n        return res\n\n    def set_params(self, **params):\n        \"\"\"Sets the parameters of this estimator.\n\n        # Arguments\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        # Returns\n            self\n        \"\"\"\n        self.check_params(params)\n        self.sk_params.update(params)\n        return self\n\n    def fit(self, x, y, **kwargs):\n        \"\"\"Constructs a new model with build_fn and fit the model according\n        to the given training data.\n\n        # Arguments\n            x : array-like, shape `(n_samples, n_features)`\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        \"\"\"\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif (not isinstance(self.build_fn, types.FunctionType) and\n              not isinstance(self.build_fn, types.MethodType)):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(x, y, **fit_args)\n\n        return history\n\n    def filter_sk_params(self, fn, override=None):\n        \"\"\"Filters sk_params and return those in fn's arguments\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to override sk_params\n\n        # Returns\n            res : dictionary dictionary containing variables\n                in both sk_params and fn's arguments.\n        \"\"\"\n        override = override or {}\n        res = {}\n        fn_args = inspect.getargspec(fn)[0]\n        for name, value in self.sk_params.items():\n            if name in fn_args:\n                res.update({name: value})\n        res.update(override)\n        return res\n\n\nclass KerasClassifier(BaseWrapper):\n    \"\"\"Implementation of the scikit-learn classifier API for Keras.\n    \"\"\"\n\n    def predict(self, x, **kwargs):\n        \"\"\"Returns the class predictions for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments\n                of `Sequential.predict_classes`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Class predictions.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n        return self.model.predict_classes(x, **kwargs)\n\n    def predict_proba(self, x, **kwargs):\n        \"\"\"Returns class probability estimates for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments\n                of `Sequential.predict_classes`.\n\n        # Returns\n            proba: array-like, shape `(n_samples, n_outputs)`\n                Class probability estimates.\n                In the case of binary classification,\n                tp match the scikit-learn API,\n                will return an array of shape '(n_samples, 2)'\n                (instead of `(n_sample, 1)` as in Keras).\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        probs = self.model.predict_proba(x, **kwargs)\n\n        # check if binary classification\n        if probs.shape[1] == 1:\n            # first column is probability of class 0 and second is of class 1\n            probs = np.hstack([1 - probs, probs])\n        return probs\n\n    def score(self, x, y, **kwargs):\n        \"\"\"Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for x.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n\n        # Raises\n            ValueError: If the underlying model isn't configured to\n                compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n                the `.compile()` method of the model.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        outputs = self.model.evaluate(x, y, **kwargs)\n        if not isinstance(outputs, list):\n            outputs = [outputs]\n        for name, output in zip(self.model.metrics_names, outputs):\n            if name == 'acc':\n                return output\n        raise ValueError('The model is not configured to compute accuracy. '\n                         'You should pass `metrics=[\"accuracy\"]` to '\n                         'the `model.compile()` method.')\n\n\nclass KerasRegressor(BaseWrapper):\n    \"\"\"Implementation of the scikit-learn regressor API for Keras.\n    \"\"\"\n\n    def predict(self, x, **kwargs):\n        \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return np.squeeze(self.model.predict(x, **kwargs))\n\n    def score(self, x, y, **kwargs):\n        \"\"\"Returns the mean loss on the given test data and labels.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        loss = self.model.evaluate(x, y, **kwargs)\n        if isinstance(loss, list):\n            return loss[0]\n        return loss\n",
      "file_patch": "@@ -18,7 +18,7 @@ class BaseWrapper(object):\n \n     # Arguments\n         build_fn: callable function or class instance\n-        sk_params: model parameters & fitting parameters\n+        **sk_params: model parameters & fitting parameters\n \n     The build_fn should construct, compile and return a Keras model, which\n     will then be used to fit/predict. One of the following\n@@ -57,18 +57,23 @@ class BaseWrapper(object):\n         self.check_params(sk_params)\n \n     def check_params(self, params):\n-        \"\"\"Check for user typos in \"params\" keys to avoid\n+        \"\"\"Checks for user typos in \"params\" keys to avoid\n         unwanted usage of default values\n \n         # Arguments\n             params: dictionary\n                 The parameters to be checked\n+\n+        # Raises\n+            ValueError: if any member of `params` is not a valid\n+                argument.\n         \"\"\"\n         legal_params_fns = [Sequential.fit, Sequential.predict,\n                             Sequential.predict_classes, Sequential.evaluate]\n         if self.build_fn is None:\n             legal_params_fns.append(self.__call__)\n-        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n+        elif (not isinstance(self.build_fn, types.FunctionType) and\n+              not isinstance(self.build_fn, types.MethodType)):\n             legal_params_fns.append(self.build_fn.__call__)\n         else:\n             legal_params_fns.append(self.build_fn)\n@@ -83,7 +88,7 @@ class BaseWrapper(object):\n                 raise ValueError('{} is not a legal parameter'.format(params_name))\n \n     def get_params(self, deep=True):\n-        \"\"\"Get parameters for this estimator.\n+        \"\"\"Gets parameters for this estimator.\n \n         # Arguments\n             deep: boolean, optional\n@@ -99,7 +104,7 @@ class BaseWrapper(object):\n         return res\n \n     def set_params(self, **params):\n-        \"\"\"Set the parameters of this estimator.\n+        \"\"\"Sets the parameters of this estimator.\n \n         # Arguments\n         params: dict\n@@ -112,12 +117,12 @@ class BaseWrapper(object):\n         self.sk_params.update(params)\n         return self\n \n-    def fit(self, X, y, **kwargs):\n-        \"\"\"Construct a new model with build_fn and fit the model according\n+    def fit(self, x, y, **kwargs):\n+        \"\"\"Constructs a new model with build_fn and fit the model according\n         to the given training data.\n \n         # Arguments\n-            X : array-like, shape `(n_samples, n_features)`\n+            x : array-like, shape `(n_samples, n_features)`\n                 Training samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n@@ -129,10 +134,10 @@ class BaseWrapper(object):\n             history : object\n                 details about the training history at each epoch.\n         \"\"\"\n-\n         if self.build_fn is None:\n             self.model = self.__call__(**self.filter_sk_params(self.__call__))\n-        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n+        elif (not isinstance(self.build_fn, types.FunctionType) and\n+              not isinstance(self.build_fn, types.MethodType)):\n             self.model = self.build_fn(\n                 **self.filter_sk_params(self.build_fn.__call__))\n         else:\n@@ -147,12 +152,12 @@ class BaseWrapper(object):\n         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n         fit_args.update(kwargs)\n \n-        history = self.model.fit(X, y, **fit_args)\n+        history = self.model.fit(x, y, **fit_args)\n \n         return history\n \n-    def filter_sk_params(self, fn, override={}):\n-        \"\"\"Filter sk_params and return those in fn's arguments\n+    def filter_sk_params(self, fn, override=None):\n+        \"\"\"Filters sk_params and return those in fn's arguments\n \n         # Arguments\n             fn : arbitrary function\n@@ -162,6 +167,7 @@ class BaseWrapper(object):\n             res : dictionary dictionary containing variables\n                 in both sk_params and fn's arguments.\n         \"\"\"\n+        override = override or {}\n         res = {}\n         fn_args = inspect.getargspec(fn)[0]\n         for name, value in self.sk_params.items():\n@@ -175,32 +181,34 @@ class KerasClassifier(BaseWrapper):\n     \"\"\"Implementation of the scikit-learn classifier API for Keras.\n     \"\"\"\n \n-    def predict(self, X, **kwargs):\n+    def predict(self, x, **kwargs):\n         \"\"\"Returns the class predictions for the given test data.\n \n         # Arguments\n-            X: array-like, shape `(n_samples, n_features)`\n+            x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             kwargs: dictionary arguments\n-                Legal arguments are the arguments of `Sequential.predict_classes`.\n+                Legal arguments are the arguments\n+                of `Sequential.predict_classes`.\n \n         # Returns\n             preds: array-like, shape `(n_samples,)`\n                 Class predictions.\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n-        return self.model.predict_classes(X, **kwargs)\n+        return self.model.predict_classes(x, **kwargs)\n \n-    def predict_proba(self, X, **kwargs):\n+    def predict_proba(self, x, **kwargs):\n         \"\"\"Returns class probability estimates for the given test data.\n \n         # Arguments\n-            X: array-like, shape `(n_samples, n_features)`\n+            x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             kwargs: dictionary arguments\n-                Legal arguments are the arguments of `Sequential.predict_classes`.\n+                Legal arguments are the arguments\n+                of `Sequential.predict_classes`.\n \n         # Returns\n             proba: array-like, shape `(n_samples, n_outputs)`\n@@ -211,7 +219,7 @@ class KerasClassifier(BaseWrapper):\n                 (instead of `(n_sample, 1)` as in Keras).\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n-        probs = self.model.predict_proba(X, **kwargs)\n+        probs = self.model.predict_proba(x, **kwargs)\n \n         # check if binary classification\n         if probs.shape[1] == 1:\n@@ -219,21 +227,26 @@ class KerasClassifier(BaseWrapper):\n             probs = np.hstack([1 - probs, probs])\n         return probs\n \n-    def score(self, X, y, **kwargs):\n+    def score(self, x, y, **kwargs):\n         \"\"\"Returns the mean accuracy on the given test data and labels.\n \n         # Arguments\n-            X: array-like, shape `(n_samples, n_features)`\n+            x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n-                True labels for X.\n+                True labels for x.\n             kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.evaluate`.\n \n         # Returns\n             score: float\n                 Mean accuracy of predictions on X wrt. y.\n+\n+        # Raises\n+            ValueError: If the underlying model isn't configured to\n+                compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n+                the `.compile()` method of the model.\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n \n@@ -243,7 +256,7 @@ class KerasClassifier(BaseWrapper):\n         if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n             y = to_categorical(y)\n \n-        outputs = self.model.evaluate(X, y, **kwargs)\n+        outputs = self.model.evaluate(x, y, **kwargs)\n         if not isinstance(outputs, list):\n             outputs = [outputs]\n         for name, output in zip(self.model.metrics_names, outputs):\n@@ -258,27 +271,27 @@ class KerasRegressor(BaseWrapper):\n     \"\"\"Implementation of the scikit-learn regressor API for Keras.\n     \"\"\"\n \n-    def predict(self, X, **kwargs):\n+    def predict(self, x, **kwargs):\n         \"\"\"Returns predictions for the given test data.\n \n         # Arguments\n             X: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n-            kwargs: dictionary arguments\n+            **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.predict`.\n         # Returns\n             preds: array-like, shape `(n_samples,)`\n                 Predictions.\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n-        return np.squeeze(self.model.predict(X, **kwargs))\n+        return np.squeeze(self.model.predict(x, **kwargs))\n \n-    def score(self, X, y, **kwargs):\n+    def score(self, x, y, **kwargs):\n         \"\"\"Returns the mean loss on the given test data and labels.\n \n         # Arguments\n-            X: array-like, shape `(n_samples, n_features)`\n+            x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             y: array-like, shape `(n_samples,)`\n@@ -291,7 +304,7 @@ class KerasRegressor(BaseWrapper):\n                 Mean accuracy of predictions on X wrt. y.\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n-        loss = self.model.evaluate(X, y, **kwargs)\n+        loss = self.model.evaluate(x, y, **kwargs)\n         if isinstance(loss, list):\n             return loss[0]\n         return loss\n",
      "files_name_in_blame_commit": [
        "scikit_learn.py",
        "normalization.py"
      ]
    }
  },
  "commits_modify_file_before_fix": {
    "size": 48
  },
  "recursive_blame_commits": {
    "recursive_blame_function_lines": {
      "261": {
        "commit_id": "be24159959672c32abb31697e721d96ae6ffaf97",
        "line_code": "    def predict(self, X, **kwargs):",
        "commit_date": "2016-02-28 13:46:20",
        "valid": 1
      },
      "262": {
        "commit_id": "8f7574437951a8f1042407d25bffb57292e3b6a6",
        "line_code": "        \"\"\"Returns predictions for the given test data.",
        "commit_date": "2017-01-10 15:34:16",
        "valid": 1
      },
      "263": {
        "commit_id": "be24159959672c32abb31697e721d96ae6ffaf97",
        "line_code": "",
        "commit_date": "2016-02-28 13:46:20",
        "valid": 0
      },
      "264": {
        "commit_id": "be24159959672c32abb31697e721d96ae6ffaf97",
        "line_code": "        # Arguments",
        "commit_date": "2016-02-28 13:46:20",
        "valid": 1
      },
      "265": {
        "commit_id": "763a2a953638ac1a1374c11d65716938060553c0",
        "line_code": "            X: array-like, shape `(n_samples, n_features)`",
        "commit_date": "2016-02-28 11:54:00",
        "valid": 1
      },
      "266": {
        "commit_id": "c9461d71483b5cfd2639abc909cc7f145f1625c4",
        "line_code": "                Test samples where n_samples in the number of samples",
        "commit_date": "2015-08-15 20:59:06",
        "valid": 1
      },
      "267": {
        "commit_id": "c9461d71483b5cfd2639abc909cc7f145f1625c4",
        "line_code": "                and n_features is the number of features.",
        "commit_date": "2015-08-15 20:59:06",
        "valid": 1
      },
      "268": {
        "commit_id": "be24159959672c32abb31697e721d96ae6ffaf97",
        "line_code": "            kwargs: dictionary arguments",
        "commit_date": "2016-02-28 13:46:20",
        "valid": 1
      },
      "269": {
        "commit_id": "763a2a953638ac1a1374c11d65716938060553c0",
        "line_code": "                Legal arguments are the arguments of `Sequential.predict`.",
        "commit_date": "2016-02-28 11:54:00",
        "valid": 1
      },
      "270": {
        "commit_id": "be24159959672c32abb31697e721d96ae6ffaf97",
        "line_code": "        # Returns",
        "commit_date": "2016-02-28 13:46:20",
        "valid": 1
      },
      "271": {
        "commit_id": "763a2a953638ac1a1374c11d65716938060553c0",
        "line_code": "            preds: array-like, shape `(n_samples,)`",
        "commit_date": "2016-02-28 11:54:00",
        "valid": 1
      },
      "272": {
        "commit_id": "c9461d71483b5cfd2639abc909cc7f145f1625c4",
        "line_code": "                Predictions.",
        "commit_date": "2015-08-15 20:59:06",
        "valid": 1
      },
      "273": {
        "commit_id": "8f7574437951a8f1042407d25bffb57292e3b6a6",
        "line_code": "        \"\"\"",
        "commit_date": "2017-01-10 15:34:16",
        "valid": 1
      },
      "274": {
        "commit_id": "be24159959672c32abb31697e721d96ae6ffaf97",
        "line_code": "        kwargs = self.filter_sk_params(Sequential.predict, kwargs)",
        "commit_date": "2016-02-28 13:46:20",
        "valid": 1
      },
      "275": {
        "commit_id": "e4dda27de186f6f98a61aee3328aa21d7ef7f7ba",
        "line_code": "        return np.squeeze(self.model.predict(X, **kwargs))",
        "commit_date": "2016-08-22 15:19:26",
        "valid": 1
      }
    },
    "commits": {
      "8f7574437951a8f1042407d25bffb57292e3b6a6": {
        "commit": {
          "commit_id": "8f7574437951a8f1042407d25bffb57292e3b6a6",
          "commit_message": "Further style fixes (still incomplete).",
          "commit_author": "Francois Chollet",
          "commit_date": "2017-01-10 15:34:16",
          "commit_parent": "ea47e6de279397cb1adf953ae971cf884587447d"
        },
        "function": {
          "function_name": "predict",
          "function_code_before": "def predict(self, X, **kwargs):\n    \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n    kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n    return np.squeeze(self.model.predict(X, **kwargs))",
          "function_code_after": "def predict(self, X, **kwargs):\n    \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n    kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n    return np.squeeze(self.model.predict(X, **kwargs))",
          "function_before_start_line": 259,
          "function_before_end_line": 273,
          "function_after_start_line": 259,
          "function_after_end_line": 273,
          "function_before_token_count": 40,
          "function_after_token_count": 0,
          "functions_name_modified_file": [
            "__init__",
            "set_params",
            "get_params",
            "check_params",
            "predict",
            "filter_sk_params",
            "predict_proba",
            "fit",
            "score"
          ],
          "functions_name_all_files": [
            "flow",
            "pool3d",
            "flow_from_directory",
            "librosa_exists",
            "reverse",
            "_assert_has_capability",
            "create_node",
            "_updated_config",
            "ctc_cost",
            "batch_normalization",
            "lecun_uniform",
            "InceptionV3",
            "step",
            "stateful",
            "stack",
            "eval",
            "_old_theano_conv3d",
            "identity_block",
            "VGG16",
            "VGG19",
            "equal",
            "save_model",
            "cast_to_floatx",
            "shape",
            "load_data",
            "greater",
            "trainable_weights",
            "conv_step",
            "moving_average_update",
            "ask_to_proceed_with_overwrite",
            "manual_variable_initialization",
            "get_updates",
            "test_on_batch",
            "asymmetric_spatial_2d_padding",
            "lesser",
            "next",
            "_fix_unknown_dimension",
            "__next__",
            "call",
            "in_train_phase",
            "permute_dimensions",
            "updates",
            "l2_normalize",
            "load_model",
            "random_normal_variable",
            "get_session",
            "apply_transform",
            "_convert_string_dtype",
            "asymmetric_temporal_padding",
            "make_sampling_table",
            "relu",
            "_preprocess_border_mode",
            "clear_session",
            "one",
            "random_normal",
            "zeros_like",
            "_pooling_function",
            "squared_hinge",
            "object_list_uid",
            "binary_crossentropy",
            "_cond",
            "random_shear",
            "_gather_list_attr",
            "non_trainable_weights",
            "__call__",
            "abs",
            "optimizer_from_config",
            "ctc_decode",
            "trainable",
            "model_from_json",
            "floatx",
            "in_test_phase",
            "state_updates",
            "resize_images",
            "predict_on_batch",
            "normal",
            "he_normal",
            "is_keras_tensor",
            "to_yaml",
            "tile",
            "_old_theano_pool3d",
            "pow",
            "_preprocess_conv2d_filter_shape",
            "regularizers",
            "_gather_dict_attr",
            "argmin",
            "clip_norm",
            "random_uniform_variable",
            "repeat",
            "Xception",
            "to_json",
            "ndim",
            "_flow_index",
            "update",
            "set_params",
            "random_binomial",
            "ctc_create_skip_idxs",
            "display_table",
            "standardize",
            "run_internal_graph",
            "texts_to_sequences",
            "validate_file",
            "resize_volumes",
            "evaluate",
            "conv2d_bn",
            "get_input_shape_at",
            "random_rotation",
            "get_fans",
            "text_to_word_sequence",
            "get_test_data",
            "ones",
            "get_variable_shape",
            "foldl",
            "orthogonal",
            "decode_predictions",
            "__getitem__",
            "sqrt",
            "get_output_shape_for",
            "spatial_2d_padding",
            "evaluate_generator",
            "categorical_crossentropy",
            "conv2d",
            "_preprocess_conv3d_kernel",
            "save",
            "batch_set_value",
            "cast",
            "int_shape",
            "compile",
            "atrous_conv2d",
            "pattern_broadcast",
            "reshape",
            "lesser_equal",
            "func_dump",
            "set_learning_phase",
            "mean_absolute_error",
            "image_dim_ordering",
            "print_tensor",
            "fit_on_texts",
            "softplus",
            "ctc_path_probs",
            "create_input_layer",
            "uniform",
            "conv_output_length",
            "add_inbound_node",
            "get_uid",
            "merge",
            "get_losses_for",
            "fit_generator",
            "ones_like",
            "output_shape",
            "prod",
            "add_update",
            "pool2d",
            "add_loss",
            "ctc_batch_cost",
            "reset_states",
            "switch",
            "count_params",
            "any",
            "set_image_dim_ordering",
            "function",
            "_old_batch_normalization",
            "get_output_mask_at",
            "predict_generator",
            "mean_squared_logarithmic_error",
            "normalize",
            "softsign",
            "preprocess_input",
            "count_total_params",
            "softmax",
            "mean_absolute_percentage_error",
            "sparse_categorical_crossentropy",
            "model_from_yaml",
            "placeholder",
            "clip",
            "dot",
            "get_word_index",
            "one_hot",
            "weights",
            "_old_normalize_batch_in_training",
            "reset_uids",
            "set_value",
            "to_dense",
            "conv_input_length",
            "categorical_probas_to_classes",
            "__iter__",
            "conv1d",
            "output_mask",
            "get_initial_states",
            "is_sparse",
            "get",
            "input_spec",
            "get_output_at",
            "summary",
            "img_to_array",
            "gradients",
            "flattened_layers",
            "training_data",
            "assert_input_compatibility",
            "arange",
            "gather",
            "is_explicit_shape",
            "_normalize_axis",
            "output",
            "get_params",
            "print_summary",
            "dropout",
            "get_layer",
            "tanh",
            "map_fn",
            "base_filter",
            "_initialize_variables",
            "get_weights",
            "dtype",
            "hard_sigmoid",
            "__init__",
            "expand_dims",
            "fit_on_sequences",
            "random_channel_shift",
            "get_output_shape_at",
            "set_epsilon",
            "fit",
            "random_zoom",
            "get_config",
            "random_transform",
            "reset",
            "cosine_proximity",
            "load_array",
            "std",
            "backend",
            "normalize_batch_in_training",
            "add_weight",
            "array_to_img",
            "sign",
            "__len__",
            "random_uniform",
            "identity",
            "var",
            "_preprocess_conv3d_filter_shape",
            "batch_get_value",
            "_recursive_list",
            "input",
            "get_source_inputs",
            "_get_node_attribute_at_index",
            "accuracy",
            "validation_data",
            "elu",
            "square",
            "multiclass_logloss",
            "all",
            "legacy_weight_ordering",
            "get_input_mask_at",
            "max",
            "poisson",
            "binary_logloss",
            "_to_tensor",
            "train_on_batch",
            "model_from_config",
            "minimum",
            "foldr",
            "argmax",
            "get_updates_for",
            "get_file",
            "conv_step_hidden",
            "temporal_padding",
            "set_session",
            "layer_test",
            "Input",
            "get_value",
            "uses_learning_phase",
            "pad_sequences",
            "MusicTaggerCRNN",
            "layer_from_config",
            "ResNet50",
            "greater_equal",
            "not_equal",
            "maximum",
            "_assert_sparse_module",
            "get_gradients",
            "ctc_update_log_p",
            "save_weights",
            "check_params",
            "skipgrams",
            "kullback_leibler_divergence",
            "random_barrel_transform",
            "convert_all_kernels_in_model",
            "in_top_k",
            "_preprocess_conv3d_input",
            "texts_to_sequences_generator",
            "rnn",
            "_get_noise_shape",
            "cos",
            "pop",
            "_preprocess_conv2d_input",
            "compute_mask",
            "get_input_at",
            "get_constants",
            "load_img",
            "deconv2d",
            "random_shift",
            "ctc_label_dense_to_sparse",
            "batch_dot",
            "set_floatx",
            "concatenate",
            "list_pictures",
            "losses",
            "urlretrieve",
            "eye",
            "predict",
            "zero",
            "glorot_uniform",
            "spatial_3d_padding",
            "save_weights_to_hdf5_group",
            "build",
            "sequences_to_matrix",
            "keras_test",
            "sigmoid",
            "_preprocess_conv2d_kernel",
            "probas_to_classes",
            "_preprocess_deconv_output_shape",
            "predict_proba",
            "conv3d",
            "update_add",
            "repeat_elements",
            "separable_conv2d",
            "log",
            "ctc_interleave_blanks",
            "stop_gradient",
            "to_list",
            "make_tuple",
            "sin",
            "flip_axis",
            "hinge",
            "score",
            "get_from_module",
            "update_sub",
            "set_weights",
            "he_uniform",
            "load_weights",
            "texts_to_matrix",
            "batch_flatten",
            "save_array",
            "input_mask",
            "conv_block",
            "squeeze",
            "input_shape",
            "constraints",
            "_preprocess_conv2d_image_shape",
            "epsilon",
            "learning_phase",
            "mean",
            "func_load",
            "variable",
            "exp",
            "_postprocess_conv2d_output",
            "set_legacy_weight_ordering",
            "to_categorical",
            "sum",
            "transform_matrix_offset_center",
            "_preprocess_conv3d_volume_shape",
            "_arguments_validation",
            "zeros",
            "flatten",
            "add",
            "round",
            "load_weights_from_hdf5_group_by_name",
            "transpose",
            "predict_classes",
            "load_weights_from_hdf5_group",
            "mean_squared_error",
            "time_distributed_dense",
            "from_config",
            "_postprocess_conv3d_output",
            "glorot_normal",
            "convert_kernel",
            "min",
            "filter_sk_params"
          ],
          "functions_name_co_evolved_modified_file": [
            "set_params",
            "get_params",
            "check_params",
            "filter_sk_params",
            "predict_proba",
            "fit",
            "score"
          ],
          "functions_name_co_evolved_all_files": [
            "output",
            "save_weights",
            "get_params",
            "check_params",
            "run_internal_graph",
            "texts_to_sequences",
            "print_summary",
            "dropout",
            "get_layer",
            "resize_volumes",
            "skipgrams",
            "reverse",
            "tanh",
            "evaluate",
            "validate_file",
            "get_input_shape_at",
            "_updated_config",
            "map_fn",
            "batch_normalization",
            "lecun_uniform",
            "InceptionV3",
            "get_weights",
            "in_top_k",
            "text_to_word_sequence",
            "texts_to_sequences_generator",
            "rnn",
            "eval",
            "identity_block",
            "ones",
            "cos",
            "VGG16",
            "foldl",
            "dtype",
            "VGG19",
            "orthogonal",
            "equal",
            "cast_to_floatx",
            "hard_sigmoid",
            "pop",
            "decode_predictions",
            "__init__",
            "compute_mask",
            "sqrt",
            "get_output_shape_for",
            "spatial_2d_padding",
            "evaluate_generator",
            "get_input_at",
            "shape",
            "expand_dims",
            "categorical_crossentropy",
            "load_img",
            "save",
            "load_data",
            "batch_set_value",
            "fit_on_sequences",
            "int_shape",
            "cast",
            "greater",
            "compile",
            "batch_dot",
            "set_floatx",
            "get_output_shape_at",
            "concatenate",
            "set_epsilon",
            "reshape",
            "manual_variable_initialization",
            "lesser_equal",
            "fit",
            "func_dump",
            "test_on_batch",
            "asymmetric_spatial_2d_padding",
            "get_config",
            "set_learning_phase",
            "lesser",
            "image_dim_ordering",
            "eye",
            "print_tensor",
            "softplus",
            "fit_on_texts",
            "_fix_unknown_dimension",
            "conv_output_length",
            "add_inbound_node",
            "get_uid",
            "std",
            "spatial_3d_padding",
            "merge",
            "build",
            "backend",
            "in_train_phase",
            "call",
            "permute_dimensions",
            "sequences_to_matrix",
            "l2_normalize",
            "normalize_batch_in_training",
            "add_weight",
            "fit_generator",
            "ones_like",
            "keras_test",
            "output_shape",
            "sigmoid",
            "prod",
            "random_normal_variable",
            "sign",
            "get_session",
            "predict_proba",
            "repeat_elements",
            "asymmetric_temporal_padding",
            "log",
            "make_sampling_table",
            "stop_gradient",
            "to_list",
            "ctc_batch_cost",
            "sin",
            "relu",
            "switch",
            "count_params",
            "var",
            "any",
            "set_image_dim_ordering",
            "batch_get_value",
            "clear_session",
            "score",
            "function",
            "_old_batch_normalization",
            "set_weights",
            "zeros_like",
            "get_output_mask_at",
            "input",
            "predict_generator",
            "softsign",
            "load_weights",
            "binary_crossentropy",
            "get_source_inputs",
            "texts_to_matrix",
            "preprocess_input",
            "_cond",
            "softmax",
            "batch_flatten",
            "_get_node_attribute_at_index",
            "elu",
            "square",
            "sparse_categorical_crossentropy",
            "input_mask",
            "conv_block",
            "squeeze",
            "input_shape",
            "model_from_yaml",
            "__call__",
            "epsilon",
            "learning_phase",
            "abs",
            "placeholder",
            "all",
            "clip",
            "mean",
            "ctc_decode",
            "model_from_json",
            "dot",
            "func_load",
            "floatx",
            "variable",
            "exp",
            "in_test_phase",
            "state_updates",
            "one_hot",
            "get_input_mask_at",
            "to_categorical",
            "resize_images",
            "max",
            "sum",
            "predict_on_batch",
            "_old_normalize_batch_in_training",
            "binary_logloss",
            "train_on_batch",
            "minimum",
            "he_normal",
            "foldr",
            "is_keras_tensor",
            "argmax",
            "_arguments_validation",
            "zeros",
            "set_value",
            "to_yaml",
            "to_dense",
            "pow",
            "get_file",
            "argmin",
            "add",
            "conv1d",
            "round",
            "output_mask",
            "random_uniform_variable",
            "temporal_padding",
            "set_session",
            "repeat",
            "load_weights_from_hdf5_group_by_name",
            "layer_test",
            "Xception",
            "get_value",
            "is_sparse",
            "to_json",
            "transpose",
            "uses_learning_phase",
            "ndim",
            "load_weights_from_hdf5_group",
            "get_output_at",
            "predict_classes",
            "pad_sequences",
            "gradients",
            "MusicTaggerCRNN",
            "update",
            "time_distributed_dense",
            "from_config",
            "glorot_normal",
            "convert_kernel",
            "assert_input_compatibility",
            "arange",
            "min",
            "ResNet50",
            "greater_equal",
            "layer_from_config",
            "set_params",
            "filter_sk_params",
            "not_equal",
            "gather",
            "maximum"
          ]
        },
        "file": {
          "file_name": "scikit_learn.py",
          "file_nloc": 140,
          "file_complexity": 33,
          "file_token_count": 842,
          "file_before": "from __future__ import absolute_import\nimport copy\nimport inspect\nimport types\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\nfrom ..models import Sequential\n\n\nclass BaseWrapper(object):\n    '''Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly.\n    Use descendant classes instead.\n\n    # Arguments\n        build_fn: callable function or class instance\n        sk_params: model parameters & fitting parameters\n\n    The build_fn should construct, compile and return a Keras model, which\n    will then be used to fit/predict. One of the following\n    three values could be passed to build_fn:\n    1. A function\n    2. An instance of a class that implements the __call__ method\n    3. None. This means you implement a class that inherits from either\n    `KerasClassifier` or `KerasRegressor`. The __call__ method of the\n    present class will then be treated as the default build_fn.\n\n    `sk_params` takes both model parameters and fitting parameters. Legal model\n    parameters are the arguments of `build_fn`. Note that like all other\n    estimators in scikit-learn, 'build_fn' should provide default values for\n    its arguments, so that you could create the estimator without passing any\n    values to `sk_params`.\n\n    `sk_params` could also accept parameters for calling `fit`, `predict`,\n    `predict_proba`, and `score` methods (e.g., `nb_epoch`, `batch_size`).\n    fitting (predicting) parameters are selected in the following order:\n\n    1. Values passed to the dictionary arguments of\n    `fit`, `predict`, `predict_proba`, and `score` methods\n    2. Values passed to `sk_params`\n    3. The default values of the `keras.models.Sequential`\n    `fit`, `predict`, `predict_proba` and `score` methods\n\n    When using scikit-learn's `grid_search` API, legal tunable parameters are\n    those you could pass to `sk_params`, including fitting parameters.\n    In other words, you could use `grid_search` to search for the best\n    `batch_size` or `nb_epoch` as well as the model parameters.\n    '''\n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n        self.check_params(sk_params)\n\n    def check_params(self, params):\n        '''Check for user typos in \"params\" keys to avoid\n        unwanted usage of default values\n\n        # Arguments\n            params: dictionary\n                The parameters to be checked\n        '''\n        legal_params_fns = [Sequential.fit, Sequential.predict,\n                            Sequential.predict_classes, Sequential.evaluate]\n        if self.build_fn is None:\n            legal_params_fns.append(self.__call__)\n        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n            legal_params_fns.append(self.build_fn.__call__)\n        else:\n            legal_params_fns.append(self.build_fn)\n\n        legal_params = []\n        for fn in legal_params_fns:\n            legal_params += inspect.getargspec(fn)[0]\n        legal_params = set(legal_params)\n\n        for params_name in params:\n            if params_name not in legal_params:\n                raise ValueError('{} is not a legal parameter'.format(params_name))\n\n    def get_params(self, deep=True):\n        '''Get parameters for this estimator.\n\n        # Arguments\n            deep: boolean, optional\n                If True, will return the parameters for this estimator and\n                contained sub-objects that are estimators.\n\n        # Returns\n            params : dict\n                Dictionary of parameter names mapped to their values.\n        '''\n        res = copy.deepcopy(self.sk_params)\n        res.update({'build_fn': self.build_fn})\n        return res\n\n    def set_params(self, **params):\n        '''Set the parameters of this estimator.\n\n        # Arguments\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        # Returns\n            self\n        '''\n        self.check_params(params)\n        self.sk_params.update(params)\n        return self\n\n    def fit(self, X, y, **kwargs):\n        '''Construct a new model with build_fn and fit the model according\n        to the given training data.\n\n        # Arguments\n            X : array-like, shape `(n_samples, n_features)`\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        '''\n\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(X, y, **fit_args)\n\n        return history\n\n    def filter_sk_params(self, fn, override={}):\n        '''Filter sk_params and return those in fn's arguments\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to override sk_params\n\n        # Returns\n            res : dictionary dictionary containing variables\n                in both sk_params and fn's arguments.\n        '''\n        res = {}\n        fn_args = inspect.getargspec(fn)[0]\n        for name, value in self.sk_params.items():\n            if name in fn_args:\n                res.update({name: value})\n        res.update(override)\n        return res\n\n\nclass KerasClassifier(BaseWrapper):\n    '''Implementation of the scikit-learn classifier API for Keras.\n    '''\n\n    def predict(self, X, **kwargs):\n        '''Returns the class predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Class predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n        return self.model.predict_classes(X, **kwargs)\n\n    def predict_proba(self, X, **kwargs):\n        '''Returns class probability estimates for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            proba: array-like, shape `(n_samples, n_outputs)`\n                Class probability estimates.\n                In the case of binary classification,\n                tp match the scikit-learn API,\n                will return an array of shape '(n_samples, 2)'\n                (instead of `(n_sample, 1)` as in Keras).\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        probs = self.model.predict_proba(X, **kwargs)\n\n        # check if binary classification\n        if probs.shape[1] == 1:\n            # first column is probability of class 0 and second is of class 1\n            probs = np.hstack([1 - probs, probs])\n        return probs\n\n    def score(self, X, y, **kwargs):\n        '''Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        outputs = self.model.evaluate(X, y, **kwargs)\n        if not isinstance(outputs, list):\n            outputs = [outputs]\n        for name, output in zip(self.model.metrics_names, outputs):\n            if name == 'acc':\n                return output\n        raise ValueError('The model is not configured to compute accuracy. '\n                         'You should pass `metrics=[\"accuracy\"]` to '\n                         'the `model.compile()` method.')\n\n\nclass KerasRegressor(BaseWrapper):\n    '''Implementation of the scikit-learn regressor API for Keras.\n    '''\n\n    def predict(self, X, **kwargs):\n        '''Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return np.squeeze(self.model.predict(X, **kwargs))\n\n    def score(self, X, y, **kwargs):\n        '''Returns the mean loss on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        loss = self.model.evaluate(X, y, **kwargs)\n        if isinstance(loss, list):\n            return loss[0]\n        return loss\n",
          "file_after": "from __future__ import absolute_import\nimport copy\nimport inspect\nimport types\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\nfrom ..models import Sequential\n\n\nclass BaseWrapper(object):\n    \"\"\"Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly.\n    Use descendant classes instead.\n\n    # Arguments\n        build_fn: callable function or class instance\n        sk_params: model parameters & fitting parameters\n\n    The build_fn should construct, compile and return a Keras model, which\n    will then be used to fit/predict. One of the following\n    three values could be passed to build_fn:\n    1. A function\n    2. An instance of a class that implements the __call__ method\n    3. None. This means you implement a class that inherits from either\n    `KerasClassifier` or `KerasRegressor`. The __call__ method of the\n    present class will then be treated as the default build_fn.\n\n    `sk_params` takes both model parameters and fitting parameters. Legal model\n    parameters are the arguments of `build_fn`. Note that like all other\n    estimators in scikit-learn, 'build_fn' should provide default values for\n    its arguments, so that you could create the estimator without passing any\n    values to `sk_params`.\n\n    `sk_params` could also accept parameters for calling `fit`, `predict`,\n    `predict_proba`, and `score` methods (e.g., `nb_epoch`, `batch_size`).\n    fitting (predicting) parameters are selected in the following order:\n\n    1. Values passed to the dictionary arguments of\n    `fit`, `predict`, `predict_proba`, and `score` methods\n    2. Values passed to `sk_params`\n    3. The default values of the `keras.models.Sequential`\n    `fit`, `predict`, `predict_proba` and `score` methods\n\n    When using scikit-learn's `grid_search` API, legal tunable parameters are\n    those you could pass to `sk_params`, including fitting parameters.\n    In other words, you could use `grid_search` to search for the best\n    `batch_size` or `nb_epoch` as well as the model parameters.\n    \"\"\"\n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n        self.check_params(sk_params)\n\n    def check_params(self, params):\n        \"\"\"Check for user typos in \"params\" keys to avoid\n        unwanted usage of default values\n\n        # Arguments\n            params: dictionary\n                The parameters to be checked\n        \"\"\"\n        legal_params_fns = [Sequential.fit, Sequential.predict,\n                            Sequential.predict_classes, Sequential.evaluate]\n        if self.build_fn is None:\n            legal_params_fns.append(self.__call__)\n        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n            legal_params_fns.append(self.build_fn.__call__)\n        else:\n            legal_params_fns.append(self.build_fn)\n\n        legal_params = []\n        for fn in legal_params_fns:\n            legal_params += inspect.getargspec(fn)[0]\n        legal_params = set(legal_params)\n\n        for params_name in params:\n            if params_name not in legal_params:\n                raise ValueError('{} is not a legal parameter'.format(params_name))\n\n    def get_params(self, deep=True):\n        \"\"\"Get parameters for this estimator.\n\n        # Arguments\n            deep: boolean, optional\n                If True, will return the parameters for this estimator and\n                contained sub-objects that are estimators.\n\n        # Returns\n            params : dict\n                Dictionary of parameter names mapped to their values.\n        \"\"\"\n        res = copy.deepcopy(self.sk_params)\n        res.update({'build_fn': self.build_fn})\n        return res\n\n    def set_params(self, **params):\n        \"\"\"Set the parameters of this estimator.\n\n        # Arguments\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        # Returns\n            self\n        \"\"\"\n        self.check_params(params)\n        self.sk_params.update(params)\n        return self\n\n    def fit(self, X, y, **kwargs):\n        \"\"\"Construct a new model with build_fn and fit the model according\n        to the given training data.\n\n        # Arguments\n            X : array-like, shape `(n_samples, n_features)`\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        \"\"\"\n\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(X, y, **fit_args)\n\n        return history\n\n    def filter_sk_params(self, fn, override={}):\n        \"\"\"Filter sk_params and return those in fn's arguments\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to override sk_params\n\n        # Returns\n            res : dictionary dictionary containing variables\n                in both sk_params and fn's arguments.\n        \"\"\"\n        res = {}\n        fn_args = inspect.getargspec(fn)[0]\n        for name, value in self.sk_params.items():\n            if name in fn_args:\n                res.update({name: value})\n        res.update(override)\n        return res\n\n\nclass KerasClassifier(BaseWrapper):\n    \"\"\"Implementation of the scikit-learn classifier API for Keras.\n    \"\"\"\n\n    def predict(self, X, **kwargs):\n        \"\"\"Returns the class predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Class predictions.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n        return self.model.predict_classes(X, **kwargs)\n\n    def predict_proba(self, X, **kwargs):\n        \"\"\"Returns class probability estimates for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            proba: array-like, shape `(n_samples, n_outputs)`\n                Class probability estimates.\n                In the case of binary classification,\n                tp match the scikit-learn API,\n                will return an array of shape '(n_samples, 2)'\n                (instead of `(n_sample, 1)` as in Keras).\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        probs = self.model.predict_proba(X, **kwargs)\n\n        # check if binary classification\n        if probs.shape[1] == 1:\n            # first column is probability of class 0 and second is of class 1\n            probs = np.hstack([1 - probs, probs])\n        return probs\n\n    def score(self, X, y, **kwargs):\n        \"\"\"Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        outputs = self.model.evaluate(X, y, **kwargs)\n        if not isinstance(outputs, list):\n            outputs = [outputs]\n        for name, output in zip(self.model.metrics_names, outputs):\n            if name == 'acc':\n                return output\n        raise ValueError('The model is not configured to compute accuracy. '\n                         'You should pass `metrics=[\"accuracy\"]` to '\n                         'the `model.compile()` method.')\n\n\nclass KerasRegressor(BaseWrapper):\n    \"\"\"Implementation of the scikit-learn regressor API for Keras.\n    \"\"\"\n\n    def predict(self, X, **kwargs):\n        \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return np.squeeze(self.model.predict(X, **kwargs))\n\n    def score(self, X, y, **kwargs):\n        \"\"\"Returns the mean loss on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        loss = self.model.evaluate(X, y, **kwargs)\n        if isinstance(loss, list):\n            return loss[0]\n        return loss\n",
          "file_patch": "@@ -9,7 +9,7 @@ from ..models import Sequential\n \n \n class BaseWrapper(object):\n-    '''Base class for the Keras scikit-learn wrapper.\n+    \"\"\"Base class for the Keras scikit-learn wrapper.\n \n     Warning: This class should not be used directly.\n     Use descendant classes instead.\n@@ -47,7 +47,7 @@ class BaseWrapper(object):\n     those you could pass to `sk_params`, including fitting parameters.\n     In other words, you could use `grid_search` to search for the best\n     `batch_size` or `nb_epoch` as well as the model parameters.\n-    '''\n+    \"\"\"\n \n     def __init__(self, build_fn=None, **sk_params):\n         self.build_fn = build_fn\n@@ -55,13 +55,13 @@ class BaseWrapper(object):\n         self.check_params(sk_params)\n \n     def check_params(self, params):\n-        '''Check for user typos in \"params\" keys to avoid\n+        \"\"\"Check for user typos in \"params\" keys to avoid\n         unwanted usage of default values\n \n         # Arguments\n             params: dictionary\n                 The parameters to be checked\n-        '''\n+        \"\"\"\n         legal_params_fns = [Sequential.fit, Sequential.predict,\n                             Sequential.predict_classes, Sequential.evaluate]\n         if self.build_fn is None:\n@@ -81,7 +81,7 @@ class BaseWrapper(object):\n                 raise ValueError('{} is not a legal parameter'.format(params_name))\n \n     def get_params(self, deep=True):\n-        '''Get parameters for this estimator.\n+        \"\"\"Get parameters for this estimator.\n \n         # Arguments\n             deep: boolean, optional\n@@ -91,13 +91,13 @@ class BaseWrapper(object):\n         # Returns\n             params : dict\n                 Dictionary of parameter names mapped to their values.\n-        '''\n+        \"\"\"\n         res = copy.deepcopy(self.sk_params)\n         res.update({'build_fn': self.build_fn})\n         return res\n \n     def set_params(self, **params):\n-        '''Set the parameters of this estimator.\n+        \"\"\"Set the parameters of this estimator.\n \n         # Arguments\n         params: dict\n@@ -105,13 +105,13 @@ class BaseWrapper(object):\n \n         # Returns\n             self\n-        '''\n+        \"\"\"\n         self.check_params(params)\n         self.sk_params.update(params)\n         return self\n \n     def fit(self, X, y, **kwargs):\n-        '''Construct a new model with build_fn and fit the model according\n+        \"\"\"Construct a new model with build_fn and fit the model according\n         to the given training data.\n \n         # Arguments\n@@ -126,7 +126,7 @@ class BaseWrapper(object):\n         # Returns\n             history : object\n                 details about the training history at each epoch.\n-        '''\n+        \"\"\"\n \n         if self.build_fn is None:\n             self.model = self.__call__(**self.filter_sk_params(self.__call__))\n@@ -150,7 +150,7 @@ class BaseWrapper(object):\n         return history\n \n     def filter_sk_params(self, fn, override={}):\n-        '''Filter sk_params and return those in fn's arguments\n+        \"\"\"Filter sk_params and return those in fn's arguments\n \n         # Arguments\n             fn : arbitrary function\n@@ -159,7 +159,7 @@ class BaseWrapper(object):\n         # Returns\n             res : dictionary dictionary containing variables\n                 in both sk_params and fn's arguments.\n-        '''\n+        \"\"\"\n         res = {}\n         fn_args = inspect.getargspec(fn)[0]\n         for name, value in self.sk_params.items():\n@@ -170,11 +170,11 @@ class BaseWrapper(object):\n \n \n class KerasClassifier(BaseWrapper):\n-    '''Implementation of the scikit-learn classifier API for Keras.\n-    '''\n+    \"\"\"Implementation of the scikit-learn classifier API for Keras.\n+    \"\"\"\n \n     def predict(self, X, **kwargs):\n-        '''Returns the class predictions for the given test data.\n+        \"\"\"Returns the class predictions for the given test data.\n \n         # Arguments\n             X: array-like, shape `(n_samples, n_features)`\n@@ -186,12 +186,12 @@ class KerasClassifier(BaseWrapper):\n         # Returns\n             preds: array-like, shape `(n_samples,)`\n                 Class predictions.\n-        '''\n+        \"\"\"\n         kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n         return self.model.predict_classes(X, **kwargs)\n \n     def predict_proba(self, X, **kwargs):\n-        '''Returns class probability estimates for the given test data.\n+        \"\"\"Returns class probability estimates for the given test data.\n \n         # Arguments\n             X: array-like, shape `(n_samples, n_features)`\n@@ -207,7 +207,7 @@ class KerasClassifier(BaseWrapper):\n                 tp match the scikit-learn API,\n                 will return an array of shape '(n_samples, 2)'\n                 (instead of `(n_sample, 1)` as in Keras).\n-        '''\n+        \"\"\"\n         kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n         probs = self.model.predict_proba(X, **kwargs)\n \n@@ -218,7 +218,7 @@ class KerasClassifier(BaseWrapper):\n         return probs\n \n     def score(self, X, y, **kwargs):\n-        '''Returns the mean accuracy on the given test data and labels.\n+        \"\"\"Returns the mean accuracy on the given test data and labels.\n \n         # Arguments\n             X: array-like, shape `(n_samples, n_features)`\n@@ -232,7 +232,7 @@ class KerasClassifier(BaseWrapper):\n         # Returns\n             score: float\n                 Mean accuracy of predictions on X wrt. y.\n-        '''\n+        \"\"\"\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n \n         loss_name = self.model.loss\n@@ -253,11 +253,11 @@ class KerasClassifier(BaseWrapper):\n \n \n class KerasRegressor(BaseWrapper):\n-    '''Implementation of the scikit-learn regressor API for Keras.\n-    '''\n+    \"\"\"Implementation of the scikit-learn regressor API for Keras.\n+    \"\"\"\n \n     def predict(self, X, **kwargs):\n-        '''Returns predictions for the given test data.\n+        \"\"\"Returns predictions for the given test data.\n \n         # Arguments\n             X: array-like, shape `(n_samples, n_features)`\n@@ -268,12 +268,12 @@ class KerasRegressor(BaseWrapper):\n         # Returns\n             preds: array-like, shape `(n_samples,)`\n                 Predictions.\n-        '''\n+        \"\"\"\n         kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n         return np.squeeze(self.model.predict(X, **kwargs))\n \n     def score(self, X, y, **kwargs):\n-        '''Returns the mean loss on the given test data and labels.\n+        \"\"\"Returns the mean loss on the given test data and labels.\n \n         # Arguments\n             X: array-like, shape `(n_samples, n_features)`\n@@ -287,7 +287,7 @@ class KerasRegressor(BaseWrapper):\n         # Returns\n             score: float\n                 Mean accuracy of predictions on X wrt. y.\n-        '''\n+        \"\"\"\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n         loss = self.model.evaluate(X, y, **kwargs)\n         if isinstance(loss, list):\n",
          "files_name_in_blame_commit": [
            "embeddings.py",
            "vgg19.py",
            "convolutional_recurrent.py",
            "scikit_learn.py",
            "noise.py",
            "generic_utils.py",
            "topology.py",
            "theano_backend.py",
            "text.py",
            "__init__.py",
            "audio_conv_utils.py",
            "inception_v3.py",
            "local.py",
            "core.py",
            "recurrent.py",
            "common.py",
            "sequence.py",
            "models.py",
            "layer_utils.py",
            "music_tagger_crnn.py",
            "np_utils.py",
            "pooling.py",
            "vgg16.py",
            "normalization.py",
            "initializations.py",
            "io_utils.py",
            "objectives.py",
            "test_utils.py",
            "wrappers.py",
            "optimizers.py",
            "imdb.py",
            "data_utils.py",
            "image.py",
            "convolutional.py",
            "advanced_activations.py",
            "resnet50.py",
            "tensorflow_backend.py",
            "xception.py",
            "reuters.py"
          ]
        }
      },
      "e4dda27de186f6f98a61aee3328aa21d7ef7f7ba": {
        "commit": {
          "commit_id": "e4dda27de186f6f98a61aee3328aa21d7ef7f7ba",
          "commit_message": "allow KerasClassifier.score to accept sparse labels (#3534)",
          "commit_author": "Dominic Breuker",
          "commit_date": "2016-08-22 15:19:26",
          "commit_parent": "f2786d9d800325cd4032af4041614f7a0d900efb"
        },
        "function": {
          "function_name": "predict",
          "function_code_before": "def predict(self, X, **kwargs):\n    \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n    kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n    return self.model.predict(X, **kwargs)",
          "function_code_after": "def predict(self, X, **kwargs):\n    \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n    kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n    return np.squeeze(self.model.predict(X, **kwargs))",
          "function_before_start_line": 252,
          "function_before_end_line": 266,
          "function_after_start_line": 259,
          "function_after_end_line": 273,
          "function_before_token_count": 35,
          "function_after_token_count": 40,
          "functions_name_modified_file": [
            "__init__",
            "set_params",
            "get_params",
            "check_params",
            "predict",
            "filter_sk_params",
            "predict_proba",
            "fit",
            "score"
          ],
          "functions_name_all_files": [
            "build_fn_clf",
            "test_clasify_build_fn",
            "test_regression_inherit_class_build_fn",
            "get_params",
            "check_params",
            "test_clasify_inherit_class_build_fn",
            "test_regression_class_build_fn",
            "fit",
            "score",
            "predict",
            "assert_classification_works",
            "assert_regression_works",
            "test_regression_build_fn",
            "test_clasify_class_build_fn",
            "__init__",
            "set_params",
            "build_fn_reg",
            "filter_sk_params",
            "predict_proba"
          ],
          "functions_name_co_evolved_modified_file": [
            "score"
          ],
          "functions_name_co_evolved_all_files": [
            "test_regression_build_fn",
            "build_fn_clf",
            "__call__",
            "test_clasify_build_fn",
            "test_regression_inherit_class_build_fn",
            "test_clasify_inherit_class_build_fn",
            "test_regression_class_build_fn",
            "assert_classification_works",
            "assert_regression_works",
            "test_clasify_class_build_fn",
            "score"
          ]
        },
        "file": {
          "file_name": "scikit_learn.py",
          "file_nloc": 140,
          "file_complexity": 31,
          "file_token_count": 817,
          "file_before": "from __future__ import absolute_import\nimport copy\nimport inspect\nimport types\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\nfrom ..models import Sequential\n\n\nclass BaseWrapper(object):\n    '''Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly.\n    Use descendant classes instead.\n\n    # Arguments\n        build_fn: callable function or class instance\n        sk_params: model parameters & fitting parameters\n\n    The build_fn should construct, compile and return a Keras model, which\n    will then be used to fit/predict. One of the following\n    three values could be passed to build_fn:\n    1. A function\n    2. An instance of a class that implements the __call__ method\n    3. None. This means you implement a class that inherits from either\n    `KerasClassifier` or `KerasRegressor`. The __call__ method of the\n    present class will then be treated as the default build_fn.\n\n    `sk_params` takes both model parameters and fitting parameters. Legal model\n    parameters are the arguments of `build_fn`. Note that like all other\n    estimators in scikit-learn, 'build_fn' should provide default values for\n    its arguments, so that you could create the estimator without passing any\n    values to `sk_params`.\n\n    `sk_params` could also accept parameters for calling `fit`, `predict`,\n    `predict_proba`, and `score` methods (e.g., `nb_epoch`, `batch_size`).\n    fitting (predicting) parameters are selected in the following order:\n\n    1. Values passed to the dictionary arguments of\n    `fit`, `predict`, `predict_proba`, and `score` methods\n    2. Values passed to `sk_params`\n    3. The default values of the `keras.models.Sequential`\n    `fit`, `predict`, `predict_proba` and `score` methods\n\n    When using scikit-learn's `grid_search` API, legal tunable parameters are\n    those you could pass to `sk_params`, including fitting parameters.\n    In other words, you could use `grid_search` to search for the best\n    `batch_size` or `nb_epoch` as well as the model parameters.\n    '''\n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n        self.check_params(sk_params)\n\n    def check_params(self, params):\n        '''Check for user typos in \"params\" keys to avoid\n        unwanted usage of default values\n\n        # Arguments\n            params: dictionary\n                The parameters to be checked\n        '''\n        legal_params_fns = [Sequential.fit, Sequential.predict,\n                            Sequential.predict_classes, Sequential.evaluate]\n        if self.build_fn is None:\n            legal_params_fns.append(self.__call__)\n        elif not isinstance(self.build_fn, types.FunctionType):\n            legal_params_fns.append(self.build_fn.__call__)\n        else:\n            legal_params_fns.append(self.build_fn)\n\n        legal_params = []\n        for fn in legal_params_fns:\n            legal_params += inspect.getargspec(fn)[0]\n        legal_params = set(legal_params)\n\n        for params_name in params:\n            if params_name not in legal_params:\n                assert False, '{} is not a legal parameter'.format(params_name)\n\n    def get_params(self, deep=True):\n        '''Get parameters for this estimator.\n\n        # Arguments\n            deep: boolean, optional\n                If True, will return the parameters for this estimator and\n                contained sub-objects that are estimators.\n\n        # Returns\n            params : dict\n                Dictionary of parameter names mapped to their values.\n        '''\n        res = copy.deepcopy(self.sk_params)\n        res.update({'build_fn': self.build_fn})\n        return res\n\n    def set_params(self, **params):\n        '''Set the parameters of this estimator.\n\n        # Arguments\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        # Returns\n            self\n        '''\n        self.check_params(params)\n        self.sk_params.update(params)\n        return self\n\n    def fit(self, X, y, **kwargs):\n        '''Construct a new model with build_fn and fit the model according\n        to the given training data.\n\n        # Arguments\n            X : array-like, shape `(n_samples, n_features)`\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        '''\n\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif not isinstance(self.build_fn, types.FunctionType):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(X, y, **fit_args)\n\n        return history\n\n    def filter_sk_params(self, fn, override={}):\n        '''Filter sk_params and return those in fn's arguments\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to override sk_params\n\n        # Returns\n            res : dictionary dictionary containing variables\n                in both sk_params and fn's arguments.\n        '''\n        res = {}\n        fn_args = inspect.getargspec(fn)[0]\n        for name, value in self.sk_params.items():\n            if name in fn_args:\n                res.update({name: value})\n        res.update(override)\n        return res\n\n\nclass KerasClassifier(BaseWrapper):\n    '''Implementation of the scikit-learn classifier API for Keras.\n    '''\n\n    def predict(self, X, **kwargs):\n        '''Returns the class predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Class predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n        return self.model.predict_classes(X, **kwargs)\n\n    def predict_proba(self, X, **kwargs):\n        '''Returns class probability estimates for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            proba: array-like, shape `(n_samples, n_outputs)`\n                Class probability estimates.\n                In the case of binary classification,\n                tp match the scikit-learn API,\n                will return an array of shape '(n_samples, 2)'\n                (instead of `(n_sample, 1)` as in Keras).\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        probs = self.model.predict_proba(X, **kwargs)\n\n        # check if binary classification\n        if probs.shape[1] == 1:\n            # first column is probability of class 0 and second is of class 1\n            probs = np.hstack([1 - probs, probs])\n        return probs\n\n    def score(self, X, y, **kwargs):\n        '''Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        outputs = self.model.evaluate(X, y, **kwargs)\n        if type(outputs) is not list:\n            outputs = [outputs]\n        for name, output in zip(self.model.metrics_names, outputs):\n            if name == 'acc':\n                return output\n        raise Exception('The model is not configured to compute accuracy. '\n                        'You should pass `metrics=[\"accuracy\"]` to '\n                        'the `model.compile()` method.')\n\n\nclass KerasRegressor(BaseWrapper):\n    '''Implementation of the scikit-learn regressor API for Keras.\n    '''\n\n    def predict(self, X, **kwargs):\n        '''Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return self.model.predict(X, **kwargs)\n\n    def score(self, X, y, **kwargs):\n        '''Returns the mean loss on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        loss = self.model.evaluate(X, y, **kwargs)\n        if type(loss) is list:\n            return loss[0]\n        return loss\n",
          "file_after": "from __future__ import absolute_import\nimport copy\nimport inspect\nimport types\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\nfrom ..models import Sequential\n\n\nclass BaseWrapper(object):\n    '''Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly.\n    Use descendant classes instead.\n\n    # Arguments\n        build_fn: callable function or class instance\n        sk_params: model parameters & fitting parameters\n\n    The build_fn should construct, compile and return a Keras model, which\n    will then be used to fit/predict. One of the following\n    three values could be passed to build_fn:\n    1. A function\n    2. An instance of a class that implements the __call__ method\n    3. None. This means you implement a class that inherits from either\n    `KerasClassifier` or `KerasRegressor`. The __call__ method of the\n    present class will then be treated as the default build_fn.\n\n    `sk_params` takes both model parameters and fitting parameters. Legal model\n    parameters are the arguments of `build_fn`. Note that like all other\n    estimators in scikit-learn, 'build_fn' should provide default values for\n    its arguments, so that you could create the estimator without passing any\n    values to `sk_params`.\n\n    `sk_params` could also accept parameters for calling `fit`, `predict`,\n    `predict_proba`, and `score` methods (e.g., `nb_epoch`, `batch_size`).\n    fitting (predicting) parameters are selected in the following order:\n\n    1. Values passed to the dictionary arguments of\n    `fit`, `predict`, `predict_proba`, and `score` methods\n    2. Values passed to `sk_params`\n    3. The default values of the `keras.models.Sequential`\n    `fit`, `predict`, `predict_proba` and `score` methods\n\n    When using scikit-learn's `grid_search` API, legal tunable parameters are\n    those you could pass to `sk_params`, including fitting parameters.\n    In other words, you could use `grid_search` to search for the best\n    `batch_size` or `nb_epoch` as well as the model parameters.\n    '''\n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n        self.check_params(sk_params)\n\n    def check_params(self, params):\n        '''Check for user typos in \"params\" keys to avoid\n        unwanted usage of default values\n\n        # Arguments\n            params: dictionary\n                The parameters to be checked\n        '''\n        legal_params_fns = [Sequential.fit, Sequential.predict,\n                            Sequential.predict_classes, Sequential.evaluate]\n        if self.build_fn is None:\n            legal_params_fns.append(self.__call__)\n        elif not isinstance(self.build_fn, types.FunctionType):\n            legal_params_fns.append(self.build_fn.__call__)\n        else:\n            legal_params_fns.append(self.build_fn)\n\n        legal_params = []\n        for fn in legal_params_fns:\n            legal_params += inspect.getargspec(fn)[0]\n        legal_params = set(legal_params)\n\n        for params_name in params:\n            if params_name not in legal_params:\n                assert False, '{} is not a legal parameter'.format(params_name)\n\n    def get_params(self, deep=True):\n        '''Get parameters for this estimator.\n\n        # Arguments\n            deep: boolean, optional\n                If True, will return the parameters for this estimator and\n                contained sub-objects that are estimators.\n\n        # Returns\n            params : dict\n                Dictionary of parameter names mapped to their values.\n        '''\n        res = copy.deepcopy(self.sk_params)\n        res.update({'build_fn': self.build_fn})\n        return res\n\n    def set_params(self, **params):\n        '''Set the parameters of this estimator.\n\n        # Arguments\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        # Returns\n            self\n        '''\n        self.check_params(params)\n        self.sk_params.update(params)\n        return self\n\n    def fit(self, X, y, **kwargs):\n        '''Construct a new model with build_fn and fit the model according\n        to the given training data.\n\n        # Arguments\n            X : array-like, shape `(n_samples, n_features)`\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        '''\n\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif not isinstance(self.build_fn, types.FunctionType):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(X, y, **fit_args)\n\n        return history\n\n    def filter_sk_params(self, fn, override={}):\n        '''Filter sk_params and return those in fn's arguments\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to override sk_params\n\n        # Returns\n            res : dictionary dictionary containing variables\n                in both sk_params and fn's arguments.\n        '''\n        res = {}\n        fn_args = inspect.getargspec(fn)[0]\n        for name, value in self.sk_params.items():\n            if name in fn_args:\n                res.update({name: value})\n        res.update(override)\n        return res\n\n\nclass KerasClassifier(BaseWrapper):\n    '''Implementation of the scikit-learn classifier API for Keras.\n    '''\n\n    def predict(self, X, **kwargs):\n        '''Returns the class predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Class predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n        return self.model.predict_classes(X, **kwargs)\n\n    def predict_proba(self, X, **kwargs):\n        '''Returns class probability estimates for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            proba: array-like, shape `(n_samples, n_outputs)`\n                Class probability estimates.\n                In the case of binary classification,\n                tp match the scikit-learn API,\n                will return an array of shape '(n_samples, 2)'\n                (instead of `(n_sample, 1)` as in Keras).\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        probs = self.model.predict_proba(X, **kwargs)\n\n        # check if binary classification\n        if probs.shape[1] == 1:\n            # first column is probability of class 0 and second is of class 1\n            probs = np.hstack([1 - probs, probs])\n        return probs\n\n    def score(self, X, y, **kwargs):\n        '''Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        outputs = self.model.evaluate(X, y, **kwargs)\n        if type(outputs) is not list:\n            outputs = [outputs]\n        for name, output in zip(self.model.metrics_names, outputs):\n            if name == 'acc':\n                return output\n        raise Exception('The model is not configured to compute accuracy. '\n                        'You should pass `metrics=[\"accuracy\"]` to '\n                        'the `model.compile()` method.')\n\n\nclass KerasRegressor(BaseWrapper):\n    '''Implementation of the scikit-learn regressor API for Keras.\n    '''\n\n    def predict(self, X, **kwargs):\n        '''Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return np.squeeze(self.model.predict(X, **kwargs))\n\n    def score(self, X, y, **kwargs):\n        '''Returns the mean loss on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        loss = self.model.evaluate(X, y, **kwargs)\n        if type(loss) is list:\n            return loss[0]\n        return loss\n",
          "file_patch": "@@ -234,6 +234,13 @@ class KerasClassifier(BaseWrapper):\n                 Mean accuracy of predictions on X wrt. y.\n         '''\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n+\n+        loss_name = self.model.loss\n+        if hasattr(loss_name, '__name__'):\n+            loss_name = loss_name.__name__\n+        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n+            y = to_categorical(y)\n+\n         outputs = self.model.evaluate(X, y, **kwargs)\n         if type(outputs) is not list:\n             outputs = [outputs]\n@@ -263,7 +270,7 @@ class KerasRegressor(BaseWrapper):\n                 Predictions.\n         '''\n         kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n-        return self.model.predict(X, **kwargs)\n+        return np.squeeze(self.model.predict(X, **kwargs))\n \n     def score(self, X, y, **kwargs):\n         '''Returns the mean loss on the given test data and labels.\n",
          "files_name_in_blame_commit": [
            "scikit_learn.py",
            "test_scikit_learn.py"
          ]
        }
      },
      "be24159959672c32abb31697e721d96ae6ffaf97": {
        "commit": {
          "commit_id": "be24159959672c32abb31697e721d96ae6ffaf97",
          "commit_message": "Refactoring of sklearn",
          "commit_author": "ipod825",
          "commit_date": "2016-02-28 13:46:20",
          "commit_parent": "943d2d4cf802dd5aceeac376c8468d8ee430817f"
        },
        "function": {
          "function_name": "predict",
          "function_code_before": "def predict(self, X):\n    \"\"\"\n        Returns predictions for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n\n        Returns\n        -------\n        preds : array-like, shape = (n_samples)\n            Predictions.\n        \"\"\"\n    return self.compiled_model_.predict(X, batch_size=self.test_batch_size, verbose=self.verbose).ravel()",
          "function_code_after": "def predict(self, X, **kwargs):\n    \"\"\" Returns predictions for the given test data.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.predict\n        # Returns\n            preds : array-like, shape = (n_samples)\n                Predictions.\n        \"\"\"\n    kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n    return self.model.predict(X, **kwargs)",
          "function_before_start_line": 229,
          "function_before_end_line": 245,
          "function_after_start_line": 208,
          "function_after_end_line": 222,
          "function_before_token_count": 33,
          "function_after_token_count": 0,
          "functions_name_modified_file": [
            "__init__",
            "set_params",
            "get_params",
            "predict",
            "filter_sk_params",
            "predict_proba",
            "fit",
            "score"
          ],
          "functions_name_all_files": [
            "__init__",
            "build_fn_clf",
            "__call__",
            "set_params",
            "get_params",
            "predict",
            "build_fn_reg",
            "filter_sk_params",
            "predict_proba",
            "fit",
            "score"
          ],
          "functions_name_co_evolved_modified_file": [
            "__init__",
            "set_params",
            "get_params",
            "filter_sk_params",
            "predict_proba",
            "fit",
            "score"
          ],
          "functions_name_co_evolved_all_files": [
            "__init__",
            "build_fn_clf",
            "__call__",
            "set_params",
            "get_params",
            "test_keras_classifier",
            "build_fn_reg",
            "filter_sk_params",
            "predict_proba",
            "fit",
            "test_keras_regressor",
            "score"
          ]
        },
        "file": {
          "file_name": "scikit_learn.py",
          "file_nloc": 104,
          "file_complexity": 16,
          "file_token_count": 565,
          "file_before": "from __future__ import absolute_import\nimport abc\nimport copy\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\n\n\nclass BaseWrapper(object):\n    \"\"\"\n    Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly. Use derived classes instead.\n\n    Parameters\n    ----------\n    train_batch_size : int, optional\n        Number of training samples evaluated at a time.\n    test_batch_size : int, optional\n        Number of test samples evaluated at a time.\n    nb_epochs : int, optional\n        Number of training epochs.\n    shuffle : boolean, optional\n        Whether to shuffle the samples at each epoch.\n    show_accuracy : boolean, optional\n        Whether to display class accuracy in the logs at each epoch.\n    validation_split : float [0, 1], optional\n        Fraction of the data to use as held-out validation data.\n    validation_data : tuple (X, y), optional\n        Data to be used as held-out validation data. Will override validation_split.\n    callbacks : list, optional\n        List of callbacks to apply during training.\n    verbose : int, optional\n        Verbosity level.\n    \"\"\"\n    __metaclass__ = abc.ABCMeta\n\n    @abc.abstractmethod\n    def __init__(self, model, optimizer, loss,\n                 train_batch_size=128, test_batch_size=128,\n                 nb_epoch=100, shuffle=True, show_accuracy=False,\n                 validation_split=0, validation_data=None, callbacks=None,\n                 verbose=0,):\n        self.model = model\n        self.optimizer = optimizer\n        self.loss = loss\n        self.compiled_model_ = None\n        self.classes_ = []\n        self.config_ = []\n        self.weights_ = []\n\n        self.train_batch_size = train_batch_size\n        self.test_batch_size = test_batch_size\n        self.nb_epoch = nb_epoch\n        self.shuffle = shuffle\n        self.show_accuracy = show_accuracy\n        self.validation_split = validation_split\n        self.validation_data = validation_data\n        self.callbacks = [] if callbacks is None else callbacks\n\n        self.verbose = verbose\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep: boolean, optional\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.\n\n        Returns\n        -------\n        params : dict\n            Dictionary of parameter names mapped to their values.\n        \"\"\"\n        return {'model': self.model, 'optimizer': self.optimizer, 'loss': self.loss}\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        Parameters\n        ----------\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        for parameter, value in params.items():\n            setattr(self, parameter, value)\n        return self\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model according to the given training data.\n\n        Makes a copy of the un-compiled model definition to use for\n        compilation and fitting, leaving the original definition\n        intact.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Training samples where n_samples in the number of samples\n            and n_features is the number of features.\n        y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n            True labels for X.\n\n        Returns\n        -------\n        history : object\n            Returns details about the training history at each epoch.\n        \"\"\"\n        if len(y.shape) == 1:\n            self.classes_ = list(np.unique(y))\n            if self.loss == 'categorical_crossentropy':\n                y = to_categorical(y)\n        else:\n            self.classes_ = np.arange(0, y.shape[1])\n\n        self.compiled_model_ = copy.deepcopy(self.model)\n        self.compiled_model_.compile(optimizer=self.optimizer, loss=self.loss)\n        history = self.compiled_model_.fit(\n            X, y, batch_size=self.train_batch_size, nb_epoch=self.nb_epoch, verbose=self.verbose,\n            shuffle=self.shuffle, show_accuracy=self.show_accuracy,\n            validation_split=self.validation_split, validation_data=self.validation_data,\n            callbacks=self.callbacks)\n\n        self.config_ = self.model.get_config()\n        self.weights_ = self.model.get_weights()\n\n        return history\n\n\nclass KerasClassifier(BaseWrapper):\n    \"\"\"\n    Implementation of the scikit-learn classifier API for Keras.\n\n    Parameters\n    ----------\n    model : object\n        An un-compiled Keras model object is required to use the scikit-learn wrapper.\n    optimizer : string\n        Optimization method used by the model during compilation/training.\n    loss : string\n        Loss function used by the model during compilation/training.\n    \"\"\"\n    def __init__(self, model, optimizer='adam', loss='categorical_crossentropy', **kwargs):\n        super(KerasClassifier, self).__init__(model, optimizer, loss, **kwargs)\n\n    def predict(self, X):\n        \"\"\"\n        Returns the class predictions for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n\n        Returns\n        -------\n        preds : array-like, shape = (n_samples)\n            Class predictions.\n        \"\"\"\n        return self.compiled_model_.predict_classes(\n            X, batch_size=self.test_batch_size, verbose=self.verbose)\n\n    def predict_proba(self, X):\n        \"\"\"\n        Returns class probability estimates for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n\n        Returns\n        -------\n        proba : array-like, shape = (n_samples, n_outputs)\n            Class probability estimates.\n        \"\"\"\n        return self.compiled_model_.predict_proba(\n            X, batch_size=self.test_batch_size, verbose=self.verbose)\n\n    def score(self, X, y):\n        \"\"\"\n        Returns the mean accuracy on the given test data and labels.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n            True labels for X.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of predictions on X wrt. y.\n        \"\"\"\n        loss, accuracy = self.compiled_model_.evaluate(\n            X, y, batch_size=self.test_batch_size, show_accuracy=True, verbose=self.verbose)\n        return accuracy\n\n\nclass KerasRegressor(BaseWrapper):\n    \"\"\"\n    Implementation of the scikit-learn regressor API for Keras.\n\n    Parameters\n    ----------\n    model : object\n        An un-compiled Keras model object is required to use the scikit-learn wrapper.\n    optimizer : string\n        Optimization method used by the model during compilation/training.\n    loss : string\n        Loss function used by the model during compilation/training.\n    \"\"\"\n    def __init__(self, model, optimizer='adam', loss='mean_squared_error', **kwargs):\n        super(KerasRegressor, self).__init__(model, optimizer, loss, **kwargs)\n\n    def predict(self, X):\n        \"\"\"\n        Returns predictions for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n\n        Returns\n        -------\n        preds : array-like, shape = (n_samples)\n            Predictions.\n        \"\"\"\n        return self.compiled_model_.predict(\n            X, batch_size=self.test_batch_size, verbose=self.verbose).ravel()\n\n    def score(self, X, y):\n        \"\"\"\n        Returns the mean accuracy on the given test data and labels.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        y : array-like, shape = (n_samples)\n            True labels for X.\n\n        Returns\n        -------\n        score : float\n            Loss from predictions on X wrt. y.\n        \"\"\"\n        loss = self.compiled_model_.evaluate(\n            X, y, batch_size=self.test_batch_size, show_accuracy=False, verbose=self.verbose)\n        return loss\n",
          "file_after": "from __future__ import absolute_import\nimport copy\nimport inspect\nimport types\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\nfrom ..models import Sequential\n\n\nclass BaseWrapper(object):\n\n    '''Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly.\n    Use derived classes instead.\n\n    # Arguments\n        build_fn: callable function or class instance,  optional\n            Implementing the logic of the model.\n        sk_params: model parameters & fitting parameters\n\n    The build_fn should construct, compile and return a Keras model, which\n    will then be used to fit data or predict unknow data. One of the following\n    three values could be passed to build_fn:\n    1. A function instance\n    2. An instance of a class that implements the __call__ function\n    3. None. This means you implement a class that inherits either\n    KerasClassifier or KerasRegressor. The __call__ function of the class will\n    then be treated as the default build_fn\n\n    'sk_params' takes both model parameters and fitting parameters. Legal model\n    parameters are the arguments of 'build_fn'. Note that like all other\n    estimators in scikit_learn, 'build_fn' should provide defalult velues for\n    its arguments, so that you could create the estimator without passing any\n    values to 'sk_params'.\n\n    'sk_params' could also accept parameters for calling 'fit', 'predict',\n    'predict_proba', and 'score' function (e.g., nb_epoch, batch_size).\n    fitting (predicting) parameters are adopts in the following order:\n\n    1. Values passed to the dictionary arguments of\n    'fit', 'predict', 'predict_proba', and 'score' functions\n    2. Values passed to 'sk_params'\n    3. The default values of the keras.models.Sequential's\n    'fit', 'predict', 'predict_proba' and 'score' functions\n\n    When using scikit_learn's grid_search api, legal tunable parameters are\n    those you could pass to 'sk_params', including fitting parameters.\n    In other words, you could use grid_search to search for the best\n    batch_size or nb_epoch as well as the model parameters.\n    '''\n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n\n    def get_params(self, deep=True):\n        '''Get parameters for this estimator.\n\n        # Arguments\n            deep: boolean, optional\n                If True, will return the parameters for this estimator and\n                contained subobjects that are estimators.\n\n        # Returns\n            params : dict\n                Dictionary of parameter names mapped to their values.\n        '''\n        res = copy.deepcopy(self.sk_params)\n        res.update({'build_fn': self.build_fn})\n        return res\n\n    def set_params(self, **params):\n        '''Set the parameters of this estimator.\n\n        # Arguments\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        # Returns\n            self\n        '''\n        self.sk_params.update(params)\n        return self\n\n    def fit(self, X, y, **kwargs):\n        '''Construct a new model with build_fn and fit the model according\n        to the given training data.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.fit\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        '''\n\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif not isinstance(self.build_fn, types.FunctionType):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        if self.model.loss.__name__ == 'categorical_crossentropy'\\\n                and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(X, y, **fit_args)\n\n        return history\n\n    def filter_sk_params(self, fn, override={}):\n        '''Filter sk_params and return those in fn's arguments\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to overrid sk_params\n\n        # Returns\n            res : dictionary dictionary containing variabls\n                in both sk_params and fn's arguments.\n        '''\n        res = {}\n        fn_args = inspect.getargspec(fn)[0]\n        for name, value in self.sk_params.items():\n            if name in fn_args:\n                res.update({name: value})\n        res.update(override)\n        return res\n\n\nclass KerasClassifier(BaseWrapper):\n\n    '''Implementation of the scikit-learn classifier API for Keras.'''\n\n    def predict(self, X, **kwargs):\n        '''# Returns the class predictions for the given test data.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.predict_classes\n\n        # Returns\n            preds : array-like, shape = (n_samples)\n                Class predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n        return self.model.predict_classes(X, **kwargs)\n\n    def predict_proba(self, X, **kwargs):\n        '''# Returns class probability estimates for the given test data.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.predict_classes\n\n        # Returns\n            proba : array-like, shape = (n_samples, n_outputs)\n                Class probability estimates.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        return self.model.predict_proba(X, **kwargs)\n\n    def score(self, X, y, **kwargs):\n        '''# Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.evaluate\n\n        # Returns\n            score : float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        kwargs.update({'show_accuracy': True})\n        loss, accuracy = self.model.evaluate(X, y, **kwargs)\n        return accuracy\n\n\nclass KerasRegressor(BaseWrapper):\n\n    '''Implementation of the scikit-learn regressor API for Keras.'''\n\n    def predict(self, X, **kwargs):\n        ''' Returns predictions for the given test data.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.predict\n        # Returns\n            preds : array-like, shape = (n_samples)\n                Predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return self.model.predict(X, **kwargs)\n\n    def score(self, X, y, **kwargs):\n        '''Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape = (n_samples)\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.evaluate\n\n        # Returns\n            score : float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        kwargs.update({'show_accuracy': False})\n        loss = self.model.evaluate(X, y, **kwargs)\n        return loss\n",
          "file_patch": "@@ -1,266 +1,243 @@\n from __future__ import absolute_import\n-import abc\n import copy\n+import inspect\n+import types\n import numpy as np\n \n from ..utils.np_utils import to_categorical\n+from ..models import Sequential\n \n \n class BaseWrapper(object):\n-    \"\"\"\n-    Base class for the Keras scikit-learn wrapper.\n-\n-    Warning: This class should not be used directly. Use derived classes instead.\n-\n-    Parameters\n-    ----------\n-    train_batch_size : int, optional\n-        Number of training samples evaluated at a time.\n-    test_batch_size : int, optional\n-        Number of test samples evaluated at a time.\n-    nb_epochs : int, optional\n-        Number of training epochs.\n-    shuffle : boolean, optional\n-        Whether to shuffle the samples at each epoch.\n-    show_accuracy : boolean, optional\n-        Whether to display class accuracy in the logs at each epoch.\n-    validation_split : float [0, 1], optional\n-        Fraction of the data to use as held-out validation data.\n-    validation_data : tuple (X, y), optional\n-        Data to be used as held-out validation data. Will override validation_split.\n-    callbacks : list, optional\n-        List of callbacks to apply during training.\n-    verbose : int, optional\n-        Verbosity level.\n-    \"\"\"\n-    __metaclass__ = abc.ABCMeta\n-\n-    @abc.abstractmethod\n-    def __init__(self, model, optimizer, loss,\n-                 train_batch_size=128, test_batch_size=128,\n-                 nb_epoch=100, shuffle=True, show_accuracy=False,\n-                 validation_split=0, validation_data=None, callbacks=None,\n-                 verbose=0,):\n-        self.model = model\n-        self.optimizer = optimizer\n-        self.loss = loss\n-        self.compiled_model_ = None\n-        self.classes_ = []\n-        self.config_ = []\n-        self.weights_ = []\n-\n-        self.train_batch_size = train_batch_size\n-        self.test_batch_size = test_batch_size\n-        self.nb_epoch = nb_epoch\n-        self.shuffle = shuffle\n-        self.show_accuracy = show_accuracy\n-        self.validation_split = validation_split\n-        self.validation_data = validation_data\n-        self.callbacks = [] if callbacks is None else callbacks\n-\n-        self.verbose = verbose\n+\n+    '''Base class for the Keras scikit-learn wrapper.\n+\n+    Warning: This class should not be used directly.\n+    Use derived classes instead.\n+\n+    # Arguments\n+        build_fn: callable function or class instance,  optional\n+            Implementing the logic of the model.\n+        sk_params: model parameters & fitting parameters\n+\n+    The build_fn should construct, compile and return a Keras model, which\n+    will then be used to fit data or predict unknow data. One of the following\n+    three values could be passed to build_fn:\n+    1. A function instance\n+    2. An instance of a class that implements the __call__ function\n+    3. None. This means you implement a class that inherits either\n+    KerasClassifier or KerasRegressor. The __call__ function of the class will\n+    then be treated as the default build_fn\n+\n+    'sk_params' takes both model parameters and fitting parameters. Legal model\n+    parameters are the arguments of 'build_fn'. Note that like all other\n+    estimators in scikit_learn, 'build_fn' should provide defalult velues for\n+    its arguments, so that you could create the estimator without passing any\n+    values to 'sk_params'.\n+\n+    'sk_params' could also accept parameters for calling 'fit', 'predict',\n+    'predict_proba', and 'score' function (e.g., nb_epoch, batch_size).\n+    fitting (predicting) parameters are adopts in the following order:\n+\n+    1. Values passed to the dictionary arguments of\n+    'fit', 'predict', 'predict_proba', and 'score' functions\n+    2. Values passed to 'sk_params'\n+    3. The default values of the keras.models.Sequential's\n+    'fit', 'predict', 'predict_proba' and 'score' functions\n+\n+    When using scikit_learn's grid_search api, legal tunable parameters are\n+    those you could pass to 'sk_params', including fitting parameters.\n+    In other words, you could use grid_search to search for the best\n+    batch_size or nb_epoch as well as the model parameters.\n+    '''\n+\n+    def __init__(self, build_fn=None, **sk_params):\n+        self.build_fn = build_fn\n+        self.sk_params = sk_params\n \n     def get_params(self, deep=True):\n-        \"\"\"\n-        Get parameters for this estimator.\n-\n-        Parameters\n-        ----------\n-        deep: boolean, optional\n-            If True, will return the parameters for this estimator and\n-            contained subobjects that are estimators.\n-\n-        Returns\n-        -------\n-        params : dict\n-            Dictionary of parameter names mapped to their values.\n-        \"\"\"\n-        return {'model': self.model, 'optimizer': self.optimizer, 'loss': self.loss}\n+        '''Get parameters for this estimator.\n+\n+        # Arguments\n+            deep: boolean, optional\n+                If True, will return the parameters for this estimator and\n+                contained subobjects that are estimators.\n+\n+        # Returns\n+            params : dict\n+                Dictionary of parameter names mapped to their values.\n+        '''\n+        res = copy.deepcopy(self.sk_params)\n+        res.update({'build_fn': self.build_fn})\n+        return res\n \n     def set_params(self, **params):\n-        \"\"\"\n-        Set the parameters of this estimator.\n+        '''Set the parameters of this estimator.\n \n-        Parameters\n-        ----------\n+        # Arguments\n         params: dict\n             Dictionary of parameter names mapped to their values.\n \n-        Returns\n-        -------\n-        self\n-        \"\"\"\n-        for parameter, value in params.items():\n-            setattr(self, parameter, value)\n+        # Returns\n+            self\n+        '''\n+        self.sk_params.update(params)\n         return self\n \n-    def fit(self, X, y):\n-        \"\"\"\n-        Fit the model according to the given training data.\n-\n-        Makes a copy of the un-compiled model definition to use for\n-        compilation and fitting, leaving the original definition\n-        intact.\n-\n-        Parameters\n-        ----------\n-        X : array-like, shape = (n_samples, n_features)\n-            Training samples where n_samples in the number of samples\n-            and n_features is the number of features.\n-        y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n-            True labels for X.\n-\n-        Returns\n-        -------\n-        history : object\n-            Returns details about the training history at each epoch.\n-        \"\"\"\n-        if len(y.shape) == 1:\n-            self.classes_ = list(np.unique(y))\n-            if self.loss == 'categorical_crossentropy':\n-                y = to_categorical(y)\n+    def fit(self, X, y, **kwargs):\n+        '''Construct a new model with build_fn and fit the model according\n+        to the given training data.\n+\n+        # Arguments\n+            X : array-like, shape = (n_samples, n_features)\n+                Training samples where n_samples in the number of samples\n+                and n_features is the number of features.\n+            y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n+                True labels for X.\n+            kwargs: dictionary arguments\n+                Legal arguments are the arguments of Sequential.fit\n+\n+        # Returns\n+            history : object\n+                details about the training history at each epoch.\n+        '''\n+\n+        if self.build_fn is None:\n+            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n+        elif not isinstance(self.build_fn, types.FunctionType):\n+            self.model = self.build_fn(\n+                **self.filter_sk_params(self.build_fn.__call__))\n         else:\n-            self.classes_ = np.arange(0, y.shape[1])\n+            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n+\n+        if self.model.loss.__name__ == 'categorical_crossentropy'\\\n+                and len(y.shape) != 2:\n+            y = to_categorical(y)\n \n-        self.compiled_model_ = copy.deepcopy(self.model)\n-        self.compiled_model_.compile(optimizer=self.optimizer, loss=self.loss)\n-        history = self.compiled_model_.fit(\n-            X, y, batch_size=self.train_batch_size, nb_epoch=self.nb_epoch, verbose=self.verbose,\n-            shuffle=self.shuffle, show_accuracy=self.show_accuracy,\n-            validation_split=self.validation_split, validation_data=self.validation_data,\n-            callbacks=self.callbacks)\n+        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n+        fit_args.update(kwargs)\n \n-        self.config_ = self.model.get_config()\n-        self.weights_ = self.model.get_weights()\n+        history = self.model.fit(X, y, **fit_args)\n \n         return history\n \n+    def filter_sk_params(self, fn, override={}):\n+        '''Filter sk_params and return those in fn's arguments\n+\n+        # Arguments\n+            fn : arbitrary function\n+            override: dictionary, values to overrid sk_params\n+\n+        # Returns\n+            res : dictionary dictionary containing variabls\n+                in both sk_params and fn's arguments.\n+        '''\n+        res = {}\n+        fn_args = inspect.getargspec(fn)[0]\n+        for name, value in self.sk_params.items():\n+            if name in fn_args:\n+                res.update({name: value})\n+        res.update(override)\n+        return res\n+\n \n class KerasClassifier(BaseWrapper):\n-    \"\"\"\n-    Implementation of the scikit-learn classifier API for Keras.\n-\n-    Parameters\n-    ----------\n-    model : object\n-        An un-compiled Keras model object is required to use the scikit-learn wrapper.\n-    optimizer : string\n-        Optimization method used by the model during compilation/training.\n-    loss : string\n-        Loss function used by the model during compilation/training.\n-    \"\"\"\n-    def __init__(self, model, optimizer='adam', loss='categorical_crossentropy', **kwargs):\n-        super(KerasClassifier, self).__init__(model, optimizer, loss, **kwargs)\n-\n-    def predict(self, X):\n-        \"\"\"\n-        Returns the class predictions for the given test data.\n-\n-        Parameters\n-        ----------\n-        X : array-like, shape = (n_samples, n_features)\n-            Test samples where n_samples in the number of samples\n-            and n_features is the number of features.\n-\n-        Returns\n-        -------\n-        preds : array-like, shape = (n_samples)\n-            Class predictions.\n-        \"\"\"\n-        return self.compiled_model_.predict_classes(\n-            X, batch_size=self.test_batch_size, verbose=self.verbose)\n-\n-    def predict_proba(self, X):\n-        \"\"\"\n-        Returns class probability estimates for the given test data.\n-\n-        Parameters\n-        ----------\n-        X : array-like, shape = (n_samples, n_features)\n-            Test samples where n_samples in the number of samples\n-            and n_features is the number of features.\n-\n-        Returns\n-        -------\n-        proba : array-like, shape = (n_samples, n_outputs)\n-            Class probability estimates.\n-        \"\"\"\n-        return self.compiled_model_.predict_proba(\n-            X, batch_size=self.test_batch_size, verbose=self.verbose)\n-\n-    def score(self, X, y):\n-        \"\"\"\n-        Returns the mean accuracy on the given test data and labels.\n-\n-        Parameters\n-        ----------\n-        X : array-like, shape = (n_samples, n_features)\n-            Test samples where n_samples in the number of samples\n-            and n_features is the number of features.\n-        y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n-            True labels for X.\n-\n-        Returns\n-        -------\n-        score : float\n-            Mean accuracy of predictions on X wrt. y.\n-        \"\"\"\n-        loss, accuracy = self.compiled_model_.evaluate(\n-            X, y, batch_size=self.test_batch_size, show_accuracy=True, verbose=self.verbose)\n+\n+    '''Implementation of the scikit-learn classifier API for Keras.'''\n+\n+    def predict(self, X, **kwargs):\n+        '''# Returns the class predictions for the given test data.\n+\n+        # Arguments\n+            X : array-like, shape = (n_samples, n_features)\n+                Test samples where n_samples in the number of samples\n+                and n_features is the number of features.\n+            kwargs: dictionary arguments\n+                Legal arguments are the arguments of Sequential.predict_classes\n+\n+        # Returns\n+            preds : array-like, shape = (n_samples)\n+                Class predictions.\n+        '''\n+        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n+        return self.model.predict_classes(X, **kwargs)\n+\n+    def predict_proba(self, X, **kwargs):\n+        '''# Returns class probability estimates for the given test data.\n+\n+        # Arguments\n+            X : array-like, shape = (n_samples, n_features)\n+                Test samples where n_samples in the number of samples\n+                and n_features is the number of features.\n+            kwargs: dictionary arguments\n+                Legal arguments are the arguments of Sequential.predict_classes\n+\n+        # Returns\n+            proba : array-like, shape = (n_samples, n_outputs)\n+                Class probability estimates.\n+        '''\n+        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n+        return self.model.predict_proba(X, **kwargs)\n+\n+    def score(self, X, y, **kwargs):\n+        '''# Returns the mean accuracy on the given test data and labels.\n+\n+        # Arguments\n+            X : array-like, shape = (n_samples, n_features)\n+                Test samples where n_samples in the number of samples\n+                and n_features is the number of features.\n+            y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n+                True labels for X.\n+            kwargs: dictionary arguments\n+                Legal arguments are the arguments of Sequential.evaluate\n+\n+        # Returns\n+            score : float\n+                Mean accuracy of predictions on X wrt. y.\n+        '''\n+        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n+        kwargs.update({'show_accuracy': True})\n+        loss, accuracy = self.model.evaluate(X, y, **kwargs)\n         return accuracy\n \n \n class KerasRegressor(BaseWrapper):\n-    \"\"\"\n-    Implementation of the scikit-learn regressor API for Keras.\n-\n-    Parameters\n-    ----------\n-    model : object\n-        An un-compiled Keras model object is required to use the scikit-learn wrapper.\n-    optimizer : string\n-        Optimization method used by the model during compilation/training.\n-    loss : string\n-        Loss function used by the model during compilation/training.\n-    \"\"\"\n-    def __init__(self, model, optimizer='adam', loss='mean_squared_error', **kwargs):\n-        super(KerasRegressor, self).__init__(model, optimizer, loss, **kwargs)\n-\n-    def predict(self, X):\n-        \"\"\"\n-        Returns predictions for the given test data.\n-\n-        Parameters\n-        ----------\n-        X : array-like, shape = (n_samples, n_features)\n-            Test samples where n_samples in the number of samples\n-            and n_features is the number of features.\n-\n-        Returns\n-        -------\n-        preds : array-like, shape = (n_samples)\n-            Predictions.\n-        \"\"\"\n-        return self.compiled_model_.predict(\n-            X, batch_size=self.test_batch_size, verbose=self.verbose).ravel()\n-\n-    def score(self, X, y):\n-        \"\"\"\n-        Returns the mean accuracy on the given test data and labels.\n-\n-        Parameters\n-        ----------\n-        X : array-like, shape = (n_samples, n_features)\n-            Test samples where n_samples in the number of samples\n-            and n_features is the number of features.\n-        y : array-like, shape = (n_samples)\n-            True labels for X.\n-\n-        Returns\n-        -------\n-        score : float\n-            Loss from predictions on X wrt. y.\n-        \"\"\"\n-        loss = self.compiled_model_.evaluate(\n-            X, y, batch_size=self.test_batch_size, show_accuracy=False, verbose=self.verbose)\n+\n+    '''Implementation of the scikit-learn regressor API for Keras.'''\n+\n+    def predict(self, X, **kwargs):\n+        ''' Returns predictions for the given test data.\n+\n+        # Arguments\n+            X : array-like, shape = (n_samples, n_features)\n+                Test samples where n_samples in the number of samples\n+                and n_features is the number of features.\n+            kwargs: dictionary arguments\n+                Legal arguments are the arguments of Sequential.predict\n+        # Returns\n+            preds : array-like, shape = (n_samples)\n+                Predictions.\n+        '''\n+        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n+        return self.model.predict(X, **kwargs)\n+\n+    def score(self, X, y, **kwargs):\n+        '''Returns the mean accuracy on the given test data and labels.\n+\n+        # Arguments\n+            X : array-like, shape = (n_samples, n_features)\n+                Test samples where n_samples in the number of samples\n+                and n_features is the number of features.\n+            y : array-like, shape = (n_samples)\n+                True labels for X.\n+            kwargs: dictionary arguments\n+                Legal arguments are the arguments of Sequential.evaluate\n+\n+        # Returns\n+            score : float\n+                Mean accuracy of predictions on X wrt. y.\n+        '''\n+        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n+        kwargs.update({'show_accuracy': False})\n+        loss = self.model.evaluate(X, y, **kwargs)\n         return loss\n",
          "files_name_in_blame_commit": [
            "scikit_learn.py",
            "test_scikit_learn.py"
          ]
        }
      },
      "763a2a953638ac1a1374c11d65716938060553c0": {
        "commit": {
          "commit_id": "763a2a953638ac1a1374c11d65716938060553c0",
          "commit_message": "Style and dosctring fixes, sklearn wrapper.",
          "commit_author": "fchollet",
          "commit_date": "2016-02-28 11:54:00",
          "commit_parent": "be24159959672c32abb31697e721d96ae6ffaf97"
        },
        "function": {
          "function_name": "predict",
          "function_code_before": "def predict(self, X, **kwargs):\n    \"\"\" Returns predictions for the given test data.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.predict\n        # Returns\n            preds : array-like, shape = (n_samples)\n                Predictions.\n        \"\"\"\n    kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n    return self.model.predict(X, **kwargs)",
          "function_code_after": "def predict(self, X, **kwargs):\n    \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n    kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n    return self.model.predict(X, **kwargs)",
          "function_before_start_line": 208,
          "function_before_end_line": 222,
          "function_after_start_line": 205,
          "function_after_end_line": 219,
          "function_before_token_count": 35,
          "function_after_token_count": 0,
          "functions_name_modified_file": [
            "__init__",
            "set_params",
            "get_params",
            "predict",
            "filter_sk_params",
            "predict_proba",
            "fit",
            "score"
          ],
          "functions_name_all_files": [
            "__init__",
            "set_params",
            "get_params",
            "predict",
            "filter_sk_params",
            "predict_proba",
            "fit",
            "score"
          ],
          "functions_name_co_evolved_modified_file": [
            "predict_proba",
            "score",
            "get_params",
            "fit"
          ],
          "functions_name_co_evolved_all_files": [
            "predict_proba",
            "score",
            "get_params",
            "fit"
          ]
        },
        "file": {
          "file_name": "scikit_learn.py",
          "file_nloc": 104,
          "file_complexity": 16,
          "file_token_count": 564,
          "file_before": "from __future__ import absolute_import\nimport copy\nimport inspect\nimport types\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\nfrom ..models import Sequential\n\n\nclass BaseWrapper(object):\n\n    '''Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly.\n    Use derived classes instead.\n\n    # Arguments\n        build_fn: callable function or class instance,  optional\n            Implementing the logic of the model.\n        sk_params: model parameters & fitting parameters\n\n    The build_fn should construct, compile and return a Keras model, which\n    will then be used to fit data or predict unknow data. One of the following\n    three values could be passed to build_fn:\n    1. A function instance\n    2. An instance of a class that implements the __call__ function\n    3. None. This means you implement a class that inherits either\n    KerasClassifier or KerasRegressor. The __call__ function of the class will\n    then be treated as the default build_fn\n\n    'sk_params' takes both model parameters and fitting parameters. Legal model\n    parameters are the arguments of 'build_fn'. Note that like all other\n    estimators in scikit_learn, 'build_fn' should provide defalult velues for\n    its arguments, so that you could create the estimator without passing any\n    values to 'sk_params'.\n\n    'sk_params' could also accept parameters for calling 'fit', 'predict',\n    'predict_proba', and 'score' function (e.g., nb_epoch, batch_size).\n    fitting (predicting) parameters are adopts in the following order:\n\n    1. Values passed to the dictionary arguments of\n    'fit', 'predict', 'predict_proba', and 'score' functions\n    2. Values passed to 'sk_params'\n    3. The default values of the keras.models.Sequential's\n    'fit', 'predict', 'predict_proba' and 'score' functions\n\n    When using scikit_learn's grid_search api, legal tunable parameters are\n    those you could pass to 'sk_params', including fitting parameters.\n    In other words, you could use grid_search to search for the best\n    batch_size or nb_epoch as well as the model parameters.\n    '''\n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n\n    def get_params(self, deep=True):\n        '''Get parameters for this estimator.\n\n        # Arguments\n            deep: boolean, optional\n                If True, will return the parameters for this estimator and\n                contained subobjects that are estimators.\n\n        # Returns\n            params : dict\n                Dictionary of parameter names mapped to their values.\n        '''\n        res = copy.deepcopy(self.sk_params)\n        res.update({'build_fn': self.build_fn})\n        return res\n\n    def set_params(self, **params):\n        '''Set the parameters of this estimator.\n\n        # Arguments\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        # Returns\n            self\n        '''\n        self.sk_params.update(params)\n        return self\n\n    def fit(self, X, y, **kwargs):\n        '''Construct a new model with build_fn and fit the model according\n        to the given training data.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.fit\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        '''\n\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif not isinstance(self.build_fn, types.FunctionType):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        if self.model.loss.__name__ == 'categorical_crossentropy'\\\n                and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(X, y, **fit_args)\n\n        return history\n\n    def filter_sk_params(self, fn, override={}):\n        '''Filter sk_params and return those in fn's arguments\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to overrid sk_params\n\n        # Returns\n            res : dictionary dictionary containing variabls\n                in both sk_params and fn's arguments.\n        '''\n        res = {}\n        fn_args = inspect.getargspec(fn)[0]\n        for name, value in self.sk_params.items():\n            if name in fn_args:\n                res.update({name: value})\n        res.update(override)\n        return res\n\n\nclass KerasClassifier(BaseWrapper):\n\n    '''Implementation of the scikit-learn classifier API for Keras.'''\n\n    def predict(self, X, **kwargs):\n        '''# Returns the class predictions for the given test data.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.predict_classes\n\n        # Returns\n            preds : array-like, shape = (n_samples)\n                Class predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n        return self.model.predict_classes(X, **kwargs)\n\n    def predict_proba(self, X, **kwargs):\n        '''# Returns class probability estimates for the given test data.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.predict_classes\n\n        # Returns\n            proba : array-like, shape = (n_samples, n_outputs)\n                Class probability estimates.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        return self.model.predict_proba(X, **kwargs)\n\n    def score(self, X, y, **kwargs):\n        '''# Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.evaluate\n\n        # Returns\n            score : float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        kwargs.update({'show_accuracy': True})\n        loss, accuracy = self.model.evaluate(X, y, **kwargs)\n        return accuracy\n\n\nclass KerasRegressor(BaseWrapper):\n\n    '''Implementation of the scikit-learn regressor API for Keras.'''\n\n    def predict(self, X, **kwargs):\n        ''' Returns predictions for the given test data.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.predict\n        # Returns\n            preds : array-like, shape = (n_samples)\n                Predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return self.model.predict(X, **kwargs)\n\n    def score(self, X, y, **kwargs):\n        '''Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X : array-like, shape = (n_samples, n_features)\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape = (n_samples)\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of Sequential.evaluate\n\n        # Returns\n            score : float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        kwargs.update({'show_accuracy': False})\n        loss = self.model.evaluate(X, y, **kwargs)\n        return loss\n",
          "file_after": "from __future__ import absolute_import\nimport copy\nimport inspect\nimport types\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\nfrom ..models import Sequential\n\n\nclass BaseWrapper(object):\n    '''Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly.\n    Use descendant classes instead.\n\n    # Arguments\n        build_fn: callable function or class instance\n        sk_params: model parameters & fitting parameters\n\n    The build_fn should construct, compile and return a Keras model, which\n    will then be used to fit/predict. One of the following\n    three values could be passed to build_fn:\n    1. A function\n    2. An instance of a class that implements the __call__ method\n    3. None. This means you implement a class that inherits from either\n    `KerasClassifier` or `KerasRegressor`. The __call__ method of the\n    present class will then be treated as the default build_fn.\n\n    `sk_params` takes both model parameters and fitting parameters. Legal model\n    parameters are the arguments of `build_fn`. Note that like all other\n    estimators in scikit-learn, 'build_fn' should provide defalult values for\n    its arguments, so that you could create the estimator without passing any\n    values to `sk_params`.\n\n    `sk_params` could also accept parameters for calling `fit`, `predict`,\n    `predict_proba`, and `score` methods (e.g., `nb_epoch`, `batch_size`).\n    fitting (predicting) parameters are selected in the following order:\n\n    1. Values passed to the dictionary arguments of\n    `fit`, `predict`, `predict_proba`, and `score` methods\n    2. Values passed to `sk_params`\n    3. The default values of the `keras.models.Sequential`\n    `fit`, `predict`, `predict_proba` and `score` methods\n\n    When using scikit-learn's `grid_search` API, legal tunable parameters are\n    those you could pass to `sk_params`, including fitting parameters.\n    In other words, you could use `grid_search` to search for the best\n    `batch_size` or `nb_epoch` as well as the model parameters.\n    '''\n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n\n    def get_params(self, deep=True):\n        '''Get parameters for this estimator.\n\n        # Arguments\n            deep: boolean, optional\n                If True, will return the parameters for this estimator and\n                contained sub-objects that are estimators.\n\n        # Returns\n            params : dict\n                Dictionary of parameter names mapped to their values.\n        '''\n        res = copy.deepcopy(self.sk_params)\n        res.update({'build_fn': self.build_fn})\n        return res\n\n    def set_params(self, **params):\n        '''Set the parameters of this estimator.\n\n        # Arguments\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        # Returns\n            self\n        '''\n        self.sk_params.update(params)\n        return self\n\n    def fit(self, X, y, **kwargs):\n        '''Construct a new model with build_fn and fit the model according\n        to the given training data.\n\n        # Arguments\n            X : array-like, shape `(n_samples, n_features)`\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        '''\n\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif not isinstance(self.build_fn, types.FunctionType):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        if self.model.loss.__name__ == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(X, y, **fit_args)\n\n        return history\n\n    def filter_sk_params(self, fn, override={}):\n        '''Filter sk_params and return those in fn's arguments\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to overrid sk_params\n\n        # Returns\n            res : dictionary dictionary containing variabls\n                in both sk_params and fn's arguments.\n        '''\n        res = {}\n        fn_args = inspect.getargspec(fn)[0]\n        for name, value in self.sk_params.items():\n            if name in fn_args:\n                res.update({name: value})\n        res.update(override)\n        return res\n\n\nclass KerasClassifier(BaseWrapper):\n    '''Implementation of the scikit-learn classifier API for Keras.\n    '''\n\n    def predict(self, X, **kwargs):\n        '''Returns the class predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Class predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n        return self.model.predict_classes(X, **kwargs)\n\n    def predict_proba(self, X, **kwargs):\n        '''Returns class probability estimates for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict_classes`.\n\n        # Returns\n            proba: array-like, shape `(n_samples, n_outputs)`\n                Class probability estimates.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        return self.model.predict_proba(X, **kwargs)\n\n    def score(self, X, y, **kwargs):\n        '''Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        kwargs.update({'show_accuracy': True})\n        loss, accuracy = self.model.evaluate(X, y, **kwargs)\n        return accuracy\n\n\nclass KerasRegressor(BaseWrapper):\n    '''Implementation of the scikit-learn regressor API for Keras.\n    '''\n\n    def predict(self, X, **kwargs):\n        '''Returns predictions for the given test data.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        '''\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return self.model.predict(X, **kwargs)\n\n    def score(self, X, y, **kwargs):\n        '''Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            X: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)`\n                True labels for X.\n            kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        '''\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        kwargs.update({'show_accuracy': False})\n        loss = self.model.evaluate(X, y, **kwargs)\n        return loss\n",
          "file_patch": "@@ -9,46 +9,44 @@ from ..models import Sequential\n \n \n class BaseWrapper(object):\n-\n     '''Base class for the Keras scikit-learn wrapper.\n \n     Warning: This class should not be used directly.\n-    Use derived classes instead.\n+    Use descendant classes instead.\n \n     # Arguments\n-        build_fn: callable function or class instance,  optional\n-            Implementing the logic of the model.\n+        build_fn: callable function or class instance\n         sk_params: model parameters & fitting parameters\n \n     The build_fn should construct, compile and return a Keras model, which\n-    will then be used to fit data or predict unknow data. One of the following\n+    will then be used to fit/predict. One of the following\n     three values could be passed to build_fn:\n-    1. A function instance\n-    2. An instance of a class that implements the __call__ function\n-    3. None. This means you implement a class that inherits either\n-    KerasClassifier or KerasRegressor. The __call__ function of the class will\n-    then be treated as the default build_fn\n-\n-    'sk_params' takes both model parameters and fitting parameters. Legal model\n-    parameters are the arguments of 'build_fn'. Note that like all other\n-    estimators in scikit_learn, 'build_fn' should provide defalult velues for\n+    1. A function\n+    2. An instance of a class that implements the __call__ method\n+    3. None. This means you implement a class that inherits from either\n+    `KerasClassifier` or `KerasRegressor`. The __call__ method of the\n+    present class will then be treated as the default build_fn.\n+\n+    `sk_params` takes both model parameters and fitting parameters. Legal model\n+    parameters are the arguments of `build_fn`. Note that like all other\n+    estimators in scikit-learn, 'build_fn' should provide defalult values for\n     its arguments, so that you could create the estimator without passing any\n-    values to 'sk_params'.\n+    values to `sk_params`.\n \n-    'sk_params' could also accept parameters for calling 'fit', 'predict',\n-    'predict_proba', and 'score' function (e.g., nb_epoch, batch_size).\n-    fitting (predicting) parameters are adopts in the following order:\n+    `sk_params` could also accept parameters for calling `fit`, `predict`,\n+    `predict_proba`, and `score` methods (e.g., `nb_epoch`, `batch_size`).\n+    fitting (predicting) parameters are selected in the following order:\n \n     1. Values passed to the dictionary arguments of\n-    'fit', 'predict', 'predict_proba', and 'score' functions\n-    2. Values passed to 'sk_params'\n-    3. The default values of the keras.models.Sequential's\n-    'fit', 'predict', 'predict_proba' and 'score' functions\n-\n-    When using scikit_learn's grid_search api, legal tunable parameters are\n-    those you could pass to 'sk_params', including fitting parameters.\n-    In other words, you could use grid_search to search for the best\n-    batch_size or nb_epoch as well as the model parameters.\n+    `fit`, `predict`, `predict_proba`, and `score` methods\n+    2. Values passed to `sk_params`\n+    3. The default values of the `keras.models.Sequential`\n+    `fit`, `predict`, `predict_proba` and `score` methods\n+\n+    When using scikit-learn's `grid_search` API, legal tunable parameters are\n+    those you could pass to `sk_params`, including fitting parameters.\n+    In other words, you could use `grid_search` to search for the best\n+    `batch_size` or `nb_epoch` as well as the model parameters.\n     '''\n \n     def __init__(self, build_fn=None, **sk_params):\n@@ -61,7 +59,7 @@ class BaseWrapper(object):\n         # Arguments\n             deep: boolean, optional\n                 If True, will return the parameters for this estimator and\n-                contained subobjects that are estimators.\n+                contained sub-objects that are estimators.\n \n         # Returns\n             params : dict\n@@ -89,13 +87,13 @@ class BaseWrapper(object):\n         to the given training data.\n \n         # Arguments\n-            X : array-like, shape = (n_samples, n_features)\n+            X : array-like, shape `(n_samples, n_features)`\n                 Training samples where n_samples in the number of samples\n                 and n_features is the number of features.\n-            y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n+            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                 True labels for X.\n             kwargs: dictionary arguments\n-                Legal arguments are the arguments of Sequential.fit\n+                Legal arguments are the arguments of `Sequential.fit`\n \n         # Returns\n             history : object\n@@ -110,8 +108,7 @@ class BaseWrapper(object):\n         else:\n             self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n \n-        if self.model.loss.__name__ == 'categorical_crossentropy'\\\n-                and len(y.shape) != 2:\n+        if self.model.loss.__name__ == 'categorical_crossentropy' and len(y.shape) != 2:\n             y = to_categorical(y)\n \n         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n@@ -142,57 +139,57 @@ class BaseWrapper(object):\n \n \n class KerasClassifier(BaseWrapper):\n-\n-    '''Implementation of the scikit-learn classifier API for Keras.'''\n+    '''Implementation of the scikit-learn classifier API for Keras.\n+    '''\n \n     def predict(self, X, **kwargs):\n-        '''# Returns the class predictions for the given test data.\n+        '''Returns the class predictions for the given test data.\n \n         # Arguments\n-            X : array-like, shape = (n_samples, n_features)\n+            X: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             kwargs: dictionary arguments\n-                Legal arguments are the arguments of Sequential.predict_classes\n+                Legal arguments are the arguments of `Sequential.predict_classes`.\n \n         # Returns\n-            preds : array-like, shape = (n_samples)\n+            preds: array-like, shape `(n_samples,)`\n                 Class predictions.\n         '''\n         kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n         return self.model.predict_classes(X, **kwargs)\n \n     def predict_proba(self, X, **kwargs):\n-        '''# Returns class probability estimates for the given test data.\n+        '''Returns class probability estimates for the given test data.\n \n         # Arguments\n-            X : array-like, shape = (n_samples, n_features)\n+            X: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             kwargs: dictionary arguments\n-                Legal arguments are the arguments of Sequential.predict_classes\n+                Legal arguments are the arguments of `Sequential.predict_classes`.\n \n         # Returns\n-            proba : array-like, shape = (n_samples, n_outputs)\n+            proba: array-like, shape `(n_samples, n_outputs)`\n                 Class probability estimates.\n         '''\n         kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n         return self.model.predict_proba(X, **kwargs)\n \n     def score(self, X, y, **kwargs):\n-        '''# Returns the mean accuracy on the given test data and labels.\n+        '''Returns the mean accuracy on the given test data and labels.\n \n         # Arguments\n-            X : array-like, shape = (n_samples, n_features)\n+            X: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n-            y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n+            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                 True labels for X.\n             kwargs: dictionary arguments\n-                Legal arguments are the arguments of Sequential.evaluate\n+                Legal arguments are the arguments of `Sequential.evaluate`.\n \n         # Returns\n-            score : float\n+            score: float\n                 Mean accuracy of predictions on X wrt. y.\n         '''\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n@@ -202,20 +199,20 @@ class KerasClassifier(BaseWrapper):\n \n \n class KerasRegressor(BaseWrapper):\n-\n-    '''Implementation of the scikit-learn regressor API for Keras.'''\n+    '''Implementation of the scikit-learn regressor API for Keras.\n+    '''\n \n     def predict(self, X, **kwargs):\n-        ''' Returns predictions for the given test data.\n+        '''Returns predictions for the given test data.\n \n         # Arguments\n-            X : array-like, shape = (n_samples, n_features)\n+            X: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             kwargs: dictionary arguments\n-                Legal arguments are the arguments of Sequential.predict\n+                Legal arguments are the arguments of `Sequential.predict`.\n         # Returns\n-            preds : array-like, shape = (n_samples)\n+            preds: array-like, shape `(n_samples,)`\n                 Predictions.\n         '''\n         kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n@@ -225,16 +222,16 @@ class KerasRegressor(BaseWrapper):\n         '''Returns the mean accuracy on the given test data and labels.\n \n         # Arguments\n-            X : array-like, shape = (n_samples, n_features)\n+            X: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n-            y : array-like, shape = (n_samples)\n+            y: array-like, shape `(n_samples,)`\n                 True labels for X.\n             kwargs: dictionary arguments\n-                Legal arguments are the arguments of Sequential.evaluate\n+                Legal arguments are the arguments of `Sequential.evaluate`.\n \n         # Returns\n-            score : float\n+            score: float\n                 Mean accuracy of predictions on X wrt. y.\n         '''\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n",
          "files_name_in_blame_commit": [
            "scikit_learn.py"
          ]
        }
      },
      "c9461d71483b5cfd2639abc909cc7f145f1625c4": {
        "commit": {
          "commit_id": "c9461d71483b5cfd2639abc909cc7f145f1625c4",
          "commit_message": "Added regressor class.",
          "commit_author": "John Wittenauer",
          "commit_date": "2015-08-15 20:59:06",
          "commit_parent": "dbe948ec97271321fa60772ba1cb22509f59d76b"
        },
        "function": {
          "function_name": "predict",
          "function_code_before": "def predict(self, X, batch_size=128, verbose=0):\n    \"\"\"\n        Returns the class predictions for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        batch_size : int, optional\n            Number of test samples evaluated at a time.\n        verbose : int, optional\n            Verbosity level.\n\n        Returns\n        -------\n        preds : array-like, shape = (n_samples)\n            Class predictions.\n        \"\"\"\n    return self.compiled_model_.predict_classes(X, batch_size=batch_size, verbose=verbose)",
          "function_code_after": "def predict(self, X, batch_size=128, verbose=0):\n    \"\"\"\n        Returns predictions for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        batch_size : int, optional\n            Number of test samples evaluated at a time.\n        verbose : int, optional\n            Verbosity level.\n\n        Returns\n        -------\n        preds : array-like, shape = (n_samples)\n            Predictions.\n        \"\"\"\n    return self.compiled_model_.predict(X, batch_size=batch_size, verbose=verbose)",
          "function_before_start_line": 135,
          "function_before_end_line": 154,
          "function_after_start_line": 218,
          "function_after_end_line": 237,
          "function_before_token_count": 33,
          "function_after_token_count": 33,
          "functions_name_modified_file": [
            "__init__",
            "set_params",
            "get_params",
            "predict",
            "predict_proba",
            "fit",
            "score"
          ],
          "functions_name_all_files": [
            "__init__",
            "set_params",
            "get_params",
            "predict",
            "predict_proba",
            "fit",
            "score"
          ],
          "functions_name_co_evolved_modified_file": [
            "__init__",
            "score"
          ],
          "functions_name_co_evolved_all_files": [
            "__init__",
            "score"
          ]
        },
        "file": {
          "file_name": "scikit_learn.py",
          "file_nloc": 86,
          "file_complexity": 14,
          "file_token_count": 615,
          "file_before": "from __future__ import absolute_import\nimport abc\nimport copy\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\n\n\nclass BaseWrapper(object):\n    \"\"\"\n    Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly. Use derived classes instead.\n    \"\"\"\n    __metaclass__ = abc.ABCMeta\n\n    @abc.abstractmethod\n    def __init__(self, model, optimizer, loss):\n        self.model = model\n        self.optimizer = optimizer\n        self.loss = loss\n        self.compiled_model_ = None\n        self.classes_ = []\n        self.config_ = []\n        self.weights_ = []\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep: boolean, optional\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.\n\n        Returns\n        -------\n        params : dict\n            Dictionary of parameter names mapped to their values.\n        \"\"\"\n        return {'model': self.model, 'optimizer': self.optimizer, 'loss': self.loss}\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        Parameters\n        ----------\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        for parameter, value in params.items():\n            setattr(self, parameter, value)\n        return self\n\n    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=0, shuffle=True, show_accuracy=False,\n            validation_split=0, validation_data=None, callbacks=[]):\n        \"\"\"\n        Fit the model according to the given training data.\n\n        Makes a copy of the un-compiled model definition to use for\n        compilation and fitting, leaving the original definition\n        intact.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Training samples where n_samples in the number of samples\n            and n_features is the number of features.\n        y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n            True labels for X.\n        batch_size : int, optional\n            Number of training samples evaluated at a time.\n        nb_epochs : int, optional\n            Number of training epochs.\n        verbose : int, optional\n            Verbosity level.\n        shuffle : boolean, optional\n            Whether to shuffle the samples at each epoch.\n        show_accuracy : boolean, optional\n            Whether to display class accuracy in the logs at each epoch.\n        validation_split : float [0, 1], optional\n            Fraction of the data to use as held-out validation data.\n        validation_data : tuple (X, y), optional\n            Data to be used as held-out validation data. Will override validation_split.\n        callbacks : list, optional\n            List of callbacks to apply during training.\n\n        Returns\n        -------\n        history : object\n            Returns details about the training history at each epoch.\n        \"\"\"\n        if len(y.shape) == 1:\n            self.classes_ = list(np.unique(y))\n            if self.loss == 'categorical_crossentropy':\n                y = to_categorical(y)\n        else:\n            self.classes_ = np.arange(0, y.shape[1])\n\n        self.compiled_model_ = copy.deepcopy(self.model)\n        self.compiled_model_.compile(optimizer=self.optimizer, loss=self.loss)\n        history = self.compiled_model_.fit(X, y, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose,\n                                           shuffle=shuffle, show_accuracy=show_accuracy,\n                                           validation_split=validation_split, validation_data=validation_data,\n                                           callbacks=callbacks)\n\n        self.config_ = self.model.get_config()\n        self.weights_ = self.model.get_weights()\n\n        return history\n\n\nclass KerasClassifier(BaseWrapper):\n    \"\"\"\n    Implementation of the scikit-learn classifier API for Keras.\n\n    Parameters\n    ----------\n    model : object\n        An un-compiled Keras model object is required to use the scikit-learn wrapper.\n    optimizer : string\n        Optimization method used by the model during compilation/training.\n    loss : string\n        Loss function used by the model during compilation/training.\n    \"\"\"\n    def __init__(self, model, optimizer='adam', loss='categorical_crossentropy'):\n        super(KerasClassifier, self).__init__(model, optimizer, loss)\n\n    def predict(self, X, batch_size=128, verbose=0):\n        \"\"\"\n        Returns the class predictions for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        batch_size : int, optional\n            Number of test samples evaluated at a time.\n        verbose : int, optional\n            Verbosity level.\n\n        Returns\n        -------\n        preds : array-like, shape = (n_samples)\n            Class predictions.\n        \"\"\"\n        return self.compiled_model_.predict_classes(X, batch_size=batch_size, verbose=verbose)\n\n    def predict_proba(self, X, batch_size=128, verbose=0):\n        \"\"\"\n        Returns class probability estimates for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        batch_size : int, optional\n            Number of test samples evaluated at a time.\n        verbose : int, optional\n            Verbosity level.\n\n        Returns\n        -------\n        proba : array-like, shape = (n_samples, n_outputs)\n            Class probability estimates.\n        \"\"\"\n        return self.compiled_model_.predict_proba(X, batch_size=batch_size, verbose=verbose)\n\n    def score(self, X, y, batch_size=128, verbose=0):\n        \"\"\"\n        Returns the mean accuracy on the given test data and labels.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n            True labels for X.\n        batch_size : int, optional\n            Number of test samples evaluated at a time.\n        verbose : int, optional\n            Verbosity level.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of predictions on X wrt. y.\n        \"\"\"\n        loss, accuracy = self.compiled_model_.evaluate(X, y, batch_size=batch_size, show_accuracy=True, verbose=verbose)\n        return accuracy\n",
          "file_after": "from __future__ import absolute_import\nimport abc\nimport copy\nimport numpy as np\n\nfrom ..utils.np_utils import to_categorical\n\n\nclass BaseWrapper(object):\n    \"\"\"\n    Base class for the Keras scikit-learn wrapper.\n\n    Warning: This class should not be used directly. Use derived classes instead.\n    \"\"\"\n    __metaclass__ = abc.ABCMeta\n\n    @abc.abstractmethod\n    def __init__(self, model, optimizer, loss):\n        self.model = model\n        self.optimizer = optimizer\n        self.loss = loss\n        self.compiled_model_ = None\n        self.classes_ = []\n        self.config_ = []\n        self.weights_ = []\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep: boolean, optional\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.\n\n        Returns\n        -------\n        params : dict\n            Dictionary of parameter names mapped to their values.\n        \"\"\"\n        return {'model': self.model, 'optimizer': self.optimizer, 'loss': self.loss}\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        Parameters\n        ----------\n        params: dict\n            Dictionary of parameter names mapped to their values.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        for parameter, value in params.items():\n            setattr(self, parameter, value)\n        return self\n\n    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=0, shuffle=True, show_accuracy=False,\n            validation_split=0, validation_data=None, callbacks=[]):\n        \"\"\"\n        Fit the model according to the given training data.\n\n        Makes a copy of the un-compiled model definition to use for\n        compilation and fitting, leaving the original definition\n        intact.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Training samples where n_samples in the number of samples\n            and n_features is the number of features.\n        y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n            True labels for X.\n        batch_size : int, optional\n            Number of training samples evaluated at a time.\n        nb_epochs : int, optional\n            Number of training epochs.\n        verbose : int, optional\n            Verbosity level.\n        shuffle : boolean, optional\n            Whether to shuffle the samples at each epoch.\n        show_accuracy : boolean, optional\n            Whether to display class accuracy in the logs at each epoch.\n        validation_split : float [0, 1], optional\n            Fraction of the data to use as held-out validation data.\n        validation_data : tuple (X, y), optional\n            Data to be used as held-out validation data. Will override validation_split.\n        callbacks : list, optional\n            List of callbacks to apply during training.\n\n        Returns\n        -------\n        history : object\n            Returns details about the training history at each epoch.\n        \"\"\"\n        if len(y.shape) == 1:\n            self.classes_ = list(np.unique(y))\n            if self.loss == 'categorical_crossentropy':\n                y = to_categorical(y)\n        else:\n            self.classes_ = np.arange(0, y.shape[1])\n\n        self.compiled_model_ = copy.deepcopy(self.model)\n        self.compiled_model_.compile(optimizer=self.optimizer, loss=self.loss)\n        history = self.compiled_model_.fit(X, y, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose,\n                                           shuffle=shuffle, show_accuracy=show_accuracy,\n                                           validation_split=validation_split, validation_data=validation_data,\n                                           callbacks=callbacks)\n\n        self.config_ = self.model.get_config()\n        self.weights_ = self.model.get_weights()\n\n        return history\n\n\nclass KerasClassifier(BaseWrapper):\n    \"\"\"\n    Implementation of the scikit-learn classifier API for Keras.\n\n    Parameters\n    ----------\n    model : object\n        An un-compiled Keras model object is required to use the scikit-learn wrapper.\n    optimizer : string\n        Optimization method used by the model during compilation/training.\n    loss : string\n        Loss function used by the model during compilation/training.\n    \"\"\"\n    def __init__(self, model, optimizer='adam', loss='categorical_crossentropy'):\n        super(KerasClassifier, self).__init__(model, optimizer, loss)\n\n    def predict(self, X, batch_size=128, verbose=0):\n        \"\"\"\n        Returns the class predictions for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        batch_size : int, optional\n            Number of test samples evaluated at a time.\n        verbose : int, optional\n            Verbosity level.\n\n        Returns\n        -------\n        preds : array-like, shape = (n_samples)\n            Class predictions.\n        \"\"\"\n        return self.compiled_model_.predict_classes(X, batch_size=batch_size, verbose=verbose)\n\n    def predict_proba(self, X, batch_size=128, verbose=0):\n        \"\"\"\n        Returns class probability estimates for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        batch_size : int, optional\n            Number of test samples evaluated at a time.\n        verbose : int, optional\n            Verbosity level.\n\n        Returns\n        -------\n        proba : array-like, shape = (n_samples, n_outputs)\n            Class probability estimates.\n        \"\"\"\n        return self.compiled_model_.predict_proba(X, batch_size=batch_size, verbose=verbose)\n\n    def score(self, X, y, batch_size=128, verbose=0):\n        \"\"\"\n        Returns the mean accuracy on the given test data and labels.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n            True labels for X.\n        batch_size : int, optional\n            Number of test samples evaluated at a time.\n        verbose : int, optional\n            Verbosity level.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of predictions on X wrt. y.\n        \"\"\"\n        loss, accuracy = self.compiled_model_.evaluate(X, y, batch_size=batch_size, show_accuracy=True, verbose=verbose)\n        return accuracy\n\n\nclass KerasRegressor(BaseWrapper):\n    \"\"\"\n    Implementation of the scikit-learn regressor API for Keras.\n\n    Parameters\n    ----------\n    model : object\n        An un-compiled Keras model object is required to use the scikit-learn wrapper.\n    optimizer : string\n        Optimization method used by the model during compilation/training.\n    loss : string\n        Loss function used by the model during compilation/training.\n    \"\"\"\n    def __init__(self, model, optimizer='adam', loss='mean_squared_error'):\n        super(KerasRegressor, self).__init__(model, optimizer, loss)\n\n    def predict(self, X, batch_size=128, verbose=0):\n        \"\"\"\n        Returns predictions for the given test data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        batch_size : int, optional\n            Number of test samples evaluated at a time.\n        verbose : int, optional\n            Verbosity level.\n\n        Returns\n        -------\n        preds : array-like, shape = (n_samples)\n            Predictions.\n        \"\"\"\n        return self.compiled_model_.predict(X, batch_size=batch_size, verbose=verbose)\n\n    def score(self, X, y, batch_size=128, verbose=0):\n        \"\"\"\n        Returns the mean accuracy on the given test data and labels.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples where n_samples in the number of samples\n            and n_features is the number of features.\n        y : array-like, shape = (n_samples)\n            True labels for X.\n        batch_size : int, optional\n            Number of test samples evaluated at a time.\n        verbose : int, optional\n            Verbosity level.\n\n        Returns\n        -------\n        score : float\n            Loss from predictions on X wrt. y.\n        \"\"\"\n        loss = self.compiled_model_.evaluate(X, y, batch_size=batch_size, show_accuracy=False, verbose=verbose)\n        return loss\n",
          "file_patch": "@@ -197,3 +197,65 @@ class KerasClassifier(BaseWrapper):\n         \"\"\"\n         loss, accuracy = self.compiled_model_.evaluate(X, y, batch_size=batch_size, show_accuracy=True, verbose=verbose)\n         return accuracy\n+\n+\n+class KerasRegressor(BaseWrapper):\n+    \"\"\"\n+    Implementation of the scikit-learn regressor API for Keras.\n+\n+    Parameters\n+    ----------\n+    model : object\n+        An un-compiled Keras model object is required to use the scikit-learn wrapper.\n+    optimizer : string\n+        Optimization method used by the model during compilation/training.\n+    loss : string\n+        Loss function used by the model during compilation/training.\n+    \"\"\"\n+    def __init__(self, model, optimizer='adam', loss='mean_squared_error'):\n+        super(KerasRegressor, self).__init__(model, optimizer, loss)\n+\n+    def predict(self, X, batch_size=128, verbose=0):\n+        \"\"\"\n+        Returns predictions for the given test data.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape = (n_samples, n_features)\n+            Test samples where n_samples in the number of samples\n+            and n_features is the number of features.\n+        batch_size : int, optional\n+            Number of test samples evaluated at a time.\n+        verbose : int, optional\n+            Verbosity level.\n+\n+        Returns\n+        -------\n+        preds : array-like, shape = (n_samples)\n+            Predictions.\n+        \"\"\"\n+        return self.compiled_model_.predict(X, batch_size=batch_size, verbose=verbose)\n+\n+    def score(self, X, y, batch_size=128, verbose=0):\n+        \"\"\"\n+        Returns the mean accuracy on the given test data and labels.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape = (n_samples, n_features)\n+            Test samples where n_samples in the number of samples\n+            and n_features is the number of features.\n+        y : array-like, shape = (n_samples)\n+            True labels for X.\n+        batch_size : int, optional\n+            Number of test samples evaluated at a time.\n+        verbose : int, optional\n+            Verbosity level.\n+\n+        Returns\n+        -------\n+        score : float\n+            Loss from predictions on X wrt. y.\n+        \"\"\"\n+        loss = self.compiled_model_.evaluate(X, y, batch_size=batch_size, show_accuracy=False, verbose=verbose)\n+        return loss\n",
          "files_name_in_blame_commit": [
            "scikit_learn.py"
          ]
        }
      }
    }
  }
}